{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Building Logistic Regression models\n",
    "\n",
    "The simple model built in the proof of concept showed acceptable performances, however an attempt to improve its ability\n",
    "to generalize should be made involving techniques to scale the data and reduce its dimensionality."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Data scaling\n",
    "\n",
    "A step that could help improving the performance of the model might be scaling the data, allowing the algorithm to\n",
    "converge faster.\n",
    "\n",
    "This step is usually important when features vary a lot in magnitudes, units and range. This is not the case as each of\n",
    "them represents the same measure so it could end up being ineffective or even negative.\n",
    "\n",
    "The options available to scale the data are using a MinMax scaler to reduce the values in a given range (the default one\n",
    "is between 0 and 1) and Standard scaler to adjust the data to have a normal distribution."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Dimensionality reduction\n",
    "\n",
    "Another important step could be reducing the number of features onto which the model should be fitted. This step could\n",
    "help avoiding overfitting as the number of features in the dataset is very large in opposition to the fact that\n",
    "Logistic Regression is a fairly simple model.\n",
    "\n",
    "Dimensionality reduction could be achieved with a variety of techniques, PCA above all. An alternative method would be\n",
    "to train a Random Forest Regressor over the train data, cross validate it and have a look at features importance to\n",
    "choose them for the Logistic Regressor."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Hyperparameters tuning\n",
    "\n",
    "The pipeline to apply and the hyperparameters for each step can be chosen applying a grid search approach over the 9\n",
    "possible combinations of scalers/selectors. Logistic regression itself has a variety of hyperparameters to be tuned.\n",
    "\n",
    "The research can be done with the help of GridSearchCV, cross-validating each model trained with every combination of \n",
    "hyperparameters.\n",
    "\n",
    "```python\n",
    "from numpy import logspace\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "steps = []\n",
    "\n",
    "scalers = [None, MinMaxScaler(), StandardScaler()]\n",
    "selectors = [None, PCA(), RandomForestRegressor()]\n",
    "\n",
    "for scaler in scalers:\n",
    "    for selector in selectors:\n",
    "        # Logistic regression hyperparameters\n",
    "        log_reg_param_grid = [\n",
    "                {\n",
    "                    \"classifier__solver\": [\"liblinear\"],\n",
    "                    \"classifier__penalty\": [\"l1\", \"l2\"],\n",
    "                    \"classifier__C\": logspace(-1, 3, 5, endpoint=True),\n",
    "                    \"classifier__random_state\": [RANDOM_STATE],\n",
    "                    \"classifier__max_iter\": [1000],\n",
    "                    \"classifier__n_jobs\": [N_JOBS]\n",
    "                },\n",
    "                {\n",
    "                    \"classifier__solver\": [\"lbfgs\"],\n",
    "                    \"classifier__penalty\": [\"none\", \"l2\"],\n",
    "                    \"classifier__C\": logspace(-1, 3, 5, endpoint=True),\n",
    "                    \"classifier__random_state\": [RANDOM_STATE],\n",
    "                    \"classifier__max_iter\": [1000],\n",
    "                    \"classifier__n_jobs\": [N_JOBS]\n",
    "                }\n",
    "            ]\n",
    "        \n",
    "        if scaler is not None:\n",
    "            steps.append((\"scaler\", scaler))\n",
    "\n",
    "        if type(selector) is PCA:\n",
    "            \n",
    "            # PCA hyperparameters\n",
    "            for param_grid in log_reg_param_grid:\n",
    "                param_grid[\"selector__n_components\"] = [0.95]\n",
    "\n",
    "        elif type(selector) is RandomForestRegressor:\n",
    "    \n",
    "            # Random Forest parameters\n",
    "            for param_grid in log_reg_param_grid:\n",
    "                param_grid[\"selector__estimator__n_estimators\"] = [10, 100, 1000]\n",
    "                param_grid[\"selector__estimator__random_state\"] = [RANDOM_STATE]\n",
    "                param_grid[\"selector__estimator__n_jobs\"] = [N_JOBS]\n",
    "                param_grid[\"selector__threshold\"] = [0.01, 0.025, 0.05]\n",
    "\n",
    "            steps.append((\"selector\", SelectFromModel(selector)))\n",
    "\n",
    "        steps.append((\"classifier\", LogisticRegression()))\n",
    "        pipeline = Pipeline(steps=steps)\n",
    "        classifier = GridSearchCV(pipeline, param_grid=log_reg_param_grid)\n",
    "\n",
    "```\n",
    "\n",
    "This configuration yields over 3 thousands of combinations to be explored and the whole logic such as model fitting and\n",
    "dumping has been all gathered in a single function."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from src.modeling import model_builder\n",
    "\n",
    "model_builder.build_log_reg_models()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Models are stored in [models](/models) directory as .joblib files that can be used to generate predictions over the test set to\n",
    "actually estimate their ability to generalize."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}