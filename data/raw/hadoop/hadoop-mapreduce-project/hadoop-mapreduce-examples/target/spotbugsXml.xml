
<BugCollection sequence='0' release='' analysisTimestamp='1568197733952' version='3.1.12' timestamp='1568191472000'><Project projectName='Apache Hadoop MapReduce Examples'><Jar>./hadoop/hadoop-mapreduce-project/hadoop-mapreduce-examples/target/classes</Jar><AuxClasspathEntry>.m2/repository/commons-cli/commons-cli/1.2/commons-cli-1.2.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/commons-logging/commons-logging/1.1.3/commons-logging-1.1.3.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-jobclient/3.1.1/hadoop-mapreduce-client-jobclient-3.1.1.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-common/3.1.1/hadoop-mapreduce-client-common-3.1.1.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/org/apache/hadoop/hadoop-yarn-client/3.1.1/hadoop-yarn-client-3.1.1.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-core/3.1.1/hadoop-mapreduce-client-core-3.1.1.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/org/apache/avro/avro/1.7.7/avro-1.7.7.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/org/codehaus/jackson/jackson-core-asl/1.9.13/jackson-core-asl-1.9.13.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/com/thoughtworks/paranamer/paranamer/2.3/paranamer-2.3.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/org/xerial/snappy/snappy-java/1.0.5/snappy-java-1.0.5.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/org/slf4j/slf4j-log4j12/1.7.25/slf4j-log4j12-1.7.25.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/org/apache/hadoop/hadoop-annotations/3.1.1/hadoop-annotations-3.1.1.jar</AuxClasspathEntry><AuxClasspathEntry>/usr/lib/jvm/java-8-openjdk-amd64/jre/../lib/tools.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/com/google/inject/extensions/guice-servlet/4.0/guice-servlet-4.0.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/com/google/inject/guice/4.0/guice-4.0.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/javax/inject/javax.inject/1/javax.inject-1.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/aopalliance/aopalliance/1.0/aopalliance-1.0.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/io/netty/netty/3.10.5.Final/netty-3.10.5.Final.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/org/apache/hadoop/hadoop-common/3.1.1/hadoop-common-3.1.1.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/org/apache/commons/commons-math3/3.1.1/commons-math3-3.1.1.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/org/apache/httpcomponents/httpclient/4.5.2/httpclient-4.5.2.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/org/apache/httpcomponents/httpcore/4.4.4/httpcore-4.4.4.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/commons-codec/commons-codec/1.11/commons-codec-1.11.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/commons-io/commons-io/2.5/commons-io-2.5.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/commons-net/commons-net/3.6/commons-net-3.6.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/commons-collections/commons-collections/3.2.2/commons-collections-3.2.2.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/javax/servlet/javax.servlet-api/3.1.0/javax.servlet-api-3.1.0.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/org/eclipse/jetty/jetty-server/9.3.19.v20170502/jetty-server-9.3.19.v20170502.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/org/eclipse/jetty/jetty-http/9.3.19.v20170502/jetty-http-9.3.19.v20170502.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/org/eclipse/jetty/jetty-io/9.3.19.v20170502/jetty-io-9.3.19.v20170502.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/org/eclipse/jetty/jetty-util/9.3.19.v20170502/jetty-util-9.3.19.v20170502.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/org/eclipse/jetty/jetty-servlet/9.3.19.v20170502/jetty-servlet-9.3.19.v20170502.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/org/eclipse/jetty/jetty-security/9.3.19.v20170502/jetty-security-9.3.19.v20170502.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/org/eclipse/jetty/jetty-webapp/9.3.19.v20170502/jetty-webapp-9.3.19.v20170502.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/org/eclipse/jetty/jetty-xml/9.3.19.v20170502/jetty-xml-9.3.19.v20170502.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/javax/servlet/jsp/jsp-api/2.1/jsp-api-2.1.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/com/sun/jersey/jersey-core/1.19/jersey-core-1.19.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/javax/ws/rs/jsr311-api/1.1.1/jsr311-api-1.1.1.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/com/sun/jersey/jersey-servlet/1.19/jersey-servlet-1.19.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/com/sun/jersey/jersey-json/1.19/jersey-json-1.19.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/org/codehaus/jettison/jettison/1.1/jettison-1.1.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/com/sun/xml/bind/jaxb-impl/2.2.3-1/jaxb-impl-2.2.3-1.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/org/codehaus/jackson/jackson-jaxrs/1.9.13/jackson-jaxrs-1.9.13.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/org/codehaus/jackson/jackson-xc/1.9.13/jackson-xc-1.9.13.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/com/sun/jersey/jersey-server/1.19/jersey-server-1.19.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/log4j/log4j/1.2.17/log4j-1.2.17.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/commons-lang/commons-lang/2.6/commons-lang-2.6.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/commons-beanutils/commons-beanutils/1.9.3/commons-beanutils-1.9.3.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/org/apache/commons/commons-configuration2/2.1.1/commons-configuration2-2.1.1.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/org/apache/commons/commons-lang3/3.4/commons-lang3-3.4.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/com/google/re2j/re2j/1.1/re2j-1.1.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/com/google/code/gson/gson/2.2.4/gson-2.2.4.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/org/apache/hadoop/hadoop-auth/3.1.1/hadoop-auth-3.1.1.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/com/nimbusds/nimbus-jose-jwt/4.41.1/nimbus-jose-jwt-4.41.1.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/com/github/stephenc/jcip/jcip-annotations/1.0-1/jcip-annotations-1.0-1.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/net/minidev/json-smart/2.3/json-smart-2.3.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/net/minidev/accessors-smart/1.2/accessors-smart-1.2.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/org/ow2/asm/asm/5.0.4/asm-5.0.4.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/org/apache/curator/curator-framework/2.12.0/curator-framework-2.12.0.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/com/jcraft/jsch/0.1.54/jsch-0.1.54.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/org/apache/curator/curator-client/2.12.0/curator-client-2.12.0.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/org/apache/curator/curator-recipes/2.12.0/curator-recipes-2.12.0.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/com/google/code/findbugs/jsr305/3.0.0/jsr305-3.0.0.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/org/apache/htrace/htrace-core4/4.1.0-incubating/htrace-core4-4.1.0-incubating.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/org/apache/zookeeper/zookeeper/3.4.9/zookeeper-3.4.9.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/org/apache/commons/commons-compress/1.4.1/commons-compress-1.4.1.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/org/tukaani/xz/1.0/xz-1.0.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/org/apache/kerby/kerb-simplekdc/1.0.1/kerb-simplekdc-1.0.1.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/org/apache/kerby/kerb-client/1.0.1/kerb-client-1.0.1.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/org/apache/kerby/kerby-config/1.0.1/kerby-config-1.0.1.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/org/apache/kerby/kerb-core/1.0.1/kerb-core-1.0.1.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/org/apache/kerby/kerby-pkix/1.0.1/kerby-pkix-1.0.1.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/org/apache/kerby/kerby-asn1/1.0.1/kerby-asn1-1.0.1.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/org/apache/kerby/kerby-util/1.0.1/kerby-util-1.0.1.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/org/apache/kerby/kerb-common/1.0.1/kerb-common-1.0.1.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/org/apache/kerby/kerb-crypto/1.0.1/kerb-crypto-1.0.1.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/org/apache/kerby/kerb-util/1.0.1/kerb-util-1.0.1.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/org/apache/kerby/token-provider/1.0.1/token-provider-1.0.1.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/org/apache/kerby/kerb-admin/1.0.1/kerb-admin-1.0.1.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/org/apache/kerby/kerb-server/1.0.1/kerb-server-1.0.1.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/org/apache/kerby/kerb-identity/1.0.1/kerb-identity-1.0.1.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/org/apache/kerby/kerby-xdr/1.0.1/kerby-xdr-1.0.1.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/org/codehaus/woodstox/stax2-api/3.1.4/stax2-api-3.1.4.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/com/fasterxml/woodstox/woodstox-core/5.0.3/woodstox-core-5.0.3.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/commons-daemon/commons-daemon/1.0.13/commons-daemon-1.0.13.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/org/fusesource/leveldbjni/leveldbjni-all/1.8/leveldbjni-all-1.8.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/org/apache/hadoop/hadoop-yarn-server-common/3.1.1/hadoop-yarn-server-common-3.1.1.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/org/apache/hadoop/hadoop-yarn-registry/3.1.1/hadoop-yarn-registry-3.1.1.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/dnsjava/dnsjava/2.1.7/dnsjava-2.1.7.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/org/apache/geronimo/specs/geronimo-jcache_1.0_spec/1.0-alpha-1/geronimo-jcache_1.0_spec-1.0-alpha-1.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/org/ehcache/ehcache/3.3.1/ehcache-3.3.1.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/com/zaxxer/HikariCP-java7/2.4.12/HikariCP-java7-2.4.12.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/com/microsoft/sqlserver/mssql-jdbc/6.2.1.jre7/mssql-jdbc-6.2.1.jre7.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/org/apache/hadoop/hadoop-yarn-server-nodemanager/3.1.1/hadoop-yarn-server-nodemanager-3.1.1.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/javax/xml/bind/jaxb-api/2.2.11/jaxb-api-2.2.11.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/com/sun/jersey/jersey-client/1.19/jersey-client-1.19.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/io/dropwizard/metrics/metrics-core/3.2.4/metrics-core-3.2.4.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/com/sun/jersey/contribs/jersey-guice/1.19/jersey-guice-1.19.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/org/apache/hadoop/hadoop-yarn-common/3.1.1/hadoop-yarn-common-3.1.1.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/com/fasterxml/jackson/module/jackson-module-jaxb-annotations/2.7.8/jackson-module-jaxb-annotations-2.7.8.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/com/fasterxml/jackson/jaxrs/jackson-jaxrs-json-provider/2.7.8/jackson-jaxrs-json-provider-2.7.8.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/com/fasterxml/jackson/jaxrs/jackson-jaxrs-base/2.7.8/jackson-jaxrs-base-2.7.8.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/org/apache/hadoop/hadoop-yarn-api/3.1.1/hadoop-yarn-api-3.1.1.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-app/3.1.1/hadoop-mapreduce-client-app-3.1.1.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/org/apache/hadoop/hadoop-yarn-server-web-proxy/3.1.1/hadoop-yarn-server-web-proxy-3.1.1.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-shuffle/3.1.1/hadoop-mapreduce-client-shuffle-3.1.1.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/org/hsqldb/hsqldb/2.3.4/hsqldb-2.3.4.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/com/google/guava/guava/11.0.2/guava-11.0.2.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/org/slf4j/slf4j-api/1.7.25/slf4j-api-1.7.25.jar</AuxClasspathEntry><SrcDir>./hadoop/hadoop-mapreduce-project/hadoop-mapreduce-examples/src/main/java</SrcDir><WrkDir>./hadoop/hadoop-mapreduce-project/hadoop-mapreduce-examples/target</WrkDir></Project><BugInstance instanceOccurrenceNum='0' instanceHash='baa57dfddf18c70d6e3a92904733bd9c' cweid='382' rank='19' abbrev='Dm' category='BAD_PRACTICE' priority='3' type='DM_EXIT' instanceOccurrenceMax='0'><ShortMessage>Method invokes System.exit(...)</ShortMessage><LongMessage>org.apache.hadoop.examples.BaileyBorweinPlouffe.compute(int, int, int, String, Configuration, PrintStream) invokes System.exit(...), which shuts down the entire virtual machine</LongMessage><Class classname='org.apache.hadoop.examples.BaileyBorweinPlouffe' primary='true'><SourceLine classname='org.apache.hadoop.examples.BaileyBorweinPlouffe' start='73' end='646' sourcepath='org/apache/hadoop/examples/BaileyBorweinPlouffe.java' sourcefile='BaileyBorweinPlouffe.java'><Message>At BaileyBorweinPlouffe.java:[lines 73-646]</Message></SourceLine><Message>In class org.apache.hadoop.examples.BaileyBorweinPlouffe</Message></Class><Method isStatic='true' classname='org.apache.hadoop.examples.BaileyBorweinPlouffe' signature='(IIILjava/lang/String;Lorg/apache/hadoop/conf/Configuration;Ljava/io/PrintStream;)V' name='compute' primary='true'><SourceLine endBytecode='903' classname='org.apache.hadoop.examples.BaileyBorweinPlouffe' start='351' end='397' sourcepath='org/apache/hadoop/examples/BaileyBorweinPlouffe.java' sourcefile='BaileyBorweinPlouffe.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.examples.BaileyBorweinPlouffe.compute(int, int, int, String, Configuration, PrintStream)</Message></Method><SourceLine endBytecode='387' classname='org.apache.hadoop.examples.BaileyBorweinPlouffe' start='388' end='388' sourcepath='org/apache/hadoop/examples/BaileyBorweinPlouffe.java' sourcefile='BaileyBorweinPlouffe.java' startBytecode='387' primary='true'><Message>At BaileyBorweinPlouffe.java:[line 388]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='c23b5182ba80620bd91542792b8af1bb' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from org.apache.hadoop.mapreduce.InputSplit to org.apache.hadoop.examples.BaileyBorweinPlouffe$BbpSplit in org.apache.hadoop.examples.BaileyBorweinPlouffe$BbpInputFormat.createRecordReader(InputSplit, TaskAttemptContext)</LongMessage><Class classname='org.apache.hadoop.examples.BaileyBorweinPlouffe$BbpInputFormat' primary='true'><SourceLine classname='org.apache.hadoop.examples.BaileyBorweinPlouffe$BbpInputFormat' start='259' end='288' sourcepath='org/apache/hadoop/examples/BaileyBorweinPlouffe.java' sourcefile='BaileyBorweinPlouffe.java'><Message>At BaileyBorweinPlouffe.java:[lines 259-288]</Message></SourceLine><Message>In class org.apache.hadoop.examples.BaileyBorweinPlouffe$BbpInputFormat</Message></Class><Method isStatic='false' classname='org.apache.hadoop.examples.BaileyBorweinPlouffe$BbpInputFormat' signature='(Lorg/apache/hadoop/mapreduce/InputSplit;Lorg/apache/hadoop/mapreduce/TaskAttemptContext;)Lorg/apache/hadoop/mapreduce/RecordReader;' name='createRecordReader' primary='true'><SourceLine endBytecode='8' classname='org.apache.hadoop.examples.BaileyBorweinPlouffe$BbpInputFormat' start='285' end='288' sourcepath='org/apache/hadoop/examples/BaileyBorweinPlouffe.java' sourcefile='BaileyBorweinPlouffe.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.examples.BaileyBorweinPlouffe$BbpInputFormat.createRecordReader(InputSplit, TaskAttemptContext)</Message></Method><Type role='TYPE_FOUND' descriptor='Lorg/apache/hadoop/mapreduce/InputSplit;'><SourceLine classname='org.apache.hadoop.mapreduce.InputSplit' start='44' end='75' sourcepath='org/apache/hadoop/mapreduce/InputSplit.java' sourcefile='InputSplit.java'><Message>At InputSplit.java:[lines 44-75]</Message></SourceLine><Message>Actual type org.apache.hadoop.mapreduce.InputSplit</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/examples/BaileyBorweinPlouffe$BbpSplit;'><SourceLine classname='org.apache.hadoop.examples.BaileyBorweinPlouffe$BbpSplit' start='211' end='252' sourcepath='org/apache/hadoop/examples/BaileyBorweinPlouffe.java' sourcefile='BaileyBorweinPlouffe.java'><Message>At BaileyBorweinPlouffe.java:[lines 211-252]</Message></SourceLine><Message>Expected org.apache.hadoop.examples.BaileyBorweinPlouffe$BbpSplit</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='0' name='generic' register='1'><Message>Value loaded from generic</Message></LocalVariable><SourceLine endBytecode='1' classname='org.apache.hadoop.examples.BaileyBorweinPlouffe$BbpInputFormat' start='285' end='285' sourcepath='org/apache/hadoop/examples/BaileyBorweinPlouffe.java' sourcefile='BaileyBorweinPlouffe.java' startBytecode='1' primary='true'><Message>At BaileyBorweinPlouffe.java:[line 285]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='bbe48804b56124854990b4be06bf7ed1' rank='20' abbrev='SIC' category='PERFORMANCE' priority='3' type='SIC_INNER_SHOULD_BE_STATIC_ANON' instanceOccurrenceMax='0'><ShortMessage>Could be refactored into a named static inner class</ShortMessage><LongMessage>The class org.apache.hadoop.examples.BaileyBorweinPlouffe$BbpInputFormat$1 could be refactored into a named _static_ inner class</LongMessage><Class role='CLASS_ANONYMOUS' classname='org.apache.hadoop.examples.BaileyBorweinPlouffe$BbpInputFormat$1'><SourceLine classname='org.apache.hadoop.examples.BaileyBorweinPlouffe$BbpInputFormat$1' start='288' end='312' sourcepath='org/apache/hadoop/examples/BaileyBorweinPlouffe.java' sourcefile='BaileyBorweinPlouffe.java'><Message>At BaileyBorweinPlouffe.java:[lines 288-312]</Message></SourceLine><Message>Anonymous class org.apache.hadoop.examples.BaileyBorweinPlouffe$BbpInputFormat$1</Message></Class><Class classname='org.apache.hadoop.examples.BaileyBorweinPlouffe$BbpInputFormat' primary='true'><SourceLine classname='org.apache.hadoop.examples.BaileyBorweinPlouffe$BbpInputFormat' start='259' end='288' sourcepath='org/apache/hadoop/examples/BaileyBorweinPlouffe.java' sourcefile='BaileyBorweinPlouffe.java'><Message>At BaileyBorweinPlouffe.java:[lines 259-288]</Message></SourceLine><Message>In class org.apache.hadoop.examples.BaileyBorweinPlouffe$BbpInputFormat</Message></Class><Method isStatic='false' classname='org.apache.hadoop.examples.BaileyBorweinPlouffe$BbpInputFormat' signature='(Lorg/apache/hadoop/mapreduce/InputSplit;Lorg/apache/hadoop/mapreduce/TaskAttemptContext;)Lorg/apache/hadoop/mapreduce/RecordReader;' name='createRecordReader' primary='true'><SourceLine endBytecode='90' classname='org.apache.hadoop.examples.BaileyBorweinPlouffe$BbpInputFormat' start='285' end='288' sourcepath='org/apache/hadoop/examples/BaileyBorweinPlouffe.java' sourcefile='BaileyBorweinPlouffe.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.examples.BaileyBorweinPlouffe$BbpInputFormat.createRecordReader(InputSplit, TaskAttemptContext)</Message></Method><SourceLine endBytecode='11' classname='org.apache.hadoop.examples.BaileyBorweinPlouffe$BbpInputFormat' start='288' end='288' sourcepath='org/apache/hadoop/examples/BaileyBorweinPlouffe.java' sourcefile='BaileyBorweinPlouffe.java' startBytecode='11' primary='true'><Message>At BaileyBorweinPlouffe.java:[line 288]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='9e5f4142aa9a14f14a7fde81ba9cedc4' rank='20' abbrev='SIC' category='PERFORMANCE' priority='3' type='SIC_INNER_SHOULD_BE_STATIC_ANON' instanceOccurrenceMax='0'><ShortMessage>Could be refactored into a named static inner class</ShortMessage><LongMessage>The class org.apache.hadoop.examples.BaileyBorweinPlouffe$BbpReducer$1 could be refactored into a named _static_ inner class</LongMessage><Class role='CLASS_ANONYMOUS' classname='org.apache.hadoop.examples.BaileyBorweinPlouffe$BbpReducer$1'><SourceLine classname='org.apache.hadoop.examples.BaileyBorweinPlouffe$BbpReducer$1' start='170' end='183' sourcepath='org/apache/hadoop/examples/BaileyBorweinPlouffe.java' sourcefile='BaileyBorweinPlouffe.java'><Message>At BaileyBorweinPlouffe.java:[lines 170-183]</Message></SourceLine><Message>Anonymous class org.apache.hadoop.examples.BaileyBorweinPlouffe$BbpReducer$1</Message></Class><Class classname='org.apache.hadoop.examples.BaileyBorweinPlouffe$BbpReducer' primary='true'><SourceLine classname='org.apache.hadoop.examples.BaileyBorweinPlouffe$BbpReducer' start='114' end='190' sourcepath='org/apache/hadoop/examples/BaileyBorweinPlouffe.java' sourcefile='BaileyBorweinPlouffe.java'><Message>At BaileyBorweinPlouffe.java:[lines 114-190]</Message></SourceLine><Message>In class org.apache.hadoop.examples.BaileyBorweinPlouffe$BbpReducer</Message></Class><Method isStatic='false' classname='org.apache.hadoop.examples.BaileyBorweinPlouffe$BbpReducer' signature='(Lorg/apache/hadoop/mapreduce/Reducer$Context;)V' name='cleanup' primary='true'><SourceLine endBytecode='770' classname='org.apache.hadoop.examples.BaileyBorweinPlouffe$BbpReducer' start='137' end='190' sourcepath='org/apache/hadoop/examples/BaileyBorweinPlouffe.java' sourcefile='BaileyBorweinPlouffe.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.examples.BaileyBorweinPlouffe$BbpReducer.cleanup(Reducer$Context)</Message></Method><SourceLine endBytecode='302' classname='org.apache.hadoop.examples.BaileyBorweinPlouffe$BbpReducer' start='170' end='170' sourcepath='org/apache/hadoop/examples/BaileyBorweinPlouffe.java' sourcefile='BaileyBorweinPlouffe.java' startBytecode='302' primary='true'><Message>At BaileyBorweinPlouffe.java:[line 170]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='96bcdb1c4339dccd268d3a409d466858' rank='19' abbrev='It' category='BAD_PRACTICE' priority='3' type='IT_NO_SUCH_ELEMENT' instanceOccurrenceMax='0'><ShortMessage>Iterator next() method can't throw NoSuchElementException</ShortMessage><LongMessage>org.apache.hadoop.examples.BaileyBorweinPlouffe$BbpReducer$1.next() can't throw NoSuchElementException</LongMessage><Class classname='org.apache.hadoop.examples.BaileyBorweinPlouffe$BbpReducer$1' primary='true'><SourceLine classname='org.apache.hadoop.examples.BaileyBorweinPlouffe$BbpReducer$1' start='170' end='183' sourcepath='org/apache/hadoop/examples/BaileyBorweinPlouffe.java' sourcefile='BaileyBorweinPlouffe.java'><Message>At BaileyBorweinPlouffe.java:[lines 170-183]</Message></SourceLine><Message>In class org.apache.hadoop.examples.BaileyBorweinPlouffe$BbpReducer$1</Message></Class><Method isStatic='false' classname='org.apache.hadoop.examples.BaileyBorweinPlouffe$BbpReducer$1' signature='()Ljava/lang/Integer;' name='next' primary='true'><SourceLine endBytecode='66' classname='org.apache.hadoop.examples.BaileyBorweinPlouffe$BbpReducer$1' start='178' end='179' sourcepath='org/apache/hadoop/examples/BaileyBorweinPlouffe.java' sourcefile='BaileyBorweinPlouffe.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.examples.BaileyBorweinPlouffe$BbpReducer$1.next()</Message></Method><SourceLine synthetic='true' endBytecode='66' classname='org.apache.hadoop.examples.BaileyBorweinPlouffe$BbpReducer$1' start='178' end='179' sourcepath='org/apache/hadoop/examples/BaileyBorweinPlouffe.java' sourcefile='BaileyBorweinPlouffe.java' startBytecode='0'><Message>At BaileyBorweinPlouffe.java:[lines 178-179]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='9e24ee472cae8d0a291c158afd3c9702' cweid='391' rank='19' abbrev='DE' category='BAD_PRACTICE' priority='3' type='DE_MIGHT_IGNORE' instanceOccurrenceMax='0'><ShortMessage>Method might ignore exception</ShortMessage><LongMessage>org.apache.hadoop.examples.DBCountPageView.dropTables() might ignore java.lang.Exception</LongMessage><Class classname='org.apache.hadoop.examples.DBCountPageView' primary='true'><SourceLine classname='org.apache.hadoop.examples.DBCountPageView' start='78' end='439' sourcepath='org/apache/hadoop/examples/DBCountPageView.java' sourcefile='DBCountPageView.java'><Message>At DBCountPageView.java:[lines 78-439]</Message></SourceLine><Message>In class org.apache.hadoop.examples.DBCountPageView</Message></Class><Method isStatic='false' classname='org.apache.hadoop.examples.DBCountPageView' signature='()V' name='dropTables' primary='true'><SourceLine endBytecode='254' classname='org.apache.hadoop.examples.DBCountPageView' start='148' end='160' sourcepath='org/apache/hadoop/examples/DBCountPageView.java' sourcefile='DBCountPageView.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.examples.DBCountPageView.dropTables()</Message></Method><Class role='CLASS_EXCEPTION' classname='java.lang.Exception'><SourceLine classname='java.lang.Exception' start='54' end='123' sourcepath='java/lang/Exception.java' sourcefile='Exception.java'><Message>At Exception.java:[lines 54-123]</Message></SourceLine><Message>Exception class java.lang.Exception</Message></Class><SourceLine endBytecode='67' classname='org.apache.hadoop.examples.DBCountPageView' start='158' end='158' sourcepath='org/apache/hadoop/examples/DBCountPageView.java' sourcefile='DBCountPageView.java' startBytecode='67' primary='true'><Message>At DBCountPageView.java:[line 158]</Message></SourceLine><SourceLine endBytecode='67' classname='org.apache.hadoop.examples.DBCountPageView' start='158' end='158' sourcepath='org/apache/hadoop/examples/DBCountPageView.java' sourcefile='DBCountPageView.java' startBytecode='67' primary='true'><Message>At DBCountPageView.java:[line 158]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='32861ee8b1dbc9237d99edd5b1a3af3c' rank='20' abbrev='OBL' category='EXPERIMENTAL' priority='2' type='OBL_UNSATISFIED_OBLIGATION' instanceOccurrenceMax='0'><ShortMessage>Method may fail to clean up stream or resource</ShortMessage><LongMessage>org.apache.hadoop.examples.DBCountPageView.verify() may fail to clean up java.sql.ResultSet</LongMessage><Class classname='org.apache.hadoop.examples.DBCountPageView' primary='true'><SourceLine classname='org.apache.hadoop.examples.DBCountPageView' start='78' end='439' sourcepath='org/apache/hadoop/examples/DBCountPageView.java' sourcefile='DBCountPageView.java'><Message>At DBCountPageView.java:[lines 78-439]</Message></SourceLine><Message>In class org.apache.hadoop.examples.DBCountPageView</Message></Class><Method isStatic='false' classname='org.apache.hadoop.examples.DBCountPageView' signature='()Z' name='verify' primary='true'><SourceLine endBytecode='509' classname='org.apache.hadoop.examples.DBCountPageView' start='257' end='280' sourcepath='org/apache/hadoop/examples/DBCountPageView.java' sourcefile='DBCountPageView.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.examples.DBCountPageView.verify()</Message></Method><Class role='CLASS_REFTYPE' classname='java.sql.ResultSet'><SourceLine classname='java.sql.ResultSet' start='4188' end='4289' sourcepath='java/sql/ResultSet.java' sourcefile='ResultSet.java'><Message>At ResultSet.java:[lines 4188-4289]</Message></SourceLine><Message>Reference type java.sql.ResultSet</Message></Class><Int role='INT_OBLIGATIONS_REMAINING' value='1'><Message>1 instances of obligation remaining</Message></Int><SourceLine role='SOURCE_LINE_OBLIGATION_CREATED' endBytecode='23' classname='org.apache.hadoop.examples.DBCountPageView' start='263' end='263' sourcepath='org/apache/hadoop/examples/DBCountPageView.java' sourcefile='DBCountPageView.java' startBytecode='23' primary='true'><Message>Obligation to clean up resource created at DBCountPageView.java:[line 263] is not discharged</Message></SourceLine><SourceLine role='SOURCE_LINE_PATH_CONTINUES' endBytecode='30' classname='org.apache.hadoop.examples.DBCountPageView' start='264' end='264' sourcepath='org/apache/hadoop/examples/DBCountPageView.java' sourcefile='DBCountPageView.java' startBytecode='30'><Message>Path continues at DBCountPageView.java:[line 264]</Message></SourceLine><SourceLine role='SOURCE_LINE_PATH_CONTINUES' endBytecode='38' classname='org.apache.hadoop.examples.DBCountPageView' start='265' end='265' sourcepath='org/apache/hadoop/examples/DBCountPageView.java' sourcefile='DBCountPageView.java' startBytecode='38'><Message>Path continues at DBCountPageView.java:[line 265]</Message></SourceLine><SourceLine role='SOURCE_LINE_PATH_CONTINUES' endBytecode='48' classname='org.apache.hadoop.examples.DBCountPageView' start='267' end='267' sourcepath='org/apache/hadoop/examples/DBCountPageView.java' sourcefile='DBCountPageView.java' startBytecode='48'><Message>Path continues at DBCountPageView.java:[line 267]</Message></SourceLine><SourceLine role='SOURCE_LINE_OBLIGATION_CREATED' endBytecode='50' classname='org.apache.hadoop.examples.DBCountPageView' start='267' end='267' sourcepath='org/apache/hadoop/examples/DBCountPageView.java' sourcefile='DBCountPageView.java' startBytecode='50'><Message>Obligation to clean up resource created at DBCountPageView.java:[line 267] is not discharged</Message></SourceLine><SourceLine role='SOURCE_LINE_PATH_CONTINUES' endBytecode='57' classname='org.apache.hadoop.examples.DBCountPageView' start='268' end='268' sourcepath='org/apache/hadoop/examples/DBCountPageView.java' sourcefile='DBCountPageView.java' startBytecode='57'><Message>Path continues at DBCountPageView.java:[line 268]</Message></SourceLine><SourceLine role='SOURCE_LINE_PATH_CONTINUES' endBytecode='65' classname='org.apache.hadoop.examples.DBCountPageView' start='269' end='269' sourcepath='org/apache/hadoop/examples/DBCountPageView.java' sourcefile='DBCountPageView.java' startBytecode='65'><Message>Path continues at DBCountPageView.java:[line 269]</Message></SourceLine><SourceLine role='SOURCE_LINE_PATH_CONTINUES' endBytecode='75' classname='org.apache.hadoop.examples.DBCountPageView' start='271' end='271' sourcepath='org/apache/hadoop/examples/DBCountPageView.java' sourcefile='DBCountPageView.java' startBytecode='75'><Message>Path continues at DBCountPageView.java:[line 271]</Message></SourceLine><SourceLine role='SOURCE_LINE_PATH_CONTINUES' endBytecode='103' classname='org.apache.hadoop.examples.DBCountPageView' start='272' end='272' sourcepath='org/apache/hadoop/examples/DBCountPageView.java' sourcefile='DBCountPageView.java' startBytecode='103'><Message>Path continues at DBCountPageView.java:[line 272]</Message></SourceLine><SourceLine role='SOURCE_LINE_PATH_CONTINUES' endBytecode='131' classname='org.apache.hadoop.examples.DBCountPageView' start='274' end='274' sourcepath='org/apache/hadoop/examples/DBCountPageView.java' sourcefile='DBCountPageView.java' startBytecode='131'><Message>Path continues at DBCountPageView.java:[line 274]</Message></SourceLine><SourceLine role='SOURCE_LINE_PATH_CONTINUES' endBytecode='153' classname='org.apache.hadoop.examples.DBCountPageView' start='276' end='276' sourcepath='org/apache/hadoop/examples/DBCountPageView.java' sourcefile='DBCountPageView.java' startBytecode='153'><Message>Path continues at DBCountPageView.java:[line 276]</Message></SourceLine><SourceLine role='SOURCE_LINE_PATH_CONTINUES' endBytecode='163' classname='org.apache.hadoop.examples.DBCountPageView' start='278' end='278' sourcepath='org/apache/hadoop/examples/DBCountPageView.java' sourcefile='DBCountPageView.java' startBytecode='163'><Message>Path continues at DBCountPageView.java:[line 278]</Message></SourceLine><SourceLine role='SOURCE_LINE_PATH_CONTINUES' endBytecode='175' classname='org.apache.hadoop.examples.DBCountPageView' start='274' end='274' sourcepath='org/apache/hadoop/examples/DBCountPageView.java' sourcefile='DBCountPageView.java' startBytecode='175'><Message>Path continues at DBCountPageView.java:[line 274]</Message></SourceLine><String role='STRING_REMAINING_OBLIGATIONS' value='{ResultSet x 1}'><Message>Remaining obligations: {ResultSet x 1}</Message></String></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='32d41ed7a40ea8464667f52e3165a14b' cweid='89' rank='15' abbrev='SQL' category='SECURITY' priority='3' type='SQL_NONCONSTANT_STRING_PASSED_TO_EXECUTE' instanceOccurrenceMax='0'><ShortMessage>Nonconstant string passed to execute or addBatch method on an SQL statement</ShortMessage><LongMessage>org.apache.hadoop.examples.DBCountPageView.createTables() passes a nonconstant String to an execute or addBatch method on an SQL statement</LongMessage><Class classname='org.apache.hadoop.examples.DBCountPageView' primary='true'><SourceLine classname='org.apache.hadoop.examples.DBCountPageView' start='78' end='439' sourcepath='org/apache/hadoop/examples/DBCountPageView.java' sourcefile='DBCountPageView.java'><Message>At DBCountPageView.java:[lines 78-439]</Message></SourceLine><Message>In class org.apache.hadoop.examples.DBCountPageView</Message></Class><Method isStatic='false' classname='org.apache.hadoop.examples.DBCountPageView' signature='()V' name='createTables' primary='true'><SourceLine endBytecode='52' classname='org.apache.hadoop.examples.DBCountPageView' start='163' end='188' sourcepath='org/apache/hadoop/examples/DBCountPageView.java' sourcefile='DBCountPageView.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.examples.DBCountPageView.createTables()</Message></Method><SourceLine endBytecode='77' classname='org.apache.hadoop.examples.DBCountPageView' start='182' end='182' sourcepath='org/apache/hadoop/examples/DBCountPageView.java' sourcefile='DBCountPageView.java' startBytecode='77' primary='true'><Message>At DBCountPageView.java:[line 182]</Message></SourceLine><SourceLine role='SOURCE_LINE_ANOTHER_INSTANCE' endBytecode='86' classname='org.apache.hadoop.examples.DBCountPageView' start='183' end='183' sourcepath='org/apache/hadoop/examples/DBCountPageView.java' sourcefile='DBCountPageView.java' startBytecode='86'><Message>Another occurrence at DBCountPageView.java:[line 183]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='c8a48868a2513368ecf66a8c9d0745e0' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from org.apache.hadoop.mapreduce.InputSplit to org.apache.hadoop.mapreduce.lib.input.CombineFileSplit in org.apache.hadoop.examples.MultiFileWordCount$MyInputFormat.createRecordReader(InputSplit, TaskAttemptContext)</LongMessage><Class classname='org.apache.hadoop.examples.MultiFileWordCount$MyInputFormat' primary='true'><SourceLine classname='org.apache.hadoop.examples.MultiFileWordCount$MyInputFormat' start='102' end='107' sourcepath='org/apache/hadoop/examples/MultiFileWordCount.java' sourcefile='MultiFileWordCount.java'><Message>At MultiFileWordCount.java:[lines 102-107]</Message></SourceLine><Message>In class org.apache.hadoop.examples.MultiFileWordCount$MyInputFormat</Message></Class><Method isStatic='false' classname='org.apache.hadoop.examples.MultiFileWordCount$MyInputFormat' signature='(Lorg/apache/hadoop/mapreduce/InputSplit;Lorg/apache/hadoop/mapreduce/TaskAttemptContext;)Lorg/apache/hadoop/mapreduce/RecordReader;' name='createRecordReader' primary='true'><SourceLine endBytecode='7' classname='org.apache.hadoop.examples.MultiFileWordCount$MyInputFormat' start='107' end='107' sourcepath='org/apache/hadoop/examples/MultiFileWordCount.java' sourcefile='MultiFileWordCount.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.examples.MultiFileWordCount$MyInputFormat.createRecordReader(InputSplit, TaskAttemptContext)</Message></Method><Type role='TYPE_FOUND' descriptor='Lorg/apache/hadoop/mapreduce/InputSplit;'><SourceLine classname='org.apache.hadoop.mapreduce.InputSplit' start='44' end='75' sourcepath='org/apache/hadoop/mapreduce/InputSplit.java' sourcefile='InputSplit.java'><Message>At InputSplit.java:[lines 44-75]</Message></SourceLine><Message>Actual type org.apache.hadoop.mapreduce.InputSplit</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/mapreduce/lib/input/CombineFileSplit;'><SourceLine classname='org.apache.hadoop.mapreduce.lib.input.CombineFileSplit' start='59' end='198' sourcepath='org/apache/hadoop/mapreduce/lib/input/CombineFileSplit.java' sourcefile='CombineFileSplit.java'><Message>At CombineFileSplit.java:[lines 59-198]</Message></SourceLine><Message>Expected org.apache.hadoop.mapreduce.lib.input.CombineFileSplit</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='4' name='split' register='1'><Message>Value loaded from split</Message></LocalVariable><SourceLine endBytecode='5' classname='org.apache.hadoop.examples.MultiFileWordCount$MyInputFormat' start='107' end='107' sourcepath='org/apache/hadoop/examples/MultiFileWordCount.java' sourcefile='MultiFileWordCount.java' startBytecode='5' primary='true'><Message>At MultiFileWordCount.java:[line 107]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='7b1f4d78500082789be60c405aef3f0f' rank='20' abbrev='UwF' category='STYLE' priority='3' type='UWF_FIELD_NOT_INITIALIZED_IN_CONSTRUCTOR' instanceOccurrenceMax='0'><ShortMessage>Field not initialized in constructor but dereferenced without null check</ShortMessage><LongMessage>MultiFileWordCount$WordOffset.fileName not initialized in constructor and dereferenced in org.apache.hadoop.examples.MultiFileWordCount$WordOffset.compareTo(Object)</LongMessage><Class classname='org.apache.hadoop.examples.MultiFileWordCount$WordOffset' primary='true'><SourceLine classname='org.apache.hadoop.examples.MultiFileWordCount$WordOffset' start='59' end='92' sourcepath='org/apache/hadoop/examples/MultiFileWordCount.java' sourcefile='MultiFileWordCount.java'><Message>At MultiFileWordCount.java:[lines 59-92]</Message></SourceLine><Message>In class org.apache.hadoop.examples.MultiFileWordCount$WordOffset</Message></Class><Field isStatic='false' classname='org.apache.hadoop.examples.MultiFileWordCount$WordOffset' signature='Ljava/lang/String;' name='fileName' primary='true'><SourceLine classname='org.apache.hadoop.examples.MultiFileWordCount$WordOffset' sourcepath='org/apache/hadoop/examples/MultiFileWordCount.java' sourcefile='MultiFileWordCount.java'><Message>In MultiFileWordCount.java</Message></SourceLine><Message>Field org.apache.hadoop.examples.MultiFileWordCount$WordOffset.fileName</Message></Field><Method isStatic='false' classname='org.apache.hadoop.examples.MultiFileWordCount$WordOffset' signature='(Ljava/lang/Object;)I' name='compareTo' primary='true'><SourceLine endBytecode='140' classname='org.apache.hadoop.examples.MultiFileWordCount$WordOffset' start='75' end='81' sourcepath='org/apache/hadoop/examples/MultiFileWordCount.java' sourcefile='MultiFileWordCount.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.examples.MultiFileWordCount$WordOffset.compareTo(Object)</Message></Method><SourceLine endBytecode='13' classname='org.apache.hadoop.examples.MultiFileWordCount$WordOffset' start='77' end='77' sourcepath='org/apache/hadoop/examples/MultiFileWordCount.java' sourcefile='MultiFileWordCount.java' startBytecode='13' primary='true'><Message>At MultiFileWordCount.java:[line 77]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='b024d3d3e0a91165524f94fae46946b0' cweid='382' rank='19' abbrev='Dm' category='BAD_PRACTICE' priority='3' type='DM_EXIT' instanceOccurrenceMax='0'><ShortMessage>Method invokes System.exit(...)</ShortMessage><LongMessage>org.apache.hadoop.examples.QuasiMonteCarlo.estimatePi(int, long, Path, Configuration) invokes System.exit(...), which shuts down the entire virtual machine</LongMessage><Class classname='org.apache.hadoop.examples.QuasiMonteCarlo' primary='true'><SourceLine classname='org.apache.hadoop.examples.QuasiMonteCarlo' start='78' end='369' sourcepath='org/apache/hadoop/examples/QuasiMonteCarlo.java' sourcefile='QuasiMonteCarlo.java'><Message>At QuasiMonteCarlo.java:[lines 78-369]</Message></SourceLine><Message>In class org.apache.hadoop.examples.QuasiMonteCarlo</Message></Class><Method isStatic='true' classname='org.apache.hadoop.examples.QuasiMonteCarlo' signature='(IJLorg/apache/hadoop/fs/Path;Lorg/apache/hadoop/conf/Configuration;)Ljava/math/BigDecimal;' name='estimatePi' primary='true'><SourceLine endBytecode='1306' classname='org.apache.hadoop.examples.QuasiMonteCarlo' start='252' end='334' sourcepath='org/apache/hadoop/examples/QuasiMonteCarlo.java' sourcefile='QuasiMonteCarlo.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.examples.QuasiMonteCarlo.estimatePi(int, long, Path, Configuration)</Message></Method><SourceLine endBytecode='418' classname='org.apache.hadoop.examples.QuasiMonteCarlo' start='310' end='310' sourcepath='org/apache/hadoop/examples/QuasiMonteCarlo.java' sourcefile='QuasiMonteCarlo.java' startBytecode='418' primary='true'><Message>At QuasiMonteCarlo.java:[line 310]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='3cb0e8d0924ec534d64052d453ab555c' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from org.apache.hadoop.mapreduce.InputSplit to org.apache.hadoop.mapreduce.lib.input.FileSplit in org.apache.hadoop.examples.RandomWriter$RandomInputFormat.createRecordReader(InputSplit, TaskAttemptContext)</LongMessage><Class classname='org.apache.hadoop.examples.RandomWriter$RandomInputFormat' primary='true'><SourceLine classname='org.apache.hadoop.examples.RandomWriter$RandomInputFormat' start='98' end='161' sourcepath='org/apache/hadoop/examples/RandomWriter.java' sourcefile='RandomWriter.java'><Message>At RandomWriter.java:[lines 98-161]</Message></SourceLine><Message>In class org.apache.hadoop.examples.RandomWriter$RandomInputFormat</Message></Class><Method isStatic='false' classname='org.apache.hadoop.examples.RandomWriter$RandomInputFormat' signature='(Lorg/apache/hadoop/mapreduce/InputSplit;Lorg/apache/hadoop/mapreduce/TaskAttemptContext;)Lorg/apache/hadoop/mapreduce/RecordReader;' name='createRecordReader' primary='true'><SourceLine endBytecode='6' classname='org.apache.hadoop.examples.RandomWriter$RandomInputFormat' start='161' end='161' sourcepath='org/apache/hadoop/examples/RandomWriter.java' sourcefile='RandomWriter.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.examples.RandomWriter$RandomInputFormat.createRecordReader(InputSplit, TaskAttemptContext)</Message></Method><Type role='TYPE_FOUND' descriptor='Lorg/apache/hadoop/mapreduce/InputSplit;'><SourceLine classname='org.apache.hadoop.mapreduce.InputSplit' start='44' end='75' sourcepath='org/apache/hadoop/mapreduce/InputSplit.java' sourcefile='InputSplit.java'><Message>At InputSplit.java:[lines 44-75]</Message></SourceLine><Message>Actual type org.apache.hadoop.mapreduce.InputSplit</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/mapreduce/lib/input/FileSplit;'><SourceLine classname='org.apache.hadoop.mapreduce.lib.input.FileSplit' start='48' end='133' sourcepath='org/apache/hadoop/mapreduce/lib/input/FileSplit.java' sourcefile='FileSplit.java'><Message>At FileSplit.java:[lines 48-133]</Message></SourceLine><Message>Expected org.apache.hadoop.mapreduce.lib.input.FileSplit</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='4' name='split' register='1'><Message>Value loaded from split</Message></LocalVariable><SourceLine endBytecode='5' classname='org.apache.hadoop.examples.RandomWriter$RandomInputFormat' start='161' end='161' sourcepath='org/apache/hadoop/examples/RandomWriter.java' sourcefile='RandomWriter.java' startBytecode='5' primary='true'><Message>At RandomWriter.java:[line 161]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='1fab7727f41fc12e98ff1cc6062f12ba' rank='19' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_COMPARATOR_SHOULD_BE_SERIALIZABLE' instanceOccurrenceMax='0'><ShortMessage>Comparator doesn't implement Serializable</ShortMessage><LongMessage>org.apache.hadoop.examples.SecondarySort$FirstGroupingComparator implements Comparator but not Serializable</LongMessage><Class classname='org.apache.hadoop.examples.SecondarySort$FirstGroupingComparator' primary='true'><SourceLine classname='org.apache.hadoop.examples.SecondarySort$FirstGroupingComparator' start='145' end='157' sourcepath='org/apache/hadoop/examples/SecondarySort.java' sourcefile='SecondarySort.java'><Message>At SecondarySort.java:[lines 145-157]</Message></SourceLine><Message>In class org.apache.hadoop.examples.SecondarySort$FirstGroupingComparator</Message></Class><SourceLine synthetic='true' classname='org.apache.hadoop.examples.SecondarySort$FirstGroupingComparator' start='145' end='157' sourcepath='org/apache/hadoop/examples/SecondarySort.java' sourcefile='SecondarySort.java'><Message>At SecondarySort.java:[lines 145-157]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='c8741232a3379fbb1b5ae6d154e7a0d9' rank='19' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_COMPARATOR_SHOULD_BE_SERIALIZABLE' instanceOccurrenceMax='0'><ShortMessage>Comparator doesn't implement Serializable</ShortMessage><LongMessage>org.apache.hadoop.examples.SecondarySort$IntPair$Comparator implements Comparator but not Serializable</LongMessage><Class classname='org.apache.hadoop.examples.SecondarySort$IntPair$Comparator' primary='true'><SourceLine classname='org.apache.hadoop.examples.SecondarySort$IntPair$Comparator' start='105' end='110' sourcepath='org/apache/hadoop/examples/SecondarySort.java' sourcefile='SecondarySort.java'><Message>At SecondarySort.java:[lines 105-110]</Message></SourceLine><Message>In class org.apache.hadoop.examples.SecondarySort$IntPair$Comparator</Message></Class><SourceLine synthetic='true' classname='org.apache.hadoop.examples.SecondarySort$IntPair$Comparator' start='105' end='110' sourcepath='org/apache/hadoop/examples/SecondarySort.java' sourcefile='SecondarySort.java'><Message>At SecondarySort.java:[lines 105-110]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='3dbf122bd456ad76a8bb7095c6c773d4' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from org.apache.hadoop.examples.dancing.DancingLinks$Node&lt;ColumnName&gt; to org.apache.hadoop.examples.dancing.DancingLinks$ColumnHeader in org.apache.hadoop.examples.dancing.DancingLinks.findBestColumn()</LongMessage><Class classname='org.apache.hadoop.examples.dancing.DancingLinks' primary='true'><SourceLine classname='org.apache.hadoop.examples.dancing.DancingLinks' start='38' end='434' sourcepath='org/apache/hadoop/examples/dancing/DancingLinks.java' sourcefile='DancingLinks.java'><Message>At DancingLinks.java:[lines 38-434]</Message></SourceLine><Message>In class org.apache.hadoop.examples.dancing.DancingLinks</Message></Class><Method isStatic='false' classname='org.apache.hadoop.examples.dancing.DancingLinks' signature='()Lorg/apache/hadoop/examples/dancing/DancingLinks$ColumnHeader;' name='findBestColumn' primary='true'><SourceLine endBytecode='28' classname='org.apache.hadoop.examples.dancing.DancingLinks' start='203' end='213' sourcepath='org/apache/hadoop/examples/dancing/DancingLinks.java' sourcefile='DancingLinks.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.examples.dancing.DancingLinks.findBestColumn()</Message></Method><Type role='TYPE_FOUND' descriptor='Lorg/apache/hadoop/examples/dancing/DancingLinks$Node;' typeParameters='&lt;ColumnName&gt;'><SourceLine classname='org.apache.hadoop.examples.dancing.DancingLinks$Node' start='53' end='63' sourcepath='org/apache/hadoop/examples/dancing/DancingLinks.java' sourcefile='DancingLinks.java'><Message>At DancingLinks.java:[lines 53-63]</Message></SourceLine><Message>Actual type org.apache.hadoop.examples.dancing.DancingLinks$Node&lt;ColumnName&gt;</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/examples/dancing/DancingLinks$ColumnHeader;'><SourceLine classname='org.apache.hadoop.examples.dancing.DancingLinks$ColumnHeader' start='76' end='84' sourcepath='org/apache/hadoop/examples/dancing/DancingLinks.java' sourcefile='DancingLinks.java'><Message>At DancingLinks.java:[lines 76-84]</Message></SourceLine><Message>Expected org.apache.hadoop.examples.dancing.DancingLinks$ColumnHeader</Message></Type><Field isStatic='false' role='FIELD_VALUE_OF' classname='org.apache.hadoop.examples.dancing.DancingLinks$Node' signature='Lorg/apache/hadoop/examples/dancing/DancingLinks$Node;' name='right' sourceSignature='Lorg/apache/hadoop/examples/dancing/DancingLinks$Node&lt;TColumnName;&gt;;' primary='true'><SourceLine classname='org.apache.hadoop.examples.dancing.DancingLinks$Node' sourcepath='org/apache/hadoop/examples/dancing/DancingLinks.java' sourcefile='DancingLinks.java'><Message>In DancingLinks.java</Message></SourceLine><Message>Value loaded from field org.apache.hadoop.examples.dancing.DancingLinks$Node.right</Message></Field><SourceLine endBytecode='12' classname='org.apache.hadoop.examples.dancing.DancingLinks' start='205' end='205' sourcepath='org/apache/hadoop/examples/dancing/DancingLinks.java' sourcefile='DancingLinks.java' startBytecode='12' primary='true'><Message>At DancingLinks.java:[line 205]</Message></SourceLine><SourceLine role='SOURCE_LINE_ANOTHER_INSTANCE' endBytecode='43' classname='org.apache.hadoop.examples.dancing.DancingLinks' start='211' end='211' sourcepath='org/apache/hadoop/examples/dancing/DancingLinks.java' sourcefile='DancingLinks.java' startBytecode='43'><Message>Another occurrence at DancingLinks.java:[line 211]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='44d44620b6b0e6d2c5f7687d73687585' cweid='218' rank='18' abbrev='MS' category='MALICIOUS_CODE' priority='2' type='MS_PKGPROTECT' instanceOccurrenceMax='0'><ShortMessage>Field should be package protected</ShortMessage><LongMessage>org.apache.hadoop.examples.dancing.Pentomino.fourRotations should be package protected</LongMessage><Class classname='org.apache.hadoop.examples.dancing.Pentomino' primary='true'><SourceLine classname='org.apache.hadoop.examples.dancing.Pentomino' start='144' end='457' sourcepath='org/apache/hadoop/examples/dancing/Pentomino.java' sourcefile='Pentomino.java'><Message>At Pentomino.java:[lines 144-457]</Message></SourceLine><Message>In class org.apache.hadoop.examples.dancing.Pentomino</Message></Class><Field isStatic='true' classname='org.apache.hadoop.examples.dancing.Pentomino' signature='[I' name='fourRotations' primary='true'><SourceLine classname='org.apache.hadoop.examples.dancing.Pentomino' sourcepath='org/apache/hadoop/examples/dancing/Pentomino.java' sourcefile='Pentomino.java'><Message>In Pentomino.java</Message></SourceLine><Message>Field org.apache.hadoop.examples.dancing.Pentomino.fourRotations</Message></Field><SourceLine endBytecode='43' classname='org.apache.hadoop.examples.dancing.Pentomino' start='273' end='273' sourcepath='org/apache/hadoop/examples/dancing/Pentomino.java' sourcefile='Pentomino.java' startBytecode='43' primary='true'><Message>At Pentomino.java:[line 273]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='f9b51ccf7026ee04bbe07c21c23f9c92' cweid='218' rank='18' abbrev='MS' category='MALICIOUS_CODE' priority='2' type='MS_PKGPROTECT' instanceOccurrenceMax='0'><ShortMessage>Field should be package protected</ShortMessage><LongMessage>org.apache.hadoop.examples.dancing.Pentomino.oneRotation should be package protected</LongMessage><Class classname='org.apache.hadoop.examples.dancing.Pentomino' primary='true'><SourceLine classname='org.apache.hadoop.examples.dancing.Pentomino' start='144' end='457' sourcepath='org/apache/hadoop/examples/dancing/Pentomino.java' sourcefile='Pentomino.java'><Message>At Pentomino.java:[lines 144-457]</Message></SourceLine><Message>In class org.apache.hadoop.examples.dancing.Pentomino</Message></Class><Field isStatic='true' classname='org.apache.hadoop.examples.dancing.Pentomino' signature='[I' name='oneRotation' primary='true'><SourceLine classname='org.apache.hadoop.examples.dancing.Pentomino' sourcepath='org/apache/hadoop/examples/dancing/Pentomino.java' sourcefile='Pentomino.java'><Message>In Pentomino.java</Message></SourceLine><Message>Field org.apache.hadoop.examples.dancing.Pentomino.oneRotation</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.examples.dancing.Pentomino' start='263' end='263' sourcepath='org/apache/hadoop/examples/dancing/Pentomino.java' sourcefile='Pentomino.java' startBytecode='7' primary='true'><Message>At Pentomino.java:[line 263]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='e02b8d18f4330ce31c47c18080c73cdf' cweid='218' rank='18' abbrev='MS' category='MALICIOUS_CODE' priority='2' type='MS_PKGPROTECT' instanceOccurrenceMax='0'><ShortMessage>Field should be package protected</ShortMessage><LongMessage>org.apache.hadoop.examples.dancing.Pentomino.twoRotations should be package protected</LongMessage><Class classname='org.apache.hadoop.examples.dancing.Pentomino' primary='true'><SourceLine classname='org.apache.hadoop.examples.dancing.Pentomino' start='144' end='457' sourcepath='org/apache/hadoop/examples/dancing/Pentomino.java' sourcefile='Pentomino.java'><Message>At Pentomino.java:[lines 144-457]</Message></SourceLine><Message>In class org.apache.hadoop.examples.dancing.Pentomino</Message></Class><Field isStatic='true' classname='org.apache.hadoop.examples.dancing.Pentomino' signature='[I' name='twoRotations' primary='true'><SourceLine classname='org.apache.hadoop.examples.dancing.Pentomino' sourcepath='org/apache/hadoop/examples/dancing/Pentomino.java' sourcefile='Pentomino.java'><Message>In Pentomino.java</Message></SourceLine><Message>Field org.apache.hadoop.examples.dancing.Pentomino.twoRotations</Message></Field><SourceLine endBytecode='21' classname='org.apache.hadoop.examples.dancing.Pentomino' start='268' end='268' sourcepath='org/apache/hadoop/examples/dancing/Pentomino.java' sourcefile='Pentomino.java' startBytecode='21' primary='true'><Message>At Pentomino.java:[line 268]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='bb7dea4917c1fc911400a3823cbbc7b8' cweid='374' rank='18' abbrev='EI2' category='MALICIOUS_CODE' priority='2' type='EI_EXPOSE_REP2' instanceOccurrenceMax='0'><ShortMessage>May expose internal representation by incorporating reference to mutable object</ShortMessage><LongMessage>new org.apache.hadoop.examples.dancing.Pentomino$Piece(String, String, boolean, int[]) may expose internal representation by storing an externally mutable object into Pentomino$Piece.rotations</LongMessage><Class classname='org.apache.hadoop.examples.dancing.Pentomino$Piece' primary='true'><SourceLine classname='org.apache.hadoop.examples.dancing.Pentomino$Piece' start='40' end='116' sourcepath='org/apache/hadoop/examples/dancing/Pentomino.java' sourcefile='Pentomino.java'><Message>At Pentomino.java:[lines 40-116]</Message></SourceLine><Message>In class org.apache.hadoop.examples.dancing.Pentomino$Piece</Message></Class><Method isStatic='false' classname='org.apache.hadoop.examples.dancing.Pentomino$Piece' signature='(Ljava/lang/String;Ljava/lang/String;Z[I)V' name='&lt;init&gt;' primary='true'><SourceLine endBytecode='535' classname='org.apache.hadoop.examples.dancing.Pentomino$Piece' start='47' end='65' sourcepath='org/apache/hadoop/examples/dancing/Pentomino.java' sourcefile='Pentomino.java' startBytecode='0'></SourceLine><Message>In method new org.apache.hadoop.examples.dancing.Pentomino$Piece(String, String, boolean, int[])</Message></Method><Field isStatic='false' classname='org.apache.hadoop.examples.dancing.Pentomino$Piece' signature='[I' name='rotations' primary='true'><SourceLine classname='org.apache.hadoop.examples.dancing.Pentomino$Piece' sourcepath='org/apache/hadoop/examples/dancing/Pentomino.java' sourcefile='Pentomino.java'><Message>In Pentomino.java</Message></SourceLine><Message>Field org.apache.hadoop.examples.dancing.Pentomino$Piece.rotations</Message></Field><LocalVariable role='LOCAL_VARIABLE_NAMED' pc='12' name='rotations' register='4'><Message>Local variable named rotations</Message></LocalVariable><SourceLine endBytecode='12' classname='org.apache.hadoop.examples.dancing.Pentomino$Piece' start='49' end='49' sourcepath='org/apache/hadoop/examples/dancing/Pentomino.java' sourcefile='Pentomino.java' startBytecode='12' primary='true'><Message>At Pentomino.java:[line 49]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='f371df805b4827c5828ebaf7cec653ea' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from org.apache.hadoop.mapreduce.InputSplit to org.apache.hadoop.examples.pi.DistSum$Machine$SummationSplit in org.apache.hadoop.examples.pi.DistSum$Machine$AbstractInputFormat.createRecordReader(InputSplit, TaskAttemptContext)</LongMessage><Class classname='org.apache.hadoop.examples.pi.DistSum$Machine$AbstractInputFormat' primary='true'><SourceLine classname='org.apache.hadoop.examples.pi.DistSum$Machine$AbstractInputFormat' start='207' end='215' sourcepath='org/apache/hadoop/examples/pi/DistSum.java' sourcefile='DistSum.java'><Message>At DistSum.java:[lines 207-215]</Message></SourceLine><Message>In class org.apache.hadoop.examples.pi.DistSum$Machine$AbstractInputFormat</Message></Class><Method isStatic='false' classname='org.apache.hadoop.examples.pi.DistSum$Machine$AbstractInputFormat' signature='(Lorg/apache/hadoop/mapreduce/InputSplit;Lorg/apache/hadoop/mapreduce/TaskAttemptContext;)Lorg/apache/hadoop/mapreduce/RecordReader;' name='createRecordReader' primary='true'><SourceLine endBytecode='8' classname='org.apache.hadoop.examples.pi.DistSum$Machine$AbstractInputFormat' start='212' end='215' sourcepath='org/apache/hadoop/examples/pi/DistSum.java' sourcefile='DistSum.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.examples.pi.DistSum$Machine$AbstractInputFormat.createRecordReader(InputSplit, TaskAttemptContext)</Message></Method><Type role='TYPE_FOUND' descriptor='Lorg/apache/hadoop/mapreduce/InputSplit;'><SourceLine classname='org.apache.hadoop.mapreduce.InputSplit' start='44' end='75' sourcepath='org/apache/hadoop/mapreduce/InputSplit.java' sourcefile='InputSplit.java'><Message>At InputSplit.java:[lines 44-75]</Message></SourceLine><Message>Actual type org.apache.hadoop.mapreduce.InputSplit</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/examples/pi/DistSum$Machine$SummationSplit;'><SourceLine classname='org.apache.hadoop.examples.pi.DistSum$Machine$SummationSplit' start='177' end='203' sourcepath='org/apache/hadoop/examples/pi/DistSum.java' sourcefile='DistSum.java'><Message>At DistSum.java:[lines 177-203]</Message></SourceLine><Message>Expected org.apache.hadoop.examples.pi.DistSum$Machine$SummationSplit</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='0' name='generic' register='1'><Message>Value loaded from generic</Message></LocalVariable><SourceLine endBytecode='1' classname='org.apache.hadoop.examples.pi.DistSum$Machine$AbstractInputFormat' start='212' end='212' sourcepath='org/apache/hadoop/examples/pi/DistSum.java' sourcefile='DistSum.java' startBytecode='1' primary='true'><Message>At DistSum.java:[line 212]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='89c9fceec1dabe62e270775db8731190' rank='20' abbrev='SIC' category='PERFORMANCE' priority='3' type='SIC_INNER_SHOULD_BE_STATIC_ANON' instanceOccurrenceMax='0'><ShortMessage>Could be refactored into a named static inner class</ShortMessage><LongMessage>The class org.apache.hadoop.examples.pi.DistSum$Machine$AbstractInputFormat$1 could be refactored into a named _static_ inner class</LongMessage><Class role='CLASS_ANONYMOUS' classname='org.apache.hadoop.examples.pi.DistSum$Machine$AbstractInputFormat$1'><SourceLine classname='org.apache.hadoop.examples.pi.DistSum$Machine$AbstractInputFormat$1' start='215' end='235' sourcepath='org/apache/hadoop/examples/pi/DistSum.java' sourcefile='DistSum.java'><Message>At DistSum.java:[lines 215-235]</Message></SourceLine><Message>Anonymous class org.apache.hadoop.examples.pi.DistSum$Machine$AbstractInputFormat$1</Message></Class><Class classname='org.apache.hadoop.examples.pi.DistSum$Machine$AbstractInputFormat' primary='true'><SourceLine classname='org.apache.hadoop.examples.pi.DistSum$Machine$AbstractInputFormat' start='207' end='215' sourcepath='org/apache/hadoop/examples/pi/DistSum.java' sourcefile='DistSum.java'><Message>At DistSum.java:[lines 207-215]</Message></SourceLine><Message>In class org.apache.hadoop.examples.pi.DistSum$Machine$AbstractInputFormat</Message></Class><Method isStatic='false' classname='org.apache.hadoop.examples.pi.DistSum$Machine$AbstractInputFormat' signature='(Lorg/apache/hadoop/mapreduce/InputSplit;Lorg/apache/hadoop/mapreduce/TaskAttemptContext;)Lorg/apache/hadoop/mapreduce/RecordReader;' name='createRecordReader' primary='true'><SourceLine endBytecode='90' classname='org.apache.hadoop.examples.pi.DistSum$Machine$AbstractInputFormat' start='212' end='215' sourcepath='org/apache/hadoop/examples/pi/DistSum.java' sourcefile='DistSum.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.examples.pi.DistSum$Machine$AbstractInputFormat.createRecordReader(InputSplit, TaskAttemptContext)</Message></Method><SourceLine endBytecode='11' classname='org.apache.hadoop.examples.pi.DistSum$Machine$AbstractInputFormat' start='215' end='215' sourcepath='org/apache/hadoop/examples/pi/DistSum.java' sourcefile='DistSum.java' startBytecode='11' primary='true'><Message>At DistSum.java:[line 215]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='2c18d9622dc907ce60cdb015a454e3f' cweid='396' rank='20' abbrev='REC' category='STYLE' priority='3' type='REC_CATCH_EXCEPTION' instanceOccurrenceMax='0'><ShortMessage>Exception is caught when Exception is not thrown</ShortMessage><LongMessage>Exception is caught when Exception is not thrown in org.apache.hadoop.examples.pi.Util.runJob(String, Job, DistSum$Machine, String, Util$Timer)</LongMessage><Class classname='org.apache.hadoop.examples.pi.Util' primary='true'><SourceLine classname='org.apache.hadoop.examples.pi.Util' start='53' end='332' sourcepath='org/apache/hadoop/examples/pi/Util.java' sourcefile='Util.java'><Message>At Util.java:[lines 53-332]</Message></SourceLine><Message>In class org.apache.hadoop.examples.pi.Util</Message></Class><Method isStatic='true' classname='org.apache.hadoop.examples.pi.Util' signature='(Ljava/lang/String;Lorg/apache/hadoop/mapreduce/Job;Lorg/apache/hadoop/examples/pi/DistSum$Machine;Ljava/lang/String;Lorg/apache/hadoop/examples/pi/Util$Timer;)V' name='runJob' primary='true'><SourceLine endBytecode='667' classname='org.apache.hadoop.examples.pi.Util' start='258' end='286' sourcepath='org/apache/hadoop/examples/pi/Util.java' sourcefile='Util.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.examples.pi.Util.runJob(String, Job, DistSum$Machine, String, Util$Timer)</Message></Method><SourceLine endBytecode='229' classname='org.apache.hadoop.examples.pi.Util' start='280' end='280' sourcepath='org/apache/hadoop/examples/pi/Util.java' sourcefile='Util.java' startBytecode='229' primary='true'><Message>At Util.java:[line 280]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='fa4f3389cc3973ef4a7161db78af8259' cweid='382' rank='19' abbrev='Dm' category='BAD_PRACTICE' priority='3' type='DM_EXIT' instanceOccurrenceMax='0'><ShortMessage>Method invokes System.exit(...)</ShortMessage><LongMessage>org.apache.hadoop.examples.terasort.GenSort.usage() invokes System.exit(...), which shuts down the entire virtual machine</LongMessage><Class classname='org.apache.hadoop.examples.terasort.GenSort' primary='true'><SourceLine classname='org.apache.hadoop.examples.terasort.GenSort' start='33' end='249' sourcepath='org/apache/hadoop/examples/terasort/GenSort.java' sourcefile='GenSort.java'><Message>At GenSort.java:[lines 33-249]</Message></SourceLine><Message>In class org.apache.hadoop.examples.terasort.GenSort</Message></Class><Method isStatic='true' classname='org.apache.hadoop.examples.terasort.GenSort' signature='()V' name='usage' primary='true'><SourceLine endBytecode='238' classname='org.apache.hadoop.examples.terasort.GenSort' start='151' end='171' sourcepath='org/apache/hadoop/examples/terasort/GenSort.java' sourcefile='GenSort.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.examples.terasort.GenSort.usage()</Message></Method><SourceLine endBytecode='113' classname='org.apache.hadoop.examples.terasort.GenSort' start='170' end='170' sourcepath='org/apache/hadoop/examples/terasort/GenSort.java' sourcefile='GenSort.java' startBytecode='113' primary='true'><Message>At GenSort.java:[line 170]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='a44674eb5e87285f3f93bdaa3ef87ab7' rank='19' abbrev='OS' category='BAD_PRACTICE' priority='3' type='OS_OPEN_STREAM_EXCEPTION_PATH' instanceOccurrenceMax='0'><ShortMessage>Method may fail to close stream on exception</ShortMessage><LongMessage>org.apache.hadoop.examples.terasort.GenSort.main(String[]) may fail to close stream on exception</LongMessage><Class classname='org.apache.hadoop.examples.terasort.GenSort' primary='true'><SourceLine classname='org.apache.hadoop.examples.terasort.GenSort' start='33' end='249' sourcepath='org/apache/hadoop/examples/terasort/GenSort.java' sourcefile='GenSort.java'><Message>At GenSort.java:[lines 33-249]</Message></SourceLine><Message>In class org.apache.hadoop.examples.terasort.GenSort</Message></Class><Method isStatic='true' classname='org.apache.hadoop.examples.terasort.GenSort' signature='([Ljava/lang/String;)V' name='main' primary='true'><SourceLine endBytecode='88' classname='org.apache.hadoop.examples.terasort.GenSort' start='207' end='249' sourcepath='org/apache/hadoop/examples/terasort/GenSort.java' sourcefile='GenSort.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.examples.terasort.GenSort.main(String[])</Message></Method><Type role='TYPE_CLOSEIT' descriptor='Ljava/io/OutputStream;'><SourceLine classname='java.io.OutputStream' start='46' end='152' sourcepath='java/io/OutputStream.java' sourcefile='OutputStream.java'><Message>At OutputStream.java:[lines 46-152]</Message></SourceLine><Message>Need to close java.io.OutputStream </Message></Type><SourceLine endBytecode='156' classname='org.apache.hadoop.examples.terasort.GenSort' start='242' end='242' sourcepath='org/apache/hadoop/examples/terasort/GenSort.java' sourcefile='GenSort.java' startBytecode='156' primary='true'><Message>At GenSort.java:[line 242]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='eeeeeb5fed49f5c73920bec32b78a389' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from org.apache.hadoop.mapreduce.InputSplit to org.apache.hadoop.examples.terasort.TeraGen$RangeInputFormat$RangeInputSplit in org.apache.hadoop.examples.terasort.TeraGen$RangeInputFormat$RangeRecordReader.initialize(InputSplit, TaskAttemptContext)</LongMessage><Class classname='org.apache.hadoop.examples.terasort.TeraGen$RangeInputFormat$RangeRecordReader' primary='true'><SourceLine classname='org.apache.hadoop.examples.terasort.TeraGen$RangeInputFormat$RangeRecordReader' start='115' end='157' sourcepath='org/apache/hadoop/examples/terasort/TeraGen.java' sourcefile='TeraGen.java'><Message>At TeraGen.java:[lines 115-157]</Message></SourceLine><Message>In class org.apache.hadoop.examples.terasort.TeraGen$RangeInputFormat$RangeRecordReader</Message></Class><Method isStatic='false' classname='org.apache.hadoop.examples.terasort.TeraGen$RangeInputFormat$RangeRecordReader' signature='(Lorg/apache/hadoop/mapreduce/InputSplit;Lorg/apache/hadoop/mapreduce/TaskAttemptContext;)V' name='initialize' primary='true'><SourceLine endBytecode='13' classname='org.apache.hadoop.examples.terasort.TeraGen$RangeInputFormat$RangeRecordReader' start='127' end='130' sourcepath='org/apache/hadoop/examples/terasort/TeraGen.java' sourcefile='TeraGen.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.examples.terasort.TeraGen$RangeInputFormat$RangeRecordReader.initialize(InputSplit, TaskAttemptContext)</Message></Method><Type role='TYPE_FOUND' descriptor='Lorg/apache/hadoop/mapreduce/InputSplit;'><SourceLine classname='org.apache.hadoop.mapreduce.InputSplit' start='44' end='75' sourcepath='org/apache/hadoop/mapreduce/InputSplit.java' sourcefile='InputSplit.java'><Message>At InputSplit.java:[lines 44-75]</Message></SourceLine><Message>Actual type org.apache.hadoop.mapreduce.InputSplit</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/examples/terasort/TeraGen$RangeInputFormat$RangeInputSplit;'><SourceLine classname='org.apache.hadoop.examples.terasort.TeraGen$RangeInputFormat$RangeInputSplit' start='86' end='109' sourcepath='org/apache/hadoop/examples/terasort/TeraGen.java' sourcefile='TeraGen.java'><Message>At TeraGen.java:[lines 86-109]</Message></SourceLine><Message>Expected org.apache.hadoop.examples.terasort.TeraGen$RangeInputFormat$RangeInputSplit</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='1' name='split' register='1'><Message>Value loaded from split</Message></LocalVariable><SourceLine endBytecode='2' classname='org.apache.hadoop.examples.terasort.TeraGen$RangeInputFormat$RangeRecordReader' start='127' end='127' sourcepath='org/apache/hadoop/examples/terasort/TeraGen.java' sourcefile='TeraGen.java' startBytecode='2' primary='true'><Message>At TeraGen.java:[line 127]</Message></SourceLine><SourceLine role='SOURCE_LINE_ANOTHER_INSTANCE' endBytecode='18' classname='org.apache.hadoop.examples.terasort.TeraGen$RangeInputFormat$RangeRecordReader' start='129' end='129' sourcepath='org/apache/hadoop/examples/terasort/TeraGen.java' sourcefile='TeraGen.java' startBytecode='18'><Message>Another occurrence at TeraGen.java:[line 129]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='e6e3217afbd1f4198023b0ece35a7aad' rank='15' abbrev='ST' category='STYLE' priority='1' type='ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD' instanceOccurrenceMax='0'><ShortMessage>Write to static field from instance method</ShortMessage><LongMessage>Write to static field org.apache.hadoop.examples.terasort.TeraInputFormat.lastResult from instance method org.apache.hadoop.examples.terasort.TeraInputFormat.getSplits(JobContext)</LongMessage><Class classname='org.apache.hadoop.examples.terasort.TeraInputFormat' primary='true'><SourceLine classname='org.apache.hadoop.examples.terasort.TeraInputFormat' start='50' end='306' sourcepath='org/apache/hadoop/examples/terasort/TeraInputFormat.java' sourcefile='TeraInputFormat.java'><Message>At TeraInputFormat.java:[lines 50-306]</Message></SourceLine><Message>In class org.apache.hadoop.examples.terasort.TeraInputFormat</Message></Class><Method isStatic='false' classname='org.apache.hadoop.examples.terasort.TeraInputFormat' signature='(Lorg/apache/hadoop/mapreduce/JobContext;)Ljava/util/List;' name='getSplits' primary='true'><SourceLine endBytecode='322' classname='org.apache.hadoop.examples.terasort.TeraInputFormat' start='289' end='306' sourcepath='org/apache/hadoop/examples/terasort/TeraInputFormat.java' sourcefile='TeraInputFormat.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.examples.terasort.TeraInputFormat.getSplits(JobContext)</Message></Method><Field isStatic='true' classname='org.apache.hadoop.examples.terasort.TeraInputFormat' signature='Ljava/util/List;' name='lastResult' primary='true'><SourceLine classname='org.apache.hadoop.examples.terasort.TeraInputFormat' sourcepath='org/apache/hadoop/examples/terasort/TeraInputFormat.java' sourcefile='TeraInputFormat.java'><Message>In TeraInputFormat.java</Message></SourceLine><Message>Field org.apache.hadoop.examples.terasort.TeraInputFormat.lastResult</Message></Field><SourceLine endBytecode='119' classname='org.apache.hadoop.examples.terasort.TeraInputFormat' start='302' end='302' sourcepath='org/apache/hadoop/examples/terasort/TeraInputFormat.java' sourcefile='TeraInputFormat.java' startBytecode='119' primary='true'><Message>At TeraInputFormat.java:[line 302]</Message></SourceLine><SourceLine role='SOURCE_LINE_ANOTHER_INSTANCE' endBytecode='24' classname='org.apache.hadoop.examples.terasort.TeraInputFormat' start='295' end='295' sourcepath='org/apache/hadoop/examples/terasort/TeraInputFormat.java' sourcefile='TeraInputFormat.java' startBytecode='24'><Message>Another occurrence at TeraInputFormat.java:[line 295]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='124dcdda39f88af11ce4facabf03f7ca' rank='17' abbrev='ST' category='STYLE' priority='2' type='ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD' instanceOccurrenceMax='0'><ShortMessage>Write to static field from instance method</ShortMessage><LongMessage>Write to static field org.apache.hadoop.examples.terasort.TeraInputFormat.lastContext from instance method org.apache.hadoop.examples.terasort.TeraInputFormat.getSplits(JobContext)</LongMessage><Class classname='org.apache.hadoop.examples.terasort.TeraInputFormat' primary='true'><SourceLine classname='org.apache.hadoop.examples.terasort.TeraInputFormat' start='50' end='306' sourcepath='org/apache/hadoop/examples/terasort/TeraInputFormat.java' sourcefile='TeraInputFormat.java'><Message>At TeraInputFormat.java:[lines 50-306]</Message></SourceLine><Message>In class org.apache.hadoop.examples.terasort.TeraInputFormat</Message></Class><Method isStatic='false' classname='org.apache.hadoop.examples.terasort.TeraInputFormat' signature='(Lorg/apache/hadoop/mapreduce/JobContext;)Ljava/util/List;' name='getSplits' primary='true'><SourceLine endBytecode='322' classname='org.apache.hadoop.examples.terasort.TeraInputFormat' start='289' end='306' sourcepath='org/apache/hadoop/examples/terasort/TeraInputFormat.java' sourcefile='TeraInputFormat.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.examples.terasort.TeraInputFormat.getSplits(JobContext)</Message></Method><Field isStatic='true' classname='org.apache.hadoop.examples.terasort.TeraInputFormat' signature='Lorg/apache/hadoop/mapreduce/MRJobConfig;' name='lastContext' primary='true'><SourceLine classname='org.apache.hadoop.examples.terasort.TeraInputFormat' sourcepath='org/apache/hadoop/examples/terasort/TeraInputFormat.java' sourcefile='TeraInputFormat.java'><Message>In TeraInputFormat.java</Message></SourceLine><Message>Field org.apache.hadoop.examples.terasort.TeraInputFormat.lastContext</Message></Field><SourceLine endBytecode='16' classname='org.apache.hadoop.examples.terasort.TeraInputFormat' start='294' end='294' sourcepath='org/apache/hadoop/examples/terasort/TeraInputFormat.java' sourcefile='TeraInputFormat.java' startBytecode='16' primary='true'><Message>At TeraInputFormat.java:[line 294]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='5d21129d421c22e6b83c85713027a54' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from org.apache.hadoop.mapreduce.InputSplit to org.apache.hadoop.mapreduce.lib.input.FileSplit in org.apache.hadoop.examples.terasort.TeraInputFormat$TeraRecordReader.initialize(InputSplit, TaskAttemptContext)</LongMessage><Class classname='org.apache.hadoop.examples.terasort.TeraInputFormat$TeraRecordReader' primary='true'><SourceLine classname='org.apache.hadoop.examples.terasort.TeraInputFormat$TeraRecordReader' start='211' end='276' sourcepath='org/apache/hadoop/examples/terasort/TeraInputFormat.java' sourcefile='TeraInputFormat.java'><Message>At TeraInputFormat.java:[lines 211-276]</Message></SourceLine><Message>In class org.apache.hadoop.examples.terasort.TeraInputFormat$TeraRecordReader</Message></Class><Method isStatic='false' classname='org.apache.hadoop.examples.terasort.TeraInputFormat$TeraRecordReader' signature='(Lorg/apache/hadoop/mapreduce/InputSplit;Lorg/apache/hadoop/mapreduce/TaskAttemptContext;)V' name='initialize' primary='true'><SourceLine endBytecode='39' classname='org.apache.hadoop.examples.terasort.TeraInputFormat$TeraRecordReader' start='225' end='233' sourcepath='org/apache/hadoop/examples/terasort/TeraInputFormat.java' sourcefile='TeraInputFormat.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.examples.terasort.TeraInputFormat$TeraRecordReader.initialize(InputSplit, TaskAttemptContext)</Message></Method><Type role='TYPE_FOUND' descriptor='Lorg/apache/hadoop/mapreduce/InputSplit;'><SourceLine classname='org.apache.hadoop.mapreduce.InputSplit' start='44' end='75' sourcepath='org/apache/hadoop/mapreduce/InputSplit.java' sourcefile='InputSplit.java'><Message>At InputSplit.java:[lines 44-75]</Message></SourceLine><Message>Actual type org.apache.hadoop.mapreduce.InputSplit</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/mapreduce/lib/input/FileSplit;'><SourceLine classname='org.apache.hadoop.mapreduce.lib.input.FileSplit' start='48' end='133' sourcepath='org/apache/hadoop/mapreduce/lib/input/FileSplit.java' sourcefile='FileSplit.java'><Message>At FileSplit.java:[lines 48-133]</Message></SourceLine><Message>Expected org.apache.hadoop.mapreduce.lib.input.FileSplit</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='0' name='split' register='1'><Message>Value loaded from split</Message></LocalVariable><SourceLine endBytecode='1' classname='org.apache.hadoop.examples.terasort.TeraInputFormat$TeraRecordReader' start='225' end='225' sourcepath='org/apache/hadoop/examples/terasort/TeraInputFormat.java' sourcefile='TeraInputFormat.java' startBytecode='1' primary='true'><Message>At TeraInputFormat.java:[line 225]</Message></SourceLine><SourceLine role='SOURCE_LINE_ANOTHER_INSTANCE' endBytecode='31' classname='org.apache.hadoop.examples.terasort.TeraInputFormat$TeraRecordReader' start='228' end='228' sourcepath='org/apache/hadoop/examples/terasort/TeraInputFormat.java' sourcefile='TeraInputFormat.java' startBytecode='31'><Message>Another occurrence at TeraInputFormat.java:[line 228]</Message></SourceLine><SourceLine role='SOURCE_LINE_ANOTHER_INSTANCE' endBytecode='73' classname='org.apache.hadoop.examples.terasort.TeraInputFormat$TeraRecordReader' start='232' end='232' sourcepath='org/apache/hadoop/examples/terasort/TeraInputFormat.java' sourcefile='TeraInputFormat.java' startBytecode='73'><Message>Another occurrence at TeraInputFormat.java:[line 232]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='b19a75ad79da3bd5a37ae2d9b4fea89f' rank='17' abbrev='BSHIFT' category='STYLE' priority='2' type='ICAST_QUESTIONABLE_UNSIGNED_RIGHT_SHIFT' instanceOccurrenceMax='0'><ShortMessage>Unsigned right shift cast to short/byte</ShortMessage><LongMessage>Unsigned right shift cast to short/byte in org.apache.hadoop.examples.terasort.Unsigned16.getHexDigit(int)</LongMessage><Class classname='org.apache.hadoop.examples.terasort.Unsigned16' primary='true'><SourceLine classname='org.apache.hadoop.examples.terasort.Unsigned16' start='35' end='294' sourcepath='org/apache/hadoop/examples/terasort/Unsigned16.java' sourcefile='Unsigned16.java'><Message>At Unsigned16.java:[lines 35-294]</Message></SourceLine><Message>In class org.apache.hadoop.examples.terasort.Unsigned16</Message></Class><Method isStatic='false' classname='org.apache.hadoop.examples.terasort.Unsigned16' signature='(I)C' name='getHexDigit' primary='true'><SourceLine endBytecode='144' classname='org.apache.hadoop.examples.terasort.Unsigned16' start='179' end='187' sourcepath='org/apache/hadoop/examples/terasort/Unsigned16.java' sourcefile='Unsigned16.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.examples.terasort.Unsigned16.getHexDigit(int)</Message></Method><SourceLine endBytecode='17' classname='org.apache.hadoop.examples.terasort.Unsigned16' start='181' end='181' sourcepath='org/apache/hadoop/examples/terasort/Unsigned16.java' sourcefile='Unsigned16.java' startBytecode='17' primary='true'><Message>At Unsigned16.java:[line 181]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='b698484fce20d9b02a17112292e1f110' rank='20' abbrev='NS' category='STYLE' priority='3' type='NS_NON_SHORT_CIRCUIT' instanceOccurrenceMax='0'><ShortMessage>Questionable use of non-short-circuit logic</ShortMessage><LongMessage>Questionable use of non-short-circuit logic in org.apache.hadoop.examples.terasort.Unsigned16.add(Unsigned16)</LongMessage><Class classname='org.apache.hadoop.examples.terasort.Unsigned16' primary='true'><SourceLine classname='org.apache.hadoop.examples.terasort.Unsigned16' start='35' end='294' sourcepath='org/apache/hadoop/examples/terasort/Unsigned16.java' sourcefile='Unsigned16.java'><Message>At Unsigned16.java:[lines 35-294]</Message></SourceLine><Message>In class org.apache.hadoop.examples.terasort.Unsigned16</Message></Class><Method isStatic='false' classname='org.apache.hadoop.examples.terasort.Unsigned16' signature='(Lorg/apache/hadoop/examples/terasort/Unsigned16;)V' name='add' primary='true'><SourceLine endBytecode='294' classname='org.apache.hadoop.examples.terasort.Unsigned16' start='251' end='261' sourcepath='org/apache/hadoop/examples/terasort/Unsigned16.java' sourcefile='Unsigned16.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.examples.terasort.Unsigned16.add(Unsigned16)</Message></Method><SourceLine endBytecode='87' classname='org.apache.hadoop.examples.terasort.Unsigned16' start='257' end='257' sourcepath='org/apache/hadoop/examples/terasort/Unsigned16.java' sourcefile='Unsigned16.java' startBytecode='87' primary='true'><Message>At Unsigned16.java:[line 257]</Message></SourceLine></BugInstance><BugCategory category='BAD_PRACTICE'><Description>Bad practice</Description></BugCategory><BugCategory category='MALICIOUS_CODE'><Description>Malicious code vulnerability</Description></BugCategory><BugCategory category='PERFORMANCE'><Description>Performance</Description></BugCategory><BugCategory category='STYLE'><Description>Dodgy code</Description></BugCategory><BugCategory category='SECURITY'><Description>Security</Description></BugCategory><BugCategory category='EXPERIMENTAL'><Description>Experimental</Description></BugCategory><BugPattern abbrev='UwF' category='STYLE' type='UWF_FIELD_NOT_INITIALIZED_IN_CONSTRUCTOR'><ShortDescription>Field not initialized in constructor but dereferenced without null check</ShortDescription><Details>

  &lt;p&gt; This field is never initialized within any constructor, and is therefore could be null after
the object is constructed. Elsewhere, it is loaded and dereferenced without a null check.
This could be a either an error or a questionable design, since
it means a null pointer exception will be generated if that field is dereferenced
before being initialized.
&lt;/p&gt;

    </Details></BugPattern><BugPattern cweid='374' abbrev='EI2' category='MALICIOUS_CODE' type='EI_EXPOSE_REP2'><ShortDescription>May expose internal representation by incorporating reference to mutable object</ShortDescription><Details>

  &lt;p&gt; This code stores a reference to an externally mutable object into the
  internal representation of the object.&amp;nbsp;
   If instances
   are accessed by untrusted code, and unchecked changes to
   the mutable object would compromise security or other
   important properties, you will need to do something different.
  Storing a copy of the object is better approach in many situations.&lt;/p&gt;

    </Details></BugPattern><BugPattern abbrev='BSHIFT' category='STYLE' type='ICAST_QUESTIONABLE_UNSIGNED_RIGHT_SHIFT'><ShortDescription>Unsigned right shift cast to short/byte</ShortDescription><Details>

&lt;p&gt;
The code performs an unsigned right shift, whose result is then
cast to a short or byte, which discards the upper bits of the result.
Since the upper bits are discarded, there may be no difference between
a signed and unsigned right shift (depending upon the size of the shift).
&lt;/p&gt;

    </Details></BugPattern><BugPattern abbrev='BC' category='STYLE' type='BC_UNCONFIRMED_CAST'><ShortDescription>Unchecked/unconfirmed cast</ShortDescription><Details>

&lt;p&gt;
This cast is unchecked, and not all instances of the type casted from can be cast to
the type it is being cast to. Check that your program logic ensures that this
cast will not fail.
&lt;/p&gt;

    </Details></BugPattern><BugPattern cweid='396' abbrev='REC' category='STYLE' type='REC_CATCH_EXCEPTION'><ShortDescription>Exception is caught when Exception is not thrown</ShortDescription><Details>
  
  &lt;p&gt;
  This method uses a try-catch block that catches Exception objects, but Exception is not
  thrown within the try block, and RuntimeException is not explicitly caught.  It is a common bug pattern to
  say try { ... } catch (Exception e) { something } as a shorthand for catching a number of types of exception
  each of whose catch blocks is identical, but this construct also accidentally catches RuntimeException as well,
  masking potential bugs.
  &lt;/p&gt;
  &lt;p&gt;A better approach is to either explicitly catch the specific exceptions that are thrown,
  or to explicitly catch RuntimeException exception, rethrow it, and then catch all non-Runtime Exceptions, as shown below:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;try {
    ...
} catch (RuntimeException e) {
    throw e;
} catch (Exception e) {
    ... deal with all non-runtime exceptions ...
}
&lt;/code&gt;&lt;/pre&gt;
  
     </Details></BugPattern><BugPattern abbrev='OBL' category='EXPERIMENTAL' type='OBL_UNSATISFIED_OBLIGATION'><ShortDescription>Method may fail to clean up stream or resource</ShortDescription><Details>
          
          &lt;p&gt;
          This method may fail to clean up (close, dispose of) a stream,
          database object, or other
          resource requiring an explicit cleanup operation.
          &lt;/p&gt;

          &lt;p&gt;
          In general, if a method opens a stream or other resource,
          the method should use a try/finally block to ensure that
          the stream or resource is cleaned up before the method
          returns.
          &lt;/p&gt;

          &lt;p&gt;
          This bug pattern is essentially the same as the
          OS_OPEN_STREAM and ODR_OPEN_DATABASE_RESOURCE
          bug patterns, but is based on a different
          (and hopefully better) static analysis technique.
          We are interested is getting feedback about the
          usefulness of this bug pattern.
          For sending feedback, check:
          &lt;/p&gt;
          &lt;ul&gt;
            &lt;li&gt;&lt;a href="https://github.com/spotbugs/spotbugs/blob/master/CONTRIBUTING.md"&gt;contributing guideline&lt;/a&gt;&lt;/li&gt;
            &lt;li&gt;&lt;a href="https://github.com/spotbugs/discuss/issues?q="&gt;malinglist&lt;/a&gt;&lt;/li&gt;
          &lt;/ul&gt;

          &lt;p&gt;
          In particular,
          the false-positive suppression heuristics for this
          bug pattern have not been extensively tuned, so
          reports about false positives are helpful to us.
          &lt;/p&gt;

          &lt;p&gt;
          See Weimer and Necula, &lt;i&gt;Finding and Preventing Run-Time Error Handling Mistakes&lt;/i&gt;, for
          a description of the analysis technique.
          &lt;/p&gt;
          
      </Details></BugPattern><BugPattern abbrev='It' category='BAD_PRACTICE' type='IT_NO_SUCH_ELEMENT'><ShortDescription>Iterator next() method can't throw NoSuchElementException</ShortDescription><Details>

  &lt;p&gt; This class implements the &lt;code&gt;java.util.Iterator&lt;/code&gt; interface.&amp;nbsp;
  However, its &lt;code&gt;next()&lt;/code&gt; method is not capable of throwing
  &lt;code&gt;java.util.NoSuchElementException&lt;/code&gt;.&amp;nbsp; The &lt;code&gt;next()&lt;/code&gt;
  method should be changed so it throws &lt;code&gt;NoSuchElementException&lt;/code&gt;
  if is called when there are no more elements to return.&lt;/p&gt;

    </Details></BugPattern><BugPattern abbrev='MS' category='MALICIOUS_CODE' type='MS_PKGPROTECT'><ShortDescription>Field should be package protected</ShortDescription><Details>

  &lt;p&gt; A mutable static field could be changed by malicious code or
   by accident.
   The field could be made package protected to avoid
   this vulnerability.&lt;/p&gt;

    </Details></BugPattern><BugPattern abbrev='ST' category='STYLE' type='ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD'><ShortDescription>Write to static field from instance method</ShortDescription><Details>

  &lt;p&gt; This instance method writes to a static field. This is tricky to get
correct if multiple instances are being manipulated,
and generally bad practice.
&lt;/p&gt;

    </Details></BugPattern><BugPattern abbrev='SIC' category='PERFORMANCE' type='SIC_INNER_SHOULD_BE_STATIC_ANON'><ShortDescription>Could be refactored into a named static inner class</ShortDescription><Details>

  &lt;p&gt; This class is an inner class, but does not use its embedded reference
  to the object which created it.&amp;nbsp; This reference makes the instances
  of the class larger, and may keep the reference to the creator object
  alive longer than necessary.&amp;nbsp; If possible, the class should be
  made into a &lt;em&gt;static&lt;/em&gt; inner class. Since anonymous inner
classes cannot be marked as static, doing this will require refactoring
the inner class so that it is a named inner class.&lt;/p&gt;

    </Details></BugPattern><BugPattern cweid='89' abbrev='SQL' category='SECURITY' type='SQL_NONCONSTANT_STRING_PASSED_TO_EXECUTE'><ShortDescription>Nonconstant string passed to execute or addBatch method on an SQL statement</ShortDescription><Details>

  &lt;p&gt;The method invokes the execute or addBatch method on an SQL statement with a String that seems
to be dynamically generated. Consider using
a prepared statement instead. It is more efficient and less vulnerable to
SQL injection attacks.
&lt;/p&gt;

    </Details></BugPattern><BugPattern abbrev='OS' category='BAD_PRACTICE' type='OS_OPEN_STREAM_EXCEPTION_PATH'><ShortDescription>Method may fail to close stream on exception</ShortDescription><Details>

&lt;p&gt; The method creates an IO stream object, does not assign it to any
fields, pass it to other methods, or return it, and does not appear to close
it on all possible exception paths out of the method.&amp;nbsp;
This may result in a file descriptor leak.&amp;nbsp; It is generally a good
idea to use a &lt;code&gt;finally&lt;/code&gt; block to ensure that streams are
closed.&lt;/p&gt;

    </Details></BugPattern><BugPattern abbrev='NS' category='STYLE' type='NS_NON_SHORT_CIRCUIT'><ShortDescription>Questionable use of non-short-circuit logic</ShortDescription><Details>

  &lt;p&gt; This code seems to be using non-short-circuit logic (e.g., &amp;amp;
or |)
rather than short-circuit logic (&amp;amp;&amp;amp; or ||).
Non-short-circuit logic causes both sides of the expression
to be evaluated even when the result can be inferred from
knowing the left-hand side. This can be less efficient and
can result in errors if the left-hand side guards cases
when evaluating the right-hand side can generate an error.

&lt;p&gt;See &lt;a href="https://docs.oracle.com/javase/specs/jls/se7/html/jls-15.html#jls-15.22.2"&gt;the Java
Language Specification&lt;/a&gt; for details.

&lt;/p&gt;

    </Details></BugPattern><BugPattern abbrev='DE' category='BAD_PRACTICE' type='DE_MIGHT_IGNORE'><ShortDescription>Method might ignore exception</ShortDescription><Details>

  &lt;p&gt; This method might ignore an exception.&amp;nbsp; In general, exceptions
  should be handled or reported in some way, or they should be thrown
  out of the method.&lt;/p&gt;

    </Details></BugPattern><BugPattern cweid='382' abbrev='Dm' category='BAD_PRACTICE' type='DM_EXIT'><ShortDescription>Method invokes System.exit(...)</ShortDescription><Details>

  &lt;p&gt; Invoking System.exit shuts down the entire Java virtual machine. This
   should only been done when it is appropriate. Such calls make it
   hard or impossible for your code to be invoked by other code.
   Consider throwing a RuntimeException instead.&lt;/p&gt;

    </Details></BugPattern><BugPattern abbrev='Se' category='BAD_PRACTICE' type='SE_COMPARATOR_SHOULD_BE_SERIALIZABLE'><ShortDescription>Comparator doesn't implement Serializable</ShortDescription><Details>

  &lt;p&gt; This class implements the &lt;code&gt;Comparator&lt;/code&gt; interface. You
should consider whether or not it should also implement the &lt;code&gt;Serializable&lt;/code&gt;
interface. If a comparator is used to construct an ordered collection
such as a &lt;code&gt;TreeMap&lt;/code&gt;, then the &lt;code&gt;TreeMap&lt;/code&gt;
will be serializable only if the comparator is also serializable.
As most comparators have little or no state, making them serializable
is generally easy and good defensive programming.
&lt;/p&gt;

    </Details></BugPattern><BugCode abbrev='BC'><Description>Bad casts of object references</Description></BugCode><BugCode cweid='391' abbrev='DE'><Description>Dropped or ignored exception</Description></BugCode><BugCode abbrev='ST'><Description>Misuse of static fields</Description></BugCode><BugCode abbrev='OS'><Description>Stream not closed on all paths</Description></BugCode><BugCode abbrev='UwF'><Description>Unwritten field</Description></BugCode><BugCode abbrev='NS'><Description>Suspicious use of non-short-circuit boolean operator</Description></BugCode><BugCode cweid='218' abbrev='MS'><Description>Mutable static field</Description></BugCode><BugCode abbrev='Dm'><Description>Dubious method used</Description></BugCode><BugCode abbrev='It'><Description>Incorrect definition of Iterator</Description></BugCode><BugCode abbrev='SIC'><Description>Inner class could be made static</Description></BugCode><BugCode abbrev='SQL'><Description>Potential SQL Problem</Description></BugCode><BugCode abbrev='EI2'><Description>Storing reference to mutable object</Description></BugCode><BugCode abbrev='REC'><Description>RuntimeException capture</Description></BugCode><BugCode abbrev='Se'><Description>Incorrect definition of Serializable class</Description></BugCode><BugCode abbrev='BSHIFT'><Description>Bad shift</Description></BugCode><BugCode abbrev='OBL'><Description>Unsatisfied obligation to clean up stream or resource</Description></BugCode><Errors missingClasses='0' errors='0'></Errors><FindBugsSummary num_packages='5' total_classes='150' priority_1='1' priority_2='9' priority_3='20' total_size='5498' clock_seconds='6.79' referenced_classes='442' vm_version='25.222-b10' total_bugs='30' java_version='1.8.0_222' gc_seconds='0.24' alloc_mbytes='455.50' cpu_seconds='29.28' peak_mbytes='295.05' timestamp='Wed, 11 Sep 2019 10:44:32 +0200'><FileStats path='org/apache/hadoop/examples/AggregateWordCount.java' size='23' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/examples/AggregateWordHistogram.java' size='20' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/examples/BaileyBorweinPlouffe.java' size='378' bugHash='489612f149fab72edfe1bacf0f8ed8a8' bugCount='5'></FileStats><FileStats path='org/apache/hadoop/examples/DBCountPageView.java' size='242' bugHash='0bb22e4a36a980ff83d7465bc7cb65aa' bugCount='3'></FileStats><FileStats path='org/apache/hadoop/examples/ExampleDriver.java' size='34' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/examples/Grep.java' size='43' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/examples/Join.java' size='82' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/examples/MultiFileWordCount.java' size='136' bugHash='c3d8455800f8f1e28e07f41de8ea04b5' bugCount='2'></FileStats><FileStats path='org/apache/hadoop/examples/QuasiMonteCarlo.java' size='164' bugHash='87db61106345ebb2676d5c0554e4ffa2' bugCount='1'></FileStats><FileStats path='org/apache/hadoop/examples/RandomTextWriter.java' size='124' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/examples/RandomWriter.java' size='156' bugHash='e668b34f719b46fde8dcc274169a42fd' bugCount='1'></FileStats><FileStats path='org/apache/hadoop/examples/SecondarySort.java' size='121' bugHash='36c30795ee9e0681f6ab6b4d09eb8527' bugCount='2'></FileStats><FileStats path='org/apache/hadoop/examples/Sort.java' size='100' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/examples/WordCount.java' size='50' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/examples/WordMean.java' size='92' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/examples/WordMedian.java' size='95' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/examples/WordStandardDeviation.java' size='107' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/examples/dancing/DancingLinks.java' size='229' bugHash='8a6a74ab5313a9f8e93038e12ec8ff02' bugCount='1'></FileStats><FileStats path='org/apache/hadoop/examples/dancing/DistributedPentomino.java' size='118' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/examples/dancing/OneSidedPentomino.java' size='31' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/examples/dancing/Pentomino.java' size='251' bugHash='1cb5d0445683863dad48bbc6d30b98ca' bugCount='4'></FileStats><FileStats path='org/apache/hadoop/examples/dancing/Sudoku.java' size='159' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/examples/pi/Combinable.java' size='2' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/examples/pi/Container.java' size='2' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/examples/pi/DistBbp.java' size='50' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/examples/pi/DistSum.java' size='374' bugHash='15770b6ec86affacba0463814125d203' bugCount='2'></FileStats><FileStats path='org/apache/hadoop/examples/pi/Parser.java' size='102' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/examples/pi/SummationWritable.java' size='67' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/examples/pi/TaskResult.java' size='55' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/examples/pi/Util.java' size='186' bugHash='f7f5fb982a15b11cf41a3a6dc9609f57' bugCount='1'></FileStats><FileStats path='org/apache/hadoop/examples/pi/math/ArithmeticProgression.java' size='64' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/examples/pi/math/Bellard.java' size='234' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/examples/pi/math/LongLong.java' size='37' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/examples/pi/math/Modular.java' size='60' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/examples/pi/math/Montgomery.java' size='43' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/examples/pi/math/Summation.java' size='131' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/examples/terasort/GenSort.java' size='134' bugHash='5bb820f85225f4e276090325c9162459' bugCount='2'></FileStats><FileStats path='org/apache/hadoop/examples/terasort/Random16.java' size='33' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/examples/terasort/TeraChecksum.java' size='57' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/examples/terasort/TeraGen.java' size='176' bugHash='2faea6795783d2ef2df539ad5047b950' bugCount='1'></FileStats><FileStats path='org/apache/hadoop/examples/terasort/TeraInputFormat.java' size='192' bugHash='c66100d1fda823f7c212aaabca43adcc' bugCount='3'></FileStats><FileStats path='org/apache/hadoop/examples/terasort/TeraOutputFormat.java' size='69' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/examples/terasort/TeraScheduler.java' size='180' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/examples/terasort/TeraSort.java' size='196' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/examples/terasort/TeraSortConfigKeys.java' size='38' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/examples/terasort/TeraValidate.java' size='110' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/examples/terasort/Unsigned16.java' size='151' bugHash='7c67c8ab6a3653aa078cbded41feabb6' bugCount='2'></FileStats><PackageStats package='org.apache.hadoop.examples' total_bugs='14' priority_2='3' priority_3='11' total_size='1967' total_types='58'><ClassStats bugs='0' size='9' interface='false' sourceFile='AggregateWordCount.java' class='org.apache.hadoop.examples.AggregateWordCount'></ClassStats><ClassStats bugs='0' size='14' interface='false' sourceFile='AggregateWordCount.java' class='org.apache.hadoop.examples.AggregateWordCount$WordCountPlugInClass'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='AggregateWordHistogram.java' class='org.apache.hadoop.examples.AggregateWordHistogram'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='AggregateWordHistogram.java' class='org.apache.hadoop.examples.AggregateWordHistogram$AggregateWordHistogramPlugin'></ClassStats><ClassStats bugs='1' size='213' priority_3='1' interface='false' sourceFile='BaileyBorweinPlouffe.java' class='org.apache.hadoop.examples.BaileyBorweinPlouffe'></ClassStats><ClassStats bugs='0' size='1' interface='false' sourceFile='BaileyBorweinPlouffe.java' class='org.apache.hadoop.examples.BaileyBorweinPlouffe$1'></ClassStats><ClassStats bugs='2' size='19' priority_3='2' interface='false' sourceFile='BaileyBorweinPlouffe.java' class='org.apache.hadoop.examples.BaileyBorweinPlouffe$BbpInputFormat'></ClassStats><ClassStats bugs='0' size='21' interface='false' sourceFile='BaileyBorweinPlouffe.java' class='org.apache.hadoop.examples.BaileyBorweinPlouffe$BbpInputFormat$1'></ClassStats><ClassStats bugs='0' size='14' interface='false' sourceFile='BaileyBorweinPlouffe.java' class='org.apache.hadoop.examples.BaileyBorweinPlouffe$BbpMapper'></ClassStats><ClassStats bugs='1' size='38' priority_3='1' interface='false' sourceFile='BaileyBorweinPlouffe.java' class='org.apache.hadoop.examples.BaileyBorweinPlouffe$BbpReducer'></ClassStats><ClassStats bugs='1' size='16' priority_3='1' interface='false' sourceFile='BaileyBorweinPlouffe.java' class='org.apache.hadoop.examples.BaileyBorweinPlouffe$BbpReducer$1'></ClassStats><ClassStats bugs='0' size='32' interface='false' sourceFile='BaileyBorweinPlouffe.java' class='org.apache.hadoop.examples.BaileyBorweinPlouffe$BbpSplit'></ClassStats><ClassStats bugs='0' size='24' interface='false' sourceFile='BaileyBorweinPlouffe.java' class='org.apache.hadoop.examples.BaileyBorweinPlouffe$Fraction'></ClassStats><ClassStats bugs='3' size='167' priority_2='1' priority_3='2' interface='false' sourceFile='DBCountPageView.java' class='org.apache.hadoop.examples.DBCountPageView'></ClassStats><ClassStats bugs='0' size='26' interface='false' sourceFile='DBCountPageView.java' class='org.apache.hadoop.examples.DBCountPageView$AccessRecord'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='DBCountPageView.java' class='org.apache.hadoop.examples.DBCountPageView$PageviewMapper'></ClassStats><ClassStats bugs='0' size='26' interface='false' sourceFile='DBCountPageView.java' class='org.apache.hadoop.examples.DBCountPageView$PageviewRecord'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='DBCountPageView.java' class='org.apache.hadoop.examples.DBCountPageView$PageviewReducer'></ClassStats><ClassStats bugs='0' size='34' interface='false' sourceFile='ExampleDriver.java' class='org.apache.hadoop.examples.ExampleDriver'></ClassStats><ClassStats bugs='0' size='43' interface='false' sourceFile='Grep.java' class='org.apache.hadoop.examples.Grep'></ClassStats><ClassStats bugs='0' size='82' interface='false' sourceFile='Join.java' class='org.apache.hadoop.examples.Join'></ClassStats><ClassStats bugs='0' size='26' interface='false' sourceFile='MultiFileWordCount.java' class='org.apache.hadoop.examples.MultiFileWordCount'></ClassStats><ClassStats bugs='0' size='59' interface='false' sourceFile='MultiFileWordCount.java' class='org.apache.hadoop.examples.MultiFileWordCount$CombineFileLineRecordReader'></ClassStats><ClassStats bugs='0' size='16' interface='false' sourceFile='MultiFileWordCount.java' class='org.apache.hadoop.examples.MultiFileWordCount$MapClass'></ClassStats><ClassStats bugs='1' size='5' priority_3='1' interface='false' sourceFile='MultiFileWordCount.java' class='org.apache.hadoop.examples.MultiFileWordCount$MyInputFormat'></ClassStats><ClassStats bugs='1' size='30' priority_3='1' interface='false' sourceFile='MultiFileWordCount.java' class='org.apache.hadoop.examples.MultiFileWordCount$WordOffset'></ClassStats><ClassStats bugs='1' size='77' priority_3='1' interface='false' sourceFile='QuasiMonteCarlo.java' class='org.apache.hadoop.examples.QuasiMonteCarlo'></ClassStats><ClassStats bugs='0' size='39' interface='false' sourceFile='QuasiMonteCarlo.java' class='org.apache.hadoop.examples.QuasiMonteCarlo$HaltonSequence'></ClassStats><ClassStats bugs='0' size='22' interface='false' sourceFile='QuasiMonteCarlo.java' class='org.apache.hadoop.examples.QuasiMonteCarlo$QmcMapper'></ClassStats><ClassStats bugs='0' size='26' interface='false' sourceFile='QuasiMonteCarlo.java' class='org.apache.hadoop.examples.QuasiMonteCarlo$QmcReducer'></ClassStats><ClassStats bugs='0' size='70' interface='false' sourceFile='RandomTextWriter.java' class='org.apache.hadoop.examples.RandomTextWriter'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='RandomTextWriter.java' class='org.apache.hadoop.examples.RandomTextWriter$Counters'></ClassStats><ClassStats bugs='0' size='45' interface='false' sourceFile='RandomTextWriter.java' class='org.apache.hadoop.examples.RandomTextWriter$RandomTextMapper'></ClassStats><ClassStats bugs='0' size='55' interface='false' sourceFile='RandomWriter.java' class='org.apache.hadoop.examples.RandomWriter'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='RandomWriter.java' class='org.apache.hadoop.examples.RandomWriter$Counters'></ClassStats><ClassStats bugs='1' size='13' priority_3='1' interface='false' sourceFile='RandomWriter.java' class='org.apache.hadoop.examples.RandomWriter$RandomInputFormat'></ClassStats><ClassStats bugs='0' size='30' interface='false' sourceFile='RandomWriter.java' class='org.apache.hadoop.examples.RandomWriter$RandomInputFormat$RandomRecordReader'></ClassStats><ClassStats bugs='0' size='49' interface='false' sourceFile='RandomWriter.java' class='org.apache.hadoop.examples.RandomWriter$RandomMapper'></ClassStats><ClassStats bugs='0' size='23' interface='false' sourceFile='SecondarySort.java' class='org.apache.hadoop.examples.SecondarySort'></ClassStats><ClassStats bugs='1' size='10' priority_2='1' interface='false' sourceFile='SecondarySort.java' class='org.apache.hadoop.examples.SecondarySort$FirstGroupingComparator'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SecondarySort.java' class='org.apache.hadoop.examples.SecondarySort$FirstPartitioner'></ClassStats><ClassStats bugs='0' size='40' interface='false' sourceFile='SecondarySort.java' class='org.apache.hadoop.examples.SecondarySort$IntPair'></ClassStats><ClassStats bugs='1' size='6' priority_2='1' interface='false' sourceFile='SecondarySort.java' class='org.apache.hadoop.examples.SecondarySort$IntPair$Comparator'></ClassStats><ClassStats bugs='0' size='20' interface='false' sourceFile='SecondarySort.java' class='org.apache.hadoop.examples.SecondarySort$MapClass'></ClassStats><ClassStats bugs='0' size='16' interface='false' sourceFile='SecondarySort.java' class='org.apache.hadoop.examples.SecondarySort$Reduce'></ClassStats><ClassStats bugs='0' size='100' interface='false' sourceFile='Sort.java' class='org.apache.hadoop.examples.Sort'></ClassStats><ClassStats bugs='0' size='21' interface='false' sourceFile='WordCount.java' class='org.apache.hadoop.examples.WordCount'></ClassStats><ClassStats bugs='0' size='14' interface='false' sourceFile='WordCount.java' class='org.apache.hadoop.examples.WordCount$IntSumReducer'></ClassStats><ClassStats bugs='0' size='15' interface='false' sourceFile='WordCount.java' class='org.apache.hadoop.examples.WordCount$TokenizerMapper'></ClassStats><ClassStats bugs='0' size='63' interface='false' sourceFile='WordMean.java' class='org.apache.hadoop.examples.WordMean'></ClassStats><ClassStats bugs='0' size='15' interface='false' sourceFile='WordMean.java' class='org.apache.hadoop.examples.WordMean$WordMeanMapper'></ClassStats><ClassStats bugs='0' size='14' interface='false' sourceFile='WordMean.java' class='org.apache.hadoop.examples.WordMean$WordMeanReducer'></ClassStats><ClassStats bugs='0' size='67' interface='false' sourceFile='WordMedian.java' class='org.apache.hadoop.examples.WordMedian'></ClassStats><ClassStats bugs='0' size='14' interface='false' sourceFile='WordMedian.java' class='org.apache.hadoop.examples.WordMedian$WordMedianMapper'></ClassStats><ClassStats bugs='0' size='14' interface='false' sourceFile='WordMedian.java' class='org.apache.hadoop.examples.WordMedian$WordMedianReducer'></ClassStats><ClassStats bugs='0' size='74' interface='false' sourceFile='WordStandardDeviation.java' class='org.apache.hadoop.examples.WordStandardDeviation'></ClassStats><ClassStats bugs='0' size='19' interface='false' sourceFile='WordStandardDeviation.java' class='org.apache.hadoop.examples.WordStandardDeviation$WordStandardDeviationMapper'></ClassStats><ClassStats bugs='0' size='14' interface='false' sourceFile='WordStandardDeviation.java' class='org.apache.hadoop.examples.WordStandardDeviation$WordStandardDeviationReducer'></ClassStats></PackageStats><PackageStats package='org.apache.hadoop.examples.dancing' total_bugs='5' priority_2='4' priority_3='1' total_size='788' total_types='21'><ClassStats bugs='1' size='198' priority_3='1' interface='false' sourceFile='DancingLinks.java' class='org.apache.hadoop.examples.dancing.DancingLinks'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='DancingLinks.java' class='org.apache.hadoop.examples.dancing.DancingLinks$ColumnHeader'></ClassStats><ClassStats bugs='0' size='17' interface='false' sourceFile='DancingLinks.java' class='org.apache.hadoop.examples.dancing.DancingLinks$Node'></ClassStats><ClassStats bugs='0' size='2' interface='true' sourceFile='DancingLinks.java' class='org.apache.hadoop.examples.dancing.DancingLinks$SolutionAcceptor'></ClassStats><ClassStats bugs='0' size='67' interface='false' sourceFile='DistributedPentomino.java' class='org.apache.hadoop.examples.dancing.DistributedPentomino'></ClassStats><ClassStats bugs='0' size='37' interface='false' sourceFile='DistributedPentomino.java' class='org.apache.hadoop.examples.dancing.DistributedPentomino$PentMap'></ClassStats><ClassStats bugs='0' size='14' interface='false' sourceFile='DistributedPentomino.java' class='org.apache.hadoop.examples.dancing.DistributedPentomino$PentMap$SolutionCatcher'></ClassStats><ClassStats bugs='0' size='31' interface='false' sourceFile='OneSidedPentomino.java' class='org.apache.hadoop.examples.dancing.OneSidedPentomino'></ClassStats><ClassStats bugs='3' size='161' priority_2='3' interface='false' sourceFile='Pentomino.java' class='org.apache.hadoop.examples.dancing.Pentomino'></ClassStats><ClassStats bugs='0' size='1' interface='true' sourceFile='Pentomino.java' class='org.apache.hadoop.examples.dancing.Pentomino$ColumnName'></ClassStats><ClassStats bugs='1' size='59' priority_2='1' interface='false' sourceFile='Pentomino.java' class='org.apache.hadoop.examples.dancing.Pentomino$Piece'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='Pentomino.java' class='org.apache.hadoop.examples.dancing.Pentomino$Point'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='Pentomino.java' class='org.apache.hadoop.examples.dancing.Pentomino$SolutionCategory'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='Pentomino.java' class='org.apache.hadoop.examples.dancing.Pentomino$SolutionPrinter'></ClassStats><ClassStats bugs='0' size='99' interface='false' sourceFile='Sudoku.java' class='org.apache.hadoop.examples.dancing.Sudoku'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='Sudoku.java' class='org.apache.hadoop.examples.dancing.Sudoku$CellConstraint'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='Sudoku.java' class='org.apache.hadoop.examples.dancing.Sudoku$ColumnConstraint'></ClassStats><ClassStats bugs='0' size='1' interface='true' sourceFile='Sudoku.java' class='org.apache.hadoop.examples.dancing.Sudoku$ColumnName'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='Sudoku.java' class='org.apache.hadoop.examples.dancing.Sudoku$RowConstraint'></ClassStats><ClassStats bugs='0' size='17' interface='false' sourceFile='Sudoku.java' class='org.apache.hadoop.examples.dancing.Sudoku$SolutionPrinter'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='Sudoku.java' class='org.apache.hadoop.examples.dancing.Sudoku$SquareConstraint'></ClassStats></PackageStats><PackageStats package='org.apache.hadoop.examples.pi' total_bugs='3' priority_3='3' total_size='838' total_types='26'><ClassStats bugs='0' size='2' interface='true' sourceFile='Combinable.java' class='org.apache.hadoop.examples.pi.Combinable'></ClassStats><ClassStats bugs='0' size='2' interface='true' sourceFile='Container.java' class='org.apache.hadoop.examples.pi.Container'></ClassStats><ClassStats bugs='0' size='50' interface='false' sourceFile='DistBbp.java' class='org.apache.hadoop.examples.pi.DistBbp'></ClassStats><ClassStats bugs='0' size='106' interface='false' sourceFile='DistSum.java' class='org.apache.hadoop.examples.pi.DistSum'></ClassStats><ClassStats bugs='0' size='14' interface='false' sourceFile='DistSum.java' class='org.apache.hadoop.examples.pi.DistSum$1'></ClassStats><ClassStats bugs='0' size='25' interface='false' sourceFile='DistSum.java' class='org.apache.hadoop.examples.pi.DistSum$Computation'></ClassStats><ClassStats bugs='0' size='17' interface='false' sourceFile='DistSum.java' class='org.apache.hadoop.examples.pi.DistSum$Machine'></ClassStats><ClassStats bugs='2' size='6' priority_3='2' interface='false' sourceFile='DistSum.java' class='org.apache.hadoop.examples.pi.DistSum$Machine$AbstractInputFormat'></ClassStats><ClassStats bugs='0' size='21' interface='false' sourceFile='DistSum.java' class='org.apache.hadoop.examples.pi.DistSum$Machine$AbstractInputFormat$1'></ClassStats><ClassStats bugs='0' size='24' interface='false' sourceFile='DistSum.java' class='org.apache.hadoop.examples.pi.DistSum$Machine$SummationSplit'></ClassStats><ClassStats bugs='0' size='14' interface='false' sourceFile='DistSum.java' class='org.apache.hadoop.examples.pi.DistSum$MapSide'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='DistSum.java' class='org.apache.hadoop.examples.pi.DistSum$MapSide$PartitionInputFormat'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='DistSum.java' class='org.apache.hadoop.examples.pi.DistSum$MapSide$SummingMapper'></ClassStats><ClassStats bugs='0' size='30' interface='false' sourceFile='DistSum.java' class='org.apache.hadoop.examples.pi.DistSum$MixMachine'></ClassStats><ClassStats bugs='0' size='42' interface='false' sourceFile='DistSum.java' class='org.apache.hadoop.examples.pi.DistSum$Parameters'></ClassStats><ClassStats bugs='0' size='20' interface='false' sourceFile='DistSum.java' class='org.apache.hadoop.examples.pi.DistSum$ReduceSide'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='DistSum.java' class='org.apache.hadoop.examples.pi.DistSum$ReduceSide$IndexPartitioner'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='DistSum.java' class='org.apache.hadoop.examples.pi.DistSum$ReduceSide$PartitionMapper'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='DistSum.java' class='org.apache.hadoop.examples.pi.DistSum$ReduceSide$SummationInputFormat'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='DistSum.java' class='org.apache.hadoop.examples.pi.DistSum$ReduceSide$SummingReducer'></ClassStats><ClassStats bugs='0' size='102' interface='false' sourceFile='Parser.java' class='org.apache.hadoop.examples.pi.Parser'></ClassStats><ClassStats bugs='0' size='53' interface='false' sourceFile='SummationWritable.java' class='org.apache.hadoop.examples.pi.SummationWritable'></ClassStats><ClassStats bugs='0' size='14' interface='false' sourceFile='SummationWritable.java' class='org.apache.hadoop.examples.pi.SummationWritable$ArithmeticProgressionWritable'></ClassStats><ClassStats bugs='0' size='55' interface='false' sourceFile='TaskResult.java' class='org.apache.hadoop.examples.pi.TaskResult'></ClassStats><ClassStats bugs='1' size='163' priority_3='1' interface='false' sourceFile='Util.java' class='org.apache.hadoop.examples.pi.Util'></ClassStats><ClassStats bugs='0' size='23' interface='false' sourceFile='Util.java' class='org.apache.hadoop.examples.pi.Util$Timer'></ClassStats></PackageStats><PackageStats package='org.apache.hadoop.examples.pi.math' total_bugs='0' total_size='569' total_types='12'><ClassStats bugs='0' size='64' interface='false' sourceFile='ArithmeticProgression.java' class='org.apache.hadoop.examples.pi.math.ArithmeticProgression'></ClassStats><ClassStats bugs='0' size='49' interface='false' sourceFile='Bellard.java' class='org.apache.hadoop.examples.pi.math.Bellard'></ClassStats><ClassStats bugs='0' size='1' interface='false' sourceFile='Bellard.java' class='org.apache.hadoop.examples.pi.math.Bellard$1'></ClassStats><ClassStats bugs='0' size='67' interface='false' sourceFile='Bellard.java' class='org.apache.hadoop.examples.pi.math.Bellard$Parameter'></ClassStats><ClassStats bugs='0' size='71' interface='false' sourceFile='Bellard.java' class='org.apache.hadoop.examples.pi.math.Bellard$Sum'></ClassStats><ClassStats bugs='0' size='15' interface='false' sourceFile='Bellard.java' class='org.apache.hadoop.examples.pi.math.Bellard$Sum$1'></ClassStats><ClassStats bugs='0' size='31' interface='false' sourceFile='Bellard.java' class='org.apache.hadoop.examples.pi.math.Bellard$Sum$Tail'></ClassStats><ClassStats bugs='0' size='37' interface='false' sourceFile='LongLong.java' class='org.apache.hadoop.examples.pi.math.LongLong'></ClassStats><ClassStats bugs='0' size='60' interface='false' sourceFile='Modular.java' class='org.apache.hadoop.examples.pi.math.Modular'></ClassStats><ClassStats bugs='0' size='27' interface='false' sourceFile='Montgomery.java' class='org.apache.hadoop.examples.pi.math.Montgomery'></ClassStats><ClassStats bugs='0' size='16' interface='false' sourceFile='Montgomery.java' class='org.apache.hadoop.examples.pi.math.Montgomery$Product'></ClassStats><ClassStats bugs='0' size='131' interface='false' sourceFile='Summation.java' class='org.apache.hadoop.examples.pi.math.Summation'></ClassStats></PackageStats><PackageStats package='org.apache.hadoop.examples.terasort' priority_1='1' total_bugs='8' priority_2='2' priority_3='5' total_size='1336' total_types='33'><ClassStats bugs='2' size='134' priority_3='2' interface='false' sourceFile='GenSort.java' class='org.apache.hadoop.examples.terasort.GenSort'></ClassStats><ClassStats bugs='0' size='25' interface='false' sourceFile='Random16.java' class='org.apache.hadoop.examples.terasort.Random16'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='Random16.java' class='org.apache.hadoop.examples.terasort.Random16$RandomConstant'></ClassStats><ClassStats bugs='0' size='26' interface='false' sourceFile='TeraChecksum.java' class='org.apache.hadoop.examples.terasort.TeraChecksum'></ClassStats><ClassStats bugs='0' size='20' interface='false' sourceFile='TeraChecksum.java' class='org.apache.hadoop.examples.terasort.TeraChecksum$ChecksumMapper'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='TeraChecksum.java' class='org.apache.hadoop.examples.terasort.TeraChecksum$ChecksumReducer'></ClassStats><ClassStats bugs='0' size='52' interface='false' sourceFile='TeraGen.java' class='org.apache.hadoop.examples.terasort.TeraGen'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='TeraGen.java' class='org.apache.hadoop.examples.terasort.TeraGen$Counters'></ClassStats><ClassStats bugs='0' size='17' interface='false' sourceFile='TeraGen.java' class='org.apache.hadoop.examples.terasort.TeraGen$RangeInputFormat'></ClassStats><ClassStats bugs='0' size='22' interface='false' sourceFile='TeraGen.java' class='org.apache.hadoop.examples.terasort.TeraGen$RangeInputFormat$RangeInputSplit'></ClassStats><ClassStats bugs='1' size='33' priority_3='1' interface='false' sourceFile='TeraGen.java' class='org.apache.hadoop.examples.terasort.TeraGen$RangeInputFormat$RangeRecordReader'></ClassStats><ClassStats bugs='0' size='44' interface='false' sourceFile='TeraGen.java' class='org.apache.hadoop.examples.terasort.TeraGen$SortGenMapper'></ClassStats><ClassStats bugs='2' size='67' priority_1='1' priority_2='1' interface='false' sourceFile='TeraInputFormat.java' class='org.apache.hadoop.examples.terasort.TeraInputFormat'></ClassStats><ClassStats bugs='0' size='31' interface='false' sourceFile='TeraInputFormat.java' class='org.apache.hadoop.examples.terasort.TeraInputFormat$1'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='TeraInputFormat.java' class='org.apache.hadoop.examples.terasort.TeraInputFormat$SamplerThreadGroup'></ClassStats><ClassStats bugs='1' size='53' priority_3='1' interface='false' sourceFile='TeraInputFormat.java' class='org.apache.hadoop.examples.terasort.TeraInputFormat$TeraRecordReader'></ClassStats><ClassStats bugs='0' size='31' interface='false' sourceFile='TeraInputFormat.java' class='org.apache.hadoop.examples.terasort.TeraInputFormat$TextSampler'></ClassStats><ClassStats bugs='0' size='46' interface='false' sourceFile='TeraOutputFormat.java' class='org.apache.hadoop.examples.terasort.TeraOutputFormat'></ClassStats><ClassStats bugs='0' size='23' interface='false' sourceFile='TeraOutputFormat.java' class='org.apache.hadoop.examples.terasort.TeraOutputFormat$TeraRecordWriter'></ClassStats><ClassStats bugs='0' size='147' interface='false' sourceFile='TeraScheduler.java' class='org.apache.hadoop.examples.terasort.TeraScheduler'></ClassStats><ClassStats bugs='0' size='14' interface='false' sourceFile='TeraScheduler.java' class='org.apache.hadoop.examples.terasort.TeraScheduler$Host'></ClassStats><ClassStats bugs='0' size='19' interface='false' sourceFile='TeraScheduler.java' class='org.apache.hadoop.examples.terasort.TeraScheduler$Split'></ClassStats><ClassStats bugs='0' size='65' interface='false' sourceFile='TeraSort.java' class='org.apache.hadoop.examples.terasort.TeraSort'></ClassStats><ClassStats bugs='0' size='22' interface='false' sourceFile='TeraSort.java' class='org.apache.hadoop.examples.terasort.TeraSort$SimplePartitioner'></ClassStats><ClassStats bugs='0' size='52' interface='false' sourceFile='TeraSort.java' class='org.apache.hadoop.examples.terasort.TeraSort$TotalOrderPartitioner'></ClassStats><ClassStats bugs='0' size='25' interface='false' sourceFile='TeraSort.java' class='org.apache.hadoop.examples.terasort.TeraSort$TotalOrderPartitioner$InnerTrieNode'></ClassStats><ClassStats bugs='0' size='22' interface='false' sourceFile='TeraSort.java' class='org.apache.hadoop.examples.terasort.TeraSort$TotalOrderPartitioner$LeafTrieNode'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='TeraSort.java' class='org.apache.hadoop.examples.terasort.TeraSort$TotalOrderPartitioner$TrieNode'></ClassStats><ClassStats bugs='0' size='38' interface='false' sourceFile='TeraSortConfigKeys.java' class='org.apache.hadoop.examples.terasort.TeraSortConfigKeys'></ClassStats><ClassStats bugs='0' size='39' interface='false' sourceFile='TeraValidate.java' class='org.apache.hadoop.examples.terasort.TeraValidate'></ClassStats><ClassStats bugs='0' size='37' interface='false' sourceFile='TeraValidate.java' class='org.apache.hadoop.examples.terasort.TeraValidate$ValidateMapper'></ClassStats><ClassStats bugs='0' size='34' interface='false' sourceFile='TeraValidate.java' class='org.apache.hadoop.examples.terasort.TeraValidate$ValidateReducer'></ClassStats><ClassStats bugs='2' size='151' priority_2='1' priority_3='1' interface='false' sourceFile='Unsigned16.java' class='org.apache.hadoop.examples.terasort.Unsigned16'></ClassStats></PackageStats><FindBugsProfile><ClassProfile avgMicrosecondsPerInvocation='358' totalMilliseconds='603' name='edu.umd.cs.findbugs.classfile.engine.ClassDataAnalysisEngine' maxMicrosecondsPerInvocation='1069' standardDeviationMicrosecondsPerInvocation='155' invocations='1685'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='280' totalMilliseconds='470' name='edu.umd.cs.findbugs.classfile.engine.ClassInfoAnalysisEngine' maxMicrosecondsPerInvocation='44922' standardDeviationMicrosecondsPerInvocation='1535' invocations='1678'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='363' totalMilliseconds='274' name='edu.umd.cs.findbugs.classfile.engine.bcel.UnconditionalValueDerefDataflowFactory' maxMicrosecondsPerInvocation='37340' standardDeviationMicrosecondsPerInvocation='1771' invocations='755'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='344' totalMilliseconds='272' name='edu.umd.cs.findbugs.classfile.engine.bcel.ValueNumberDataflowFactory' maxMicrosecondsPerInvocation='34384' standardDeviationMicrosecondsPerInvocation='1861' invocations='792'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='340' totalMilliseconds='264' name='edu.umd.cs.findbugs.classfile.engine.bcel.IsNullValueDataflowFactory' maxMicrosecondsPerInvocation='17393' standardDeviationMicrosecondsPerInvocation='1149' invocations='777'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='320' totalMilliseconds='253' name='edu.umd.cs.findbugs.classfile.engine.bcel.TypeDataflowFactory' maxMicrosecondsPerInvocation='28357' standardDeviationMicrosecondsPerInvocation='1510' invocations='789'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='546' totalMilliseconds='241' name='edu.umd.cs.findbugs.detect.FieldItemSummary' maxMicrosecondsPerInvocation='15134' standardDeviationMicrosecondsPerInvocation='1240' invocations='442'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='302' totalMilliseconds='237' name='edu.umd.cs.findbugs.classfile.engine.bcel.MethodGenFactory' maxMicrosecondsPerInvocation='190281' standardDeviationMicrosecondsPerInvocation='6800' invocations='783'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='329' totalMilliseconds='235' name='edu.umd.cs.findbugs.ba.npe.NullDerefAndRedundantComparisonFinder' maxMicrosecondsPerInvocation='33530' standardDeviationMicrosecondsPerInvocation='1357' invocations='713'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='496' totalMilliseconds='219' name='edu.umd.cs.findbugs.detect.FindNoSideEffectMethods' maxMicrosecondsPerInvocation='6820' standardDeviationMicrosecondsPerInvocation='875' invocations='442'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='135' totalMilliseconds='216' name='edu.umd.cs.findbugs.OpcodeStack$JumpInfoFactory' maxMicrosecondsPerInvocation='4374' standardDeviationMicrosecondsPerInvocation='252' invocations='1601'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='193' totalMilliseconds='150' name='edu.umd.cs.findbugs.classfile.engine.bcel.CFGFactory' maxMicrosecondsPerInvocation='22246' standardDeviationMicrosecondsPerInvocation='954' invocations='777'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='197' totalMilliseconds='128' name='edu.umd.cs.findbugs.detect.FindRefComparison$SpecialTypeAnalysis' maxMicrosecondsPerInvocation='11426' standardDeviationMicrosecondsPerInvocation='558' invocations='650'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='214' totalMilliseconds='94' name='edu.umd.cs.findbugs.detect.NoteDirectlyRelevantTypeQualifiers' maxMicrosecondsPerInvocation='9424' standardDeviationMicrosecondsPerInvocation='600' invocations='442'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='709' totalMilliseconds='90' name='edu.umd.cs.findbugs.classfile.impl.ZipCodeBaseFactory' maxMicrosecondsPerInvocation='63429' standardDeviationMicrosecondsPerInvocation='5588' invocations='127'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='147' totalMilliseconds='77' name='edu.umd.cs.findbugs.classfile.engine.bcel.JavaClassAnalysisEngine' maxMicrosecondsPerInvocation='15595' standardDeviationMicrosecondsPerInvocation='718' invocations='523'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='91' totalMilliseconds='71' name='edu.umd.cs.findbugs.classfile.engine.bcel.ConstantDataflowFactory' maxMicrosecondsPerInvocation='8748' standardDeviationMicrosecondsPerInvocation='379' invocations='777'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='474' totalMilliseconds='68' name='edu.umd.cs.findbugs.detect.StreamResourceTracker' maxMicrosecondsPerInvocation='4527' standardDeviationMicrosecondsPerInvocation='680' invocations='144'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='443' totalMilliseconds='66' name='edu.umd.cs.findbugs.detect.FindOpenStream' maxMicrosecondsPerInvocation='8953' standardDeviationMicrosecondsPerInvocation='1077' invocations='150'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='38' totalMilliseconds='62' name='edu.umd.cs.findbugs.util.TopologicalSort' maxMicrosecondsPerInvocation='1638' standardDeviationMicrosecondsPerInvocation='78' invocations='1624'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='139' totalMilliseconds='61' name='edu.umd.cs.findbugs.detect.BuildObligationPolicyDatabase' maxMicrosecondsPerInvocation='4873' standardDeviationMicrosecondsPerInvocation='314' invocations='442'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='3' totalMilliseconds='60' name='edu.umd.cs.findbugs.DetectorToDetector2Adapter' maxMicrosecondsPerInvocation='65' standardDeviationMicrosecondsPerInvocation='0' invocations='18726'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='79' totalMilliseconds='56' name='edu.umd.cs.findbugs.detect.FindNullDeref$CheckCallSitesAndReturnInstructions' maxMicrosecondsPerInvocation='14800' standardDeviationMicrosecondsPerInvocation='758' invocations='713'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='125' totalMilliseconds='55' name='edu.umd.cs.findbugs.detect.FunctionsThatMightBeMistakenForProcedures' maxMicrosecondsPerInvocation='9032' standardDeviationMicrosecondsPerInvocation='504' invocations='442'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='123' totalMilliseconds='54' name='edu.umd.cs.findbugs.detect.CalledMethods' maxMicrosecondsPerInvocation='3768' standardDeviationMicrosecondsPerInvocation='286' invocations='442'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='355' totalMilliseconds='53' name='edu.umd.cs.findbugs.detect.UnreadFields' maxMicrosecondsPerInvocation='11904' standardDeviationMicrosecondsPerInvocation='1135' invocations='150'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='75' totalMilliseconds='50' name='edu.umd.cs.findbugs.classfile.engine.bcel.LiveLocalStoreDataflowFactory' maxMicrosecondsPerInvocation='9377' standardDeviationMicrosecondsPerInvocation='451' invocations='666'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='109' totalMilliseconds='48' name='edu.umd.cs.findbugs.detect.OverridingEqualsNotSymmetrical' maxMicrosecondsPerInvocation='6699' standardDeviationMicrosecondsPerInvocation='357' invocations='442'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='3' totalMilliseconds='47' name='edu.umd.cs.findbugs.ba.npe.TypeQualifierNullnessAnnotationDatabase' maxMicrosecondsPerInvocation='1812' standardDeviationMicrosecondsPerInvocation='21' invocations='13338'></ClassProfile></FindBugsProfile></FindBugsSummary><ClassFeatures></ClassFeatures><History></History></BugCollection>