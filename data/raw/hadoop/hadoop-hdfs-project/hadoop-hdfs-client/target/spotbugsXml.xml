
<BugCollection sequence='0' release='' analysisTimestamp='1568192561896' version='3.1.12' timestamp='1568190886000'><Project projectName='Apache Hadoop HDFS Client'><Jar>./hadoop/hadoop-hdfs-project/hadoop-hdfs-client/target/classes</Jar><Jar>./hadoop/hadoop-hdfs-project/hadoop-hdfs-client/target/test-classes</Jar><AuxClasspathEntry>./hadoop/hadoop-hdfs-project/hadoop-hdfs-client/target/test-classes</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/com/squareup/okhttp/okhttp/2.7.5/okhttp-2.7.5.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/com/squareup/okio/okio/1.6.0/okio-1.6.0.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/org/apache/hadoop/hadoop-common/3.1.1/hadoop-common-3.1.1.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/com/google/guava/guava/11.0.2/guava-11.0.2.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/commons-cli/commons-cli/1.2/commons-cli-1.2.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/org/apache/commons/commons-math3/3.1.1/commons-math3-3.1.1.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/org/apache/httpcomponents/httpclient/4.5.2/httpclient-4.5.2.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/org/apache/httpcomponents/httpcore/4.4.4/httpcore-4.4.4.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/commons-codec/commons-codec/1.11/commons-codec-1.11.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/commons-io/commons-io/2.5/commons-io-2.5.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/commons-net/commons-net/3.6/commons-net-3.6.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/commons-collections/commons-collections/3.2.2/commons-collections-3.2.2.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/javax/servlet/javax.servlet-api/3.1.0/javax.servlet-api-3.1.0.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/org/eclipse/jetty/jetty-server/9.3.19.v20170502/jetty-server-9.3.19.v20170502.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/org/eclipse/jetty/jetty-http/9.3.19.v20170502/jetty-http-9.3.19.v20170502.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/org/eclipse/jetty/jetty-io/9.3.19.v20170502/jetty-io-9.3.19.v20170502.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/org/eclipse/jetty/jetty-util/9.3.19.v20170502/jetty-util-9.3.19.v20170502.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/org/eclipse/jetty/jetty-servlet/9.3.19.v20170502/jetty-servlet-9.3.19.v20170502.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/org/eclipse/jetty/jetty-security/9.3.19.v20170502/jetty-security-9.3.19.v20170502.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/org/eclipse/jetty/jetty-webapp/9.3.19.v20170502/jetty-webapp-9.3.19.v20170502.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/org/eclipse/jetty/jetty-xml/9.3.19.v20170502/jetty-xml-9.3.19.v20170502.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/javax/servlet/jsp/jsp-api/2.1/jsp-api-2.1.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/com/sun/jersey/jersey-core/1.19/jersey-core-1.19.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/javax/ws/rs/jsr311-api/1.1.1/jsr311-api-1.1.1.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/com/sun/jersey/jersey-servlet/1.19/jersey-servlet-1.19.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/com/sun/jersey/jersey-json/1.19/jersey-json-1.19.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/org/codehaus/jettison/jettison/1.1/jettison-1.1.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/com/sun/xml/bind/jaxb-impl/2.2.3-1/jaxb-impl-2.2.3-1.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/javax/xml/bind/jaxb-api/2.2.11/jaxb-api-2.2.11.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/org/codehaus/jackson/jackson-core-asl/1.9.13/jackson-core-asl-1.9.13.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/org/codehaus/jackson/jackson-jaxrs/1.9.13/jackson-jaxrs-1.9.13.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/org/codehaus/jackson/jackson-xc/1.9.13/jackson-xc-1.9.13.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/com/sun/jersey/jersey-server/1.19/jersey-server-1.19.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/commons-lang/commons-lang/2.6/commons-lang-2.6.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/commons-beanutils/commons-beanutils/1.9.3/commons-beanutils-1.9.3.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/org/apache/commons/commons-configuration2/2.1.1/commons-configuration2-2.1.1.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/org/apache/commons/commons-lang3/3.4/commons-lang3-3.4.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/org/slf4j/slf4j-api/1.7.25/slf4j-api-1.7.25.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/org/slf4j/slf4j-log4j12/1.7.25/slf4j-log4j12-1.7.25.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/org/apache/avro/avro/1.7.7/avro-1.7.7.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/com/thoughtworks/paranamer/paranamer/2.3/paranamer-2.3.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/org/xerial/snappy/snappy-java/1.0.5/snappy-java-1.0.5.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/com/google/re2j/re2j/1.1/re2j-1.1.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/com/google/code/gson/gson/2.2.4/gson-2.2.4.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/org/apache/hadoop/hadoop-auth/3.1.1/hadoop-auth-3.1.1.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/com/nimbusds/nimbus-jose-jwt/4.41.1/nimbus-jose-jwt-4.41.1.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/com/github/stephenc/jcip/jcip-annotations/1.0-1/jcip-annotations-1.0-1.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/net/minidev/json-smart/2.3/json-smart-2.3.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/net/minidev/accessors-smart/1.2/accessors-smart-1.2.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/org/ow2/asm/asm/5.0.4/asm-5.0.4.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/org/apache/curator/curator-framework/2.12.0/curator-framework-2.12.0.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/com/jcraft/jsch/0.1.54/jsch-0.1.54.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/org/apache/curator/curator-client/2.12.0/curator-client-2.12.0.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/org/apache/curator/curator-recipes/2.12.0/curator-recipes-2.12.0.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/com/google/code/findbugs/jsr305/3.0.0/jsr305-3.0.0.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/org/apache/htrace/htrace-core4/4.1.0-incubating/htrace-core4-4.1.0-incubating.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/org/apache/zookeeper/zookeeper/3.4.9/zookeeper-3.4.9.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/io/netty/netty/3.10.5.Final/netty-3.10.5.Final.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/org/apache/commons/commons-compress/1.4.1/commons-compress-1.4.1.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/org/tukaani/xz/1.0/xz-1.0.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/org/apache/kerby/kerb-simplekdc/1.0.1/kerb-simplekdc-1.0.1.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/org/apache/kerby/kerb-client/1.0.1/kerb-client-1.0.1.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/org/apache/kerby/kerby-config/1.0.1/kerby-config-1.0.1.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/org/apache/kerby/kerb-core/1.0.1/kerb-core-1.0.1.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/org/apache/kerby/kerby-pkix/1.0.1/kerby-pkix-1.0.1.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/org/apache/kerby/kerby-asn1/1.0.1/kerby-asn1-1.0.1.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/org/apache/kerby/kerby-util/1.0.1/kerby-util-1.0.1.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/org/apache/kerby/kerb-common/1.0.1/kerb-common-1.0.1.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/org/apache/kerby/kerb-crypto/1.0.1/kerb-crypto-1.0.1.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/org/apache/kerby/kerb-util/1.0.1/kerb-util-1.0.1.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/org/apache/kerby/token-provider/1.0.1/token-provider-1.0.1.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/org/apache/kerby/kerb-admin/1.0.1/kerb-admin-1.0.1.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/org/apache/kerby/kerb-server/1.0.1/kerb-server-1.0.1.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/org/apache/kerby/kerb-identity/1.0.1/kerb-identity-1.0.1.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/org/apache/kerby/kerby-xdr/1.0.1/kerby-xdr-1.0.1.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/org/codehaus/woodstox/stax2-api/3.1.4/stax2-api-3.1.4.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/com/fasterxml/woodstox/woodstox-core/5.0.3/woodstox-core-5.0.3.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/junit/junit/4.11/junit-4.11.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/org/hamcrest/hamcrest-core/1.3/hamcrest-core-1.3.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/org/mockito/mockito-all/1.8.5/mockito-all-1.8.5.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/io/netty/netty-all/4.0.52.Final/netty-all-4.0.52.Final.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/org/mock-server/mockserver-netty/3.9.2/mockserver-netty-3.9.2.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/org/mock-server/mockserver-client-java/3.9.2/mockserver-client-java-3.9.2.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/org/mock-server/mockserver-core/3.9.2/mockserver-core-3.9.2.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/io/netty/netty-codec-socks/4.0.24.Final/netty-codec-socks-4.0.24.Final.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/org/skyscreamer/jsonassert/1.3.0/jsonassert-1.3.0.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/org/json/json/20090211/json-20090211.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/org/bouncycastle/bcprov-jdk15on/1.51/bcprov-jdk15on-1.51.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/ch/qos/logback/logback-classic/1.1.2/logback-classic-1.1.2.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/ch/qos/logback/logback-core/1.1.2/logback-core-1.1.2.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/org/apache/hadoop/hadoop-common/3.1.1/hadoop-common-3.1.1-tests.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/commons-logging/commons-logging/1.1.3/commons-logging-1.1.3.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/log4j/log4j/1.2.17/log4j-1.2.17.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/com/fasterxml/jackson/core/jackson-annotations/2.7.8/jackson-annotations-2.7.8.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/com/fasterxml/jackson/core/jackson-databind/2.7.8/jackson-databind-2.7.8.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/com/fasterxml/jackson/core/jackson-core/2.7.8/jackson-core-2.7.8.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/org/apache/hadoop/hadoop-annotations/3.1.1/hadoop-annotations-3.1.1.jar</AuxClasspathEntry><AuxClasspathEntry>/usr/lib/jvm/java-8-openjdk-amd64/jre/../lib/tools.jar</AuxClasspathEntry><SrcDir>./hadoop/hadoop-hdfs-project/hadoop-hdfs-client/src/main/java</SrcDir><SrcDir>./hadoop/hadoop-hdfs-project/hadoop-hdfs-client/src/test/java</SrcDir><WrkDir>./hadoop/hadoop-hdfs-project/hadoop-hdfs-client/target</WrkDir></Project><BugInstance instanceOccurrenceNum='0' instanceHash='df7cd3e1ed4ac62df2ef63ab3e2f5268' cweid='253' rank='16' abbrev='RV' category='BAD_PRACTICE' priority='2' type='RV_RETURN_VALUE_IGNORED_BAD_PRACTICE' instanceOccurrenceMax='0'><ShortMessage>Method ignores exceptional return value</ShortMessage><LongMessage>Exceptional return value of java.io.File.createNewFile() ignored in org.apache.hadoop.fs.TestUrlStreamHandlerFactory.testFsUrlStreamHandlerFactory()</LongMessage><Class classname='org.apache.hadoop.fs.TestUrlStreamHandlerFactory' primary='true'><SourceLine classname='org.apache.hadoop.fs.TestUrlStreamHandlerFactory' start='38' end='99' sourcepath='org/apache/hadoop/fs/TestUrlStreamHandlerFactory.java' sourcefile='TestUrlStreamHandlerFactory.java'><Message>At TestUrlStreamHandlerFactory.java:[lines 38-99]</Message></SourceLine><Message>In class org.apache.hadoop.fs.TestUrlStreamHandlerFactory</Message></Class><Method isStatic='false' classname='org.apache.hadoop.fs.TestUrlStreamHandlerFactory' signature='()V' name='testFsUrlStreamHandlerFactory' primary='true'><SourceLine endBytecode='156' classname='org.apache.hadoop.fs.TestUrlStreamHandlerFactory' start='84' end='99' sourcepath='org/apache/hadoop/fs/TestUrlStreamHandlerFactory.java' sourcefile='TestUrlStreamHandlerFactory.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.fs.TestUrlStreamHandlerFactory.testFsUrlStreamHandlerFactory()</Message></Method><Method isStatic='false' role='METHOD_CALLED' classname='java.io.File' signature='()Z' name='createNewFile'><SourceLine endBytecode='98' classname='java.io.File' start='1007' end='1012' sourcepath='java/io/File.java' sourcefile='File.java' startBytecode='0'></SourceLine><Message>Called method java.io.File.createNewFile()</Message></Method><SourceLine endBytecode='14' classname='org.apache.hadoop.fs.TestUrlStreamHandlerFactory' start='85' end='85' sourcepath='org/apache/hadoop/fs/TestUrlStreamHandlerFactory.java' sourcefile='TestUrlStreamHandlerFactory.java' startBytecode='14' primary='true'><Message>At TestUrlStreamHandlerFactory.java:[line 85]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='6a01ff31bb4fea1a0398a6d769917b76' rank='20' abbrev='SIC' category='PERFORMANCE' priority='3' type='SIC_INNER_SHOULD_BE_STATIC_ANON' instanceOccurrenceMax='0'><ShortMessage>Could be refactored into a named static inner class</ShortMessage><LongMessage>The class org.apache.hadoop.fs.TestUrlStreamHandlerFactory$1 could be refactored into a named _static_ inner class</LongMessage><Class role='CLASS_ANONYMOUS' classname='org.apache.hadoop.fs.TestUrlStreamHandlerFactory$1'><SourceLine classname='org.apache.hadoop.fs.TestUrlStreamHandlerFactory$1' start='62' end='67' sourcepath='org/apache/hadoop/fs/TestUrlStreamHandlerFactory.java' sourcefile='TestUrlStreamHandlerFactory.java'><Message>At TestUrlStreamHandlerFactory.java:[lines 62-67]</Message></SourceLine><Message>Anonymous class org.apache.hadoop.fs.TestUrlStreamHandlerFactory$1</Message></Class><Class classname='org.apache.hadoop.fs.TestUrlStreamHandlerFactory' primary='true'><SourceLine classname='org.apache.hadoop.fs.TestUrlStreamHandlerFactory' start='38' end='99' sourcepath='org/apache/hadoop/fs/TestUrlStreamHandlerFactory.java' sourcefile='TestUrlStreamHandlerFactory.java'><Message>At TestUrlStreamHandlerFactory.java:[lines 38-99]</Message></SourceLine><Message>In class org.apache.hadoop.fs.TestUrlStreamHandlerFactory</Message></Class><Method isStatic='false' classname='org.apache.hadoop.fs.TestUrlStreamHandlerFactory' signature='()V' name='singleRun' primary='true'><SourceLine endBytecode='373' classname='org.apache.hadoop.fs.TestUrlStreamHandlerFactory' start='55' end='80' sourcepath='org/apache/hadoop/fs/TestUrlStreamHandlerFactory.java' sourcefile='TestUrlStreamHandlerFactory.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.fs.TestUrlStreamHandlerFactory.singleRun()</Message></Method><SourceLine endBytecode='61' classname='org.apache.hadoop.fs.TestUrlStreamHandlerFactory' start='62' end='62' sourcepath='org/apache/hadoop/fs/TestUrlStreamHandlerFactory.java' sourcefile='TestUrlStreamHandlerFactory.java' startBytecode='61' primary='true'><Message>At TestUrlStreamHandlerFactory.java:[line 62]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='b70464760be6ceafd4df5bdb075a0405' rank='18' abbrev='UrF' category='STYLE' priority='2' type='URF_UNREAD_PUBLIC_OR_PROTECTED_FIELD' instanceOccurrenceMax='0'><ShortMessage>Unread public/protected field</ShortMessage><LongMessage>Unread public/protected field: org.apache.hadoop.fs.TestUrlStreamHandlerFactory.globalTimeout</LongMessage><Class classname='org.apache.hadoop.fs.TestUrlStreamHandlerFactory' primary='true'><SourceLine classname='org.apache.hadoop.fs.TestUrlStreamHandlerFactory' start='38' end='99' sourcepath='org/apache/hadoop/fs/TestUrlStreamHandlerFactory.java' sourcefile='TestUrlStreamHandlerFactory.java'><Message>At TestUrlStreamHandlerFactory.java:[lines 38-99]</Message></SourceLine><Message>In class org.apache.hadoop.fs.TestUrlStreamHandlerFactory</Message></Class><Field isStatic='false' classname='org.apache.hadoop.fs.TestUrlStreamHandlerFactory' signature='Lorg/junit/rules/Timeout;' name='globalTimeout' primary='true'><SourceLine classname='org.apache.hadoop.fs.TestUrlStreamHandlerFactory' sourcepath='org/apache/hadoop/fs/TestUrlStreamHandlerFactory.java' sourcefile='TestUrlStreamHandlerFactory.java'><Message>In TestUrlStreamHandlerFactory.java</Message></SourceLine><Message>Field org.apache.hadoop.fs.TestUrlStreamHandlerFactory.globalTimeout</Message></Field><SourceLine endBytecode='15' classname='org.apache.hadoop.fs.TestUrlStreamHandlerFactory' start='44' end='44' sourcepath='org/apache/hadoop/fs/TestUrlStreamHandlerFactory.java' sourcefile='TestUrlStreamHandlerFactory.java' startBytecode='15' primary='true'><Message>At TestUrlStreamHandlerFactory.java:[line 44]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='561aa400e060fda0ee6dce3f70240' cweid='374' rank='18' abbrev='EI' category='MALICIOUS_CODE' priority='2' type='EI_EXPOSE_REP' instanceOccurrenceMax='0'><ShortMessage>May expose internal representation by returning reference to mutable object</ShortMessage><LongMessage>org.apache.hadoop.fs.XAttr.getValue() may expose internal representation by returning XAttr.value</LongMessage><Class classname='org.apache.hadoop.fs.XAttr' primary='true'><SourceLine classname='org.apache.hadoop.fs.XAttr' start='58' end='161' sourcepath='org/apache/hadoop/fs/XAttr.java' sourcefile='XAttr.java'><Message>At XAttr.java:[lines 58-161]</Message></SourceLine><Message>In class org.apache.hadoop.fs.XAttr</Message></Class><Method isStatic='false' classname='org.apache.hadoop.fs.XAttr' signature='()[B' name='getValue' primary='true'><SourceLine endBytecode='46' classname='org.apache.hadoop.fs.XAttr' start='112' end='112' sourcepath='org/apache/hadoop/fs/XAttr.java' sourcefile='XAttr.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.fs.XAttr.getValue()</Message></Method><Field isStatic='false' classname='org.apache.hadoop.fs.XAttr' signature='[B' name='value' primary='true'><SourceLine classname='org.apache.hadoop.fs.XAttr' sourcepath='org/apache/hadoop/fs/XAttr.java' sourcefile='XAttr.java'><Message>In XAttr.java</Message></SourceLine><Message>Field org.apache.hadoop.fs.XAttr.value</Message></Field><SourceLine endBytecode='4' classname='org.apache.hadoop.fs.XAttr' start='112' end='112' sourcepath='org/apache/hadoop/fs/XAttr.java' sourcefile='XAttr.java' startBytecode='4' primary='true'><Message>At XAttr.java:[line 112]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='6bc4eda9a029c1361b5cf31b705db0db' cweid='374' rank='18' abbrev='EI2' category='MALICIOUS_CODE' priority='2' type='EI_EXPOSE_REP2' instanceOccurrenceMax='0'><ShortMessage>May expose internal representation by incorporating reference to mutable object</ShortMessage><LongMessage>org.apache.hadoop.fs.XAttr$Builder.setValue(byte[]) may expose internal representation by storing an externally mutable object into XAttr$Builder.value</LongMessage><Class classname='org.apache.hadoop.fs.XAttr$Builder' primary='true'><SourceLine classname='org.apache.hadoop.fs.XAttr$Builder' start='72' end='93' sourcepath='org/apache/hadoop/fs/XAttr.java' sourcefile='XAttr.java'><Message>At XAttr.java:[lines 72-93]</Message></SourceLine><Message>In class org.apache.hadoop.fs.XAttr$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.fs.XAttr$Builder' signature='([B)Lorg/apache/hadoop/fs/XAttr$Builder;' name='setValue' primary='true'><SourceLine endBytecode='62' classname='org.apache.hadoop.fs.XAttr$Builder' start='88' end='89' sourcepath='org/apache/hadoop/fs/XAttr.java' sourcefile='XAttr.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.fs.XAttr$Builder.setValue(byte[])</Message></Method><Field isStatic='false' classname='org.apache.hadoop.fs.XAttr$Builder' signature='[B' name='value' primary='true'><SourceLine classname='org.apache.hadoop.fs.XAttr$Builder' sourcepath='org/apache/hadoop/fs/XAttr.java' sourcefile='XAttr.java'><Message>In XAttr.java</Message></SourceLine><Message>Field org.apache.hadoop.fs.XAttr$Builder.value</Message></Field><LocalVariable role='LOCAL_VARIABLE_NAMED' pc='2' name='value' register='1'><Message>Local variable named value</Message></LocalVariable><SourceLine endBytecode='2' classname='org.apache.hadoop.fs.XAttr$Builder' start='88' end='88' sourcepath='org/apache/hadoop/fs/XAttr.java' sourcefile='XAttr.java' startBytecode='2' primary='true'><Message>At XAttr.java:[line 88]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='891bc6a18ffade8e3410ef2deacffbd5' cweid='366' rank='20' abbrev='IS' category='MT_CORRECTNESS' priority='3' type='IS2_INCONSISTENT_SYNC' instanceOccurrenceMax='0'><ShortMessage>Inconsistent synchronization</ShortMessage><LongMessage>Inconsistent synchronization of org.apache.hadoop.hdfs.DFSClient.encryptionKey; locked 83% of time</LongMessage><Class classname='org.apache.hadoop.hdfs.DFSClient' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.DFSClient' start='205' end='3143' sourcepath='org/apache/hadoop/hdfs/DFSClient.java' sourcefile='DFSClient.java'><Message>At DFSClient.java:[lines 205-3143]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.DFSClient</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.DFSClient' signature='Lorg/apache/hadoop/hdfs/security/token/block/DataEncryptionKey;' name='encryptionKey' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.DFSClient' sourcepath='org/apache/hadoop/hdfs/DFSClient.java' sourcefile='DFSClient.java'><Message>In DFSClient.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.DFSClient.encryptionKey</Message></Field><Int role='INT_SYNC_PERCENT' value='83'><Message>Synchronized 83% of the time</Message></Int><SourceLine role='SOURCE_LINE_UNSYNC_ACCESS' endBytecode='1' classname='org.apache.hadoop.hdfs.DFSClient' start='1755' end='1755' sourcepath='org/apache/hadoop/hdfs/DFSClient.java' sourcefile='DFSClient.java' startBytecode='1' primary='true'><Message>Unsynchronized access at DFSClient.java:[line 1755]</Message></SourceLine><SourceLine role='SOURCE_LINE_SYNC_ACCESS' endBytecode='17' classname='org.apache.hadoop.hdfs.DFSClient' start='1723' end='1723' sourcepath='org/apache/hadoop/hdfs/DFSClient.java' sourcefile='DFSClient.java' startBytecode='17'><Message>Synchronized access at DFSClient.java:[line 1723]</Message></SourceLine><SourceLine role='SOURCE_LINE_SYNC_ACCESS' endBytecode='12' classname='org.apache.hadoop.hdfs.DFSClient' start='1741' end='1741' sourcepath='org/apache/hadoop/hdfs/DFSClient.java' sourcefile='DFSClient.java' startBytecode='12'><Message>Synchronized access at DFSClient.java:[line 1741]</Message></SourceLine><SourceLine role='SOURCE_LINE_SYNC_ACCESS' endBytecode='19' classname='org.apache.hadoop.hdfs.DFSClient' start='1741' end='1741' sourcepath='org/apache/hadoop/hdfs/DFSClient.java' sourcefile='DFSClient.java' startBytecode='19'><Message>Synchronized access at DFSClient.java:[line 1741]</Message></SourceLine><SourceLine role='SOURCE_LINE_SYNC_ACCESS' endBytecode='53' classname='org.apache.hadoop.hdfs.DFSClient' start='1744' end='1744' sourcepath='org/apache/hadoop/hdfs/DFSClient.java' sourcefile='DFSClient.java' startBytecode='53'><Message>Synchronized access at DFSClient.java:[line 1744]</Message></SourceLine><SourceLine role='SOURCE_LINE_SYNC_ACCESS' endBytecode='57' classname='org.apache.hadoop.hdfs.DFSClient' start='1746' end='1746' sourcepath='org/apache/hadoop/hdfs/DFSClient.java' sourcefile='DFSClient.java' startBytecode='57'><Message>Synchronized access at DFSClient.java:[line 1746]</Message></SourceLine><Property name='edu.umd.cs.findbugs.detect.InconsistentSyncWarningProperty.ONLY_UNSYNC_IN_GETTERS' value='true'></Property></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='1e59b6cfe0aafbb2095b051bb9fe378c' rank='19' abbrev='UC' category='STYLE' priority='3' type='UC_USELESS_CONDITION' instanceOccurrenceMax='0'><ShortMessage>Condition has no effect</ShortMessage><LongMessage>Useless condition: it's known that namespaceQuota != Long.MAX_VALUE at this point</LongMessage><Class classname='org.apache.hadoop.hdfs.DFSClient' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.DFSClient' start='205' end='3143' sourcepath='org/apache/hadoop/hdfs/DFSClient.java' sourcefile='DFSClient.java'><Message>At DFSClient.java:[lines 205-3143]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.DFSClient</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.DFSClient' signature='(Ljava/lang/String;JJ)V' name='setQuota' primary='true'><SourceLine endBytecode='538' classname='org.apache.hadoop.hdfs.DFSClient' start='2473' end='2498' sourcepath='org/apache/hadoop/hdfs/DFSClient.java' sourcefile='DFSClient.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.DFSClient.setQuota(String, long, long)</Message></Method><String value='namespaceQuota != Long.MAX_VALUE'><Message>Value namespaceQuota != Long.MAX_VALUE</Message></String><SourceLine endBytecode='15' classname='org.apache.hadoop.hdfs.DFSClient' start='2475' end='2475' sourcepath='org/apache/hadoop/hdfs/DFSClient.java' sourcefile='DFSClient.java' startBytecode='15' primary='true'><Message>At DFSClient.java:[line 2475]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='c5164a2a1f883364e5433a56a1198afa' rank='19' abbrev='UC' category='STYLE' priority='3' type='UC_USELESS_CONDITION' instanceOccurrenceMax='0'><ShortMessage>Condition has no effect</ShortMessage><LongMessage>Useless condition: it's known that storagespaceQuota != Long.MAX_VALUE at this point</LongMessage><Class classname='org.apache.hadoop.hdfs.DFSClient' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.DFSClient' start='205' end='3143' sourcepath='org/apache/hadoop/hdfs/DFSClient.java' sourcefile='DFSClient.java'><Message>At DFSClient.java:[lines 205-3143]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.DFSClient</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.DFSClient' signature='(Ljava/lang/String;JJ)V' name='setQuota' primary='true'><SourceLine endBytecode='538' classname='org.apache.hadoop.hdfs.DFSClient' start='2473' end='2498' sourcepath='org/apache/hadoop/hdfs/DFSClient.java' sourcefile='DFSClient.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.DFSClient.setQuota(String, long, long)</Message></Method><String value='storagespaceQuota != Long.MAX_VALUE'><Message>Value storagespaceQuota != Long.MAX_VALUE</Message></String><SourceLine endBytecode='39' classname='org.apache.hadoop.hdfs.DFSClient' start='2475' end='2475' sourcepath='org/apache/hadoop/hdfs/DFSClient.java' sourcefile='DFSClient.java' startBytecode='39' primary='true'><Message>At DFSClient.java:[line 2475]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='34754688437493f2dc992698cfe5b74f' rank='19' abbrev='UC' category='STYLE' priority='3' type='UC_USELESS_CONDITION' instanceOccurrenceMax='0'><ShortMessage>Condition has no effect</ShortMessage><LongMessage>Useless condition: it's known that quota != Long.MAX_VALUE at this point</LongMessage><Class classname='org.apache.hadoop.hdfs.DFSClient' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.DFSClient' start='205' end='3143' sourcepath='org/apache/hadoop/hdfs/DFSClient.java' sourcefile='DFSClient.java'><Message>At DFSClient.java:[lines 205-3143]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.DFSClient</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.DFSClient' signature='(Ljava/lang/String;Lorg/apache/hadoop/fs/StorageType;J)V' name='setQuotaByStorageType' primary='true'><SourceLine endBytecode='568' classname='org.apache.hadoop.hdfs.DFSClient' start='2506' end='2528' sourcepath='org/apache/hadoop/hdfs/DFSClient.java' sourcefile='DFSClient.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.DFSClient.setQuotaByStorageType(String, StorageType, long)</Message></Method><String value='quota != Long.MAX_VALUE'><Message>Value quota != Long.MAX_VALUE</Message></String><SourceLine endBytecode='15' classname='org.apache.hadoop.hdfs.DFSClient' start='2507' end='2507' sourcepath='org/apache/hadoop/hdfs/DFSClient.java' sourcefile='DFSClient.java' startBytecode='15' primary='true'><Message>At DFSClient.java:[line 2507]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='a9ec560db7e3b5ac5628b95af2c53bc5' cweid='218' rank='20' abbrev='MS' category='MALICIOUS_CODE' priority='3' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.DFSClientFaultInjector.exceptionNum isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.DFSClientFaultInjector' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.DFSClientFaultInjector' start='32' end='67' sourcepath='org/apache/hadoop/hdfs/DFSClientFaultInjector.java' sourcefile='DFSClientFaultInjector.java'><Message>At DFSClientFaultInjector.java:[lines 32-67]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.DFSClientFaultInjector</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.DFSClientFaultInjector' signature='Ljava/util/concurrent/atomic/AtomicLong;' name='exceptionNum' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.DFSClientFaultInjector' sourcepath='org/apache/hadoop/hdfs/DFSClientFaultInjector.java' sourcefile='DFSClientFaultInjector.java'><Message>In DFSClientFaultInjector.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.DFSClientFaultInjector.exceptionNum</Message></Field><SourceLine endBytecode='18' classname='org.apache.hadoop.hdfs.DFSClientFaultInjector' start='34' end='34' sourcepath='org/apache/hadoop/hdfs/DFSClientFaultInjector.java' sourcefile='DFSClientFaultInjector.java' startBytecode='18' primary='true'><Message>At DFSClientFaultInjector.java:[line 34]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='570bc54ecc3be5c8775090965096df20' rank='20' abbrev='UrF' category='STYLE' priority='3' type='URF_UNREAD_PUBLIC_OR_PROTECTED_FIELD' instanceOccurrenceMax='0'><ShortMessage>Unread public/protected field</ShortMessage><LongMessage>Unread public/protected field: org.apache.hadoop.hdfs.DFSClientFaultInjector.exceptionNum</LongMessage><Class classname='org.apache.hadoop.hdfs.DFSClientFaultInjector' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.DFSClientFaultInjector' start='32' end='67' sourcepath='org/apache/hadoop/hdfs/DFSClientFaultInjector.java' sourcefile='DFSClientFaultInjector.java'><Message>At DFSClientFaultInjector.java:[lines 32-67]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.DFSClientFaultInjector</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.DFSClientFaultInjector' signature='Ljava/util/concurrent/atomic/AtomicLong;' name='exceptionNum' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.DFSClientFaultInjector' sourcepath='org/apache/hadoop/hdfs/DFSClientFaultInjector.java' sourcefile='DFSClientFaultInjector.java'><Message>In DFSClientFaultInjector.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.DFSClientFaultInjector.exceptionNum</Message></Field><SourceLine endBytecode='18' classname='org.apache.hadoop.hdfs.DFSClientFaultInjector' start='34' end='34' sourcepath='org/apache/hadoop/hdfs/DFSClientFaultInjector.java' sourcefile='DFSClientFaultInjector.java' startBytecode='18' primary='true'><Message>At DFSClientFaultInjector.java:[line 34]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='df9622e7505b8c955f5701672e91a8b0' cweid='366' rank='17' abbrev='IS' category='MT_CORRECTNESS' priority='2' type='IS2_INCONSISTENT_SYNC' instanceOccurrenceMax='0'><ShortMessage>Inconsistent synchronization</ShortMessage><LongMessage>Inconsistent synchronization of org.apache.hadoop.hdfs.DFSInputStream.cachingStrategy; locked 80% of time</LongMessage><Class classname='org.apache.hadoop.hdfs.DFSInputStream' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.DFSInputStream' start='96' end='1772' sourcepath='org/apache/hadoop/hdfs/DFSInputStream.java' sourcefile='DFSInputStream.java'><Message>At DFSInputStream.java:[lines 96-1772]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.DFSInputStream</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.DFSInputStream' signature='Lorg/apache/hadoop/hdfs/server/datanode/CachingStrategy;' name='cachingStrategy' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.DFSInputStream' sourcepath='org/apache/hadoop/hdfs/DFSInputStream.java' sourcefile='DFSInputStream.java'><Message>In DFSInputStream.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.DFSInputStream.cachingStrategy</Message></Field><Int role='INT_SYNC_PERCENT' value='80'><Message>Synchronized 80% of the time</Message></Int><SourceLine role='SOURCE_LINE_UNSYNC_ACCESS' endBytecode='21' classname='org.apache.hadoop.hdfs.DFSInputStream' start='621' end='621' sourcepath='org/apache/hadoop/hdfs/DFSInputStream.java' sourcefile='DFSInputStream.java' startBytecode='21' primary='true'><Message>Unsynchronized access at DFSInputStream.java:[line 621]</Message></SourceLine><SourceLine role='SOURCE_LINE_SYNC_ACCESS' endBytecode='13' classname='org.apache.hadoop.hdfs.DFSInputStream' start='1616' end='1616' sourcepath='org/apache/hadoop/hdfs/DFSInputStream.java' sourcefile='DFSInputStream.java' startBytecode='13'><Message>Synchronized access at DFSInputStream.java:[line 1616]</Message></SourceLine><SourceLine role='SOURCE_LINE_SYNC_ACCESS' endBytecode='26' classname='org.apache.hadoop.hdfs.DFSInputStream' start='1618' end='1618' sourcepath='org/apache/hadoop/hdfs/DFSInputStream.java' sourcefile='DFSInputStream.java' startBytecode='26'><Message>Synchronized access at DFSInputStream.java:[line 1618]</Message></SourceLine><SourceLine role='SOURCE_LINE_SYNC_ACCESS' endBytecode='13' classname='org.apache.hadoop.hdfs.DFSInputStream' start='1605' end='1605' sourcepath='org/apache/hadoop/hdfs/DFSInputStream.java' sourcefile='DFSInputStream.java' startBytecode='13'><Message>Synchronized access at DFSInputStream.java:[line 1605]</Message></SourceLine><SourceLine role='SOURCE_LINE_SYNC_ACCESS' endBytecode='26' classname='org.apache.hadoop.hdfs.DFSInputStream' start='1607' end='1607' sourcepath='org/apache/hadoop/hdfs/DFSInputStream.java' sourcefile='DFSInputStream.java' startBytecode='26'><Message>Synchronized access at DFSInputStream.java:[line 1607]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='96d48afae253cac986bfab09393512' cweid='218' rank='18' abbrev='MS' category='MALICIOUS_CODE' priority='2' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.DFSInputStream.tcpReadsDisabledForTesting isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.DFSInputStream' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.DFSInputStream' start='96' end='1772' sourcepath='org/apache/hadoop/hdfs/DFSInputStream.java' sourcefile='DFSInputStream.java'><Message>At DFSInputStream.java:[lines 96-1772]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.DFSInputStream</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.DFSInputStream' signature='Z' name='tcpReadsDisabledForTesting' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.DFSInputStream' sourcepath='org/apache/hadoop/hdfs/DFSInputStream.java' sourcefile='DFSInputStream.java'><Message>In DFSInputStream.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.DFSInputStream.tcpReadsDisabledForTesting</Message></Field><SourceLine endBytecode='18' classname='org.apache.hadoop.hdfs.DFSInputStream' start='101' end='101' sourcepath='org/apache/hadoop/hdfs/DFSInputStream.java' sourcefile='DFSInputStream.java' startBytecode='18' primary='true'><Message>At DFSInputStream.java:[line 101]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='7bd700d8d70d1fd1d47ef0d8a1a5aad6' rank='20' abbrev='SIC' category='PERFORMANCE' priority='3' type='SIC_INNER_SHOULD_BE_STATIC_ANON' instanceOccurrenceMax='0'><ShortMessage>Could be refactored into a named static inner class</ShortMessage><LongMessage>The class org.apache.hadoop.hdfs.DFSInputStream$1 could be refactored into a named _static_ inner class</LongMessage><Class role='CLASS_ANONYMOUS' classname='org.apache.hadoop.hdfs.DFSInputStream$1'><SourceLine classname='org.apache.hadoop.hdfs.DFSInputStream$1' start='657' end='663' sourcepath='org/apache/hadoop/hdfs/DFSInputStream.java' sourcefile='DFSInputStream.java'><Message>At DFSInputStream.java:[lines 657-663]</Message></SourceLine><Message>Anonymous class org.apache.hadoop.hdfs.DFSInputStream$1</Message></Class><Class classname='org.apache.hadoop.hdfs.DFSInputStream' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.DFSInputStream' start='96' end='1772' sourcepath='org/apache/hadoop/hdfs/DFSInputStream.java' sourcefile='DFSInputStream.java'><Message>At DFSInputStream.java:[lines 96-1772]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.DFSInputStream</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.DFSInputStream' signature='()V' name='close' primary='true'><SourceLine endBytecode='238' classname='org.apache.hadoop.hdfs.DFSInputStream' start='649' end='671' sourcepath='org/apache/hadoop/hdfs/DFSInputStream.java' sourcefile='DFSInputStream.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.DFSInputStream.close()</Message></Method><SourceLine endBytecode='65' classname='org.apache.hadoop.hdfs.DFSInputStream' start='657' end='657' sourcepath='org/apache/hadoop/hdfs/DFSInputStream.java' sourcefile='DFSInputStream.java' startBytecode='65' primary='true'><Message>At DFSInputStream.java:[line 657]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='6393cd97759127bcf3810471b604f8bd' cweid='366' rank='20' abbrev='IS' category='MT_CORRECTNESS' priority='3' type='IS2_INCONSISTENT_SYNC' instanceOccurrenceMax='0'><ShortMessage>Inconsistent synchronization</ShortMessage><LongMessage>Inconsistent synchronization of org.apache.hadoop.hdfs.DFSOutputStream.streamer; locked 80% of time</LongMessage><Class classname='org.apache.hadoop.hdfs.DFSOutputStream' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.DFSOutputStream' start='93' end='1114' sourcepath='org/apache/hadoop/hdfs/DFSOutputStream.java' sourcefile='DFSOutputStream.java'><Message>At DFSOutputStream.java:[lines 93-1114]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.DFSOutputStream</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.DFSOutputStream' signature='Lorg/apache/hadoop/hdfs/DataStreamer;' name='streamer' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.DFSOutputStream' sourcepath='org/apache/hadoop/hdfs/DFSOutputStream.java' sourcefile='DFSOutputStream.java'><Message>In DFSOutputStream.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.DFSOutputStream.streamer</Message></Field><Int role='INT_SYNC_PERCENT' value='80'><Message>Synchronized 80% of the time</Message></Int><SourceLine role='SOURCE_LINE_UNSYNC_ACCESS' endBytecode='1' classname='org.apache.hadoop.hdfs.DFSOutputStream' start='1060' end='1060' sourcepath='org/apache/hadoop/hdfs/DFSOutputStream.java' sourcefile='DFSOutputStream.java' startBytecode='1' primary='true'><Message>Unsynchronized access at DFSOutputStream.java:[line 1060]</Message></SourceLine><SourceLine role='SOURCE_LINE_SYNC_ACCESS' endBytecode='24' classname='org.apache.hadoop.hdfs.DFSOutputStream' start='1065' end='1065' sourcepath='org/apache/hadoop/hdfs/DFSOutputStream.java' sourcefile='DFSOutputStream.java' startBytecode='24'><Message>Synchronized access at DFSOutputStream.java:[line 1065]</Message></SourceLine><SourceLine role='SOURCE_LINE_SYNC_ACCESS' endBytecode='1' classname='org.apache.hadoop.hdfs.DFSStripedOutputStream' start='344' end='344' sourcepath='org/apache/hadoop/hdfs/DFSStripedOutputStream.java' sourcefile='DFSStripedOutputStream.java' startBytecode='1'><Message>Synchronized access at DFSStripedOutputStream.java:[line 344]</Message></SourceLine><SourceLine role='SOURCE_LINE_SYNC_ACCESS' endBytecode='41' classname='org.apache.hadoop.hdfs.DFSStripedOutputStream' start='351' end='351' sourcepath='org/apache/hadoop/hdfs/DFSStripedOutputStream.java' sourcefile='DFSStripedOutputStream.java' startBytecode='41'><Message>Synchronized access at DFSStripedOutputStream.java:[line 351]</Message></SourceLine><SourceLine role='SOURCE_LINE_SYNC_ACCESS' endBytecode='1' classname='org.apache.hadoop.hdfs.DFSStripedOutputStream' start='339' end='339' sourcepath='org/apache/hadoop/hdfs/DFSStripedOutputStream.java' sourcefile='DFSStripedOutputStream.java' startBytecode='1'><Message>Synchronized access at DFSStripedOutputStream.java:[line 339]</Message></SourceLine><SourceLine role='SOURCE_LINE_SYNC_ACCESS' endBytecode='181' classname='org.apache.hadoop.hdfs.DFSStripedOutputStream' start='432' end='432' sourcepath='org/apache/hadoop/hdfs/DFSStripedOutputStream.java' sourcefile='DFSStripedOutputStream.java' startBytecode='181'><Message>Synchronized access at DFSStripedOutputStream.java:[line 432]</Message></SourceLine><Property name='edu.umd.cs.findbugs.detect.InconsistentSyncWarningProperty.ONLY_UNSYNC_IN_GETTERS' value='true'></Property></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='97e560d19fd16775bcc01f615e6298fd' rank='20' abbrev='PZLA' category='STYLE' priority='3' type='PZLA_PREFER_ZERO_LENGTH_ARRAYS' instanceOccurrenceMax='0'><ShortMessage>Consider returning a zero length array rather than null</ShortMessage><LongMessage>Should org.apache.hadoop.hdfs.DFSOutputStream.getPipeline() return a zero length array rather than null?</LongMessage><Class classname='org.apache.hadoop.hdfs.DFSOutputStream' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.DFSOutputStream' start='93' end='1114' sourcepath='org/apache/hadoop/hdfs/DFSOutputStream.java' sourcefile='DFSOutputStream.java'><Message>At DFSOutputStream.java:[lines 93-1114]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.DFSOutputStream</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.DFSOutputStream' signature='()[Lorg/apache/hadoop/hdfs/protocol/DatanodeInfo;' name='getPipeline' primary='true'><SourceLine endBytecode='147' classname='org.apache.hadoop.hdfs.DFSOutputStream' start='162' end='171' sourcepath='org/apache/hadoop/hdfs/DFSOutputStream.java' sourcefile='DFSOutputStream.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.DFSOutputStream.getPipeline()</Message></Method><SourceLine endBytecode='11' classname='org.apache.hadoop.hdfs.DFSOutputStream' start='163' end='163' sourcepath='org/apache/hadoop/hdfs/DFSOutputStream.java' sourcefile='DFSOutputStream.java' startBytecode='11' primary='true'><Message>At DFSOutputStream.java:[line 163]</Message></SourceLine><SourceLine endBytecode='25' classname='org.apache.hadoop.hdfs.DFSOutputStream' start='167' end='167' sourcepath='org/apache/hadoop/hdfs/DFSOutputStream.java' sourcefile='DFSOutputStream.java' startBytecode='25'><Message>At DFSOutputStream.java:[line 167]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='9d85a34e1f5610b0db62e365e55f6c16' cweid='374' rank='18' abbrev='EI' category='MALICIOUS_CODE' priority='2' type='EI_EXPOSE_REP' instanceOccurrenceMax='0'><ShortMessage>May expose internal representation by returning reference to mutable object</ShortMessage><LongMessage>org.apache.hadoop.hdfs.DFSPacket.getTraceParents() may expose internal representation by returning DFSPacket.traceParents</LongMessage><Class classname='org.apache.hadoop.hdfs.DFSPacket' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.DFSPacket' start='41' end='362' sourcepath='org/apache/hadoop/hdfs/DFSPacket.java' sourcefile='DFSPacket.java'><Message>At DFSPacket.java:[lines 41-362]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.DFSPacket</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.DFSPacket' signature='()[Lorg/apache/htrace/core/SpanId;' name='getTraceParents' primary='true'><SourceLine endBytecode='298' classname='org.apache.hadoop.hdfs.DFSPacket' start='334' end='354' sourcepath='org/apache/hadoop/hdfs/DFSPacket.java' sourcefile='DFSPacket.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.DFSPacket.getTraceParents()</Message></Method><Field isStatic='false' classname='org.apache.hadoop.hdfs.DFSPacket' signature='[Lorg/apache/htrace/core/SpanId;' name='traceParents' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.DFSPacket' sourcepath='org/apache/hadoop/hdfs/DFSPacket.java' sourcefile='DFSPacket.java'><Message>In DFSPacket.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.DFSPacket.traceParents</Message></Field><SourceLine endBytecode='107' classname='org.apache.hadoop.hdfs.DFSPacket' start='354' end='354' sourcepath='org/apache/hadoop/hdfs/DFSPacket.java' sourcefile='DFSPacket.java' startBytecode='107' primary='true'><Message>At DFSPacket.java:[line 354]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='d2d2a8b5bec7dc4f8737b9394c7c8394' cweid='374' rank='18' abbrev='EI2' category='MALICIOUS_CODE' priority='2' type='EI_EXPOSE_REP2' instanceOccurrenceMax='0'><ShortMessage>May expose internal representation by incorporating reference to mutable object</ShortMessage><LongMessage>new org.apache.hadoop.hdfs.DFSPacket(byte[], int, long, long, int, boolean) may expose internal representation by storing an externally mutable object into DFSPacket.buf</LongMessage><Class classname='org.apache.hadoop.hdfs.DFSPacket' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.DFSPacket' start='41' end='362' sourcepath='org/apache/hadoop/hdfs/DFSPacket.java' sourcefile='DFSPacket.java'><Message>At DFSPacket.java:[lines 41-362]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.DFSPacket</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.DFSPacket' signature='([BIJJIZ)V' name='&lt;init&gt;' primary='true'><SourceLine endBytecode='229' classname='org.apache.hadoop.hdfs.DFSPacket' start='86' end='99' sourcepath='org/apache/hadoop/hdfs/DFSPacket.java' sourcefile='DFSPacket.java' startBytecode='0'></SourceLine><Message>In method new org.apache.hadoop.hdfs.DFSPacket(byte[], int, long, long, int, boolean)</Message></Method><Field isStatic='false' classname='org.apache.hadoop.hdfs.DFSPacket' signature='[B' name='buf' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.DFSPacket' sourcepath='org/apache/hadoop/hdfs/DFSPacket.java' sourcefile='DFSPacket.java'><Message>In DFSPacket.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.DFSPacket.buf</Message></Field><LocalVariable role='LOCAL_VARIABLE_NAMED' pc='35' name='buf' register='1'><Message>Local variable named buf</Message></LocalVariable><SourceLine endBytecode='35' classname='org.apache.hadoop.hdfs.DFSPacket' start='92' end='92' sourcepath='org/apache/hadoop/hdfs/DFSPacket.java' sourcefile='DFSPacket.java' startBytecode='35' primary='true'><Message>At DFSPacket.java:[line 92]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='6da9d18e12d7be1d48d4439cef44d10a' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from org.apache.hadoop.hdfs.protocol.LocatedBlock to org.apache.hadoop.hdfs.protocol.LocatedStripedBlock in org.apache.hadoop.hdfs.DFSStripedInputStream.readOneStripe(DFSUtilClient$CorruptedBlocks)</LongMessage><Class classname='org.apache.hadoop.hdfs.DFSStripedInputStream' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.DFSStripedInputStream' start='59' end='530' sourcepath='org/apache/hadoop/hdfs/DFSStripedInputStream.java' sourcefile='DFSStripedInputStream.java'><Message>At DFSStripedInputStream.java:[lines 59-530]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.DFSStripedInputStream</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.DFSStripedInputStream' signature='(Lorg/apache/hadoop/hdfs/DFSUtilClient$CorruptedBlocks;)V' name='readOneStripe' primary='true'><SourceLine endBytecode='118' classname='org.apache.hadoop.hdfs.DFSStripedInputStream' start='299' end='327' sourcepath='org/apache/hadoop/hdfs/DFSStripedInputStream.java' sourcefile='DFSStripedInputStream.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.DFSStripedInputStream.readOneStripe(DFSUtilClient$CorruptedBlocks)</Message></Method><Type role='TYPE_FOUND' descriptor='Lorg/apache/hadoop/hdfs/protocol/LocatedBlock;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.LocatedBlock' start='81' end='279' sourcepath='org/apache/hadoop/hdfs/protocol/LocatedBlock.java' sourcefile='LocatedBlock.java'><Message>At LocatedBlock.java:[lines 81-279]</Message></SourceLine><Message>Actual type org.apache.hadoop.hdfs.protocol.LocatedBlock</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/LocatedStripedBlock;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.LocatedStripedBlock' start='36' end='86' sourcepath='org/apache/hadoop/hdfs/protocol/LocatedStripedBlock.java' sourcefile='LocatedStripedBlock.java'><Message>At LocatedStripedBlock.java:[lines 36-86]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.LocatedStripedBlock</Message></Type><Field isStatic='false' role='FIELD_VALUE_OF' classname='org.apache.hadoop.hdfs.DFSInputStream' signature='Lorg/apache/hadoop/hdfs/protocol/LocatedBlock;' name='currentLocatedBlock' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.DFSInputStream' sourcepath='org/apache/hadoop/hdfs/DFSInputStream.java' sourcefile='DFSInputStream.java'><Message>In DFSInputStream.java</Message></SourceLine><Message>Value loaded from field org.apache.hadoop.hdfs.DFSInputStream.currentLocatedBlock</Message></Field><SourceLine endBytecode='78' classname='org.apache.hadoop.hdfs.DFSStripedInputStream' start='311' end='311' sourcepath='org/apache/hadoop/hdfs/DFSStripedInputStream.java' sourcefile='DFSStripedInputStream.java' startBytecode='78' primary='true'><Message>At DFSStripedInputStream.java:[line 311]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='97c3c63cf161a1ccc3ee2edc5ac956db' cweid='366' rank='20' abbrev='IS' category='MT_CORRECTNESS' priority='3' type='IS2_INCONSISTENT_SYNC' instanceOccurrenceMax='0'><ShortMessage>Inconsistent synchronization</ShortMessage><LongMessage>Inconsistent synchronization of org.apache.hadoop.hdfs.DFSStripedInputStream.curStripeBuf; locked 91% of time</LongMessage><Class classname='org.apache.hadoop.hdfs.DFSStripedInputStream' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.DFSStripedInputStream' start='59' end='530' sourcepath='org/apache/hadoop/hdfs/DFSStripedInputStream.java' sourcefile='DFSStripedInputStream.java'><Message>At DFSStripedInputStream.java:[lines 59-530]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.DFSStripedInputStream</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.DFSStripedInputStream' signature='Ljava/nio/ByteBuffer;' name='curStripeBuf' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.DFSStripedInputStream' sourcepath='org/apache/hadoop/hdfs/DFSStripedInputStream.java' sourcefile='DFSStripedInputStream.java'><Message>In DFSStripedInputStream.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.DFSStripedInputStream.curStripeBuf</Message></Field><Int role='INT_SYNC_PERCENT' value='91'><Message>Synchronized 91% of the time</Message></Int><SourceLine role='SOURCE_LINE_UNSYNC_ACCESS' endBytecode='1' classname='org.apache.hadoop.hdfs.DFSStripedInputStream' start='138' end='138' sourcepath='org/apache/hadoop/hdfs/DFSStripedInputStream.java' sourcefile='DFSStripedInputStream.java' startBytecode='1' primary='true'><Message>Unsynchronized access at DFSStripedInputStream.java:[line 138]</Message></SourceLine><SourceLine role='SOURCE_LINE_SYNC_ACCESS' endBytecode='13' classname='org.apache.hadoop.hdfs.DFSStripedInputStream' start='421' end='421' sourcepath='org/apache/hadoop/hdfs/DFSStripedInputStream.java' sourcefile='DFSStripedInputStream.java' startBytecode='13'><Message>Synchronized access at DFSStripedInputStream.java:[line 421]</Message></SourceLine><SourceLine role='SOURCE_LINE_SYNC_ACCESS' endBytecode='24' classname='org.apache.hadoop.hdfs.DFSStripedInputStream' start='422' end='422' sourcepath='org/apache/hadoop/hdfs/DFSStripedInputStream.java' sourcefile='DFSStripedInputStream.java' startBytecode='24'><Message>Synchronized access at DFSStripedInputStream.java:[line 422]</Message></SourceLine><SourceLine role='SOURCE_LINE_SYNC_ACCESS' endBytecode='29' classname='org.apache.hadoop.hdfs.DFSStripedInputStream' start='422' end='422' sourcepath='org/apache/hadoop/hdfs/DFSStripedInputStream.java' sourcefile='DFSStripedInputStream.java' startBytecode='29'><Message>Synchronized access at DFSStripedInputStream.java:[line 422]</Message></SourceLine><SourceLine role='SOURCE_LINE_SYNC_ACCESS' endBytecode='89' classname='org.apache.hadoop.hdfs.DFSStripedInputStream' start='347' end='347' sourcepath='org/apache/hadoop/hdfs/DFSStripedInputStream.java' sourcefile='DFSStripedInputStream.java' startBytecode='89'><Message>Synchronized access at DFSStripedInputStream.java:[line 347]</Message></SourceLine><SourceLine role='SOURCE_LINE_SYNC_ACCESS' endBytecode='104' classname='org.apache.hadoop.hdfs.DFSStripedInputStream' start='314' end='314' sourcepath='org/apache/hadoop/hdfs/DFSStripedInputStream.java' sourcefile='DFSStripedInputStream.java' startBytecode='104'><Message>Synchronized access at DFSStripedInputStream.java:[line 314]</Message></SourceLine><SourceLine role='SOURCE_LINE_SYNC_ACCESS' endBytecode='196' classname='org.apache.hadoop.hdfs.DFSStripedInputStream' start='324' end='324' sourcepath='org/apache/hadoop/hdfs/DFSStripedInputStream.java' sourcefile='DFSStripedInputStream.java' startBytecode='196'><Message>Synchronized access at DFSStripedInputStream.java:[line 324]</Message></SourceLine><SourceLine role='SOURCE_LINE_SYNC_ACCESS' endBytecode='206' classname='org.apache.hadoop.hdfs.DFSStripedInputStream' start='325' end='325' sourcepath='org/apache/hadoop/hdfs/DFSStripedInputStream.java' sourcefile='DFSStripedInputStream.java' startBytecode='206'><Message>Synchronized access at DFSStripedInputStream.java:[line 325]</Message></SourceLine><SourceLine role='SOURCE_LINE_SYNC_ACCESS' endBytecode='37' classname='org.apache.hadoop.hdfs.DFSStripedInputStream' start='122' end='122' sourcepath='org/apache/hadoop/hdfs/DFSStripedInputStream.java' sourcefile='DFSStripedInputStream.java' startBytecode='37'><Message>Synchronized access at DFSStripedInputStream.java:[line 122]</Message></SourceLine><SourceLine role='SOURCE_LINE_SYNC_ACCESS' endBytecode='5' classname='org.apache.hadoop.hdfs.DFSStripedInputStream' start='118' end='118' sourcepath='org/apache/hadoop/hdfs/DFSStripedInputStream.java' sourcefile='DFSStripedInputStream.java' startBytecode='5'><Message>Synchronized access at DFSStripedInputStream.java:[line 118]</Message></SourceLine><SourceLine role='SOURCE_LINE_SYNC_ACCESS' endBytecode='44' classname='org.apache.hadoop.hdfs.DFSStripedInputStream' start='123' end='123' sourcepath='org/apache/hadoop/hdfs/DFSStripedInputStream.java' sourcefile='DFSStripedInputStream.java' startBytecode='44'><Message>Synchronized access at DFSStripedInputStream.java:[line 123]</Message></SourceLine><SourceLine role='SOURCE_LINE_SYNC_ACCESS' endBytecode='33' classname='org.apache.hadoop.hdfs.DFSStripedInputStream' start='119' end='119' sourcepath='org/apache/hadoop/hdfs/DFSStripedInputStream.java' sourcefile='DFSStripedInputStream.java' startBytecode='33'><Message>Synchronized access at DFSStripedInputStream.java:[line 119]</Message></SourceLine><Property name='edu.umd.cs.findbugs.detect.InconsistentSyncWarningProperty.ONLY_UNSYNC_IN_GETTERS' value='true'></Property></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='e9b9621c565886d72faeae41ea5f58ab' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from org.apache.hadoop.hdfs.DataStreamer to org.apache.hadoop.hdfs.StripedDataStreamer in org.apache.hadoop.hdfs.DFSStripedOutputStream.getCurrentStreamer()</LongMessage><Class classname='org.apache.hadoop.hdfs.DFSStripedOutputStream' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.DFSStripedOutputStream' start='80' end='1302' sourcepath='org/apache/hadoop/hdfs/DFSStripedOutputStream.java' sourcefile='DFSStripedOutputStream.java'><Message>At DFSStripedOutputStream.java:[lines 80-1302]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.DFSStripedOutputStream</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.DFSStripedOutputStream' signature='()Lorg/apache/hadoop/hdfs/StripedDataStreamer;' name='getCurrentStreamer' primary='true'><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.DFSStripedOutputStream' start='339' end='339' sourcepath='org/apache/hadoop/hdfs/DFSStripedOutputStream.java' sourcefile='DFSStripedOutputStream.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.DFSStripedOutputStream.getCurrentStreamer()</Message></Method><Type role='TYPE_FOUND' descriptor='Lorg/apache/hadoop/hdfs/DataStreamer;'><SourceLine classname='org.apache.hadoop.hdfs.DataStreamer' start='115' end='2116' sourcepath='org/apache/hadoop/hdfs/DataStreamer.java' sourcefile='DataStreamer.java'><Message>At DataStreamer.java:[lines 115-2116]</Message></SourceLine><Message>Actual type org.apache.hadoop.hdfs.DataStreamer</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/StripedDataStreamer;'><SourceLine classname='org.apache.hadoop.hdfs.StripedDataStreamer' start='46' end='192' sourcepath='org/apache/hadoop/hdfs/StripedDataStreamer.java' sourcefile='StripedDataStreamer.java'><Message>At StripedDataStreamer.java:[lines 46-192]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.StripedDataStreamer</Message></Type><Field isStatic='false' role='FIELD_VALUE_OF' classname='org.apache.hadoop.hdfs.DFSOutputStream' signature='Lorg/apache/hadoop/hdfs/DataStreamer;' name='streamer' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.DFSOutputStream' sourcepath='org/apache/hadoop/hdfs/DFSOutputStream.java' sourcefile='DFSOutputStream.java'><Message>In DFSOutputStream.java</Message></SourceLine><Message>Value loaded from field org.apache.hadoop.hdfs.DFSOutputStream.streamer</Message></Field><SourceLine endBytecode='4' classname='org.apache.hadoop.hdfs.DFSStripedOutputStream' start='339' end='339' sourcepath='org/apache/hadoop/hdfs/DFSStripedOutputStream.java' sourcefile='DFSStripedOutputStream.java' startBytecode='4' primary='true'><Message>At DFSStripedOutputStream.java:[line 339]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='a047c47bb28b0a1ae927e9a3245ef2c3' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST_OF_RETURN_VALUE' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast of return value from method</ShortMessage><LongMessage>Unchecked/unconfirmed cast from org.apache.hadoop.hdfs.protocol.LocatedBlock to org.apache.hadoop.hdfs.protocol.LocatedStripedBlock of return value in org.apache.hadoop.hdfs.DFSStripedOutputStream.allocateNewBlock()</LongMessage><Class classname='org.apache.hadoop.hdfs.DFSStripedOutputStream' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.DFSStripedOutputStream' start='80' end='1302' sourcepath='org/apache/hadoop/hdfs/DFSStripedOutputStream.java' sourcefile='DFSStripedOutputStream.java'><Message>At DFSStripedOutputStream.java:[lines 80-1302]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.DFSStripedOutputStream</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.DFSStripedOutputStream' signature='()V' name='allocateNewBlock' primary='true'><SourceLine endBytecode='175' classname='org.apache.hadoop.hdfs.DFSStripedOutputStream' start='463' end='509' sourcepath='org/apache/hadoop/hdfs/DFSStripedOutputStream.java' sourcefile='DFSStripedOutputStream.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.DFSStripedOutputStream.allocateNewBlock()</Message></Method><Type role='TYPE_FOUND' descriptor='Lorg/apache/hadoop/hdfs/protocol/LocatedBlock;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.LocatedBlock' start='81' end='279' sourcepath='org/apache/hadoop/hdfs/protocol/LocatedBlock.java' sourcefile='LocatedBlock.java'><Message>At LocatedBlock.java:[lines 81-279]</Message></SourceLine><Message>Actual type org.apache.hadoop.hdfs.protocol.LocatedBlock</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/LocatedStripedBlock;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.LocatedStripedBlock' start='36' end='86' sourcepath='org/apache/hadoop/hdfs/protocol/LocatedStripedBlock.java' sourcefile='LocatedStripedBlock.java'><Message>At LocatedStripedBlock.java:[lines 36-86]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.LocatedStripedBlock</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='174' name='lb' register='2'><Message>Value loaded from lb</Message></LocalVariable><SourceLine endBytecode='175' classname='org.apache.hadoop.hdfs.DFSStripedOutputStream' start='486' end='486' sourcepath='org/apache/hadoop/hdfs/DFSStripedOutputStream.java' sourcefile='DFSStripedOutputStream.java' startBytecode='175' primary='true'><Message>At DFSStripedOutputStream.java:[line 486]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='262311efe1d06a651925a8fea2800fe9' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST_OF_RETURN_VALUE' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast of return value from method</ShortMessage><LongMessage>Unchecked/unconfirmed cast from Throwable to Exception of return value in org.apache.hadoop.hdfs.DFSStripedOutputStream.flushAllInternals()</LongMessage><Class classname='org.apache.hadoop.hdfs.DFSStripedOutputStream' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.DFSStripedOutputStream' start='80' end='1302' sourcepath='org/apache/hadoop/hdfs/DFSStripedOutputStream.java' sourcefile='DFSStripedOutputStream.java'><Message>At DFSStripedOutputStream.java:[lines 80-1302]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.DFSStripedOutputStream</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.DFSStripedOutputStream' signature='()V' name='flushAllInternals' primary='true'><SourceLine endBytecode='110' classname='org.apache.hadoop.hdfs.DFSStripedOutputStream' start='1235' end='1275' sourcepath='org/apache/hadoop/hdfs/DFSStripedOutputStream.java' sourcefile='DFSStripedOutputStream.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.DFSStripedOutputStream.flushAllInternals()</Message></Method><Type role='TYPE_FOUND' descriptor='Ljava/lang/Throwable;'><SourceLine classname='java.lang.Throwable' start='115' end='1108' sourcepath='java/lang/Throwable.java' sourcefile='Throwable.java'><Message>At Throwable.java:[lines 115-1108]</Message></SourceLine><Message>Actual type Throwable</Message></Type><Type role='TYPE_EXPECTED' descriptor='Ljava/lang/Exception;'><SourceLine classname='java.lang.Exception' start='54' end='123' sourcepath='java/lang/Exception.java' sourcefile='Exception.java'><Message>At Exception.java:[lines 54-123]</Message></SourceLine><Message>Expected Exception</Message></Type><SourceLine endBytecode='242' classname='org.apache.hadoop.hdfs.DFSStripedOutputStream' start='1272' end='1272' sourcepath='org/apache/hadoop/hdfs/DFSStripedOutputStream.java' sourcefile='DFSStripedOutputStream.java' startBytecode='242' primary='true'><Message>At DFSStripedOutputStream.java:[line 1272]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='40f6d94aaf650088d94c353678f689a5' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST_OF_RETURN_VALUE' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast of return value from method</ShortMessage><LongMessage>Unchecked/unconfirmed cast from org.apache.hadoop.hdfs.protocol.LocatedBlock to org.apache.hadoop.hdfs.protocol.LocatedStripedBlock of return value in org.apache.hadoop.hdfs.DFSStripedOutputStream.updateBlockForPipeline(Set)</LongMessage><Class classname='org.apache.hadoop.hdfs.DFSStripedOutputStream' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.DFSStripedOutputStream' start='80' end='1302' sourcepath='org/apache/hadoop/hdfs/DFSStripedOutputStream.java' sourcefile='DFSStripedOutputStream.java'><Message>At DFSStripedOutputStream.java:[lines 80-1302]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.DFSStripedOutputStream</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.DFSStripedOutputStream' signature='(Ljava/util/Set;)Lorg/apache/hadoop/hdfs/protocol/ExtendedBlock;' name='updateBlockForPipeline' primary='true'><SourceLine endBytecode='80' classname='org.apache.hadoop.hdfs.DFSStripedOutputStream' start='757' end='775' sourcepath='org/apache/hadoop/hdfs/DFSStripedOutputStream.java' sourcefile='DFSStripedOutputStream.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.DFSStripedOutputStream.updateBlockForPipeline(Set)</Message></Method><Type role='TYPE_FOUND' descriptor='Lorg/apache/hadoop/hdfs/protocol/LocatedBlock;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.LocatedBlock' start='81' end='279' sourcepath='org/apache/hadoop/hdfs/protocol/LocatedBlock.java' sourcefile='LocatedBlock.java'><Message>At LocatedBlock.java:[lines 81-279]</Message></SourceLine><Message>Actual type org.apache.hadoop.hdfs.protocol.LocatedBlock</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/LocatedStripedBlock;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.LocatedStripedBlock' start='36' end='86' sourcepath='org/apache/hadoop/hdfs/protocol/LocatedStripedBlock.java' sourcefile='LocatedStripedBlock.java'><Message>At LocatedStripedBlock.java:[lines 36-86]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.LocatedStripedBlock</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='51' name='updated' register='2'><Message>Value loaded from updated</Message></LocalVariable><SourceLine endBytecode='52' classname='org.apache.hadoop.hdfs.DFSStripedOutputStream' start='762' end='762' sourcepath='org/apache/hadoop/hdfs/DFSStripedOutputStream.java' sourcefile='DFSStripedOutputStream.java' startBytecode='52' primary='true'><Message>At DFSStripedOutputStream.java:[line 762]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='312f727ba3ec924c2a6599def3a513c0' cweid='366' rank='20' abbrev='IS' category='MT_CORRECTNESS' priority='3' type='IS2_INCONSISTENT_SYNC' instanceOccurrenceMax='0'><ShortMessage>Inconsistent synchronization</ShortMessage><LongMessage>Inconsistent synchronization of org.apache.hadoop.hdfs.DFSStripedOutputStream.currentBlockGroup; locked 95% of time</LongMessage><Class classname='org.apache.hadoop.hdfs.DFSStripedOutputStream' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.DFSStripedOutputStream' start='80' end='1302' sourcepath='org/apache/hadoop/hdfs/DFSStripedOutputStream.java' sourcefile='DFSStripedOutputStream.java'><Message>At DFSStripedOutputStream.java:[lines 80-1302]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.DFSStripedOutputStream</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.DFSStripedOutputStream' signature='Lorg/apache/hadoop/hdfs/protocol/ExtendedBlock;' name='currentBlockGroup' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.DFSStripedOutputStream' sourcepath='org/apache/hadoop/hdfs/DFSStripedOutputStream.java' sourcefile='DFSStripedOutputStream.java'><Message>In DFSStripedOutputStream.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.DFSStripedOutputStream.currentBlockGroup</Message></Field><Int role='INT_SYNC_PERCENT' value='95'><Message>Synchronized 95% of the time</Message></Int><SourceLine role='SOURCE_LINE_UNSYNC_ACCESS' endBytecode='1' classname='org.apache.hadoop.hdfs.DFSStripedOutputStream' start='1302' end='1302' sourcepath='org/apache/hadoop/hdfs/DFSStripedOutputStream.java' sourcefile='DFSStripedOutputStream.java' startBytecode='1' primary='true'><Message>Unsynchronized access at DFSStripedOutputStream.java:[line 1302]</Message></SourceLine><SourceLine role='SOURCE_LINE_SYNC_ACCESS' endBytecode='120' classname='org.apache.hadoop.hdfs.DFSStripedOutputStream' start='797' end='797' sourcepath='org/apache/hadoop/hdfs/DFSStripedOutputStream.java' sourcefile='DFSStripedOutputStream.java' startBytecode='120'><Message>Synchronized access at DFSStripedOutputStream.java:[line 797]</Message></SourceLine><SourceLine role='SOURCE_LINE_SYNC_ACCESS' endBytecode='181' classname='org.apache.hadoop.hdfs.DFSStripedOutputStream' start='801' end='801' sourcepath='org/apache/hadoop/hdfs/DFSStripedOutputStream.java' sourcefile='DFSStripedOutputStream.java' startBytecode='181'><Message>Synchronized access at DFSStripedOutputStream.java:[line 801]</Message></SourceLine><SourceLine role='SOURCE_LINE_SYNC_ACCESS' endBytecode='210' classname='org.apache.hadoop.hdfs.DFSStripedOutputStream' start='803' end='803' sourcepath='org/apache/hadoop/hdfs/DFSStripedOutputStream.java' sourcefile='DFSStripedOutputStream.java' startBytecode='210'><Message>Synchronized access at DFSStripedOutputStream.java:[line 803]</Message></SourceLine><SourceLine role='SOURCE_LINE_SYNC_ACCESS' endBytecode='223' classname='org.apache.hadoop.hdfs.DFSStripedOutputStream' start='805' end='805' sourcepath='org/apache/hadoop/hdfs/DFSStripedOutputStream.java' sourcefile='DFSStripedOutputStream.java' startBytecode='223'><Message>Synchronized access at DFSStripedOutputStream.java:[line 805]</Message></SourceLine><SourceLine role='SOURCE_LINE_SYNC_ACCESS' endBytecode='227' classname='org.apache.hadoop.hdfs.DFSStripedOutputStream' start='806' end='806' sourcepath='org/apache/hadoop/hdfs/DFSStripedOutputStream.java' sourcefile='DFSStripedOutputStream.java' startBytecode='227'><Message>Synchronized access at DFSStripedOutputStream.java:[line 806]</Message></SourceLine><SourceLine role='SOURCE_LINE_SYNC_ACCESS' endBytecode='1' classname='org.apache.hadoop.hdfs.DFSStripedOutputStream' start='1040' end='1040' sourcepath='org/apache/hadoop/hdfs/DFSStripedOutputStream.java' sourcefile='DFSStripedOutputStream.java' startBytecode='1'><Message>Synchronized access at DFSStripedOutputStream.java:[line 1040]</Message></SourceLine><SourceLine role='SOURCE_LINE_SYNC_ACCESS' endBytecode='12' classname='org.apache.hadoop.hdfs.DFSStripedOutputStream' start='1040' end='1040' sourcepath='org/apache/hadoop/hdfs/DFSStripedOutputStream.java' sourcefile='DFSStripedOutputStream.java' startBytecode='12'><Message>Synchronized access at DFSStripedOutputStream.java:[line 1040]</Message></SourceLine><SourceLine role='SOURCE_LINE_SYNC_ACCESS' endBytecode='8' classname='org.apache.hadoop.hdfs.DFSStripedOutputStream' start='757' end='757' sourcepath='org/apache/hadoop/hdfs/DFSStripedOutputStream.java' sourcefile='DFSStripedOutputStream.java' startBytecode='8'><Message>Synchronized access at DFSStripedOutputStream.java:[line 757]</Message></SourceLine><SourceLine role='SOURCE_LINE_SYNC_ACCESS' endBytecode='37' classname='org.apache.hadoop.hdfs.DFSStripedOutputStream' start='760' end='760' sourcepath='org/apache/hadoop/hdfs/DFSStripedOutputStream.java' sourcefile='DFSStripedOutputStream.java' startBytecode='37'><Message>Synchronized access at DFSStripedOutputStream.java:[line 760]</Message></SourceLine><SourceLine role='SOURCE_LINE_SYNC_ACCESS' endBytecode='1' classname='org.apache.hadoop.hdfs.DFSStripedOutputStream' start='512' end='512' sourcepath='org/apache/hadoop/hdfs/DFSStripedOutputStream.java' sourcefile='DFSStripedOutputStream.java' startBytecode='1'><Message>Synchronized access at DFSStripedOutputStream.java:[line 512]</Message></SourceLine><SourceLine role='SOURCE_LINE_SYNC_ACCESS' endBytecode='8' classname='org.apache.hadoop.hdfs.DFSStripedOutputStream' start='512' end='512' sourcepath='org/apache/hadoop/hdfs/DFSStripedOutputStream.java' sourcefile='DFSStripedOutputStream.java' startBytecode='8'><Message>Synchronized access at DFSStripedOutputStream.java:[line 512]</Message></SourceLine><SourceLine role='SOURCE_LINE_SYNC_ACCESS' endBytecode='31' classname='org.apache.hadoop.hdfs.DFSStripedOutputStream' start='444' end='444' sourcepath='org/apache/hadoop/hdfs/DFSStripedOutputStream.java' sourcefile='DFSStripedOutputStream.java' startBytecode='31'><Message>Synchronized access at DFSStripedOutputStream.java:[line 444]</Message></SourceLine><SourceLine role='SOURCE_LINE_SYNC_ACCESS' endBytecode='1' classname='org.apache.hadoop.hdfs.DFSStripedOutputStream' start='857' end='857' sourcepath='org/apache/hadoop/hdfs/DFSStripedOutputStream.java' sourcefile='DFSStripedOutputStream.java' startBytecode='1'><Message>Synchronized access at DFSStripedOutputStream.java:[line 857]</Message></SourceLine><SourceLine role='SOURCE_LINE_SYNC_ACCESS' endBytecode='37' classname='org.apache.hadoop.hdfs.DFSStripedOutputStream' start='523' end='523' sourcepath='org/apache/hadoop/hdfs/DFSStripedOutputStream.java' sourcefile='DFSStripedOutputStream.java' startBytecode='37'><Message>Synchronized access at DFSStripedOutputStream.java:[line 523]</Message></SourceLine><SourceLine role='SOURCE_LINE_SYNC_ACCESS' endBytecode='55' classname='org.apache.hadoop.hdfs.DFSStripedOutputStream' start='528' end='528' sourcepath='org/apache/hadoop/hdfs/DFSStripedOutputStream.java' sourcefile='DFSStripedOutputStream.java' startBytecode='55'><Message>Synchronized access at DFSStripedOutputStream.java:[line 528]</Message></SourceLine><SourceLine role='SOURCE_LINE_SYNC_ACCESS' endBytecode='59' classname='org.apache.hadoop.hdfs.DFSStripedOutputStream' start='528' end='528' sourcepath='org/apache/hadoop/hdfs/DFSStripedOutputStream.java' sourcefile='DFSStripedOutputStream.java' startBytecode='59'><Message>Synchronized access at DFSStripedOutputStream.java:[line 528]</Message></SourceLine><SourceLine role='SOURCE_LINE_SYNC_ACCESS' endBytecode='1' classname='org.apache.hadoop.hdfs.DFSStripedOutputStream' start='463' end='463' sourcepath='org/apache/hadoop/hdfs/DFSStripedOutputStream.java' sourcefile='DFSStripedOutputStream.java' startBytecode='1'><Message>Synchronized access at DFSStripedOutputStream.java:[line 463]</Message></SourceLine><SourceLine role='SOURCE_LINE_SYNC_ACCESS' endBytecode='92' classname='org.apache.hadoop.hdfs.DFSStripedOutputStream' start='477' end='477' sourcepath='org/apache/hadoop/hdfs/DFSStripedOutputStream.java' sourcefile='DFSStripedOutputStream.java' startBytecode='92'><Message>Synchronized access at DFSStripedOutputStream.java:[line 477]</Message></SourceLine><SourceLine role='SOURCE_LINE_SYNC_ACCESS' endBytecode='116' classname='org.apache.hadoop.hdfs.DFSStripedOutputStream' start='479' end='479' sourcepath='org/apache/hadoop/hdfs/DFSStripedOutputStream.java' sourcefile='DFSStripedOutputStream.java' startBytecode='116'><Message>Synchronized access at DFSStripedOutputStream.java:[line 479]</Message></SourceLine><SourceLine role='SOURCE_LINE_SYNC_ACCESS' endBytecode='161' classname='org.apache.hadoop.hdfs.DFSStripedOutputStream' start='483' end='483' sourcepath='org/apache/hadoop/hdfs/DFSStripedOutputStream.java' sourcefile='DFSStripedOutputStream.java' startBytecode='161'><Message>Synchronized access at DFSStripedOutputStream.java:[line 483]</Message></SourceLine><SourceLine role='SOURCE_LINE_SYNC_ACCESS' endBytecode='225' classname='org.apache.hadoop.hdfs.DFSStripedOutputStream' start='1206' end='1206' sourcepath='org/apache/hadoop/hdfs/DFSStripedOutputStream.java' sourcefile='DFSStripedOutputStream.java' startBytecode='225'><Message>Synchronized access at DFSStripedOutputStream.java:[line 1206]</Message></SourceLine><SourceLine role='SOURCE_LINE_SYNC_ACCESS' endBytecode='1' classname='org.apache.hadoop.hdfs.DFSStripedOutputStream' start='590' end='590' sourcepath='org/apache/hadoop/hdfs/DFSStripedOutputStream.java' sourcefile='DFSStripedOutputStream.java' startBytecode='1'><Message>Synchronized access at DFSStripedOutputStream.java:[line 590]</Message></SourceLine><SourceLine role='SOURCE_LINE_SYNC_ACCESS' endBytecode='12' classname='org.apache.hadoop.hdfs.DFSStripedOutputStream' start='590' end='590' sourcepath='org/apache/hadoop/hdfs/DFSStripedOutputStream.java' sourcefile='DFSStripedOutputStream.java' startBytecode='12'><Message>Synchronized access at DFSStripedOutputStream.java:[line 590]</Message></SourceLine><Property name='edu.umd.cs.findbugs.detect.InconsistentSyncWarningProperty.ONLY_UNSYNC_IN_GETTERS' value='true'></Property></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='f57eaff5d2542bfde9997aba270ce617' cweid='396' rank='20' abbrev='REC' category='STYLE' priority='3' type='REC_CATCH_EXCEPTION' instanceOccurrenceMax='0'><ShortMessage>Exception is caught when Exception is not thrown</ShortMessage><LongMessage>Exception is caught when Exception is not thrown in org.apache.hadoop.hdfs.DFSStripedOutputStream.closeImpl()</LongMessage><Class classname='org.apache.hadoop.hdfs.DFSStripedOutputStream' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.DFSStripedOutputStream' start='80' end='1302' sourcepath='org/apache/hadoop/hdfs/DFSStripedOutputStream.java' sourcefile='DFSStripedOutputStream.java'><Message>At DFSStripedOutputStream.java:[lines 80-1302]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.DFSStripedOutputStream</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.DFSStripedOutputStream' signature='()V' name='closeImpl' primary='true'><SourceLine endBytecode='999' classname='org.apache.hadoop.hdfs.DFSStripedOutputStream' start='1138' end='1216' sourcepath='org/apache/hadoop/hdfs/DFSStripedOutputStream.java' sourcefile='DFSStripedOutputStream.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.DFSStripedOutputStream.closeImpl()</Message></Method><SourceLine endBytecode='182' classname='org.apache.hadoop.hdfs.DFSStripedOutputStream' start='1187' end='1187' sourcepath='org/apache/hadoop/hdfs/DFSStripedOutputStream.java' sourcefile='DFSStripedOutputStream.java' startBytecode='182' primary='true'><Message>At DFSStripedOutputStream.java:[line 1187]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='c10756bd089ce36543d98f7c366bfff5' rank='20' abbrev='RI' category='STYLE' priority='3' type='RI_REDUNDANT_INTERFACES' instanceOccurrenceMax='0'><ShortMessage>Class implements same interface as superclass</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.DFSStripedOutputStream implements same interface as superclass</LongMessage><Class classname='org.apache.hadoop.hdfs.DFSStripedOutputStream' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.DFSStripedOutputStream' start='80' end='1302' sourcepath='org/apache/hadoop/hdfs/DFSStripedOutputStream.java' sourcefile='DFSStripedOutputStream.java'><Message>At DFSStripedOutputStream.java:[lines 80-1302]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.DFSStripedOutputStream</Message></Class><Class role='INTERFACE_TYPE' classname='org.apache.hadoop.fs.StreamCapabilities'><SourceLine classname='org.apache.hadoop.fs.StreamCapabilities' sourcepath='org/apache/hadoop/fs/StreamCapabilities.java' sourcefile='StreamCapabilities.java'><Message>In StreamCapabilities.java</Message></SourceLine><Message>Interface org.apache.hadoop.fs.StreamCapabilities</Message></Class><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.DFSStripedOutputStream' start='80' end='1302' sourcepath='org/apache/hadoop/hdfs/DFSStripedOutputStream.java' sourcefile='DFSStripedOutputStream.java'><Message>At DFSStripedOutputStream.java:[lines 80-1302]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='6d757daee5fb8ccdbaf06c0c6d816852' rank='20' abbrev='SIC' category='PERFORMANCE' priority='3' type='SIC_INNER_SHOULD_BE_STATIC_ANON' instanceOccurrenceMax='0'><ShortMessage>Could be refactored into a named static inner class</ShortMessage><LongMessage>The class org.apache.hadoop.hdfs.DFSStripedOutputStream$1 could be refactored into a named _static_ inner class</LongMessage><Class role='CLASS_ANONYMOUS' classname='org.apache.hadoop.hdfs.DFSStripedOutputStream$1'><SourceLine classname='org.apache.hadoop.hdfs.DFSStripedOutputStream$1' start='1246' end='1250' sourcepath='org/apache/hadoop/hdfs/DFSStripedOutputStream.java' sourcefile='DFSStripedOutputStream.java'><Message>At DFSStripedOutputStream.java:[lines 1246-1250]</Message></SourceLine><Message>Anonymous class org.apache.hadoop.hdfs.DFSStripedOutputStream$1</Message></Class><Class classname='org.apache.hadoop.hdfs.DFSStripedOutputStream' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.DFSStripedOutputStream' start='80' end='1302' sourcepath='org/apache/hadoop/hdfs/DFSStripedOutputStream.java' sourcefile='DFSStripedOutputStream.java'><Message>At DFSStripedOutputStream.java:[lines 80-1302]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.DFSStripedOutputStream</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.DFSStripedOutputStream' signature='()V' name='flushAllInternals' primary='true'><SourceLine endBytecode='642' classname='org.apache.hadoop.hdfs.DFSStripedOutputStream' start='1235' end='1275' sourcepath='org/apache/hadoop/hdfs/DFSStripedOutputStream.java' sourcefile='DFSStripedOutputStream.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.DFSStripedOutputStream.flushAllInternals()</Message></Method><SourceLine endBytecode='62' classname='org.apache.hadoop.hdfs.DFSStripedOutputStream' start='1245' end='1245' sourcepath='org/apache/hadoop/hdfs/DFSStripedOutputStream.java' sourcefile='DFSStripedOutputStream.java' startBytecode='62' primary='true'><Message>At DFSStripedOutputStream.java:[line 1245]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='a2b48be51b71fe3ccb011f3a73a2a73c' rank='19' abbrev='Nm' category='BAD_PRACTICE' priority='3' type='NM_CONFUSING' instanceOccurrenceMax='0'><ShortMessage>Confusing method names</ShortMessage><LongMessage>Confusing to have methods org.apache.hadoop.hdfs.DataStreamer.getStorageIDs() and org.apache.hadoop.hdfs.security.token.block.BlockTokenIdentifier.getStorageIds()</LongMessage><Class classname='org.apache.hadoop.hdfs.DataStreamer' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.DataStreamer' start='115' end='2116' sourcepath='org/apache/hadoop/hdfs/DataStreamer.java' sourcefile='DataStreamer.java'><Message>At DataStreamer.java:[lines 115-2116]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.DataStreamer</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.DataStreamer' signature='()[Ljava/lang/String;' name='getStorageIDs' primary='true'><SourceLine endBytecode='46' classname='org.apache.hadoop.hdfs.DataStreamer' start='1922' end='1922' sourcepath='org/apache/hadoop/hdfs/DataStreamer.java' sourcefile='DataStreamer.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.DataStreamer.getStorageIDs()</Message></Method><Class classname='org.apache.hadoop.hdfs.security.token.block.BlockTokenIdentifier'><SourceLine classname='org.apache.hadoop.hdfs.security.token.block.BlockTokenIdentifier' start='43' end='316' sourcepath='org/apache/hadoop/hdfs/security/token/block/BlockTokenIdentifier.java' sourcefile='BlockTokenIdentifier.java'><Message>At BlockTokenIdentifier.java:[lines 43-316]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.security.token.block.BlockTokenIdentifier</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.security.token.block.BlockTokenIdentifier' signature='()[Ljava/lang/String;' name='getStorageIds'><SourceLine endBytecode='46' classname='org.apache.hadoop.hdfs.security.token.block.BlockTokenIdentifier' start='134' end='134' sourcepath='org/apache/hadoop/hdfs/security/token/block/BlockTokenIdentifier.java' sourcefile='BlockTokenIdentifier.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.security.token.block.BlockTokenIdentifier.getStorageIds()</Message></Method><SourceLine synthetic='true' endBytecode='46' classname='org.apache.hadoop.hdfs.DataStreamer' start='1922' end='1922' sourcepath='org/apache/hadoop/hdfs/DataStreamer.java' sourcefile='DataStreamer.java' startBytecode='0'><Message>At DataStreamer.java:[line 1922]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='9cdb95e53db331f67a1ce7e79f7226fd' rank='20' abbrev='PZLA' category='STYLE' priority='3' type='PZLA_PREFER_ZERO_LENGTH_ARRAYS' instanceOccurrenceMax='0'><ShortMessage>Consider returning a zero length array rather than null</ShortMessage><LongMessage>Should org.apache.hadoop.hdfs.DataStreamer.getPinnings(DatanodeInfo[]) return a zero length array rather than null?</LongMessage><Class classname='org.apache.hadoop.hdfs.DataStreamer' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.DataStreamer' start='115' end='2116' sourcepath='org/apache/hadoop/hdfs/DataStreamer.java' sourcefile='DataStreamer.java'><Message>At DataStreamer.java:[lines 115-2116]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.DataStreamer</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.DataStreamer' signature='([Lorg/apache/hadoop/hdfs/protocol/DatanodeInfo;)[Z' name='getPinnings' primary='true'><SourceLine endBytecode='316' classname='org.apache.hadoop.hdfs.DataStreamer' start='1842' end='1859' sourcepath='org/apache/hadoop/hdfs/DataStreamer.java' sourcefile='DataStreamer.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.DataStreamer.getPinnings(DatanodeInfo[])</Message></Method><SourceLine endBytecode='8' classname='org.apache.hadoop.hdfs.DataStreamer' start='1843' end='1843' sourcepath='org/apache/hadoop/hdfs/DataStreamer.java' sourcefile='DataStreamer.java' startBytecode='8' primary='true'><Message>At DataStreamer.java:[line 1843]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='fc9e7f9db295407936a23fc8c5002e7b' rank='17' abbrev='VO' category='MT_CORRECTNESS' priority='3' type='VO_VOLATILE_REFERENCE_TO_ARRAY' instanceOccurrenceMax='0'><ShortMessage>A volatile reference to an array doesn't treat the array elements as volatile</ShortMessage><LongMessage>org.apache.hadoop.hdfs.DataStreamer.nodes is a volatile reference to an array; the array elements are non-volatile</LongMessage><Class classname='org.apache.hadoop.hdfs.DataStreamer' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.DataStreamer' start='115' end='2116' sourcepath='org/apache/hadoop/hdfs/DataStreamer.java' sourcefile='DataStreamer.java'><Message>At DataStreamer.java:[lines 115-2116]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.DataStreamer</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.DataStreamer' signature='[Lorg/apache/hadoop/hdfs/protocol/DatanodeInfo;' name='nodes' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.DataStreamer' sourcepath='org/apache/hadoop/hdfs/DataStreamer.java' sourcefile='DataStreamer.java'><Message>In DataStreamer.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.DataStreamer.nodes</Message></Field><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.DataStreamer' sourcepath='org/apache/hadoop/hdfs/DataStreamer.java' sourcefile='DataStreamer.java'><Message>In DataStreamer.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='c4c8de4ca874b8974263f6dbc2e8d54e' rank='17' abbrev='VO' category='MT_CORRECTNESS' priority='3' type='VO_VOLATILE_REFERENCE_TO_ARRAY' instanceOccurrenceMax='0'><ShortMessage>A volatile reference to an array doesn't treat the array elements as volatile</ShortMessage><LongMessage>org.apache.hadoop.hdfs.DataStreamer.storageIDs is a volatile reference to an array; the array elements are non-volatile</LongMessage><Class classname='org.apache.hadoop.hdfs.DataStreamer' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.DataStreamer' start='115' end='2116' sourcepath='org/apache/hadoop/hdfs/DataStreamer.java' sourcefile='DataStreamer.java'><Message>At DataStreamer.java:[lines 115-2116]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.DataStreamer</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.DataStreamer' signature='[Ljava/lang/String;' name='storageIDs' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.DataStreamer' sourcepath='org/apache/hadoop/hdfs/DataStreamer.java' sourcefile='DataStreamer.java'><Message>In DataStreamer.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.DataStreamer.storageIDs</Message></Field><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.DataStreamer' sourcepath='org/apache/hadoop/hdfs/DataStreamer.java' sourcefile='DataStreamer.java'><Message>In DataStreamer.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='8e6a7f18ab249d8d7a5f4978dd366efe' rank='17' abbrev='VO' category='MT_CORRECTNESS' priority='3' type='VO_VOLATILE_REFERENCE_TO_ARRAY' instanceOccurrenceMax='0'><ShortMessage>A volatile reference to an array doesn't treat the array elements as volatile</ShortMessage><LongMessage>org.apache.hadoop.hdfs.DataStreamer.storageTypes is a volatile reference to an array; the array elements are non-volatile</LongMessage><Class classname='org.apache.hadoop.hdfs.DataStreamer' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.DataStreamer' start='115' end='2116' sourcepath='org/apache/hadoop/hdfs/DataStreamer.java' sourcefile='DataStreamer.java'><Message>At DataStreamer.java:[lines 115-2116]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.DataStreamer</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.DataStreamer' signature='[Lorg/apache/hadoop/fs/StorageType;' name='storageTypes' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.DataStreamer' sourcepath='org/apache/hadoop/hdfs/DataStreamer.java' sourcefile='DataStreamer.java'><Message>In DataStreamer.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.DataStreamer.storageTypes</Message></Field><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.DataStreamer' sourcepath='org/apache/hadoop/hdfs/DataStreamer.java' sourcefile='DataStreamer.java'><Message>In DataStreamer.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='29222784bf496b445171732aca986d4d' cweid='396' rank='17' abbrev='REC' category='STYLE' priority='2' type='REC_CATCH_EXCEPTION' instanceOccurrenceMax='1'><ShortMessage>Exception is caught when Exception is not thrown</ShortMessage><LongMessage>Exception is caught when Exception is not thrown in org.apache.hadoop.hdfs.DataStreamer$ResponseProcessor.run()</LongMessage><Class classname='org.apache.hadoop.hdfs.DataStreamer$ResponseProcessor' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.DataStreamer$ResponseProcessor' start='1065' end='1212' sourcepath='org/apache/hadoop/hdfs/DataStreamer.java' sourcefile='DataStreamer.java'><Message>At DataStreamer.java:[lines 1065-1212]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.DataStreamer$ResponseProcessor</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.DataStreamer$ResponseProcessor' signature='()V' name='run' primary='true'><SourceLine endBytecode='2055' classname='org.apache.hadoop.hdfs.DataStreamer$ResponseProcessor' start='1078' end='1207' sourcepath='org/apache/hadoop/hdfs/DataStreamer.java' sourcefile='DataStreamer.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.DataStreamer$ResponseProcessor.run()</Message></Method><SourceLine endBytecode='939' classname='org.apache.hadoop.hdfs.DataStreamer$ResponseProcessor' start='1187' end='1187' sourcepath='org/apache/hadoop/hdfs/DataStreamer.java' sourcefile='DataStreamer.java' startBytecode='939' primary='true'><Message>At DataStreamer.java:[line 1187]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='1' instanceHash='29222784bf496b445171732aca986d4d' cweid='396' rank='20' abbrev='REC' category='STYLE' priority='3' type='REC_CATCH_EXCEPTION' instanceOccurrenceMax='1'><ShortMessage>Exception is caught when Exception is not thrown</ShortMessage><LongMessage>Exception is caught when Exception is not thrown in org.apache.hadoop.hdfs.DataStreamer$ResponseProcessor.run()</LongMessage><Class classname='org.apache.hadoop.hdfs.DataStreamer$ResponseProcessor' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.DataStreamer$ResponseProcessor' start='1065' end='1212' sourcepath='org/apache/hadoop/hdfs/DataStreamer.java' sourcefile='DataStreamer.java'><Message>At DataStreamer.java:[lines 1065-1212]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.DataStreamer$ResponseProcessor</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.DataStreamer$ResponseProcessor' signature='()V' name='run' primary='true'><SourceLine endBytecode='2055' classname='org.apache.hadoop.hdfs.DataStreamer$ResponseProcessor' start='1078' end='1207' sourcepath='org/apache/hadoop/hdfs/DataStreamer.java' sourcefile='DataStreamer.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.DataStreamer$ResponseProcessor.run()</Message></Method><SourceLine synthetic='true' endBytecode='2055' classname='org.apache.hadoop.hdfs.DataStreamer$ResponseProcessor' start='1078' end='1207' sourcepath='org/apache/hadoop/hdfs/DataStreamer.java' sourcefile='DataStreamer.java' startBytecode='0'><Message>At DataStreamer.java:[lines 1078-1207]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='8f39541f108d8d24399fefb43771ae59' rank='20' abbrev='Dm' category='PERFORMANCE' priority='3' type='DM_STRING_TOSTRING' instanceOccurrenceMax='0'><ShortMessage>Method invokes toString() method on a String</ShortMessage><LongMessage>org.apache.hadoop.hdfs.DistributedFileSystem.provisionEZTrash(String, FsPermission) invokes toString() method on a String</LongMessage><Class classname='org.apache.hadoop.hdfs.DistributedFileSystem' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.DistributedFileSystem' start='129' end='3284' sourcepath='org/apache/hadoop/hdfs/DistributedFileSystem.java' sourcefile='DistributedFileSystem.java'><Message>At DistributedFileSystem.java:[lines 129-3284]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.DistributedFileSystem</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.DistributedFileSystem' signature='(Ljava/lang/String;Lorg/apache/hadoop/fs/permission/FsPermission;)V' name='provisionEZTrash' primary='true'><SourceLine endBytecode='545' classname='org.apache.hadoop.hdfs.DistributedFileSystem' start='2643' end='2677' sourcepath='org/apache/hadoop/hdfs/DistributedFileSystem.java' sourcefile='DistributedFileSystem.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.DistributedFileSystem.provisionEZTrash(String, FsPermission)</Message></Method><SourceLine endBytecode='48' classname='org.apache.hadoop.hdfs.DistributedFileSystem' start='2649' end='2649' sourcepath='org/apache/hadoop/hdfs/DistributedFileSystem.java' sourcefile='DistributedFileSystem.java' startBytecode='48' primary='true'><Message>At DistributedFileSystem.java:[line 2649]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='732e86cb5c9a013e56ce4cf4adf040f8' rank='20' abbrev='PZLA' category='STYLE' priority='3' type='PZLA_PREFER_ZERO_LENGTH_ARRAYS' instanceOccurrenceMax='0'><ShortMessage>Consider returning a zero length array rather than null</ShortMessage><LongMessage>Should org.apache.hadoop.hdfs.DistributedFileSystem.getFileBlockLocations(FileStatus, long, long) return a zero length array rather than null?</LongMessage><Class classname='org.apache.hadoop.hdfs.DistributedFileSystem' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.DistributedFileSystem' start='129' end='3284' sourcepath='org/apache/hadoop/hdfs/DistributedFileSystem.java' sourcefile='DistributedFileSystem.java'><Message>At DistributedFileSystem.java:[lines 129-3284]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.DistributedFileSystem</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.DistributedFileSystem' signature='(Lorg/apache/hadoop/fs/FileStatus;JJ)[Lorg/apache/hadoop/fs/BlockLocation;' name='getFileBlockLocations' primary='true'><SourceLine endBytecode='106' classname='org.apache.hadoop.hdfs.DistributedFileSystem' start='252' end='255' sourcepath='org/apache/hadoop/hdfs/DistributedFileSystem.java' sourcefile='DistributedFileSystem.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.DistributedFileSystem.getFileBlockLocations(FileStatus, long, long)</Message></Method><SourceLine endBytecode='5' classname='org.apache.hadoop.hdfs.DistributedFileSystem' start='253' end='253' sourcepath='org/apache/hadoop/hdfs/DistributedFileSystem.java' sourcefile='DistributedFileSystem.java' startBytecode='5' primary='true'><Message>At DistributedFileSystem.java:[line 253]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='a2922a5e59e290616fa319651382aed0' rank='20' abbrev='SIC' category='PERFORMANCE' priority='3' type='SIC_INNER_SHOULD_BE_STATIC_ANON' instanceOccurrenceMax='0'><ShortMessage>Could be refactored into a named static inner class</ShortMessage><LongMessage>The class org.apache.hadoop.hdfs.DistributedFileSystem$1 could be refactored into a named _static_ inner class</LongMessage><Class role='CLASS_ANONYMOUS' classname='org.apache.hadoop.hdfs.DistributedFileSystem$1'><SourceLine classname='org.apache.hadoop.hdfs.DistributedFileSystem$1' start='183' end='186' sourcepath='org/apache/hadoop/hdfs/DistributedFileSystem.java' sourcefile='DistributedFileSystem.java'><Message>At DistributedFileSystem.java:[lines 183-186]</Message></SourceLine><Message>Anonymous class org.apache.hadoop.hdfs.DistributedFileSystem$1</Message></Class><Class classname='org.apache.hadoop.hdfs.DistributedFileSystem' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.DistributedFileSystem' start='129' end='3284' sourcepath='org/apache/hadoop/hdfs/DistributedFileSystem.java' sourcefile='DistributedFileSystem.java'><Message>At DistributedFileSystem.java:[lines 129-3284]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.DistributedFileSystem</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.DistributedFileSystem' signature='(Ljava/net/URI;Lorg/apache/hadoop/conf/Configuration;)V' name='initialize' primary='true'><SourceLine endBytecode='273' classname='org.apache.hadoop.hdfs.DistributedFileSystem' start='166' end='189' sourcepath='org/apache/hadoop/hdfs/DistributedFileSystem.java' sourcefile='DistributedFileSystem.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.DistributedFileSystem.initialize(URI, Configuration)</Message></Method><SourceLine endBytecode='131' classname='org.apache.hadoop.hdfs.DistributedFileSystem' start='181' end='181' sourcepath='org/apache/hadoop/hdfs/DistributedFileSystem.java' sourcefile='DistributedFileSystem.java' startBytecode='131' primary='true'><Message>At DistributedFileSystem.java:[line 181]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='1a8ee42cf83c5db5f6d949e34c3dcd10' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from org.apache.hadoop.fs.FileSystem to org.apache.hadoop.hdfs.DistributedFileSystem in org.apache.hadoop.hdfs.DistributedFileSystem$26.next(FileSystem, Path)</LongMessage><Class classname='org.apache.hadoop.hdfs.DistributedFileSystem$26' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.DistributedFileSystem$26' start='1175' end='1185' sourcepath='org/apache/hadoop/hdfs/DistributedFileSystem.java' sourcefile='DistributedFileSystem.java'><Message>At DistributedFileSystem.java:[lines 1175-1185]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.DistributedFileSystem$26</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.DistributedFileSystem$26' signature='(Lorg/apache/hadoop/fs/FileSystem;Lorg/apache/hadoop/fs/Path;)Lorg/apache/hadoop/fs/RemoteIterator;' name='next' primary='true'><SourceLine endBytecode='4' classname='org.apache.hadoop.hdfs.DistributedFileSystem$26' start='1185' end='1185' sourcepath='org/apache/hadoop/hdfs/DistributedFileSystem.java' sourcefile='DistributedFileSystem.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.DistributedFileSystem$26.next(FileSystem, Path)</Message></Method><Type role='TYPE_FOUND' descriptor='Lorg/apache/hadoop/fs/FileSystem;'><SourceLine classname='org.apache.hadoop.fs.FileSystem' start='124' end='4296' sourcepath='org/apache/hadoop/fs/FileSystem.java' sourcefile='FileSystem.java'><Message>At FileSystem.java:[lines 124-4296]</Message></SourceLine><Message>Actual type org.apache.hadoop.fs.FileSystem</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/DistributedFileSystem;'><SourceLine classname='org.apache.hadoop.hdfs.DistributedFileSystem' start='129' end='3284' sourcepath='org/apache/hadoop/hdfs/DistributedFileSystem.java' sourcefile='DistributedFileSystem.java'><Message>At DistributedFileSystem.java:[lines 129-3284]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.DistributedFileSystem</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='0' name='fs' register='1'><Message>Value loaded from fs</Message></LocalVariable><SourceLine endBytecode='1' classname='org.apache.hadoop.hdfs.DistributedFileSystem$26' start='1185' end='1185' sourcepath='org/apache/hadoop/hdfs/DistributedFileSystem.java' sourcefile='DistributedFileSystem.java' startBytecode='1' primary='true'><Message>At DistributedFileSystem.java:[line 1185]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='b4b18ac76644f953508ecd3ca4f93194' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from org.apache.hadoop.fs.FileSystem to org.apache.hadoop.hdfs.DistributedFileSystem in org.apache.hadoop.hdfs.DistributedFileSystem$43.next(FileSystem, Path)</LongMessage><Class classname='org.apache.hadoop.hdfs.DistributedFileSystem$43' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.DistributedFileSystem$43' start='2031' end='2048' sourcepath='org/apache/hadoop/hdfs/DistributedFileSystem.java' sourcefile='DistributedFileSystem.java'><Message>At DistributedFileSystem.java:[lines 2031-2048]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.DistributedFileSystem$43</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.DistributedFileSystem$43' signature='(Lorg/apache/hadoop/fs/FileSystem;Lorg/apache/hadoop/fs/Path;)Lorg/apache/hadoop/fs/RemoteIterator;' name='next' primary='true'><SourceLine endBytecode='8' classname='org.apache.hadoop.hdfs.DistributedFileSystem$43' start='2047' end='2047' sourcepath='org/apache/hadoop/hdfs/DistributedFileSystem.java' sourcefile='DistributedFileSystem.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.DistributedFileSystem$43.next(FileSystem, Path)</Message></Method><Type role='TYPE_FOUND' descriptor='Lorg/apache/hadoop/fs/FileSystem;'><SourceLine classname='org.apache.hadoop.fs.FileSystem' start='124' end='4296' sourcepath='org/apache/hadoop/fs/FileSystem.java' sourcefile='FileSystem.java'><Message>At FileSystem.java:[lines 124-4296]</Message></SourceLine><Message>Actual type org.apache.hadoop.fs.FileSystem</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/DistributedFileSystem;'><SourceLine classname='org.apache.hadoop.hdfs.DistributedFileSystem' start='129' end='3284' sourcepath='org/apache/hadoop/hdfs/DistributedFileSystem.java' sourcefile='DistributedFileSystem.java'><Message>At DistributedFileSystem.java:[lines 129-3284]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.DistributedFileSystem</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='0' name='fs' register='1'><Message>Value loaded from fs</Message></LocalVariable><SourceLine endBytecode='1' classname='org.apache.hadoop.hdfs.DistributedFileSystem$43' start='2047' end='2047' sourcepath='org/apache/hadoop/hdfs/DistributedFileSystem.java' sourcefile='DistributedFileSystem.java' startBytecode='1' primary='true'><Message>At DistributedFileSystem.java:[line 2047]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='5be6d956ee5f4dcc4d456a03881ce95c' rank='19' abbrev='Nm' category='BAD_PRACTICE' priority='3' type='NM_CONFUSING' instanceOccurrenceMax='0'><ShortMessage>Confusing method names</ShortMessage><LongMessage>Confusing to have methods org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.getBytesPerCRC() and org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpBlockChecksumResponseProto.getBytesPerCrc()</LongMessage><Class classname='org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer' start='79' end='474' sourcepath='org/apache/hadoop/hdfs/FileChecksumHelper.java' sourcefile='FileChecksumHelper.java'><Message>At FileChecksumHelper.java:[lines 79-474]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer' signature='()I' name='getBytesPerCRC' primary='true'><SourceLine endBytecode='46' classname='org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer' start='193' end='193' sourcepath='org/apache/hadoop/hdfs/FileChecksumHelper.java' sourcefile='FileChecksumHelper.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.getBytesPerCRC()</Message></Method><Class classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpBlockChecksumResponseProto'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpBlockChecksumResponseProto' start='25336' end='26212' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java'><Message>At DataTransferProtos.java:[lines 25336-26212]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpBlockChecksumResponseProto</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpBlockChecksumResponseProto' signature='()I' name='getBytesPerCrc'><SourceLine endBytecode='46' classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpBlockChecksumResponseProto' start='25476' end='25476' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpBlockChecksumResponseProto.getBytesPerCrc()</Message></Method><SourceLine synthetic='true' endBytecode='46' classname='org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer' start='193' end='193' sourcepath='org/apache/hadoop/hdfs/FileChecksumHelper.java' sourcefile='FileChecksumHelper.java' startBytecode='0'><Message>At FileChecksumHelper.java:[line 193]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='36bec7c1f47c1fdd0b4af996486ffa26' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST_OF_RETURN_VALUE' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast of return value from method</ShortMessage><LongMessage>Unchecked/unconfirmed cast from org.apache.hadoop.hdfs.protocol.LocatedBlock to org.apache.hadoop.hdfs.protocol.LocatedStripedBlock of return value in org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks()</LongMessage><Class classname='org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer' start='619' end='721' sourcepath='org/apache/hadoop/hdfs/FileChecksumHelper.java' sourcefile='FileChecksumHelper.java'><Message>At FileChecksumHelper.java:[lines 619-721]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer' signature='()V' name='checksumBlocks' primary='true'><SourceLine endBytecode='64' classname='org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer' start='626' end='643' sourcepath='org/apache/hadoop/hdfs/FileChecksumHelper.java' sourcefile='FileChecksumHelper.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks()</Message></Method><Type role='TYPE_FOUND' descriptor='Lorg/apache/hadoop/hdfs/protocol/LocatedBlock;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.LocatedBlock' start='81' end='279' sourcepath='org/apache/hadoop/hdfs/protocol/LocatedBlock.java' sourcefile='LocatedBlock.java'><Message>At LocatedBlock.java:[lines 81-279]</Message></SourceLine><Message>Actual type org.apache.hadoop.hdfs.protocol.LocatedBlock</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/LocatedStripedBlock;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.LocatedStripedBlock' start='36' end='86' sourcepath='org/apache/hadoop/hdfs/protocol/LocatedStripedBlock.java' sourcefile='LocatedStripedBlock.java'><Message>At LocatedStripedBlock.java:[lines 36-86]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.LocatedStripedBlock</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='78' name='locatedBlock' register='2'><Message>Value loaded from locatedBlock</Message></LocalVariable><SourceLine endBytecode='79' classname='org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer' start='636' end='636' sourcepath='org/apache/hadoop/hdfs/FileChecksumHelper.java' sourcefile='FileChecksumHelper.java' startBytecode='79' primary='true'><Message>At FileChecksumHelper.java:[line 636]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='7ec7766550b9cde4083dcba779694130' rank='20' abbrev='SIC' category='PERFORMANCE' priority='3' type='SIC_INNER_SHOULD_BE_STATIC_ANON' instanceOccurrenceMax='0'><ShortMessage>Could be refactored into a named static inner class</ShortMessage><LongMessage>The class org.apache.hadoop.hdfs.KeyProviderCache$1 could be refactored into a named _static_ inner class</LongMessage><Class role='CLASS_ANONYMOUS' classname='org.apache.hadoop.hdfs.KeyProviderCache$1'><SourceLine classname='org.apache.hadoop.hdfs.KeyProviderCache$1' start='53' end='65' sourcepath='org/apache/hadoop/hdfs/KeyProviderCache.java' sourcefile='KeyProviderCache.java'><Message>At KeyProviderCache.java:[lines 53-65]</Message></SourceLine><Message>Anonymous class org.apache.hadoop.hdfs.KeyProviderCache$1</Message></Class><Class classname='org.apache.hadoop.hdfs.KeyProviderCache' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.KeyProviderCache' start='42' end='114' sourcepath='org/apache/hadoop/hdfs/KeyProviderCache.java' sourcefile='KeyProviderCache.java'><Message>At KeyProviderCache.java:[lines 42-114]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.KeyProviderCache</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.KeyProviderCache' signature='(J)V' name='&lt;init&gt;' primary='true'><SourceLine endBytecode='104' classname='org.apache.hadoop.hdfs.KeyProviderCache' start='50' end='68' sourcepath='org/apache/hadoop/hdfs/KeyProviderCache.java' sourcefile='KeyProviderCache.java' startBytecode='0'></SourceLine><Message>In method new org.apache.hadoop.hdfs.KeyProviderCache(long)</Message></Method><SourceLine endBytecode='20' classname='org.apache.hadoop.hdfs.KeyProviderCache' start='52' end='52' sourcepath='org/apache/hadoop/hdfs/KeyProviderCache.java' sourcefile='KeyProviderCache.java' startBytecode='20' primary='true'><Message>At KeyProviderCache.java:[line 52]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='289e11078f86a1d09244779e5063286c' rank='20' abbrev='SIC' category='PERFORMANCE' priority='3' type='SIC_INNER_SHOULD_BE_STATIC_ANON' instanceOccurrenceMax='0'><ShortMessage>Could be refactored into a named static inner class</ShortMessage><LongMessage>The class org.apache.hadoop.hdfs.KeyProviderCache$2 could be refactored into a named _static_ inner class</LongMessage><Class role='CLASS_ANONYMOUS' classname='org.apache.hadoop.hdfs.KeyProviderCache$2'><SourceLine classname='org.apache.hadoop.hdfs.KeyProviderCache$2' start='76' end='79' sourcepath='org/apache/hadoop/hdfs/KeyProviderCache.java' sourcefile='KeyProviderCache.java'><Message>At KeyProviderCache.java:[lines 76-79]</Message></SourceLine><Message>Anonymous class org.apache.hadoop.hdfs.KeyProviderCache$2</Message></Class><Class classname='org.apache.hadoop.hdfs.KeyProviderCache' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.KeyProviderCache' start='42' end='114' sourcepath='org/apache/hadoop/hdfs/KeyProviderCache.java' sourcefile='KeyProviderCache.java'><Message>At KeyProviderCache.java:[lines 42-114]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.KeyProviderCache</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.KeyProviderCache' signature='(Lorg/apache/hadoop/conf/Configuration;Ljava/net/URI;)Lorg/apache/hadoop/crypto/key/KeyProvider;' name='get' primary='true'><SourceLine endBytecode='156' classname='org.apache.hadoop.hdfs.KeyProviderCache' start='72' end='84' sourcepath='org/apache/hadoop/hdfs/KeyProviderCache.java' sourcefile='KeyProviderCache.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.KeyProviderCache.get(Configuration, URI)</Message></Method><SourceLine endBytecode='18' classname='org.apache.hadoop.hdfs.KeyProviderCache' start='76' end='76' sourcepath='org/apache/hadoop/hdfs/KeyProviderCache.java' sourcefile='KeyProviderCache.java' startBytecode='18' primary='true'><Message>At KeyProviderCache.java:[line 76]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='ef69451fc54e6276a636e2a6730ab094' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST_OF_RETURN_VALUE' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast of return value from method</ShortMessage><LongMessage>Unchecked/unconfirmed cast from Throwable to java.io.IOException of return value in org.apache.hadoop.hdfs.NameNodeProxiesClient.createFailoverProxyProvider(Configuration, URI, Class, boolean, AtomicBoolean, HAProxyFactory)</LongMessage><Class classname='org.apache.hadoop.hdfs.NameNodeProxiesClient' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.NameNodeProxiesClient' start='73' end='371' sourcepath='org/apache/hadoop/hdfs/NameNodeProxiesClient.java' sourcefile='NameNodeProxiesClient.java'><Message>At NameNodeProxiesClient.java:[lines 73-371]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.NameNodeProxiesClient</Message></Class><Method isStatic='true' classname='org.apache.hadoop.hdfs.NameNodeProxiesClient' signature='(Lorg/apache/hadoop/conf/Configuration;Ljava/net/URI;Ljava/lang/Class;ZLjava/util/concurrent/atomic/AtomicBoolean;Lorg/apache/hadoop/hdfs/server/namenode/ha/HAProxyFactory;)Lorg/apache/hadoop/hdfs/server/namenode/ha/AbstractNNFailoverProxyProvider;' name='createFailoverProxyProvider' primary='true'><SourceLine endBytecode='134' classname='org.apache.hadoop.hdfs.NameNodeProxiesClient' start='225' end='272' sourcepath='org/apache/hadoop/hdfs/NameNodeProxiesClient.java' sourcefile='NameNodeProxiesClient.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.NameNodeProxiesClient.createFailoverProxyProvider(Configuration, URI, Class, boolean, AtomicBoolean, HAProxyFactory)</Message></Method><Type role='TYPE_FOUND' descriptor='Ljava/lang/Throwable;'><SourceLine classname='java.lang.Throwable' start='115' end='1108' sourcepath='java/lang/Throwable.java' sourcefile='Throwable.java'><Message>At Throwable.java:[lines 115-1108]</Message></SourceLine><Message>Actual type Throwable</Message></Type><Type role='TYPE_EXPECTED' descriptor='Ljava/io/IOException;'><SourceLine classname='java.io.IOException' start='47' end='100' sourcepath='java/io/IOException.java' sourcefile='IOException.java'><Message>At IOException.java:[lines 47-100]</Message></SourceLine><Message>Expected java.io.IOException</Message></Type><SourceLine endBytecode='163' classname='org.apache.hadoop.hdfs.NameNodeProxiesClient' start='252' end='252' sourcepath='org/apache/hadoop/hdfs/NameNodeProxiesClient.java' sourcefile='NameNodeProxiesClient.java' startBytecode='163' primary='true'><Message>At NameNodeProxiesClient.java:[line 252]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='b001afff2a80463bf988d48e604a94a' cweid='396' rank='20' abbrev='REC' category='STYLE' priority='3' type='REC_CATCH_EXCEPTION' instanceOccurrenceMax='0'><ShortMessage>Exception is caught when Exception is not thrown</ShortMessage><LongMessage>Exception is caught when Exception is not thrown in org.apache.hadoop.hdfs.NameNodeProxiesClient.createFailoverProxyProvider(Configuration, URI, Class, boolean, AtomicBoolean, HAProxyFactory)</LongMessage><Class classname='org.apache.hadoop.hdfs.NameNodeProxiesClient' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.NameNodeProxiesClient' start='73' end='371' sourcepath='org/apache/hadoop/hdfs/NameNodeProxiesClient.java' sourcefile='NameNodeProxiesClient.java'><Message>At NameNodeProxiesClient.java:[lines 73-371]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.NameNodeProxiesClient</Message></Class><Method isStatic='true' classname='org.apache.hadoop.hdfs.NameNodeProxiesClient' signature='(Lorg/apache/hadoop/conf/Configuration;Ljava/net/URI;Ljava/lang/Class;ZLjava/util/concurrent/atomic/AtomicBoolean;Lorg/apache/hadoop/hdfs/server/namenode/ha/HAProxyFactory;)Lorg/apache/hadoop/hdfs/server/namenode/ha/AbstractNNFailoverProxyProvider;' name='createFailoverProxyProvider' primary='true'><SourceLine endBytecode='775' classname='org.apache.hadoop.hdfs.NameNodeProxiesClient' start='225' end='272' sourcepath='org/apache/hadoop/hdfs/NameNodeProxiesClient.java' sourcefile='NameNodeProxiesClient.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.NameNodeProxiesClient.createFailoverProxyProvider(Configuration, URI, Class, boolean, AtomicBoolean, HAProxyFactory)</Message></Method><SourceLine endBytecode='111' classname='org.apache.hadoop.hdfs.NameNodeProxiesClient' start='247' end='247' sourcepath='org/apache/hadoop/hdfs/NameNodeProxiesClient.java' sourcefile='NameNodeProxiesClient.java' startBytecode='111' primary='true'><Message>At NameNodeProxiesClient.java:[line 247]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='764e4ba5c882d0b587e9dcaec535ac07' rank='20' abbrev='UwF' category='STYLE' priority='3' type='UWF_FIELD_NOT_INITIALIZED_IN_CONSTRUCTOR' instanceOccurrenceMax='0'><ShortMessage>Field not initialized in constructor but dereferenced without null check</ShortMessage><LongMessage>PositionStripeReader.codingBuffer not initialized in constructor and dereferenced in org.apache.hadoop.hdfs.PositionStripeReader.prepareParityChunk(int)</LongMessage><Class classname='org.apache.hadoop.hdfs.PositionStripeReader' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.PositionStripeReader' start='44' end='107' sourcepath='org/apache/hadoop/hdfs/PositionStripeReader.java' sourcefile='PositionStripeReader.java'><Message>At PositionStripeReader.java:[lines 44-107]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.PositionStripeReader</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.PositionStripeReader' signature='Ljava/nio/ByteBuffer;' name='codingBuffer' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.PositionStripeReader' sourcepath='org/apache/hadoop/hdfs/PositionStripeReader.java' sourcefile='PositionStripeReader.java'><Message>In PositionStripeReader.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.PositionStripeReader.codingBuffer</Message></Field><Method isStatic='false' classname='org.apache.hadoop.hdfs.PositionStripeReader' signature='(I)Z' name='prepareParityChunk' primary='true'><SourceLine endBytecode='180' classname='org.apache.hadoop.hdfs.PositionStripeReader' start='58' end='68' sourcepath='org/apache/hadoop/hdfs/PositionStripeReader.java' sourcefile='PositionStripeReader.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.PositionStripeReader.prepareParityChunk(int)</Message></Method><SourceLine endBytecode='50' classname='org.apache.hadoop.hdfs.PositionStripeReader' start='62' end='62' sourcepath='org/apache/hadoop/hdfs/PositionStripeReader.java' sourcefile='PositionStripeReader.java' startBytecode='50' primary='true'><Message>At PositionStripeReader.java:[line 62]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='e96502b59c180e4f910d360ef6638738' rank='20' abbrev='UrF' category='STYLE' priority='3' type='URF_UNREAD_PUBLIC_OR_PROTECTED_FIELD' instanceOccurrenceMax='0'><ShortMessage>Unread public/protected field</ShortMessage><LongMessage>Unread public/protected field: org.apache.hadoop.hdfs.StripeReader.ecPolicy</LongMessage><Class classname='org.apache.hadoop.hdfs.StripeReader' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.StripeReader' start='107' end='462' sourcepath='org/apache/hadoop/hdfs/StripeReader.java' sourcefile='StripeReader.java'><Message>At StripeReader.java:[lines 107-462]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.StripeReader</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.StripeReader' signature='Lorg/apache/hadoop/hdfs/protocol/ErasureCodingPolicy;' name='ecPolicy' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.StripeReader' sourcepath='org/apache/hadoop/hdfs/StripeReader.java' sourcefile='StripeReader.java'><Message>In StripeReader.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.StripeReader.ecPolicy</Message></Field><SourceLine endBytecode='22' classname='org.apache.hadoop.hdfs.StripeReader' start='128' end='128' sourcepath='org/apache/hadoop/hdfs/StripeReader.java' sourcefile='StripeReader.java' startBytecode='22' primary='true'><Message>At StripeReader.java:[line 128]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='1da5cb3cd609519b699b8e8e4057ae45' rank='17' abbrev='No' category='MT_CORRECTNESS' priority='3' type='NO_NOTIFY_NOT_NOTIFYALL' instanceOccurrenceMax='0'><ShortMessage>Using notify() rather than notifyAll()</ShortMessage><LongMessage>Using notify rather than notifyAll in org.apache.hadoop.hdfs.StripedDataStreamer.setupPipelineInternal(DatanodeInfo[], StorageType[], String[])</LongMessage><Class classname='org.apache.hadoop.hdfs.StripedDataStreamer' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.StripedDataStreamer' start='46' end='192' sourcepath='org/apache/hadoop/hdfs/StripedDataStreamer.java' sourcefile='StripedDataStreamer.java'><Message>At StripedDataStreamer.java:[lines 46-192]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.StripedDataStreamer</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.StripedDataStreamer' signature='([Lorg/apache/hadoop/hdfs/protocol/DatanodeInfo;[Lorg/apache/hadoop/fs/StorageType;[Ljava/lang/String;)V' name='setupPipelineInternal' primary='true'><SourceLine endBytecode='496' classname='org.apache.hadoop.hdfs.StripedDataStreamer' start='128' end='181' sourcepath='org/apache/hadoop/hdfs/StripedDataStreamer.java' sourcefile='StripedDataStreamer.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.StripedDataStreamer.setupPipelineInternal(DatanodeInfo[], StorageType[], String[])</Message></Method><SourceLine endBytecode='156' classname='org.apache.hadoop.hdfs.StripedDataStreamer' start='157' end='157' sourcepath='org/apache/hadoop/hdfs/StripedDataStreamer.java' sourcefile='StripedDataStreamer.java' startBytecode='156' primary='true'><Message>At StripedDataStreamer.java:[line 157]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='6fe17f6821a4ae3a8121720742367f36' cweid='253' rank='19' abbrev='RV' category='BAD_PRACTICE' priority='3' type='RV_RETURN_VALUE_IGNORED_BAD_PRACTICE' instanceOccurrenceMax='0'><ShortMessage>Method ignores exceptional return value</ShortMessage><LongMessage>Exceptional return value of java.util.concurrent.ExecutorService.submit(Runnable) ignored in org.apache.hadoop.hdfs.TestDFSOpsCountStatistics.testCurrentAccess()</LongMessage><Class classname='org.apache.hadoop.hdfs.TestDFSOpsCountStatistics' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.TestDFSOpsCountStatistics' start='56' end='214' sourcepath='org/apache/hadoop/hdfs/TestDFSOpsCountStatistics.java' sourcefile='TestDFSOpsCountStatistics.java'><Message>At TestDFSOpsCountStatistics.java:[lines 56-214]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.TestDFSOpsCountStatistics</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.TestDFSOpsCountStatistics' signature='()V' name='testCurrentAccess' primary='true'><SourceLine endBytecode='411' classname='org.apache.hadoop.hdfs.TestDFSOpsCountStatistics' start='150' end='186' sourcepath='org/apache/hadoop/hdfs/TestDFSOpsCountStatistics.java' sourcefile='TestDFSOpsCountStatistics.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.TestDFSOpsCountStatistics.testCurrentAccess()</Message></Method><Method isStatic='false' role='METHOD_CALLED' classname='java.util.concurrent.ExecutorService' signature='(Ljava/lang/Runnable;)Ljava/util/concurrent/Future;' name='submit'><SourceLine classname='java.util.concurrent.ExecutorService' sourcepath='java/util/concurrent/ExecutorService.java' sourcefile='ExecutorService.java'></SourceLine><Message>Called method java.util.concurrent.ExecutorService.submit(Runnable)</Message></Method><SourceLine endBytecode='75' classname='org.apache.hadoop.hdfs.TestDFSOpsCountStatistics' start='160' end='160' sourcepath='org/apache/hadoop/hdfs/TestDFSOpsCountStatistics.java' sourcefile='TestDFSOpsCountStatistics.java' startBytecode='75' primary='true'><Message>At TestDFSOpsCountStatistics.java:[line 160]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='2b62d35ce2552c9dd7c162615bb83df7' rank='20' abbrev='SIC' category='PERFORMANCE' priority='3' type='SIC_INNER_SHOULD_BE_STATIC_ANON' instanceOccurrenceMax='0'><ShortMessage>Could be refactored into a named static inner class</ShortMessage><LongMessage>The class org.apache.hadoop.hdfs.TestPeerCache$FakePeer$1 could be refactored into a named _static_ inner class</LongMessage><Class role='CLASS_ANONYMOUS' classname='org.apache.hadoop.hdfs.TestPeerCache$FakePeer$1'><SourceLine classname='org.apache.hadoop.hdfs.TestPeerCache$FakePeer$1' start='125' end='129' sourcepath='org/apache/hadoop/hdfs/TestPeerCache.java' sourcefile='TestPeerCache.java'><Message>At TestPeerCache.java:[lines 125-129]</Message></SourceLine><Message>Anonymous class org.apache.hadoop.hdfs.TestPeerCache$FakePeer$1</Message></Class><Class classname='org.apache.hadoop.hdfs.TestPeerCache$FakePeer' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.TestPeerCache$FakePeer' start='44' end='148' sourcepath='org/apache/hadoop/hdfs/TestPeerCache.java' sourcefile='TestPeerCache.java'><Message>At TestPeerCache.java:[lines 44-148]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.TestPeerCache$FakePeer</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.TestPeerCache$FakePeer' signature='()Lorg/apache/hadoop/net/unix/DomainSocket;' name='getDomainSocket' primary='true'><SourceLine endBytecode='80' classname='org.apache.hadoop.hdfs.TestPeerCache$FakePeer' start='121' end='124' sourcepath='org/apache/hadoop/hdfs/TestPeerCache.java' sourcefile='TestPeerCache.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.TestPeerCache$FakePeer.getDomainSocket()</Message></Method><SourceLine endBytecode='16' classname='org.apache.hadoop.hdfs.TestPeerCache$FakePeer' start='124' end='124' sourcepath='org/apache/hadoop/hdfs/TestPeerCache.java' sourcefile='TestPeerCache.java' startBytecode='16' primary='true'><Message>At TestPeerCache.java:[line 124]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='abb64875393a674ed5ce8fe7172b436a' rank='20' abbrev='ST' category='STYLE' priority='3' type='ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD' instanceOccurrenceMax='0'><ShortMessage>Write to static field from instance method</ShortMessage><LongMessage>Write to static field org.apache.hadoop.hdfs.client.impl.BlockReaderLocal.metrics from instance method new org.apache.hadoop.hdfs.client.impl.BlockReaderLocal(BlockReaderLocal$Builder)</LongMessage><Class classname='org.apache.hadoop.hdfs.client.impl.BlockReaderLocal' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.client.impl.BlockReaderLocal' start='65' end='734' sourcepath='org/apache/hadoop/hdfs/client/impl/BlockReaderLocal.java' sourcefile='BlockReaderLocal.java'><Message>At BlockReaderLocal.java:[lines 65-734]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.client.impl.BlockReaderLocal</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.client.impl.BlockReaderLocal' signature='(Lorg/apache/hadoop/hdfs/client/impl/BlockReaderLocal$Builder;)V' name='&lt;init&gt;' primary='true'><SourceLine endBytecode='623' classname='org.apache.hadoop.hdfs.client.impl.BlockReaderLocal' start='239' end='282' sourcepath='org/apache/hadoop/hdfs/client/impl/BlockReaderLocal.java' sourcefile='BlockReaderLocal.java' startBytecode='0'></SourceLine><Message>In method new org.apache.hadoop.hdfs.client.impl.BlockReaderLocal(BlockReaderLocal$Builder)</Message></Method><Field isStatic='true' classname='org.apache.hadoop.hdfs.client.impl.BlockReaderLocal' signature='Lorg/apache/hadoop/hdfs/client/impl/metrics/BlockReaderLocalMetrics;' name='metrics' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.client.impl.BlockReaderLocal' sourcepath='org/apache/hadoop/hdfs/client/impl/BlockReaderLocal.java' sourcefile='BlockReaderLocal.java'><Message>In BlockReaderLocal.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.client.impl.BlockReaderLocal.metrics</Message></Field><SourceLine endBytecode='266' classname='org.apache.hadoop.hdfs.client.impl.BlockReaderLocal' start='273' end='273' sourcepath='org/apache/hadoop/hdfs/client/impl/BlockReaderLocal.java' sourcefile='BlockReaderLocal.java' startBytecode='266' primary='true'><Message>At BlockReaderLocal.java:[line 273]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='e4c3e2a6f24f86e028e39ab9bc681970' rank='20' abbrev='SIC' category='PERFORMANCE' priority='3' type='SIC_INNER_SHOULD_BE_STATIC_ANON' instanceOccurrenceMax='0'><ShortMessage>Could be refactored into a named static inner class</ShortMessage><LongMessage>The class org.apache.hadoop.hdfs.client.impl.BlockReaderLocalLegacy$LocalDatanodeInfo$1 could be refactored into a named _static_ inner class</LongMessage><Class role='CLASS_ANONYMOUS' classname='org.apache.hadoop.hdfs.client.impl.BlockReaderLocalLegacy$LocalDatanodeInfo$1'><SourceLine classname='org.apache.hadoop.hdfs.client.impl.BlockReaderLocalLegacy$LocalDatanodeInfo$1' start='96' end='102' sourcepath='org/apache/hadoop/hdfs/client/impl/BlockReaderLocalLegacy.java' sourcefile='BlockReaderLocalLegacy.java'><Message>At BlockReaderLocalLegacy.java:[lines 96-102]</Message></SourceLine><Message>Anonymous class org.apache.hadoop.hdfs.client.impl.BlockReaderLocalLegacy$LocalDatanodeInfo$1</Message></Class><Class classname='org.apache.hadoop.hdfs.client.impl.BlockReaderLocalLegacy$LocalDatanodeInfo' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.client.impl.BlockReaderLocalLegacy$LocalDatanodeInfo' start='85' end='145' sourcepath='org/apache/hadoop/hdfs/client/impl/BlockReaderLocalLegacy.java' sourcefile='BlockReaderLocalLegacy.java'><Message>At BlockReaderLocalLegacy.java:[lines 85-145]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.client.impl.BlockReaderLocalLegacy$LocalDatanodeInfo</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.client.impl.BlockReaderLocalLegacy$LocalDatanodeInfo' signature='()V' name='&lt;init&gt;' primary='true'><SourceLine endBytecode='145' classname='org.apache.hadoop.hdfs.client.impl.BlockReaderLocalLegacy$LocalDatanodeInfo' start='89' end='105' sourcepath='org/apache/hadoop/hdfs/client/impl/BlockReaderLocalLegacy.java' sourcefile='BlockReaderLocalLegacy.java' startBytecode='0'></SourceLine><Message>In method new org.apache.hadoop.hdfs.client.impl.BlockReaderLocalLegacy$LocalDatanodeInfo()</Message></Method><SourceLine endBytecode='36' classname='org.apache.hadoop.hdfs.client.impl.BlockReaderLocalLegacy$LocalDatanodeInfo' start='94' end='94' sourcepath='org/apache/hadoop/hdfs/client/impl/BlockReaderLocalLegacy.java' sourcefile='BlockReaderLocalLegacy.java' startBytecode='36' primary='true'><Message>At BlockReaderLocalLegacy.java:[line 94]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='c33b83e1a33bd1f7735f4ec4fa051ead' rank='20' abbrev='SIC' category='PERFORMANCE' priority='3' type='SIC_INNER_SHOULD_BE_STATIC_ANON' instanceOccurrenceMax='0'><ShortMessage>Could be refactored into a named static inner class</ShortMessage><LongMessage>The class org.apache.hadoop.hdfs.client.impl.BlockReaderLocalLegacy$LocalDatanodeInfo$2 could be refactored into a named _static_ inner class</LongMessage><Class role='CLASS_ANONYMOUS' classname='org.apache.hadoop.hdfs.client.impl.BlockReaderLocalLegacy$LocalDatanodeInfo$2'><SourceLine classname='org.apache.hadoop.hdfs.client.impl.BlockReaderLocalLegacy$LocalDatanodeInfo$2' start='113' end='116' sourcepath='org/apache/hadoop/hdfs/client/impl/BlockReaderLocalLegacy.java' sourcefile='BlockReaderLocalLegacy.java'><Message>At BlockReaderLocalLegacy.java:[lines 113-116]</Message></SourceLine><Message>Anonymous class org.apache.hadoop.hdfs.client.impl.BlockReaderLocalLegacy$LocalDatanodeInfo$2</Message></Class><Class classname='org.apache.hadoop.hdfs.client.impl.BlockReaderLocalLegacy$LocalDatanodeInfo' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.client.impl.BlockReaderLocalLegacy$LocalDatanodeInfo' start='85' end='145' sourcepath='org/apache/hadoop/hdfs/client/impl/BlockReaderLocalLegacy.java' sourcefile='BlockReaderLocalLegacy.java'><Message>At BlockReaderLocalLegacy.java:[lines 85-145]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.client.impl.BlockReaderLocalLegacy$LocalDatanodeInfo</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.client.impl.BlockReaderLocalLegacy$LocalDatanodeInfo' signature='(Lorg/apache/hadoop/security/UserGroupInformation;Lorg/apache/hadoop/hdfs/protocol/DatanodeInfo;Lorg/apache/hadoop/conf/Configuration;IZ)Lorg/apache/hadoop/hdfs/protocol/ClientDatanodeProtocol;' name='getDatanodeProxy' primary='true'><SourceLine endBytecode='196' classname='org.apache.hadoop.hdfs.client.impl.BlockReaderLocalLegacy$LocalDatanodeInfo' start='111' end='124' sourcepath='org/apache/hadoop/hdfs/client/impl/BlockReaderLocalLegacy.java' sourcefile='BlockReaderLocalLegacy.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.client.impl.BlockReaderLocalLegacy$LocalDatanodeInfo.getDatanodeProxy(UserGroupInformation, DatanodeInfo, Configuration, int, boolean)</Message></Method><SourceLine endBytecode='20' classname='org.apache.hadoop.hdfs.client.impl.BlockReaderLocalLegacy$LocalDatanodeInfo' start='113' end='113' sourcepath='org/apache/hadoop/hdfs/client/impl/BlockReaderLocalLegacy.java' sourcefile='BlockReaderLocalLegacy.java' startBytecode='20' primary='true'><Message>At BlockReaderLocalLegacy.java:[line 113]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='e05aeddf15fb7838f74c0760c9868b88' rank='20' abbrev='UM' category='PERFORMANCE' priority='3' type='UM_UNNECESSARY_MATH' instanceOccurrenceMax='0'><ShortMessage>Method calls static Math class method on a constant value</ShortMessage><LongMessage>Method calls static Math class method on a constant value</LongMessage><Class classname='org.apache.hadoop.hdfs.client.impl.BlockReaderLocalLegacy$LocalDatanodeInfo' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.client.impl.BlockReaderLocalLegacy$LocalDatanodeInfo' start='85' end='145' sourcepath='org/apache/hadoop/hdfs/client/impl/BlockReaderLocalLegacy.java' sourcefile='BlockReaderLocalLegacy.java'><Message>At BlockReaderLocalLegacy.java:[lines 85-145]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.client.impl.BlockReaderLocalLegacy$LocalDatanodeInfo</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.client.impl.BlockReaderLocalLegacy$LocalDatanodeInfo' signature='()V' name='&lt;init&gt;' primary='true'><SourceLine endBytecode='145' classname='org.apache.hadoop.hdfs.client.impl.BlockReaderLocalLegacy$LocalDatanodeInfo' start='89' end='105' sourcepath='org/apache/hadoop/hdfs/client/impl/BlockReaderLocalLegacy.java' sourcefile='BlockReaderLocalLegacy.java' startBytecode='0'></SourceLine><Message>In method new org.apache.hadoop.hdfs.client.impl.BlockReaderLocalLegacy$LocalDatanodeInfo()</Message></Method><SourceLine endBytecode='19' classname='org.apache.hadoop.hdfs.client.impl.BlockReaderLocalLegacy$LocalDatanodeInfo' start='92' end='92' sourcepath='org/apache/hadoop/hdfs/client/impl/BlockReaderLocalLegacy.java' sourcefile='BlockReaderLocalLegacy.java' startBytecode='19' primary='true'><Message>At BlockReaderLocalLegacy.java:[line 92]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='3fbfb94c4ae98a618d193300b7851529' rank='20' abbrev='SIC' category='PERFORMANCE' priority='3' type='SIC_INNER_SHOULD_BE_STATIC_ANON' instanceOccurrenceMax='0'><ShortMessage>Could be refactored into a named static inner class</ShortMessage><LongMessage>The class org.apache.hadoop.hdfs.client.impl.LeaseRenewer$2 could be refactored into a named _static_ inner class</LongMessage><Class role='CLASS_ANONYMOUS' classname='org.apache.hadoop.hdfs.client.impl.LeaseRenewer$2'><SourceLine classname='org.apache.hadoop.hdfs.client.impl.LeaseRenewer$2' start='385' end='388' sourcepath='org/apache/hadoop/hdfs/client/impl/LeaseRenewer.java' sourcefile='LeaseRenewer.java'><Message>At LeaseRenewer.java:[lines 385-388]</Message></SourceLine><Message>Anonymous class org.apache.hadoop.hdfs.client.impl.LeaseRenewer$2</Message></Class><Class classname='org.apache.hadoop.hdfs.client.impl.LeaseRenewer' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.client.impl.LeaseRenewer' start='76' end='496' sourcepath='org/apache/hadoop/hdfs/client/impl/LeaseRenewer.java' sourcefile='LeaseRenewer.java'><Message>At LeaseRenewer.java:[lines 76-496]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.client.impl.LeaseRenewer</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.client.impl.LeaseRenewer' signature='()V' name='renew' primary='true'><SourceLine endBytecode='360' classname='org.apache.hadoop.hdfs.client.impl.LeaseRenewer' start='381' end='403' sourcepath='org/apache/hadoop/hdfs/client/impl/LeaseRenewer.java' sourcefile='LeaseRenewer.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.client.impl.LeaseRenewer.renew()</Message></Method><SourceLine endBytecode='32' classname='org.apache.hadoop.hdfs.client.impl.LeaseRenewer' start='385' end='385' sourcepath='org/apache/hadoop/hdfs/client/impl/LeaseRenewer.java' sourcefile='LeaseRenewer.java' startBytecode='32' primary='true'><Message>At LeaseRenewer.java:[line 385]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='bd7eb020d94349d452302b1c86f66851' cweid='563' rank='17' abbrev='DLS' category='STYLE' priority='2' type='DLS_DEAD_LOCAL_STORE' instanceOccurrenceMax='0'><ShortMessage>Dead store to local variable</ShortMessage><LongMessage>Dead store to mockStream in org.apache.hadoop.hdfs.client.impl.TestLeaseRenewer.testRenewal()</LongMessage><Class classname='org.apache.hadoop.hdfs.client.impl.TestLeaseRenewer' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.client.impl.TestLeaseRenewer' start='38' end='198' sourcepath='org/apache/hadoop/hdfs/client/impl/TestLeaseRenewer.java' sourcefile='TestLeaseRenewer.java'><Message>At TestLeaseRenewer.java:[lines 38-198]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.client.impl.TestLeaseRenewer</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.client.impl.TestLeaseRenewer' signature='()V' name='testRenewal' primary='true'><SourceLine endBytecode='51' classname='org.apache.hadoop.hdfs.client.impl.TestLeaseRenewer' start='99' end='125' sourcepath='org/apache/hadoop/hdfs/client/impl/TestLeaseRenewer.java' sourcefile='TestLeaseRenewer.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.client.impl.TestLeaseRenewer.testRenewal()</Message></Method><LocalVariable role='LOCAL_VARIABLE_NAMED' pc='45' name='mockStream' register='2'><Message>Local variable named mockStream</Message></LocalVariable><SourceLine endBytecode='44' classname='org.apache.hadoop.hdfs.client.impl.TestLeaseRenewer' start='110' end='110' sourcepath='org/apache/hadoop/hdfs/client/impl/TestLeaseRenewer.java' sourcefile='TestLeaseRenewer.java' startBytecode='44' primary='true'><Message>At TestLeaseRenewer.java:[line 110]</Message></SourceLine><Property name='edu.umd.cs.findbugs.detect.DeadLocalStoreProperty.LOCAL_NAME' value='mockStream'></Property><Property name='edu.umd.cs.findbugs.detect.DeadLocalStoreProperty.NO_LOADS' value='true'></Property></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='4c289b62135588c7c73e42207ffc2608' cweid='440' rank='17' abbrev='RV' category='STYLE' priority='2' type='RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT' instanceOccurrenceMax='0'><ShortMessage>Return value of method without side effect is ignored</ShortMessage><LongMessage>Return value of org.apache.hadoop.hdfs.DFSClient.getClientName() ignored, but method has no side effect</LongMessage><Class classname='org.apache.hadoop.hdfs.client.impl.TestLeaseRenewer' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.client.impl.TestLeaseRenewer' start='38' end='198' sourcepath='org/apache/hadoop/hdfs/client/impl/TestLeaseRenewer.java' sourcefile='TestLeaseRenewer.java'><Message>At TestLeaseRenewer.java:[lines 38-198]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.client.impl.TestLeaseRenewer</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.client.impl.TestLeaseRenewer' signature='()Lorg/apache/hadoop/hdfs/DFSClient;' name='createMockClient' primary='true'><SourceLine endBytecode='181' classname='org.apache.hadoop.hdfs.client.impl.TestLeaseRenewer' start='63' end='70' sourcepath='org/apache/hadoop/hdfs/client/impl/TestLeaseRenewer.java' sourcefile='TestLeaseRenewer.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.client.impl.TestLeaseRenewer.createMockClient()</Message></Method><Method isStatic='false' role='METHOD_CALLED' classname='org.apache.hadoop.hdfs.DFSClient' signature='()Ljava/lang/String;' name='getClientName'><SourceLine endBytecode='46' classname='org.apache.hadoop.hdfs.DFSClient' start='467' end='467' sourcepath='org/apache/hadoop/hdfs/DFSClient.java' sourcefile='DFSClient.java' startBytecode='0'></SourceLine><Message>Called method org.apache.hadoop.hdfs.DFSClient.getClientName()</Message></Method><SourceLine endBytecode='90' classname='org.apache.hadoop.hdfs.client.impl.TestLeaseRenewer' start='69' end='69' sourcepath='org/apache/hadoop/hdfs/client/impl/TestLeaseRenewer.java' sourcefile='TestLeaseRenewer.java' startBytecode='90' primary='true'><Message>At TestLeaseRenewer.java:[line 69]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='688e6ae457c228b55974a8e5b3f8b56f' cweid='440' rank='17' abbrev='RV' category='STYLE' priority='2' type='RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT' instanceOccurrenceMax='0'><ShortMessage>Return value of method without side effect is ignored</ShortMessage><LongMessage>Return value of org.apache.hadoop.hdfs.DFSClient.getConf() ignored, but method has no side effect</LongMessage><Class classname='org.apache.hadoop.hdfs.client.impl.TestLeaseRenewer' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.client.impl.TestLeaseRenewer' start='38' end='198' sourcepath='org/apache/hadoop/hdfs/client/impl/TestLeaseRenewer.java' sourcefile='TestLeaseRenewer.java'><Message>At TestLeaseRenewer.java:[lines 38-198]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.client.impl.TestLeaseRenewer</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.client.impl.TestLeaseRenewer' signature='()Lorg/apache/hadoop/hdfs/DFSClient;' name='createMockClient' primary='true'><SourceLine endBytecode='181' classname='org.apache.hadoop.hdfs.client.impl.TestLeaseRenewer' start='63' end='70' sourcepath='org/apache/hadoop/hdfs/client/impl/TestLeaseRenewer.java' sourcefile='TestLeaseRenewer.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.client.impl.TestLeaseRenewer.createMockClient()</Message></Method><Method isStatic='false' role='METHOD_CALLED' classname='org.apache.hadoop.hdfs.DFSClient' signature='()Lorg/apache/hadoop/hdfs/client/impl/DfsClientConf;' name='getConf'><SourceLine endBytecode='46' classname='org.apache.hadoop.hdfs.DFSClient' start='244' end='244' sourcepath='org/apache/hadoop/hdfs/DFSClient.java' sourcefile='DFSClient.java' startBytecode='0'></SourceLine><Message>Called method org.apache.hadoop.hdfs.DFSClient.getConf()</Message></Method><SourceLine endBytecode='72' classname='org.apache.hadoop.hdfs.client.impl.TestLeaseRenewer' start='68' end='68' sourcepath='org/apache/hadoop/hdfs/client/impl/TestLeaseRenewer.java' sourcefile='TestLeaseRenewer.java' startBytecode='72' primary='true'><Message>At TestLeaseRenewer.java:[line 68]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='53dd8bdc6fc3546ef4cff8bac7fcfb28' cweid='440' rank='17' abbrev='RV' category='STYLE' priority='2' type='RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT' instanceOccurrenceMax='0'><ShortMessage>Return value of method without side effect is ignored</ShortMessage><LongMessage>Return value of org.apache.hadoop.hdfs.DFSClient.isClientRunning() ignored, but method has no side effect</LongMessage><Class classname='org.apache.hadoop.hdfs.client.impl.TestLeaseRenewer' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.client.impl.TestLeaseRenewer' start='38' end='198' sourcepath='org/apache/hadoop/hdfs/client/impl/TestLeaseRenewer.java' sourcefile='TestLeaseRenewer.java'><Message>At TestLeaseRenewer.java:[lines 38-198]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.client.impl.TestLeaseRenewer</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.client.impl.TestLeaseRenewer' signature='()Lorg/apache/hadoop/hdfs/DFSClient;' name='createMockClient' primary='true'><SourceLine endBytecode='181' classname='org.apache.hadoop.hdfs.client.impl.TestLeaseRenewer' start='63' end='70' sourcepath='org/apache/hadoop/hdfs/client/impl/TestLeaseRenewer.java' sourcefile='TestLeaseRenewer.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.client.impl.TestLeaseRenewer.createMockClient()</Message></Method><Method isStatic='false' role='METHOD_CALLED' classname='org.apache.hadoop.hdfs.DFSClient' signature='()Z' name='isClientRunning'><SourceLine endBytecode='46' classname='org.apache.hadoop.hdfs.DFSClient' start='542' end='542' sourcepath='org/apache/hadoop/hdfs/DFSClient.java' sourcefile='DFSClient.java' startBytecode='0'></SourceLine><Message>Called method org.apache.hadoop.hdfs.DFSClient.isClientRunning()</Message></Method><SourceLine endBytecode='55' classname='org.apache.hadoop.hdfs.client.impl.TestLeaseRenewer' start='67' end='67' sourcepath='org/apache/hadoop/hdfs/client/impl/TestLeaseRenewer.java' sourcefile='TestLeaseRenewer.java' startBytecode='55' primary='true'><Message>At TestLeaseRenewer.java:[line 67]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='ffd9fe5073fc5e9ebaa7408771307120' cweid='440' rank='17' abbrev='RV' category='STYLE' priority='2' type='RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT' instanceOccurrenceMax='0'><ShortMessage>Return value of method without side effect is ignored</ShortMessage><LongMessage>Return value of DfsClientConf.getHdfsTimeout() ignored, but method has no side effect</LongMessage><Class classname='org.apache.hadoop.hdfs.client.impl.TestLeaseRenewer' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.client.impl.TestLeaseRenewer' start='38' end='198' sourcepath='org/apache/hadoop/hdfs/client/impl/TestLeaseRenewer.java' sourcefile='TestLeaseRenewer.java'><Message>At TestLeaseRenewer.java:[lines 38-198]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.client.impl.TestLeaseRenewer</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.client.impl.TestLeaseRenewer' signature='()Lorg/apache/hadoop/hdfs/DFSClient;' name='createMockClient' primary='true'><SourceLine endBytecode='181' classname='org.apache.hadoop.hdfs.client.impl.TestLeaseRenewer' start='63' end='70' sourcepath='org/apache/hadoop/hdfs/client/impl/TestLeaseRenewer.java' sourcefile='TestLeaseRenewer.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.client.impl.TestLeaseRenewer.createMockClient()</Message></Method><Method isStatic='false' role='METHOD_CALLED' classname='org.apache.hadoop.hdfs.client.impl.DfsClientConf' signature='()I' name='getHdfsTimeout'><SourceLine endBytecode='46' classname='org.apache.hadoop.hdfs.client.impl.DfsClientConf' start='356' end='356' sourcepath='org/apache/hadoop/hdfs/client/impl/DfsClientConf.java' sourcefile='DfsClientConf.java' startBytecode='0'></SourceLine><Message>Called method org.apache.hadoop.hdfs.client.impl.DfsClientConf.getHdfsTimeout()</Message></Method><SourceLine endBytecode='26' classname='org.apache.hadoop.hdfs.client.impl.TestLeaseRenewer' start='64' end='64' sourcepath='org/apache/hadoop/hdfs/client/impl/TestLeaseRenewer.java' sourcefile='TestLeaseRenewer.java' startBytecode='26' primary='true'><Message>At TestLeaseRenewer.java:[line 64]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='f88d4683dd817082bd175d54765630fd' rank='20' abbrev='SIC' category='PERFORMANCE' priority='3' type='SIC_INNER_SHOULD_BE_STATIC_ANON' instanceOccurrenceMax='0'><ShortMessage>Could be refactored into a named static inner class</ShortMessage><LongMessage>The class org.apache.hadoop.hdfs.client.impl.TestLeaseRenewer$1 could be refactored into a named _static_ inner class</LongMessage><Class role='CLASS_ANONYMOUS' classname='org.apache.hadoop.hdfs.client.impl.TestLeaseRenewer$1'><SourceLine classname='org.apache.hadoop.hdfs.client.impl.TestLeaseRenewer$1' start='100' end='104' sourcepath='org/apache/hadoop/hdfs/client/impl/TestLeaseRenewer.java' sourcefile='TestLeaseRenewer.java'><Message>At TestLeaseRenewer.java:[lines 100-104]</Message></SourceLine><Message>Anonymous class org.apache.hadoop.hdfs.client.impl.TestLeaseRenewer$1</Message></Class><Class classname='org.apache.hadoop.hdfs.client.impl.TestLeaseRenewer' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.client.impl.TestLeaseRenewer' start='38' end='198' sourcepath='org/apache/hadoop/hdfs/client/impl/TestLeaseRenewer.java' sourcefile='TestLeaseRenewer.java'><Message>At TestLeaseRenewer.java:[lines 38-198]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.client.impl.TestLeaseRenewer</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.client.impl.TestLeaseRenewer' signature='()V' name='testRenewal' primary='true'><SourceLine endBytecode='279' classname='org.apache.hadoop.hdfs.client.impl.TestLeaseRenewer' start='99' end='125' sourcepath='org/apache/hadoop/hdfs/client/impl/TestLeaseRenewer.java' sourcefile='TestLeaseRenewer.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.client.impl.TestLeaseRenewer.testRenewal()</Message></Method><SourceLine endBytecode='14' classname='org.apache.hadoop.hdfs.client.impl.TestLeaseRenewer' start='100' end='100' sourcepath='org/apache/hadoop/hdfs/client/impl/TestLeaseRenewer.java' sourcefile='TestLeaseRenewer.java' startBytecode='14' primary='true'><Message>At TestLeaseRenewer.java:[line 100]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='3cbb5a2df704203c9d38691e1972aa91' rank='20' abbrev='SIC' category='PERFORMANCE' priority='3' type='SIC_INNER_SHOULD_BE_STATIC_ANON' instanceOccurrenceMax='0'><ShortMessage>Could be refactored into a named static inner class</ShortMessage><LongMessage>The class org.apache.hadoop.hdfs.client.impl.TestLeaseRenewer$2 could be refactored into a named _static_ inner class</LongMessage><Class role='CLASS_ANONYMOUS' classname='org.apache.hadoop.hdfs.client.impl.TestLeaseRenewer$2'><SourceLine classname='org.apache.hadoop.hdfs.client.impl.TestLeaseRenewer$2' start='152' end='164' sourcepath='org/apache/hadoop/hdfs/client/impl/TestLeaseRenewer.java' sourcefile='TestLeaseRenewer.java'><Message>At TestLeaseRenewer.java:[lines 152-164]</Message></SourceLine><Message>Anonymous class org.apache.hadoop.hdfs.client.impl.TestLeaseRenewer$2</Message></Class><Class classname='org.apache.hadoop.hdfs.client.impl.TestLeaseRenewer' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.client.impl.TestLeaseRenewer' start='38' end='198' sourcepath='org/apache/hadoop/hdfs/client/impl/TestLeaseRenewer.java' sourcefile='TestLeaseRenewer.java'><Message>At TestLeaseRenewer.java:[lines 38-198]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.client.impl.TestLeaseRenewer</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.client.impl.TestLeaseRenewer' signature='()V' name='testManyDfsClientsWhereSomeNotOpen' primary='true'><SourceLine endBytecode='264' classname='org.apache.hadoop.hdfs.client.impl.TestLeaseRenewer' start='135' end='171' sourcepath='org/apache/hadoop/hdfs/client/impl/TestLeaseRenewer.java' sourcefile='TestLeaseRenewer.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.client.impl.TestLeaseRenewer.testManyDfsClientsWhereSomeNotOpen()</Message></Method><SourceLine endBytecode='116' classname='org.apache.hadoop.hdfs.client.impl.TestLeaseRenewer' start='152' end='152' sourcepath='org/apache/hadoop/hdfs/client/impl/TestLeaseRenewer.java' sourcefile='TestLeaseRenewer.java' startBytecode='116' primary='true'><Message>At TestLeaseRenewer.java:[line 152]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='3186c8c9414b183428904433f9ec6dde' rank='18' abbrev='SS' category='PERFORMANCE' priority='2' type='SS_SHOULD_BE_STATIC' instanceOccurrenceMax='0'><ShortMessage>Unread field: should this field be static?</ShortMessage><LongMessage>Unread field: org.apache.hadoop.hdfs.client.impl.TestLeaseRenewer.FAKE_AUTHORITY; should this field be static?</LongMessage><Class classname='org.apache.hadoop.hdfs.client.impl.TestLeaseRenewer' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.client.impl.TestLeaseRenewer' start='38' end='198' sourcepath='org/apache/hadoop/hdfs/client/impl/TestLeaseRenewer.java' sourcefile='TestLeaseRenewer.java'><Message>At TestLeaseRenewer.java:[lines 38-198]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.client.impl.TestLeaseRenewer</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.client.impl.TestLeaseRenewer' signature='Ljava/lang/String;' name='FAKE_AUTHORITY' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.client.impl.TestLeaseRenewer' sourcepath='org/apache/hadoop/hdfs/client/impl/TestLeaseRenewer.java' sourcefile='TestLeaseRenewer.java'><Message>In TestLeaseRenewer.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.client.impl.TestLeaseRenewer.FAKE_AUTHORITY</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.client.impl.TestLeaseRenewer' start='39' end='39' sourcepath='org/apache/hadoop/hdfs/client/impl/TestLeaseRenewer.java' sourcefile='TestLeaseRenewer.java' startBytecode='7' primary='true'><Message>At TestLeaseRenewer.java:[line 39]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='7110e9d4d782b3a5dda256ae701afd67' rank='19' abbrev='Nm' category='BAD_PRACTICE' priority='3' type='NM_CONFUSING' instanceOccurrenceMax='0'><ShortMessage>Confusing method names</ShortMessage><LongMessage>Confusing to have methods org.apache.hadoop.hdfs.inotify.Event$CreateEvent.getGroupName() and org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetOwnerRequestProto.getGroupname()</LongMessage><Class classname='org.apache.hadoop.hdfs.inotify.Event$CreateEvent' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.inotify.Event$CreateEvent' start='99' end='265' sourcepath='org/apache/hadoop/hdfs/inotify/Event.java' sourcefile='Event.java'><Message>At Event.java:[lines 99-265]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.inotify.Event$CreateEvent</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.inotify.Event$CreateEvent' signature='()Ljava/lang/String;' name='getGroupName' primary='true'><SourceLine endBytecode='46' classname='org.apache.hadoop.hdfs.inotify.Event$CreateEvent' start='224' end='224' sourcepath='org/apache/hadoop/hdfs/inotify/Event.java' sourcefile='Event.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.inotify.Event$CreateEvent.getGroupName()</Message></Method><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetOwnerRequestProto'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetOwnerRequestProto' start='13339' end='14130' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 13339-14130]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetOwnerRequestProto</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetOwnerRequestProto' signature='()Ljava/lang/String;' name='getGroupname'><SourceLine endBytecode='163' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetOwnerRequestProto' start='13541' end='13551' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetOwnerRequestProto.getGroupname()</Message></Method><SourceLine synthetic='true' endBytecode='46' classname='org.apache.hadoop.hdfs.inotify.Event$CreateEvent' start='224' end='224' sourcepath='org/apache/hadoop/hdfs/inotify/Event.java' sourcefile='Event.java' startBytecode='0'><Message>At Event.java:[line 224]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='f105a907f82f4979b94bd68079714b1' cweid='374' rank='18' abbrev='EI' category='MALICIOUS_CODE' priority='2' type='EI_EXPOSE_REP' instanceOccurrenceMax='0'><ShortMessage>May expose internal representation by returning reference to mutable object</ShortMessage><LongMessage>org.apache.hadoop.hdfs.inotify.EventBatch.getEvents() may expose internal representation by returning EventBatch.events</LongMessage><Class classname='org.apache.hadoop.hdfs.inotify.EventBatch' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.inotify.EventBatch' start='31' end='40' sourcepath='org/apache/hadoop/hdfs/inotify/EventBatch.java' sourcefile='EventBatch.java'><Message>At EventBatch.java:[lines 31-40]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.inotify.EventBatch</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.inotify.EventBatch' signature='()[Lorg/apache/hadoop/hdfs/inotify/Event;' name='getEvents' primary='true'><SourceLine endBytecode='46' classname='org.apache.hadoop.hdfs.inotify.EventBatch' start='40' end='40' sourcepath='org/apache/hadoop/hdfs/inotify/EventBatch.java' sourcefile='EventBatch.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.inotify.EventBatch.getEvents()</Message></Method><Field isStatic='false' classname='org.apache.hadoop.hdfs.inotify.EventBatch' signature='[Lorg/apache/hadoop/hdfs/inotify/Event;' name='events' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.inotify.EventBatch' sourcepath='org/apache/hadoop/hdfs/inotify/EventBatch.java' sourcefile='EventBatch.java'><Message>In EventBatch.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.inotify.EventBatch.events</Message></Field><SourceLine endBytecode='4' classname='org.apache.hadoop.hdfs.inotify.EventBatch' start='40' end='40' sourcepath='org/apache/hadoop/hdfs/inotify/EventBatch.java' sourcefile='EventBatch.java' startBytecode='4' primary='true'><Message>At EventBatch.java:[line 40]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='b55396dc20b2356ec2200310d97ddd63' cweid='374' rank='18' abbrev='EI2' category='MALICIOUS_CODE' priority='2' type='EI_EXPOSE_REP2' instanceOccurrenceMax='0'><ShortMessage>May expose internal representation by incorporating reference to mutable object</ShortMessage><LongMessage>new org.apache.hadoop.hdfs.inotify.EventBatch(long, Event[]) may expose internal representation by storing an externally mutable object into EventBatch.events</LongMessage><Class classname='org.apache.hadoop.hdfs.inotify.EventBatch' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.inotify.EventBatch' start='31' end='40' sourcepath='org/apache/hadoop/hdfs/inotify/EventBatch.java' sourcefile='EventBatch.java'><Message>At EventBatch.java:[lines 31-40]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.inotify.EventBatch</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.inotify.EventBatch' signature='(J[Lorg/apache/hadoop/hdfs/inotify/Event;)V' name='&lt;init&gt;' primary='true'><SourceLine endBytecode='88' classname='org.apache.hadoop.hdfs.inotify.EventBatch' start='31' end='34' sourcepath='org/apache/hadoop/hdfs/inotify/EventBatch.java' sourcefile='EventBatch.java' startBytecode='0'></SourceLine><Message>In method new org.apache.hadoop.hdfs.inotify.EventBatch(long, Event[])</Message></Method><Field isStatic='false' classname='org.apache.hadoop.hdfs.inotify.EventBatch' signature='[Lorg/apache/hadoop/hdfs/inotify/Event;' name='events' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.inotify.EventBatch' sourcepath='org/apache/hadoop/hdfs/inotify/EventBatch.java' sourcefile='EventBatch.java'><Message>In EventBatch.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.inotify.EventBatch.events</Message></Field><LocalVariable role='LOCAL_VARIABLE_NAMED' pc='11' name='events' register='3'><Message>Local variable named events</Message></LocalVariable><SourceLine endBytecode='11' classname='org.apache.hadoop.hdfs.inotify.EventBatch' start='33' end='33' sourcepath='org/apache/hadoop/hdfs/inotify/EventBatch.java' sourcefile='EventBatch.java' startBytecode='11' primary='true'><Message>At EventBatch.java:[line 33]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='a8fb8f21b2c8a32c2106adae072155e3' cweid='374' rank='18' abbrev='EI' category='MALICIOUS_CODE' priority='2' type='EI_EXPOSE_REP' instanceOccurrenceMax='0'><ShortMessage>May expose internal representation by returning reference to mutable object</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.BlockStoragePolicy.getCreationFallbacks() may expose internal representation by returning BlockStoragePolicy.creationFallbacks</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.BlockStoragePolicy' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.BlockStoragePolicy' start='39' end='273' sourcepath='org/apache/hadoop/hdfs/protocol/BlockStoragePolicy.java' sourcefile='BlockStoragePolicy.java'><Message>At BlockStoragePolicy.java:[lines 39-273]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.BlockStoragePolicy</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.BlockStoragePolicy' signature='()[Lorg/apache/hadoop/fs/StorageType;' name='getCreationFallbacks' primary='true'><SourceLine endBytecode='46' classname='org.apache.hadoop.hdfs.protocol.BlockStoragePolicy' start='253' end='253' sourcepath='org/apache/hadoop/hdfs/protocol/BlockStoragePolicy.java' sourcefile='BlockStoragePolicy.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.BlockStoragePolicy.getCreationFallbacks()</Message></Method><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.BlockStoragePolicy' signature='[Lorg/apache/hadoop/fs/StorageType;' name='creationFallbacks' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.BlockStoragePolicy' sourcepath='org/apache/hadoop/hdfs/protocol/BlockStoragePolicy.java' sourcefile='BlockStoragePolicy.java'><Message>In BlockStoragePolicy.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.BlockStoragePolicy.creationFallbacks</Message></Field><SourceLine endBytecode='4' classname='org.apache.hadoop.hdfs.protocol.BlockStoragePolicy' start='253' end='253' sourcepath='org/apache/hadoop/hdfs/protocol/BlockStoragePolicy.java' sourcefile='BlockStoragePolicy.java' startBytecode='4' primary='true'><Message>At BlockStoragePolicy.java:[line 253]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='18389c285c2df0aa2206bd638accaa75' cweid='374' rank='18' abbrev='EI' category='MALICIOUS_CODE' priority='2' type='EI_EXPOSE_REP' instanceOccurrenceMax='0'><ShortMessage>May expose internal representation by returning reference to mutable object</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.BlockStoragePolicy.getReplicationFallbacks() may expose internal representation by returning BlockStoragePolicy.replicationFallbacks</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.BlockStoragePolicy' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.BlockStoragePolicy' start='39' end='273' sourcepath='org/apache/hadoop/hdfs/protocol/BlockStoragePolicy.java' sourcefile='BlockStoragePolicy.java'><Message>At BlockStoragePolicy.java:[lines 39-273]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.BlockStoragePolicy</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.BlockStoragePolicy' signature='()[Lorg/apache/hadoop/fs/StorageType;' name='getReplicationFallbacks' primary='true'><SourceLine endBytecode='46' classname='org.apache.hadoop.hdfs.protocol.BlockStoragePolicy' start='258' end='258' sourcepath='org/apache/hadoop/hdfs/protocol/BlockStoragePolicy.java' sourcefile='BlockStoragePolicy.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.BlockStoragePolicy.getReplicationFallbacks()</Message></Method><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.BlockStoragePolicy' signature='[Lorg/apache/hadoop/fs/StorageType;' name='replicationFallbacks' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.BlockStoragePolicy' sourcepath='org/apache/hadoop/hdfs/protocol/BlockStoragePolicy.java' sourcefile='BlockStoragePolicy.java'><Message>In BlockStoragePolicy.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.BlockStoragePolicy.replicationFallbacks</Message></Field><SourceLine endBytecode='4' classname='org.apache.hadoop.hdfs.protocol.BlockStoragePolicy' start='258' end='258' sourcepath='org/apache/hadoop/hdfs/protocol/BlockStoragePolicy.java' sourcefile='BlockStoragePolicy.java' startBytecode='4' primary='true'><Message>At BlockStoragePolicy.java:[line 258]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='2e6ddab3879d80acfa74ba2dd0b6bfa0' cweid='374' rank='18' abbrev='EI' category='MALICIOUS_CODE' priority='2' type='EI_EXPOSE_REP' instanceOccurrenceMax='0'><ShortMessage>May expose internal representation by returning reference to mutable object</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.BlockStoragePolicy.getStorageTypes() may expose internal representation by returning BlockStoragePolicy.storageTypes</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.BlockStoragePolicy' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.BlockStoragePolicy' start='39' end='273' sourcepath='org/apache/hadoop/hdfs/protocol/BlockStoragePolicy.java' sourcefile='BlockStoragePolicy.java'><Message>At BlockStoragePolicy.java:[lines 39-273]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.BlockStoragePolicy</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.BlockStoragePolicy' signature='()[Lorg/apache/hadoop/fs/StorageType;' name='getStorageTypes' primary='true'><SourceLine endBytecode='46' classname='org.apache.hadoop.hdfs.protocol.BlockStoragePolicy' start='248' end='248' sourcepath='org/apache/hadoop/hdfs/protocol/BlockStoragePolicy.java' sourcefile='BlockStoragePolicy.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.BlockStoragePolicy.getStorageTypes()</Message></Method><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.BlockStoragePolicy' signature='[Lorg/apache/hadoop/fs/StorageType;' name='storageTypes' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.BlockStoragePolicy' sourcepath='org/apache/hadoop/hdfs/protocol/BlockStoragePolicy.java' sourcefile='BlockStoragePolicy.java'><Message>In BlockStoragePolicy.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.BlockStoragePolicy.storageTypes</Message></Field><SourceLine endBytecode='4' classname='org.apache.hadoop.hdfs.protocol.BlockStoragePolicy' start='248' end='248' sourcepath='org/apache/hadoop/hdfs/protocol/BlockStoragePolicy.java' sourcefile='BlockStoragePolicy.java' startBytecode='4' primary='true'><Message>At BlockStoragePolicy.java:[line 248]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='a307d124f37f0f4aecae7bebb022bc72' cweid='374' rank='18' abbrev='EI2' category='MALICIOUS_CODE' priority='2' type='EI_EXPOSE_REP2' instanceOccurrenceMax='0'><ShortMessage>May expose internal representation by incorporating reference to mutable object</ShortMessage><LongMessage>new org.apache.hadoop.hdfs.protocol.BlockStoragePolicy(byte, String, StorageType[], StorageType[], StorageType[], boolean) may expose internal representation by storing an externally mutable object into BlockStoragePolicy.creationFallbacks</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.BlockStoragePolicy' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.BlockStoragePolicy' start='39' end='273' sourcepath='org/apache/hadoop/hdfs/protocol/BlockStoragePolicy.java' sourcefile='BlockStoragePolicy.java'><Message>At BlockStoragePolicy.java:[lines 39-273]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.BlockStoragePolicy</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.BlockStoragePolicy' signature='(BLjava/lang/String;[Lorg/apache/hadoop/fs/StorageType;[Lorg/apache/hadoop/fs/StorageType;[Lorg/apache/hadoop/fs/StorageType;Z)V' name='&lt;init&gt;' primary='true'><SourceLine endBytecode='167' classname='org.apache.hadoop.hdfs.protocol.BlockStoragePolicy' start='69' end='76' sourcepath='org/apache/hadoop/hdfs/protocol/BlockStoragePolicy.java' sourcefile='BlockStoragePolicy.java' startBytecode='0'></SourceLine><Message>In method new org.apache.hadoop.hdfs.protocol.BlockStoragePolicy(byte, String, StorageType[], StorageType[], StorageType[], boolean)</Message></Method><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.BlockStoragePolicy' signature='[Lorg/apache/hadoop/fs/StorageType;' name='creationFallbacks' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.BlockStoragePolicy' sourcepath='org/apache/hadoop/hdfs/protocol/BlockStoragePolicy.java' sourcefile='BlockStoragePolicy.java'><Message>In BlockStoragePolicy.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.BlockStoragePolicy.creationFallbacks</Message></Field><LocalVariable role='LOCAL_VARIABLE_NAMED' pc='22' name='creationFallbacks' register='4'><Message>Local variable named creationFallbacks</Message></LocalVariable><SourceLine endBytecode='22' classname='org.apache.hadoop.hdfs.protocol.BlockStoragePolicy' start='73' end='73' sourcepath='org/apache/hadoop/hdfs/protocol/BlockStoragePolicy.java' sourcefile='BlockStoragePolicy.java' startBytecode='22' primary='true'><Message>At BlockStoragePolicy.java:[line 73]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='12cb866dc121334ecfb807f9aa1db5e7' cweid='374' rank='18' abbrev='EI2' category='MALICIOUS_CODE' priority='2' type='EI_EXPOSE_REP2' instanceOccurrenceMax='0'><ShortMessage>May expose internal representation by incorporating reference to mutable object</ShortMessage><LongMessage>new org.apache.hadoop.hdfs.protocol.BlockStoragePolicy(byte, String, StorageType[], StorageType[], StorageType[], boolean) may expose internal representation by storing an externally mutable object into BlockStoragePolicy.replicationFallbacks</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.BlockStoragePolicy' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.BlockStoragePolicy' start='39' end='273' sourcepath='org/apache/hadoop/hdfs/protocol/BlockStoragePolicy.java' sourcefile='BlockStoragePolicy.java'><Message>At BlockStoragePolicy.java:[lines 39-273]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.BlockStoragePolicy</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.BlockStoragePolicy' signature='(BLjava/lang/String;[Lorg/apache/hadoop/fs/StorageType;[Lorg/apache/hadoop/fs/StorageType;[Lorg/apache/hadoop/fs/StorageType;Z)V' name='&lt;init&gt;' primary='true'><SourceLine endBytecode='167' classname='org.apache.hadoop.hdfs.protocol.BlockStoragePolicy' start='69' end='76' sourcepath='org/apache/hadoop/hdfs/protocol/BlockStoragePolicy.java' sourcefile='BlockStoragePolicy.java' startBytecode='0'></SourceLine><Message>In method new org.apache.hadoop.hdfs.protocol.BlockStoragePolicy(byte, String, StorageType[], StorageType[], StorageType[], boolean)</Message></Method><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.BlockStoragePolicy' signature='[Lorg/apache/hadoop/fs/StorageType;' name='replicationFallbacks' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.BlockStoragePolicy' sourcepath='org/apache/hadoop/hdfs/protocol/BlockStoragePolicy.java' sourcefile='BlockStoragePolicy.java'><Message>In BlockStoragePolicy.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.BlockStoragePolicy.replicationFallbacks</Message></Field><LocalVariable role='LOCAL_VARIABLE_NAMED' pc='28' name='replicationFallbacks' register='5'><Message>Local variable named replicationFallbacks</Message></LocalVariable><SourceLine endBytecode='28' classname='org.apache.hadoop.hdfs.protocol.BlockStoragePolicy' start='74' end='74' sourcepath='org/apache/hadoop/hdfs/protocol/BlockStoragePolicy.java' sourcefile='BlockStoragePolicy.java' startBytecode='28' primary='true'><Message>At BlockStoragePolicy.java:[line 74]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='65fe3f55fb3a549755f3a17ed099b898' cweid='374' rank='18' abbrev='EI2' category='MALICIOUS_CODE' priority='2' type='EI_EXPOSE_REP2' instanceOccurrenceMax='0'><ShortMessage>May expose internal representation by incorporating reference to mutable object</ShortMessage><LongMessage>new org.apache.hadoop.hdfs.protocol.BlockStoragePolicy(byte, String, StorageType[], StorageType[], StorageType[], boolean) may expose internal representation by storing an externally mutable object into BlockStoragePolicy.storageTypes</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.BlockStoragePolicy' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.BlockStoragePolicy' start='39' end='273' sourcepath='org/apache/hadoop/hdfs/protocol/BlockStoragePolicy.java' sourcefile='BlockStoragePolicy.java'><Message>At BlockStoragePolicy.java:[lines 39-273]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.BlockStoragePolicy</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.BlockStoragePolicy' signature='(BLjava/lang/String;[Lorg/apache/hadoop/fs/StorageType;[Lorg/apache/hadoop/fs/StorageType;[Lorg/apache/hadoop/fs/StorageType;Z)V' name='&lt;init&gt;' primary='true'><SourceLine endBytecode='167' classname='org.apache.hadoop.hdfs.protocol.BlockStoragePolicy' start='69' end='76' sourcepath='org/apache/hadoop/hdfs/protocol/BlockStoragePolicy.java' sourcefile='BlockStoragePolicy.java' startBytecode='0'></SourceLine><Message>In method new org.apache.hadoop.hdfs.protocol.BlockStoragePolicy(byte, String, StorageType[], StorageType[], StorageType[], boolean)</Message></Method><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.BlockStoragePolicy' signature='[Lorg/apache/hadoop/fs/StorageType;' name='storageTypes' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.BlockStoragePolicy' sourcepath='org/apache/hadoop/hdfs/protocol/BlockStoragePolicy.java' sourcefile='BlockStoragePolicy.java'><Message>In BlockStoragePolicy.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.BlockStoragePolicy.storageTypes</Message></Field><LocalVariable role='LOCAL_VARIABLE_NAMED' pc='16' name='storageTypes' register='3'><Message>Local variable named storageTypes</Message></LocalVariable><SourceLine endBytecode='16' classname='org.apache.hadoop.hdfs.protocol.BlockStoragePolicy' start='72' end='72' sourcepath='org/apache/hadoop/hdfs/protocol/BlockStoragePolicy.java' sourcefile='BlockStoragePolicy.java' startBytecode='16' primary='true'><Message>At BlockStoragePolicy.java:[line 72]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='d3ef0e89523cbe6bc0a044854c17a64c' cweid='374' rank='18' abbrev='EI' category='MALICIOUS_CODE' priority='2' type='EI_EXPOSE_REP' instanceOccurrenceMax='0'><ShortMessage>May expose internal representation by returning reference to mutable object</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.CorruptFileBlocks.getFiles() may expose internal representation by returning CorruptFileBlocks.files</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.CorruptFileBlocks' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.CorruptFileBlocks' start='35' end='73' sourcepath='org/apache/hadoop/hdfs/protocol/CorruptFileBlocks.java' sourcefile='CorruptFileBlocks.java'><Message>At CorruptFileBlocks.java:[lines 35-73]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.CorruptFileBlocks</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.CorruptFileBlocks' signature='()[Ljava/lang/String;' name='getFiles' primary='true'><SourceLine endBytecode='46' classname='org.apache.hadoop.hdfs.protocol.CorruptFileBlocks' start='44' end='44' sourcepath='org/apache/hadoop/hdfs/protocol/CorruptFileBlocks.java' sourcefile='CorruptFileBlocks.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.CorruptFileBlocks.getFiles()</Message></Method><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.CorruptFileBlocks' signature='[Ljava/lang/String;' name='files' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.CorruptFileBlocks' sourcepath='org/apache/hadoop/hdfs/protocol/CorruptFileBlocks.java' sourcefile='CorruptFileBlocks.java'><Message>In CorruptFileBlocks.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.CorruptFileBlocks.files</Message></Field><SourceLine endBytecode='4' classname='org.apache.hadoop.hdfs.protocol.CorruptFileBlocks' start='44' end='44' sourcepath='org/apache/hadoop/hdfs/protocol/CorruptFileBlocks.java' sourcefile='CorruptFileBlocks.java' startBytecode='4' primary='true'><Message>At CorruptFileBlocks.java:[line 44]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='f17f31046f7b1272b5984c283434ef7b' cweid='374' rank='18' abbrev='EI2' category='MALICIOUS_CODE' priority='2' type='EI_EXPOSE_REP2' instanceOccurrenceMax='0'><ShortMessage>May expose internal representation by incorporating reference to mutable object</ShortMessage><LongMessage>new org.apache.hadoop.hdfs.protocol.CorruptFileBlocks(String[], String) may expose internal representation by storing an externally mutable object into CorruptFileBlocks.files</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.CorruptFileBlocks' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.CorruptFileBlocks' start='35' end='73' sourcepath='org/apache/hadoop/hdfs/protocol/CorruptFileBlocks.java' sourcefile='CorruptFileBlocks.java'><Message>At CorruptFileBlocks.java:[lines 35-73]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.CorruptFileBlocks</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.CorruptFileBlocks' signature='([Ljava/lang/String;Ljava/lang/String;)V' name='&lt;init&gt;' primary='true'><SourceLine endBytecode='88' classname='org.apache.hadoop.hdfs.protocol.CorruptFileBlocks' start='38' end='41' sourcepath='org/apache/hadoop/hdfs/protocol/CorruptFileBlocks.java' sourcefile='CorruptFileBlocks.java' startBytecode='0'></SourceLine><Message>In method new org.apache.hadoop.hdfs.protocol.CorruptFileBlocks(String[], String)</Message></Method><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.CorruptFileBlocks' signature='[Ljava/lang/String;' name='files' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.CorruptFileBlocks' sourcepath='org/apache/hadoop/hdfs/protocol/CorruptFileBlocks.java' sourcefile='CorruptFileBlocks.java'><Message>In CorruptFileBlocks.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.CorruptFileBlocks.files</Message></Field><LocalVariable role='LOCAL_VARIABLE_NAMED' pc='6' name='files' register='1'><Message>Local variable named files</Message></LocalVariable><SourceLine endBytecode='6' classname='org.apache.hadoop.hdfs.protocol.CorruptFileBlocks' start='39' end='39' sourcepath='org/apache/hadoop/hdfs/protocol/CorruptFileBlocks.java' sourcefile='CorruptFileBlocks.java' startBytecode='6' primary='true'><Message>At CorruptFileBlocks.java:[line 39]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='f5a9185ad9ca0858068e804bfeb6603c' rank='19' abbrev='Nm' category='BAD_PRACTICE' priority='3' type='NM_CONFUSING' instanceOccurrenceMax='0'><ShortMessage>Confusing method names</ShortMessage><LongMessage>Confusing to have methods org.apache.hadoop.hdfs.protocol.DatanodeInfoWithStorage.getStorageID() and org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpReplaceBlockProto.getStorageId()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.DatanodeInfoWithStorage' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.DatanodeInfoWithStorage' start='32' end='63' sourcepath='org/apache/hadoop/hdfs/protocol/DatanodeInfoWithStorage.java' sourcefile='DatanodeInfoWithStorage.java'><Message>At DatanodeInfoWithStorage.java:[lines 32-63]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.DatanodeInfoWithStorage</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.DatanodeInfoWithStorage' signature='()Ljava/lang/String;' name='getStorageID' primary='true'><SourceLine endBytecode='46' classname='org.apache.hadoop.hdfs.protocol.DatanodeInfoWithStorage' start='42' end='42' sourcepath='org/apache/hadoop/hdfs/protocol/DatanodeInfoWithStorage.java' sourcefile='DatanodeInfoWithStorage.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.DatanodeInfoWithStorage.getStorageID()</Message></Method><Class classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpReplaceBlockProto'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpReplaceBlockProto' start='10685' end='11821' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java'><Message>At DataTransferProtos.java:[lines 10685-11821]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpReplaceBlockProto</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpReplaceBlockProto' signature='()Ljava/lang/String;' name='getStorageId'><SourceLine endBytecode='163' classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpReplaceBlockProto' start='10936' end='10946' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpReplaceBlockProto.getStorageId()</Message></Method><SourceLine synthetic='true' endBytecode='46' classname='org.apache.hadoop.hdfs.protocol.DatanodeInfoWithStorage' start='42' end='42' sourcepath='org/apache/hadoop/hdfs/protocol/DatanodeInfoWithStorage.java' sourcefile='DatanodeInfoWithStorage.java' startBytecode='0'><Message>At DatanodeInfoWithStorage.java:[line 42]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='46cf1413502058dde0382c40ef5e2e04' cweid='374' rank='18' abbrev='EI' category='MALICIOUS_CODE' priority='2' type='EI_EXPOSE_REP' instanceOccurrenceMax='0'><ShortMessage>May expose internal representation by returning reference to mutable object</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.DirectoryListing.getPartialListing() may expose internal representation by returning DirectoryListing.partialListing</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.DirectoryListing' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.DirectoryListing' start='40' end='85' sourcepath='org/apache/hadoop/hdfs/protocol/DirectoryListing.java' sourcefile='DirectoryListing.java'><Message>At DirectoryListing.java:[lines 40-85]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.DirectoryListing</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.DirectoryListing' signature='()[Lorg/apache/hadoop/hdfs/protocol/HdfsFileStatus;' name='getPartialListing' primary='true'><SourceLine endBytecode='46' classname='org.apache.hadoop.hdfs.protocol.DirectoryListing' start='57' end='57' sourcepath='org/apache/hadoop/hdfs/protocol/DirectoryListing.java' sourcefile='DirectoryListing.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.DirectoryListing.getPartialListing()</Message></Method><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.DirectoryListing' signature='[Lorg/apache/hadoop/hdfs/protocol/HdfsFileStatus;' name='partialListing' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.DirectoryListing' sourcepath='org/apache/hadoop/hdfs/protocol/DirectoryListing.java' sourcefile='DirectoryListing.java'><Message>In DirectoryListing.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.DirectoryListing.partialListing</Message></Field><SourceLine endBytecode='4' classname='org.apache.hadoop.hdfs.protocol.DirectoryListing' start='57' end='57' sourcepath='org/apache/hadoop/hdfs/protocol/DirectoryListing.java' sourcefile='DirectoryListing.java' startBytecode='4' primary='true'><Message>At DirectoryListing.java:[line 57]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='36d00932ce79f195772f241d7d7edf10' cweid='374' rank='18' abbrev='EI2' category='MALICIOUS_CODE' priority='2' type='EI_EXPOSE_REP2' instanceOccurrenceMax='0'><ShortMessage>May expose internal representation by incorporating reference to mutable object</ShortMessage><LongMessage>new org.apache.hadoop.hdfs.protocol.DirectoryListing(HdfsFileStatus[], int) may expose internal representation by storing an externally mutable object into DirectoryListing.partialListing</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.DirectoryListing' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.DirectoryListing' start='40' end='85' sourcepath='org/apache/hadoop/hdfs/protocol/DirectoryListing.java' sourcefile='DirectoryListing.java'><Message>At DirectoryListing.java:[lines 40-85]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.DirectoryListing</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.DirectoryListing' signature='([Lorg/apache/hadoop/hdfs/protocol/HdfsFileStatus;I)V' name='&lt;init&gt;' primary='true'><SourceLine endBytecode='160' classname='org.apache.hadoop.hdfs.protocol.DirectoryListing' start='40' end='50' sourcepath='org/apache/hadoop/hdfs/protocol/DirectoryListing.java' sourcefile='DirectoryListing.java' startBytecode='0'></SourceLine><Message>In method new org.apache.hadoop.hdfs.protocol.DirectoryListing(HdfsFileStatus[], int)</Message></Method><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.DirectoryListing' signature='[Lorg/apache/hadoop/hdfs/protocol/HdfsFileStatus;' name='partialListing' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.DirectoryListing' sourcepath='org/apache/hadoop/hdfs/protocol/DirectoryListing.java' sourcefile='DirectoryListing.java'><Message>In DirectoryListing.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.DirectoryListing.partialListing</Message></Field><LocalVariable role='LOCAL_VARIABLE_NAMED' pc='39' name='partialListing' register='1'><Message>Local variable named partialListing</Message></LocalVariable><SourceLine endBytecode='39' classname='org.apache.hadoop.hdfs.protocol.DirectoryListing' start='48' end='48' sourcepath='org/apache/hadoop/hdfs/protocol/DirectoryListing.java' sourcefile='DirectoryListing.java' startBytecode='39' primary='true'><Message>At DirectoryListing.java:[line 48]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='53a3569edf4ec2414bd5369d3b933b0f' rank='20' abbrev='PZLA' category='STYLE' priority='3' type='PZLA_PREFER_ZERO_LENGTH_ARRAYS' instanceOccurrenceMax='0'><ShortMessage>Consider returning a zero length array rather than null</ShortMessage><LongMessage>Should org.apache.hadoop.hdfs.protocol.DirectoryListing.getLastName() return a zero length array rather than null?</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.DirectoryListing' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.DirectoryListing' start='40' end='85' sourcepath='org/apache/hadoop/hdfs/protocol/DirectoryListing.java' sourcefile='DirectoryListing.java'><Message>At DirectoryListing.java:[lines 40-85]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.DirectoryListing</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.DirectoryListing' signature='()[B' name='getLastName' primary='true'><SourceLine endBytecode='86' classname='org.apache.hadoop.hdfs.protocol.DirectoryListing' start='82' end='85' sourcepath='org/apache/hadoop/hdfs/protocol/DirectoryListing.java' sourcefile='DirectoryListing.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.DirectoryListing.getLastName()</Message></Method><SourceLine endBytecode='9' classname='org.apache.hadoop.hdfs.protocol.DirectoryListing' start='83' end='83' sourcepath='org/apache/hadoop/hdfs/protocol/DirectoryListing.java' sourcefile='DirectoryListing.java' startBytecode='9' primary='true'><Message>At DirectoryListing.java:[line 83]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='f69a48f6981a9fb121aedca78fe0c294' rank='20' abbrev='Dm' category='I18N' priority='3' type='DM_CONVERT_CASE' instanceOccurrenceMax='0'><ShortMessage>Consider using Locale parameterized version of invoked method</ShortMessage><LongMessage>Use of non-localized String.toUpperCase() or String.toLowerCase() in org.apache.hadoop.hdfs.protocol.ErasureCodingPolicy.composePolicyName(ECSchema, int)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.ErasureCodingPolicy' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.ErasureCodingPolicy' start='47' end='146' sourcepath='org/apache/hadoop/hdfs/protocol/ErasureCodingPolicy.java' sourcefile='ErasureCodingPolicy.java'><Message>At ErasureCodingPolicy.java:[lines 47-146]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.ErasureCodingPolicy</Message></Class><Method isStatic='true' classname='org.apache.hadoop.hdfs.protocol.ErasureCodingPolicy' signature='(Lorg/apache/hadoop/io/erasurecode/ECSchema;I)Ljava/lang/String;' name='composePolicyName' primary='true'><SourceLine endBytecode='185' classname='org.apache.hadoop.hdfs.protocol.ErasureCodingPolicy' start='68' end='72' sourcepath='org/apache/hadoop/hdfs/protocol/ErasureCodingPolicy.java' sourcefile='ErasureCodingPolicy.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.ErasureCodingPolicy.composePolicyName(ECSchema, int)</Message></Method><SourceLine endBytecode='48' classname='org.apache.hadoop.hdfs.protocol.ErasureCodingPolicy' start='72' end='72' sourcepath='org/apache/hadoop/hdfs/protocol/ErasureCodingPolicy.java' sourcefile='ErasureCodingPolicy.java' startBytecode='48' primary='true'><Message>At ErasureCodingPolicy.java:[line 72]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='ed9bd0360e8de316bde209a5ad35f3c2' rank='20' abbrev='UCF' category='STYLE' priority='3' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.HdfsFileStatus.&lt;static initializer for HdfsFileStatus&gt;()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.HdfsFileStatus' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.HdfsFileStatus' start='41' end='535' sourcepath='org/apache/hadoop/hdfs/protocol/HdfsFileStatus.java' sourcefile='HdfsFileStatus.java'><Message>At HdfsFileStatus.java:[lines 41-535]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.HdfsFileStatus</Message></Class><Method isStatic='true' classname='org.apache.hadoop.hdfs.protocol.HdfsFileStatus' signature='()V' name='&lt;clinit&gt;' primary='true'><SourceLine endBytecode='49' classname='org.apache.hadoop.hdfs.protocol.HdfsFileStatus' start='41' end='46' sourcepath='org/apache/hadoop/hdfs/protocol/HdfsFileStatus.java' sourcefile='HdfsFileStatus.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.HdfsFileStatus.&lt;static initializer for HdfsFileStatus&gt;()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.HdfsFileStatus' start='41' end='41' sourcepath='org/apache/hadoop/hdfs/protocol/HdfsFileStatus.java' sourcefile='HdfsFileStatus.java' startBytecode='3' primary='true'><Message>At HdfsFileStatus.java:[line 41]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='d51111a518867809a41f955d71f2e196' cweid='374' rank='18' abbrev='EI' category='MALICIOUS_CODE' priority='2' type='EI_EXPOSE_REP' instanceOccurrenceMax='0'><ShortMessage>May expose internal representation by returning reference to mutable object</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.HdfsLocatedFileStatus.getLocalNameInBytes() may expose internal representation by returning HdfsLocatedFileStatus.uPath</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.HdfsLocatedFileStatus' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.HdfsLocatedFileStatus' start='85' end='217' sourcepath='org/apache/hadoop/hdfs/protocol/HdfsLocatedFileStatus.java' sourcefile='HdfsLocatedFileStatus.java'><Message>At HdfsLocatedFileStatus.java:[lines 85-217]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.HdfsLocatedFileStatus</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.HdfsLocatedFileStatus' signature='()[B' name='getLocalNameInBytes' primary='true'><SourceLine endBytecode='46' classname='org.apache.hadoop.hdfs.protocol.HdfsLocatedFileStatus' start='133' end='133' sourcepath='org/apache/hadoop/hdfs/protocol/HdfsLocatedFileStatus.java' sourcefile='HdfsLocatedFileStatus.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.HdfsLocatedFileStatus.getLocalNameInBytes()</Message></Method><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.HdfsLocatedFileStatus' signature='[B' name='uPath' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.HdfsLocatedFileStatus' sourcepath='org/apache/hadoop/hdfs/protocol/HdfsLocatedFileStatus.java' sourcefile='HdfsLocatedFileStatus.java'><Message>In HdfsLocatedFileStatus.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.HdfsLocatedFileStatus.uPath</Message></Field><SourceLine endBytecode='4' classname='org.apache.hadoop.hdfs.protocol.HdfsLocatedFileStatus' start='133' end='133' sourcepath='org/apache/hadoop/hdfs/protocol/HdfsLocatedFileStatus.java' sourcefile='HdfsLocatedFileStatus.java' startBytecode='4' primary='true'><Message>At HdfsLocatedFileStatus.java:[line 133]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='12a38f4aa120f43065311b8a3d328bba' cweid='374' rank='18' abbrev='EI' category='MALICIOUS_CODE' priority='2' type='EI_EXPOSE_REP' instanceOccurrenceMax='0'><ShortMessage>May expose internal representation by returning reference to mutable object</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.HdfsLocatedFileStatus.getSymlinkInBytes() may expose internal representation by returning HdfsLocatedFileStatus.uSymlink</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.HdfsLocatedFileStatus' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.HdfsLocatedFileStatus' start='85' end='217' sourcepath='org/apache/hadoop/hdfs/protocol/HdfsLocatedFileStatus.java' sourcefile='HdfsLocatedFileStatus.java'><Message>At HdfsLocatedFileStatus.java:[lines 85-217]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.HdfsLocatedFileStatus</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.HdfsLocatedFileStatus' signature='()[B' name='getSymlinkInBytes' primary='true'><SourceLine endBytecode='46' classname='org.apache.hadoop.hdfs.protocol.HdfsLocatedFileStatus' start='146' end='146' sourcepath='org/apache/hadoop/hdfs/protocol/HdfsLocatedFileStatus.java' sourcefile='HdfsLocatedFileStatus.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.HdfsLocatedFileStatus.getSymlinkInBytes()</Message></Method><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.HdfsLocatedFileStatus' signature='[B' name='uSymlink' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.HdfsLocatedFileStatus' sourcepath='org/apache/hadoop/hdfs/protocol/HdfsLocatedFileStatus.java' sourcefile='HdfsLocatedFileStatus.java'><Message>In HdfsLocatedFileStatus.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.HdfsLocatedFileStatus.uSymlink</Message></Field><SourceLine endBytecode='4' classname='org.apache.hadoop.hdfs.protocol.HdfsLocatedFileStatus' start='146' end='146' sourcepath='org/apache/hadoop/hdfs/protocol/HdfsLocatedFileStatus.java' sourcefile='HdfsLocatedFileStatus.java' startBytecode='4' primary='true'><Message>At HdfsLocatedFileStatus.java:[line 146]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='9e2ee5d54833dbe929ee793ce0dd54b3' rank='19' abbrev='Se' category='BAD_PRACTICE' priority='3' type='SE_TRANSIENT_FIELD_NOT_RESTORED' instanceOccurrenceMax='0'><ShortMessage>Transient field that isn't set by deserialization. </ShortMessage><LongMessage>The field org.apache.hadoop.hdfs.protocol.HdfsLocatedFileStatus.hdfsloc is transient but isn't set by deserialization</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.HdfsLocatedFileStatus' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.HdfsLocatedFileStatus' start='85' end='217' sourcepath='org/apache/hadoop/hdfs/protocol/HdfsLocatedFileStatus.java' sourcefile='HdfsLocatedFileStatus.java'><Message>At HdfsLocatedFileStatus.java:[lines 85-217]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.HdfsLocatedFileStatus</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.HdfsLocatedFileStatus' signature='Lorg/apache/hadoop/hdfs/protocol/LocatedBlocks;' name='hdfsloc' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.HdfsLocatedFileStatus' sourcepath='org/apache/hadoop/hdfs/protocol/HdfsLocatedFileStatus.java' sourcefile='HdfsLocatedFileStatus.java'><Message>In HdfsLocatedFileStatus.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.HdfsLocatedFileStatus.hdfsloc</Message></Field><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.HdfsLocatedFileStatus' sourcepath='org/apache/hadoop/hdfs/protocol/HdfsLocatedFileStatus.java' sourcefile='HdfsLocatedFileStatus.java'><Message>In HdfsLocatedFileStatus.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='317053e9524a35c01c3d1301da2b40fb' cweid='374' rank='18' abbrev='EI' category='MALICIOUS_CODE' priority='2' type='EI_EXPOSE_REP' instanceOccurrenceMax='0'><ShortMessage>May expose internal representation by returning reference to mutable object</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.HdfsNamedFileStatus.getLocalNameInBytes() may expose internal representation by returning HdfsNamedFileStatus.uPath</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.HdfsNamedFileStatus' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.HdfsNamedFileStatus' start='73' end='177' sourcepath='org/apache/hadoop/hdfs/protocol/HdfsNamedFileStatus.java' sourcefile='HdfsNamedFileStatus.java'><Message>At HdfsNamedFileStatus.java:[lines 73-177]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.HdfsNamedFileStatus</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.HdfsNamedFileStatus' signature='()[B' name='getLocalNameInBytes' primary='true'><SourceLine endBytecode='46' classname='org.apache.hadoop.hdfs.protocol.HdfsNamedFileStatus' start='121' end='121' sourcepath='org/apache/hadoop/hdfs/protocol/HdfsNamedFileStatus.java' sourcefile='HdfsNamedFileStatus.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.HdfsNamedFileStatus.getLocalNameInBytes()</Message></Method><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.HdfsNamedFileStatus' signature='[B' name='uPath' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.HdfsNamedFileStatus' sourcepath='org/apache/hadoop/hdfs/protocol/HdfsNamedFileStatus.java' sourcefile='HdfsNamedFileStatus.java'><Message>In HdfsNamedFileStatus.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.HdfsNamedFileStatus.uPath</Message></Field><SourceLine endBytecode='4' classname='org.apache.hadoop.hdfs.protocol.HdfsNamedFileStatus' start='121' end='121' sourcepath='org/apache/hadoop/hdfs/protocol/HdfsNamedFileStatus.java' sourcefile='HdfsNamedFileStatus.java' startBytecode='4' primary='true'><Message>At HdfsNamedFileStatus.java:[line 121]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='16d7e06f6b9dff84f153358c71e565b7' cweid='374' rank='18' abbrev='EI' category='MALICIOUS_CODE' priority='2' type='EI_EXPOSE_REP' instanceOccurrenceMax='0'><ShortMessage>May expose internal representation by returning reference to mutable object</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.HdfsNamedFileStatus.getSymlinkInBytes() may expose internal representation by returning HdfsNamedFileStatus.uSymlink</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.HdfsNamedFileStatus' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.HdfsNamedFileStatus' start='73' end='177' sourcepath='org/apache/hadoop/hdfs/protocol/HdfsNamedFileStatus.java' sourcefile='HdfsNamedFileStatus.java'><Message>At HdfsNamedFileStatus.java:[lines 73-177]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.HdfsNamedFileStatus</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.HdfsNamedFileStatus' signature='()[B' name='getSymlinkInBytes' primary='true'><SourceLine endBytecode='46' classname='org.apache.hadoop.hdfs.protocol.HdfsNamedFileStatus' start='134' end='134' sourcepath='org/apache/hadoop/hdfs/protocol/HdfsNamedFileStatus.java' sourcefile='HdfsNamedFileStatus.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.HdfsNamedFileStatus.getSymlinkInBytes()</Message></Method><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.HdfsNamedFileStatus' signature='[B' name='uSymlink' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.HdfsNamedFileStatus' sourcepath='org/apache/hadoop/hdfs/protocol/HdfsNamedFileStatus.java' sourcefile='HdfsNamedFileStatus.java'><Message>In HdfsNamedFileStatus.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.HdfsNamedFileStatus.uSymlink</Message></Field><SourceLine endBytecode='4' classname='org.apache.hadoop.hdfs.protocol.HdfsNamedFileStatus' start='134' end='134' sourcepath='org/apache/hadoop/hdfs/protocol/HdfsNamedFileStatus.java' sourcefile='HdfsNamedFileStatus.java' startBytecode='4' primary='true'><Message>At HdfsNamedFileStatus.java:[line 134]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='3a7de4e663c1570770832f328401e980' rank='19' abbrev='SnVI' category='BAD_PRACTICE' priority='3' type='SE_NO_SERIALVERSIONID' instanceOccurrenceMax='0'><ShortMessage>Class is Serializable, but doesn't define serialVersionUID</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.HdfsNamedFileStatus is Serializable; consider declaring a serialVersionUID</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.HdfsNamedFileStatus' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.HdfsNamedFileStatus' start='73' end='177' sourcepath='org/apache/hadoop/hdfs/protocol/HdfsNamedFileStatus.java' sourcefile='HdfsNamedFileStatus.java'><Message>At HdfsNamedFileStatus.java:[lines 73-177]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.HdfsNamedFileStatus</Message></Class><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.HdfsNamedFileStatus' start='73' end='177' sourcepath='org/apache/hadoop/hdfs/protocol/HdfsNamedFileStatus.java' sourcefile='HdfsNamedFileStatus.java'><Message>At HdfsNamedFileStatus.java:[lines 73-177]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='69cfb0ecc554b4c469dcda88a2f0951f' cweid='374' rank='18' abbrev='EI' category='MALICIOUS_CODE' priority='2' type='EI_EXPOSE_REP' instanceOccurrenceMax='0'><ShortMessage>May expose internal representation by returning reference to mutable object</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.LocatedBlock.getCachedLocations() may expose internal representation by returning LocatedBlock.cachedLocs</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.LocatedBlock' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.LocatedBlock' start='81' end='279' sourcepath='org/apache/hadoop/hdfs/protocol/LocatedBlock.java' sourcefile='LocatedBlock.java'><Message>At LocatedBlock.java:[lines 81-279]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.LocatedBlock</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.LocatedBlock' signature='()[Lorg/apache/hadoop/hdfs/protocol/DatanodeInfo;' name='getCachedLocations' primary='true'><SourceLine endBytecode='46' classname='org.apache.hadoop.hdfs.protocol.LocatedBlock' start='261' end='261' sourcepath='org/apache/hadoop/hdfs/protocol/LocatedBlock.java' sourcefile='LocatedBlock.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.LocatedBlock.getCachedLocations()</Message></Method><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.LocatedBlock' signature='[Lorg/apache/hadoop/hdfs/protocol/DatanodeInfo;' name='cachedLocs' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.LocatedBlock' sourcepath='org/apache/hadoop/hdfs/protocol/LocatedBlock.java' sourcefile='LocatedBlock.java'><Message>In LocatedBlock.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.LocatedBlock.cachedLocs</Message></Field><SourceLine endBytecode='4' classname='org.apache.hadoop.hdfs.protocol.LocatedBlock' start='261' end='261' sourcepath='org/apache/hadoop/hdfs/protocol/LocatedBlock.java' sourcefile='LocatedBlock.java' startBytecode='4' primary='true'><Message>At LocatedBlock.java:[line 261]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='fc3c5fe16835db596dd7cc52f0a865c2' cweid='374' rank='18' abbrev='EI' category='MALICIOUS_CODE' priority='2' type='EI_EXPOSE_REP' instanceOccurrenceMax='0'><ShortMessage>May expose internal representation by returning reference to mutable object</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.LocatedBlock.getLocations() may expose internal representation by returning LocatedBlock.locs</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.LocatedBlock' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.LocatedBlock' start='81' end='279' sourcepath='org/apache/hadoop/hdfs/protocol/LocatedBlock.java' sourcefile='LocatedBlock.java'><Message>At LocatedBlock.java:[lines 81-279]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.LocatedBlock</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.LocatedBlock' signature='()[Lorg/apache/hadoop/hdfs/protocol/DatanodeInfo;' name='getLocations' primary='true'><SourceLine endBytecode='46' classname='org.apache.hadoop.hdfs.protocol.LocatedBlock' start='162' end='162' sourcepath='org/apache/hadoop/hdfs/protocol/LocatedBlock.java' sourcefile='LocatedBlock.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.LocatedBlock.getLocations()</Message></Method><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.LocatedBlock' signature='[Lorg/apache/hadoop/hdfs/protocol/DatanodeInfoWithStorage;' name='locs' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.LocatedBlock' sourcepath='org/apache/hadoop/hdfs/protocol/LocatedBlock.java' sourcefile='LocatedBlock.java'><Message>In LocatedBlock.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.LocatedBlock.locs</Message></Field><SourceLine endBytecode='4' classname='org.apache.hadoop.hdfs.protocol.LocatedBlock' start='162' end='162' sourcepath='org/apache/hadoop/hdfs/protocol/LocatedBlock.java' sourcefile='LocatedBlock.java' startBytecode='4' primary='true'><Message>At LocatedBlock.java:[line 162]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='95098df994754dcdb1249cc59db9fc80' cweid='374' rank='18' abbrev='EI' category='MALICIOUS_CODE' priority='2' type='EI_EXPOSE_REP' instanceOccurrenceMax='0'><ShortMessage>May expose internal representation by returning reference to mutable object</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.LocatedBlock.getStorageIDs() may expose internal representation by returning LocatedBlock.storageIDs</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.LocatedBlock' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.LocatedBlock' start='81' end='279' sourcepath='org/apache/hadoop/hdfs/protocol/LocatedBlock.java' sourcefile='LocatedBlock.java'><Message>At LocatedBlock.java:[lines 81-279]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.LocatedBlock</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.LocatedBlock' signature='()[Ljava/lang/String;' name='getStorageIDs' primary='true'><SourceLine endBytecode='46' classname='org.apache.hadoop.hdfs.protocol.LocatedBlock' start='170' end='170' sourcepath='org/apache/hadoop/hdfs/protocol/LocatedBlock.java' sourcefile='LocatedBlock.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.LocatedBlock.getStorageIDs()</Message></Method><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.LocatedBlock' signature='[Ljava/lang/String;' name='storageIDs' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.LocatedBlock' sourcepath='org/apache/hadoop/hdfs/protocol/LocatedBlock.java' sourcefile='LocatedBlock.java'><Message>In LocatedBlock.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.LocatedBlock.storageIDs</Message></Field><SourceLine endBytecode='4' classname='org.apache.hadoop.hdfs.protocol.LocatedBlock' start='170' end='170' sourcepath='org/apache/hadoop/hdfs/protocol/LocatedBlock.java' sourcefile='LocatedBlock.java' startBytecode='4' primary='true'><Message>At LocatedBlock.java:[line 170]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='27ee0c76fff9e5c7fbb7d2f7770f8597' cweid='374' rank='18' abbrev='EI' category='MALICIOUS_CODE' priority='2' type='EI_EXPOSE_REP' instanceOccurrenceMax='0'><ShortMessage>May expose internal representation by returning reference to mutable object</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.LocatedBlock.getStorageTypes() may expose internal representation by returning LocatedBlock.storageTypes</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.LocatedBlock' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.LocatedBlock' start='81' end='279' sourcepath='org/apache/hadoop/hdfs/protocol/LocatedBlock.java' sourcefile='LocatedBlock.java'><Message>At LocatedBlock.java:[lines 81-279]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.LocatedBlock</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.LocatedBlock' signature='()[Lorg/apache/hadoop/fs/StorageType;' name='getStorageTypes' primary='true'><SourceLine endBytecode='46' classname='org.apache.hadoop.hdfs.protocol.LocatedBlock' start='166' end='166' sourcepath='org/apache/hadoop/hdfs/protocol/LocatedBlock.java' sourcefile='LocatedBlock.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.LocatedBlock.getStorageTypes()</Message></Method><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.LocatedBlock' signature='[Lorg/apache/hadoop/fs/StorageType;' name='storageTypes' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.LocatedBlock' sourcepath='org/apache/hadoop/hdfs/protocol/LocatedBlock.java' sourcefile='LocatedBlock.java'><Message>In LocatedBlock.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.LocatedBlock.storageTypes</Message></Field><SourceLine endBytecode='4' classname='org.apache.hadoop.hdfs.protocol.LocatedBlock' start='166' end='166' sourcepath='org/apache/hadoop/hdfs/protocol/LocatedBlock.java' sourcefile='LocatedBlock.java' startBytecode='4' primary='true'><Message>At LocatedBlock.java:[line 166]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='af58324bf05a6124841de5a43a8f3fd0' cweid='374' rank='18' abbrev='EI2' category='MALICIOUS_CODE' priority='2' type='EI_EXPOSE_REP2' instanceOccurrenceMax='0'><ShortMessage>May expose internal representation by incorporating reference to mutable object</ShortMessage><LongMessage>new org.apache.hadoop.hdfs.protocol.LocatedBlock(ExtendedBlock, DatanodeInfoWithStorage[], String[], StorageType[], long, boolean, DatanodeInfo[]) may expose internal representation by storing an externally mutable object into LocatedBlock.storageIDs</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.LocatedBlock' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.LocatedBlock' start='81' end='279' sourcepath='org/apache/hadoop/hdfs/protocol/LocatedBlock.java' sourcefile='LocatedBlock.java'><Message>At LocatedBlock.java:[lines 81-279]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.LocatedBlock</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.LocatedBlock' signature='(Lorg/apache/hadoop/hdfs/protocol/ExtendedBlock;[Lorg/apache/hadoop/hdfs/protocol/DatanodeInfoWithStorage;[Ljava/lang/String;[Lorg/apache/hadoop/fs/StorageType;JZ[Lorg/apache/hadoop/hdfs/protocol/DatanodeInfo;)V' name='&lt;init&gt;' primary='true'><SourceLine endBytecode='344' classname='org.apache.hadoop.hdfs.protocol.LocatedBlock' start='116' end='126' sourcepath='org/apache/hadoop/hdfs/protocol/LocatedBlock.java' sourcefile='LocatedBlock.java' startBytecode='0'></SourceLine><Message>In method new org.apache.hadoop.hdfs.protocol.LocatedBlock(ExtendedBlock, DatanodeInfoWithStorage[], String[], StorageType[], long, boolean, DatanodeInfo[])</Message></Method><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.LocatedBlock' signature='[Ljava/lang/String;' name='storageIDs' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.LocatedBlock' sourcepath='org/apache/hadoop/hdfs/protocol/LocatedBlock.java' sourcefile='LocatedBlock.java'><Message>In LocatedBlock.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.LocatedBlock.storageIDs</Message></Field><LocalVariable role='LOCAL_VARIABLE_NAMED' pc='50' name='storageIDs' register='3'><Message>Local variable named storageIDs</Message></LocalVariable><SourceLine endBytecode='50' classname='org.apache.hadoop.hdfs.protocol.LocatedBlock' start='121' end='121' sourcepath='org/apache/hadoop/hdfs/protocol/LocatedBlock.java' sourcefile='LocatedBlock.java' startBytecode='50' primary='true'><Message>At LocatedBlock.java:[line 121]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='8405ea7a186b19bcefdbfa430ef5aae7' cweid='374' rank='18' abbrev='EI2' category='MALICIOUS_CODE' priority='2' type='EI_EXPOSE_REP2' instanceOccurrenceMax='0'><ShortMessage>May expose internal representation by incorporating reference to mutable object</ShortMessage><LongMessage>new org.apache.hadoop.hdfs.protocol.LocatedBlock(ExtendedBlock, DatanodeInfoWithStorage[], String[], StorageType[], long, boolean, DatanodeInfo[]) may expose internal representation by storing an externally mutable object into LocatedBlock.storageTypes</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.LocatedBlock' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.LocatedBlock' start='81' end='279' sourcepath='org/apache/hadoop/hdfs/protocol/LocatedBlock.java' sourcefile='LocatedBlock.java'><Message>At LocatedBlock.java:[lines 81-279]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.LocatedBlock</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.LocatedBlock' signature='(Lorg/apache/hadoop/hdfs/protocol/ExtendedBlock;[Lorg/apache/hadoop/hdfs/protocol/DatanodeInfoWithStorage;[Ljava/lang/String;[Lorg/apache/hadoop/fs/StorageType;JZ[Lorg/apache/hadoop/hdfs/protocol/DatanodeInfo;)V' name='&lt;init&gt;' primary='true'><SourceLine endBytecode='344' classname='org.apache.hadoop.hdfs.protocol.LocatedBlock' start='116' end='126' sourcepath='org/apache/hadoop/hdfs/protocol/LocatedBlock.java' sourcefile='LocatedBlock.java' startBytecode='0'></SourceLine><Message>In method new org.apache.hadoop.hdfs.protocol.LocatedBlock(ExtendedBlock, DatanodeInfoWithStorage[], String[], StorageType[], long, boolean, DatanodeInfo[])</Message></Method><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.LocatedBlock' signature='[Lorg/apache/hadoop/fs/StorageType;' name='storageTypes' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.LocatedBlock' sourcepath='org/apache/hadoop/hdfs/protocol/LocatedBlock.java' sourcefile='LocatedBlock.java'><Message>In LocatedBlock.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.LocatedBlock.storageTypes</Message></Field><LocalVariable role='LOCAL_VARIABLE_NAMED' pc='56' name='storageTypes' register='4'><Message>Local variable named storageTypes</Message></LocalVariable><SourceLine endBytecode='56' classname='org.apache.hadoop.hdfs.protocol.LocatedBlock' start='122' end='122' sourcepath='org/apache/hadoop/hdfs/protocol/LocatedBlock.java' sourcefile='LocatedBlock.java' startBytecode='56' primary='true'><Message>At LocatedBlock.java:[line 122]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='d3871858c1a00c685578c2250bd12f8b' rank='19' abbrev='Nm' category='BAD_PRACTICE' priority='3' type='NM_CONFUSING' instanceOccurrenceMax='0'><ShortMessage>Confusing method names</ShortMessage><LongMessage>Confusing to have methods org.apache.hadoop.hdfs.protocol.LocatedBlock.getBlockSize() and org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$HdfsFileStatusProto.getBlocksize()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.LocatedBlock' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.LocatedBlock' start='81' end='279' sourcepath='org/apache/hadoop/hdfs/protocol/LocatedBlock.java' sourcefile='LocatedBlock.java'><Message>At LocatedBlock.java:[lines 81-279]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.LocatedBlock</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.LocatedBlock' signature='()J' name='getBlockSize' primary='true'><SourceLine endBytecode='49' classname='org.apache.hadoop.hdfs.protocol.LocatedBlock' start='216' end='216' sourcepath='org/apache/hadoop/hdfs/protocol/LocatedBlock.java' sourcefile='LocatedBlock.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.LocatedBlock.getBlockSize()</Message></Method><Class classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$HdfsFileStatusProto'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$HdfsFileStatusProto' start='32811' end='35792' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>At HdfsProtos.java:[lines 32811-35792]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$HdfsFileStatusProto</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$HdfsFileStatusProto' signature='()J' name='getBlocksize'><SourceLine endBytecode='46' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$HdfsFileStatusProto' start='33507' end='33507' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$HdfsFileStatusProto.getBlocksize()</Message></Method><SourceLine synthetic='true' endBytecode='49' classname='org.apache.hadoop.hdfs.protocol.LocatedBlock' start='216' end='216' sourcepath='org/apache/hadoop/hdfs/protocol/LocatedBlock.java' sourcefile='LocatedBlock.java' startBytecode='0'><Message>At LocatedBlock.java:[line 216]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='ffdf2377f0ede74ecb099dd1dbb5183f' rank='20' abbrev='SIC' category='PERFORMANCE' priority='3' type='SIC_INNER_SHOULD_BE_STATIC_ANON' instanceOccurrenceMax='0'><ShortMessage>Could be refactored into a named static inner class</ShortMessage><LongMessage>The class org.apache.hadoop.hdfs.protocol.LocatedBlocks$1 could be refactored into a named _static_ inner class</LongMessage><Class role='CLASS_ANONYMOUS' classname='org.apache.hadoop.hdfs.protocol.LocatedBlocks$1'><SourceLine classname='org.apache.hadoop.hdfs.protocol.LocatedBlocks$1' start='138' end='151' sourcepath='org/apache/hadoop/hdfs/protocol/LocatedBlocks.java' sourcefile='LocatedBlocks.java'><Message>At LocatedBlocks.java:[lines 138-151]</Message></SourceLine><Message>Anonymous class org.apache.hadoop.hdfs.protocol.LocatedBlocks$1</Message></Class><Class classname='org.apache.hadoop.hdfs.protocol.LocatedBlocks' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.LocatedBlocks' start='31' end='191' sourcepath='org/apache/hadoop/hdfs/protocol/LocatedBlocks.java' sourcefile='LocatedBlocks.java'><Message>At LocatedBlocks.java:[lines 31-191]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.LocatedBlocks</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.LocatedBlocks' signature='(J)I' name='findBlock' primary='true'><SourceLine endBytecode='158' classname='org.apache.hadoop.hdfs.protocol.LocatedBlocks' start='133' end='154' sourcepath='org/apache/hadoop/hdfs/protocol/LocatedBlocks.java' sourcefile='LocatedBlocks.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.LocatedBlocks.findBlock(long)</Message></Method><SourceLine endBytecode='37' classname='org.apache.hadoop.hdfs.protocol.LocatedBlocks' start='137' end='137' sourcepath='org/apache/hadoop/hdfs/protocol/LocatedBlocks.java' sourcefile='LocatedBlocks.java' startBytecode='37' primary='true'><Message>At LocatedBlocks.java:[line 137]</Message></SourceLine><LocalVariable role='LOCAL_VARIABLE_NAMED' pc='42' name='comp' register='4'><Message>Local variable named comp</Message></LocalVariable></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='913c72c4eb0d18692ed514b1841a80d1' cweid='374' rank='18' abbrev='EI' category='MALICIOUS_CODE' priority='2' type='EI_EXPOSE_REP' instanceOccurrenceMax='0'><ShortMessage>May expose internal representation by returning reference to mutable object</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.LocatedStripedBlock.getBlockIndices() may expose internal representation by returning LocatedStripedBlock.blockIndices</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.LocatedStripedBlock' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.LocatedStripedBlock' start='36' end='86' sourcepath='org/apache/hadoop/hdfs/protocol/LocatedStripedBlock.java' sourcefile='LocatedStripedBlock.java'><Message>At LocatedStripedBlock.java:[lines 36-86]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.LocatedStripedBlock</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.LocatedStripedBlock' signature='()[B' name='getBlockIndices' primary='true'><SourceLine endBytecode='46' classname='org.apache.hadoop.hdfs.protocol.LocatedStripedBlock' start='72' end='72' sourcepath='org/apache/hadoop/hdfs/protocol/LocatedStripedBlock.java' sourcefile='LocatedStripedBlock.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.LocatedStripedBlock.getBlockIndices()</Message></Method><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.LocatedStripedBlock' signature='[B' name='blockIndices' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.LocatedStripedBlock' sourcepath='org/apache/hadoop/hdfs/protocol/LocatedStripedBlock.java' sourcefile='LocatedStripedBlock.java'><Message>In LocatedStripedBlock.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.LocatedStripedBlock.blockIndices</Message></Field><SourceLine endBytecode='4' classname='org.apache.hadoop.hdfs.protocol.LocatedStripedBlock' start='72' end='72' sourcepath='org/apache/hadoop/hdfs/protocol/LocatedStripedBlock.java' sourcefile='LocatedStripedBlock.java' startBytecode='4' primary='true'><Message>At LocatedStripedBlock.java:[line 72]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='b991cd74897aa499bb80b4110685bc33' cweid='374' rank='18' abbrev='EI' category='MALICIOUS_CODE' priority='2' type='EI_EXPOSE_REP' instanceOccurrenceMax='0'><ShortMessage>May expose internal representation by returning reference to mutable object</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.LocatedStripedBlock.getBlockTokens() may expose internal representation by returning LocatedStripedBlock.blockTokens</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.LocatedStripedBlock' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.LocatedStripedBlock' start='36' end='86' sourcepath='org/apache/hadoop/hdfs/protocol/LocatedStripedBlock.java' sourcefile='LocatedStripedBlock.java'><Message>At LocatedStripedBlock.java:[lines 36-86]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.LocatedStripedBlock</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.LocatedStripedBlock' signature='()[Lorg/apache/hadoop/security/token/Token;' name='getBlockTokens' primary='true'><SourceLine endBytecode='46' classname='org.apache.hadoop.hdfs.protocol.LocatedStripedBlock' start='81' end='81' sourcepath='org/apache/hadoop/hdfs/protocol/LocatedStripedBlock.java' sourcefile='LocatedStripedBlock.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.LocatedStripedBlock.getBlockTokens()</Message></Method><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.LocatedStripedBlock' signature='[Lorg/apache/hadoop/security/token/Token;' name='blockTokens' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.LocatedStripedBlock' sourcepath='org/apache/hadoop/hdfs/protocol/LocatedStripedBlock.java' sourcefile='LocatedStripedBlock.java'><Message>In LocatedStripedBlock.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.LocatedStripedBlock.blockTokens</Message></Field><SourceLine endBytecode='4' classname='org.apache.hadoop.hdfs.protocol.LocatedStripedBlock' start='81' end='81' sourcepath='org/apache/hadoop/hdfs/protocol/LocatedStripedBlock.java' sourcefile='LocatedStripedBlock.java' startBytecode='4' primary='true'><Message>At LocatedStripedBlock.java:[line 81]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='f85e0818daf17e75a756ded3b8b8a709' cweid='374' rank='18' abbrev='EI2' category='MALICIOUS_CODE' priority='2' type='EI_EXPOSE_REP2' instanceOccurrenceMax='0'><ShortMessage>May expose internal representation by incorporating reference to mutable object</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.LocatedStripedBlock.setBlockTokens(Token[]) may expose internal representation by storing an externally mutable object into LocatedStripedBlock.blockTokens</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.LocatedStripedBlock' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.LocatedStripedBlock' start='36' end='86' sourcepath='org/apache/hadoop/hdfs/protocol/LocatedStripedBlock.java' sourcefile='LocatedStripedBlock.java'><Message>At LocatedStripedBlock.java:[lines 36-86]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.LocatedStripedBlock</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.LocatedStripedBlock' signature='([Lorg/apache/hadoop/security/token/Token;)V' name='setBlockTokens' primary='true'><SourceLine endBytecode='79' classname='org.apache.hadoop.hdfs.protocol.LocatedStripedBlock' start='85' end='86' sourcepath='org/apache/hadoop/hdfs/protocol/LocatedStripedBlock.java' sourcefile='LocatedStripedBlock.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.LocatedStripedBlock.setBlockTokens(Token[])</Message></Method><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.LocatedStripedBlock' signature='[Lorg/apache/hadoop/security/token/Token;' name='blockTokens' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.LocatedStripedBlock' sourcepath='org/apache/hadoop/hdfs/protocol/LocatedStripedBlock.java' sourcefile='LocatedStripedBlock.java'><Message>In LocatedStripedBlock.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.LocatedStripedBlock.blockTokens</Message></Field><LocalVariable role='LOCAL_VARIABLE_NAMED' pc='2' name='tokens' register='1'><Message>Local variable named tokens</Message></LocalVariable><SourceLine endBytecode='2' classname='org.apache.hadoop.hdfs.protocol.LocatedStripedBlock' start='85' end='85' sourcepath='org/apache/hadoop/hdfs/protocol/LocatedStripedBlock.java' sourcefile='LocatedStripedBlock.java' startBytecode='2' primary='true'><Message>At LocatedStripedBlock.java:[line 85]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='a77720ef4730f9b81e7825d79ce9718b' rank='20' abbrev='CI' category='STYLE' priority='3' type='CI_CONFUSED_INHERITANCE' instanceOccurrenceMax='0'><ShortMessage>Class is final but declares protected field</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.NSQuotaExceededException is final but declares protected field org.apache.hadoop.hdfs.protocol.NSQuotaExceededException.serialVersionUID</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.NSQuotaExceededException' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.NSQuotaExceededException' start='31' end='59' sourcepath='org/apache/hadoop/hdfs/protocol/NSQuotaExceededException.java' sourcefile='NSQuotaExceededException.java'><Message>At NSQuotaExceededException.java:[lines 31-59]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.NSQuotaExceededException</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.NSQuotaExceededException' signature='J' name='serialVersionUID' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.NSQuotaExceededException' sourcepath='org/apache/hadoop/hdfs/protocol/NSQuotaExceededException.java' sourcefile='NSQuotaExceededException.java'><Message>In NSQuotaExceededException.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.NSQuotaExceededException.serialVersionUID</Message></Field><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.NSQuotaExceededException' sourcepath='org/apache/hadoop/hdfs/protocol/NSQuotaExceededException.java' sourcefile='NSQuotaExceededException.java'><Message>In NSQuotaExceededException.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='f0e54cc34c43329a51683ba2dd35c469' cweid='374' rank='18' abbrev='EI' category='MALICIOUS_CODE' priority='2' type='EI_EXPOSE_REP' instanceOccurrenceMax='0'><ShortMessage>May expose internal representation by returning reference to mutable object</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.SnapshotDiffReport$DiffReportEntry.getSourcePath() may expose internal representation by returning SnapshotDiffReport$DiffReportEntry.sourcePath</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.SnapshotDiffReport$DiffReportEntry' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.SnapshotDiffReport$DiffReportEntry' start='93' end='160' sourcepath='org/apache/hadoop/hdfs/protocol/SnapshotDiffReport.java' sourcefile='SnapshotDiffReport.java'><Message>At SnapshotDiffReport.java:[lines 93-160]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.SnapshotDiffReport$DiffReportEntry</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.SnapshotDiffReport$DiffReportEntry' signature='()[B' name='getSourcePath' primary='true'><SourceLine endBytecode='46' classname='org.apache.hadoop.hdfs.protocol.SnapshotDiffReport$DiffReportEntry' start='137' end='137' sourcepath='org/apache/hadoop/hdfs/protocol/SnapshotDiffReport.java' sourcefile='SnapshotDiffReport.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.SnapshotDiffReport$DiffReportEntry.getSourcePath()</Message></Method><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.SnapshotDiffReport$DiffReportEntry' signature='[B' name='sourcePath' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.SnapshotDiffReport$DiffReportEntry' sourcepath='org/apache/hadoop/hdfs/protocol/SnapshotDiffReport.java' sourcefile='SnapshotDiffReport.java'><Message>In SnapshotDiffReport.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.SnapshotDiffReport$DiffReportEntry.sourcePath</Message></Field><SourceLine endBytecode='4' classname='org.apache.hadoop.hdfs.protocol.SnapshotDiffReport$DiffReportEntry' start='137' end='137' sourcepath='org/apache/hadoop/hdfs/protocol/SnapshotDiffReport.java' sourcefile='SnapshotDiffReport.java' startBytecode='4' primary='true'><Message>At SnapshotDiffReport.java:[line 137]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='72245a8e69e6b8eb2acccafb56d2042b' cweid='374' rank='18' abbrev='EI' category='MALICIOUS_CODE' priority='2' type='EI_EXPOSE_REP' instanceOccurrenceMax='0'><ShortMessage>May expose internal representation by returning reference to mutable object</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.SnapshotDiffReport$DiffReportEntry.getTargetPath() may expose internal representation by returning SnapshotDiffReport$DiffReportEntry.targetPath</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.SnapshotDiffReport$DiffReportEntry' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.SnapshotDiffReport$DiffReportEntry' start='93' end='160' sourcepath='org/apache/hadoop/hdfs/protocol/SnapshotDiffReport.java' sourcefile='SnapshotDiffReport.java'><Message>At SnapshotDiffReport.java:[lines 93-160]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.SnapshotDiffReport$DiffReportEntry</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.SnapshotDiffReport$DiffReportEntry' signature='()[B' name='getTargetPath' primary='true'><SourceLine endBytecode='46' classname='org.apache.hadoop.hdfs.protocol.SnapshotDiffReport$DiffReportEntry' start='141' end='141' sourcepath='org/apache/hadoop/hdfs/protocol/SnapshotDiffReport.java' sourcefile='SnapshotDiffReport.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.SnapshotDiffReport$DiffReportEntry.getTargetPath()</Message></Method><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.SnapshotDiffReport$DiffReportEntry' signature='[B' name='targetPath' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.SnapshotDiffReport$DiffReportEntry' sourcepath='org/apache/hadoop/hdfs/protocol/SnapshotDiffReport.java' sourcefile='SnapshotDiffReport.java'><Message>In SnapshotDiffReport.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.SnapshotDiffReport$DiffReportEntry.targetPath</Message></Field><SourceLine endBytecode='4' classname='org.apache.hadoop.hdfs.protocol.SnapshotDiffReport$DiffReportEntry' start='141' end='141' sourcepath='org/apache/hadoop/hdfs/protocol/SnapshotDiffReport.java' sourcefile='SnapshotDiffReport.java' startBytecode='4' primary='true'><Message>At SnapshotDiffReport.java:[line 141]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='7d1e0d62af187a17ca8be6973e01fe83' cweid='374' rank='18' abbrev='EI2' category='MALICIOUS_CODE' priority='2' type='EI_EXPOSE_REP2' instanceOccurrenceMax='0'><ShortMessage>May expose internal representation by incorporating reference to mutable object</ShortMessage><LongMessage>new org.apache.hadoop.hdfs.protocol.SnapshotDiffReport$DiffReportEntry(SnapshotDiffReport$DiffType, byte[], byte[]) may expose internal representation by storing an externally mutable object into SnapshotDiffReport$DiffReportEntry.sourcePath</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.SnapshotDiffReport$DiffReportEntry' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.SnapshotDiffReport$DiffReportEntry' start='93' end='160' sourcepath='org/apache/hadoop/hdfs/protocol/SnapshotDiffReport.java' sourcefile='SnapshotDiffReport.java'><Message>At SnapshotDiffReport.java:[lines 93-160]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.SnapshotDiffReport$DiffReportEntry</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.SnapshotDiffReport$DiffReportEntry' signature='(Lorg/apache/hadoop/hdfs/protocol/SnapshotDiffReport$DiffType;[B[B)V' name='&lt;init&gt;' primary='true'><SourceLine endBytecode='107' classname='org.apache.hadoop.hdfs.protocol.SnapshotDiffReport$DiffReportEntry' start='100' end='104' sourcepath='org/apache/hadoop/hdfs/protocol/SnapshotDiffReport.java' sourcefile='SnapshotDiffReport.java' startBytecode='0'></SourceLine><Message>In method new org.apache.hadoop.hdfs.protocol.SnapshotDiffReport$DiffReportEntry(SnapshotDiffReport$DiffType, byte[], byte[])</Message></Method><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.SnapshotDiffReport$DiffReportEntry' signature='[B' name='sourcePath' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.SnapshotDiffReport$DiffReportEntry' sourcepath='org/apache/hadoop/hdfs/protocol/SnapshotDiffReport.java' sourcefile='SnapshotDiffReport.java'><Message>In SnapshotDiffReport.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.SnapshotDiffReport$DiffReportEntry.sourcePath</Message></Field><LocalVariable role='LOCAL_VARIABLE_NAMED' pc='11' name='sourcePath' register='2'><Message>Local variable named sourcePath</Message></LocalVariable><SourceLine endBytecode='11' classname='org.apache.hadoop.hdfs.protocol.SnapshotDiffReport$DiffReportEntry' start='102' end='102' sourcepath='org/apache/hadoop/hdfs/protocol/SnapshotDiffReport.java' sourcefile='SnapshotDiffReport.java' startBytecode='11' primary='true'><Message>At SnapshotDiffReport.java:[line 102]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='9099cdb33852132d0fad52aac5feff4d' cweid='374' rank='18' abbrev='EI2' category='MALICIOUS_CODE' priority='2' type='EI_EXPOSE_REP2' instanceOccurrenceMax='0'><ShortMessage>May expose internal representation by incorporating reference to mutable object</ShortMessage><LongMessage>new org.apache.hadoop.hdfs.protocol.SnapshotDiffReport$DiffReportEntry(SnapshotDiffReport$DiffType, byte[], byte[]) may expose internal representation by storing an externally mutable object into SnapshotDiffReport$DiffReportEntry.targetPath</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.SnapshotDiffReport$DiffReportEntry' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.SnapshotDiffReport$DiffReportEntry' start='93' end='160' sourcepath='org/apache/hadoop/hdfs/protocol/SnapshotDiffReport.java' sourcefile='SnapshotDiffReport.java'><Message>At SnapshotDiffReport.java:[lines 93-160]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.SnapshotDiffReport$DiffReportEntry</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.SnapshotDiffReport$DiffReportEntry' signature='(Lorg/apache/hadoop/hdfs/protocol/SnapshotDiffReport$DiffType;[B[B)V' name='&lt;init&gt;' primary='true'><SourceLine endBytecode='107' classname='org.apache.hadoop.hdfs.protocol.SnapshotDiffReport$DiffReportEntry' start='100' end='104' sourcepath='org/apache/hadoop/hdfs/protocol/SnapshotDiffReport.java' sourcefile='SnapshotDiffReport.java' startBytecode='0'></SourceLine><Message>In method new org.apache.hadoop.hdfs.protocol.SnapshotDiffReport$DiffReportEntry(SnapshotDiffReport$DiffType, byte[], byte[])</Message></Method><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.SnapshotDiffReport$DiffReportEntry' signature='[B' name='targetPath' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.SnapshotDiffReport$DiffReportEntry' sourcepath='org/apache/hadoop/hdfs/protocol/SnapshotDiffReport.java' sourcefile='SnapshotDiffReport.java'><Message>In SnapshotDiffReport.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.SnapshotDiffReport$DiffReportEntry.targetPath</Message></Field><LocalVariable role='LOCAL_VARIABLE_NAMED' pc='16' name='targetPath' register='3'><Message>Local variable named targetPath</Message></LocalVariable><SourceLine endBytecode='16' classname='org.apache.hadoop.hdfs.protocol.SnapshotDiffReport$DiffReportEntry' start='103' end='103' sourcepath='org/apache/hadoop/hdfs/protocol/SnapshotDiffReport.java' sourcefile='SnapshotDiffReport.java' startBytecode='16' primary='true'><Message>At SnapshotDiffReport.java:[line 103]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='a153099884dcbfc72ccf0b26652c108f' rank='20' abbrev='Dm' category='I18N' priority='3' type='DM_CONVERT_CASE' instanceOccurrenceMax='0'><ShortMessage>Consider using Locale parameterized version of invoked method</ShortMessage><LongMessage>Use of non-localized String.toUpperCase() or String.toLowerCase() in org.apache.hadoop.hdfs.protocol.SnapshotDiffReport$DiffType.parseDiffType(String)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.SnapshotDiffReport$DiffType' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.SnapshotDiffReport$DiffType' start='44' end='74' sourcepath='org/apache/hadoop/hdfs/protocol/SnapshotDiffReport.java' sourcefile='SnapshotDiffReport.java'><Message>At SnapshotDiffReport.java:[lines 44-74]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.SnapshotDiffReport$DiffType</Message></Class><Method isStatic='true' classname='org.apache.hadoop.hdfs.protocol.SnapshotDiffReport$DiffType' signature='(Ljava/lang/String;)Lorg/apache/hadoop/hdfs/protocol/SnapshotDiffReport$DiffType;' name='parseDiffType' primary='true'><SourceLine endBytecode='49' classname='org.apache.hadoop.hdfs.protocol.SnapshotDiffReport$DiffType' start='74' end='74' sourcepath='org/apache/hadoop/hdfs/protocol/SnapshotDiffReport.java' sourcefile='SnapshotDiffReport.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.SnapshotDiffReport$DiffType.parseDiffType(String)</Message></Method><SourceLine endBytecode='1' classname='org.apache.hadoop.hdfs.protocol.SnapshotDiffReport$DiffType' start='74' end='74' sourcepath='org/apache/hadoop/hdfs/protocol/SnapshotDiffReport.java' sourcefile='SnapshotDiffReport.java' startBytecode='1' primary='true'><Message>At SnapshotDiffReport.java:[line 74]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='59c8721845efc660c8188843e2a560e3' cweid='374' rank='18' abbrev='EI' category='MALICIOUS_CODE' priority='2' type='EI_EXPOSE_REP' instanceOccurrenceMax='0'><ShortMessage>May expose internal representation by returning reference to mutable object</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.SnapshotDiffReportListing.getLastPath() may expose internal representation by returning SnapshotDiffReportListing.lastPath</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.SnapshotDiffReportListing' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.SnapshotDiffReportListing' start='110' end='157' sourcepath='org/apache/hadoop/hdfs/protocol/SnapshotDiffReportListing.java' sourcefile='SnapshotDiffReportListing.java'><Message>At SnapshotDiffReportListing.java:[lines 110-157]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.SnapshotDiffReportListing</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.SnapshotDiffReportListing' signature='()[B' name='getLastPath' primary='true'><SourceLine endBytecode='46' classname='org.apache.hadoop.hdfs.protocol.SnapshotDiffReportListing' start='149' end='149' sourcepath='org/apache/hadoop/hdfs/protocol/SnapshotDiffReportListing.java' sourcefile='SnapshotDiffReportListing.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.SnapshotDiffReportListing.getLastPath()</Message></Method><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.SnapshotDiffReportListing' signature='[B' name='lastPath' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.SnapshotDiffReportListing' sourcepath='org/apache/hadoop/hdfs/protocol/SnapshotDiffReportListing.java' sourcefile='SnapshotDiffReportListing.java'><Message>In SnapshotDiffReportListing.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.SnapshotDiffReportListing.lastPath</Message></Field><SourceLine endBytecode='4' classname='org.apache.hadoop.hdfs.protocol.SnapshotDiffReportListing' start='149' end='149' sourcepath='org/apache/hadoop/hdfs/protocol/SnapshotDiffReportListing.java' sourcefile='SnapshotDiffReportListing.java' startBytecode='4' primary='true'><Message>At SnapshotDiffReportListing.java:[line 149]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='d6bd70affc62ba55f04ce107a595610' cweid='374' rank='18' abbrev='EI' category='MALICIOUS_CODE' priority='2' type='EI_EXPOSE_REP' instanceOccurrenceMax='0'><ShortMessage>May expose internal representation by returning reference to mutable object</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.SnapshotDiffReportListing$DiffReportListingEntry.getSourcePath() may expose internal representation by returning SnapshotDiffReportListing$DiffReportListingEntry.sourcePath</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.SnapshotDiffReportListing$DiffReportListingEntry' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.SnapshotDiffReportListing$DiffReportListingEntry' start='55' end='92' sourcepath='org/apache/hadoop/hdfs/protocol/SnapshotDiffReportListing.java' sourcefile='SnapshotDiffReportListing.java'><Message>At SnapshotDiffReportListing.java:[lines 55-92]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.SnapshotDiffReportListing$DiffReportListingEntry</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.SnapshotDiffReportListing$DiffReportListingEntry' signature='()[[B' name='getSourcePath' primary='true'><SourceLine endBytecode='46' classname='org.apache.hadoop.hdfs.protocol.SnapshotDiffReportListing$DiffReportListingEntry' start='84' end='84' sourcepath='org/apache/hadoop/hdfs/protocol/SnapshotDiffReportListing.java' sourcefile='SnapshotDiffReportListing.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.SnapshotDiffReportListing$DiffReportListingEntry.getSourcePath()</Message></Method><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.SnapshotDiffReportListing$DiffReportListingEntry' signature='[[B' name='sourcePath' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.SnapshotDiffReportListing$DiffReportListingEntry' sourcepath='org/apache/hadoop/hdfs/protocol/SnapshotDiffReportListing.java' sourcefile='SnapshotDiffReportListing.java'><Message>In SnapshotDiffReportListing.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.SnapshotDiffReportListing$DiffReportListingEntry.sourcePath</Message></Field><SourceLine endBytecode='4' classname='org.apache.hadoop.hdfs.protocol.SnapshotDiffReportListing$DiffReportListingEntry' start='84' end='84' sourcepath='org/apache/hadoop/hdfs/protocol/SnapshotDiffReportListing.java' sourcefile='SnapshotDiffReportListing.java' startBytecode='4' primary='true'><Message>At SnapshotDiffReportListing.java:[line 84]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='58effd3b2dd1606640d7ec2bf1329185' cweid='374' rank='18' abbrev='EI' category='MALICIOUS_CODE' priority='2' type='EI_EXPOSE_REP' instanceOccurrenceMax='0'><ShortMessage>May expose internal representation by returning reference to mutable object</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.SnapshotDiffReportListing$DiffReportListingEntry.getTargetPath() may expose internal representation by returning SnapshotDiffReportListing$DiffReportListingEntry.targetPath</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.SnapshotDiffReportListing$DiffReportListingEntry' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.SnapshotDiffReportListing$DiffReportListingEntry' start='55' end='92' sourcepath='org/apache/hadoop/hdfs/protocol/SnapshotDiffReportListing.java' sourcefile='SnapshotDiffReportListing.java'><Message>At SnapshotDiffReportListing.java:[lines 55-92]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.SnapshotDiffReportListing$DiffReportListingEntry</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.SnapshotDiffReportListing$DiffReportListingEntry' signature='()[[B' name='getTargetPath' primary='true'><SourceLine endBytecode='46' classname='org.apache.hadoop.hdfs.protocol.SnapshotDiffReportListing$DiffReportListingEntry' start='88' end='88' sourcepath='org/apache/hadoop/hdfs/protocol/SnapshotDiffReportListing.java' sourcefile='SnapshotDiffReportListing.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.SnapshotDiffReportListing$DiffReportListingEntry.getTargetPath()</Message></Method><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.SnapshotDiffReportListing$DiffReportListingEntry' signature='[[B' name='targetPath' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.SnapshotDiffReportListing$DiffReportListingEntry' sourcepath='org/apache/hadoop/hdfs/protocol/SnapshotDiffReportListing.java' sourcefile='SnapshotDiffReportListing.java'><Message>In SnapshotDiffReportListing.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.SnapshotDiffReportListing$DiffReportListingEntry.targetPath</Message></Field><SourceLine endBytecode='4' classname='org.apache.hadoop.hdfs.protocol.SnapshotDiffReportListing$DiffReportListingEntry' start='88' end='88' sourcepath='org/apache/hadoop/hdfs/protocol/SnapshotDiffReportListing.java' sourcefile='SnapshotDiffReportListing.java' startBytecode='4' primary='true'><Message>At SnapshotDiffReportListing.java:[line 88]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='d8ea17d28cfe1936c5c0fc7645eadf7a' cweid='374' rank='18' abbrev='EI2' category='MALICIOUS_CODE' priority='2' type='EI_EXPOSE_REP2' instanceOccurrenceMax='0'><ShortMessage>May expose internal representation by incorporating reference to mutable object</ShortMessage><LongMessage>new org.apache.hadoop.hdfs.protocol.SnapshotDiffReportListing$DiffReportListingEntry(long, long, byte[][], boolean, byte[][]) may expose internal representation by storing an externally mutable object into SnapshotDiffReportListing$DiffReportListingEntry.sourcePath</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.SnapshotDiffReportListing$DiffReportListingEntry' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.SnapshotDiffReportListing$DiffReportListingEntry' start='55' end='92' sourcepath='org/apache/hadoop/hdfs/protocol/SnapshotDiffReportListing.java' sourcefile='SnapshotDiffReportListing.java'><Message>At SnapshotDiffReportListing.java:[lines 55-92]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.SnapshotDiffReportListing$DiffReportListingEntry</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.SnapshotDiffReportListing$DiffReportListingEntry' signature='(JJ[[BZ[[B)V' name='&lt;init&gt;' primary='true'><SourceLine endBytecode='158' classname='org.apache.hadoop.hdfs.protocol.SnapshotDiffReportListing$DiffReportListingEntry' start='55' end='62' sourcepath='org/apache/hadoop/hdfs/protocol/SnapshotDiffReportListing.java' sourcefile='SnapshotDiffReportListing.java' startBytecode='0'></SourceLine><Message>In method new org.apache.hadoop.hdfs.protocol.SnapshotDiffReportListing$DiffReportListingEntry(long, long, byte[][], boolean, byte[][])</Message></Method><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.SnapshotDiffReportListing$DiffReportListingEntry' signature='[[B' name='sourcePath' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.SnapshotDiffReportListing$DiffReportListingEntry' sourcepath='org/apache/hadoop/hdfs/protocol/SnapshotDiffReportListing.java' sourcefile='SnapshotDiffReportListing.java'><Message>In SnapshotDiffReportListing.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.SnapshotDiffReportListing$DiffReportListingEntry.sourcePath</Message></Field><LocalVariable role='LOCAL_VARIABLE_NAMED' pc='23' name='sourcePath' register='5'><Message>Local variable named sourcePath</Message></LocalVariable><SourceLine endBytecode='23' classname='org.apache.hadoop.hdfs.protocol.SnapshotDiffReportListing$DiffReportListingEntry' start='59' end='59' sourcepath='org/apache/hadoop/hdfs/protocol/SnapshotDiffReportListing.java' sourcefile='SnapshotDiffReportListing.java' startBytecode='23' primary='true'><Message>At SnapshotDiffReportListing.java:[line 59]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='17c63ba40d962ac82f0b6436d5c7ae1' cweid='374' rank='18' abbrev='EI2' category='MALICIOUS_CODE' priority='2' type='EI_EXPOSE_REP2' instanceOccurrenceMax='0'><ShortMessage>May expose internal representation by incorporating reference to mutable object</ShortMessage><LongMessage>new org.apache.hadoop.hdfs.protocol.SnapshotDiffReportListing$DiffReportListingEntry(long, long, byte[][], boolean, byte[][]) may expose internal representation by storing an externally mutable object into SnapshotDiffReportListing$DiffReportListingEntry.targetPath</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.SnapshotDiffReportListing$DiffReportListingEntry' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.SnapshotDiffReportListing$DiffReportListingEntry' start='55' end='92' sourcepath='org/apache/hadoop/hdfs/protocol/SnapshotDiffReportListing.java' sourcefile='SnapshotDiffReportListing.java'><Message>At SnapshotDiffReportListing.java:[lines 55-92]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.SnapshotDiffReportListing$DiffReportListingEntry</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.SnapshotDiffReportListing$DiffReportListingEntry' signature='(JJ[[BZ[[B)V' name='&lt;init&gt;' primary='true'><SourceLine endBytecode='158' classname='org.apache.hadoop.hdfs.protocol.SnapshotDiffReportListing$DiffReportListingEntry' start='55' end='62' sourcepath='org/apache/hadoop/hdfs/protocol/SnapshotDiffReportListing.java' sourcefile='SnapshotDiffReportListing.java' startBytecode='0'></SourceLine><Message>In method new org.apache.hadoop.hdfs.protocol.SnapshotDiffReportListing$DiffReportListingEntry(long, long, byte[][], boolean, byte[][])</Message></Method><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.SnapshotDiffReportListing$DiffReportListingEntry' signature='[[B' name='targetPath' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.SnapshotDiffReportListing$DiffReportListingEntry' sourcepath='org/apache/hadoop/hdfs/protocol/SnapshotDiffReportListing.java' sourcefile='SnapshotDiffReportListing.java'><Message>In SnapshotDiffReportListing.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.SnapshotDiffReportListing$DiffReportListingEntry.targetPath</Message></Field><LocalVariable role='LOCAL_VARIABLE_NAMED' pc='35' name='targetPath' register='7'><Message>Local variable named targetPath</Message></LocalVariable><SourceLine endBytecode='35' classname='org.apache.hadoop.hdfs.protocol.SnapshotDiffReportListing$DiffReportListingEntry' start='61' end='61' sourcepath='org/apache/hadoop/hdfs/protocol/SnapshotDiffReportListing.java' sourcefile='SnapshotDiffReportListing.java' startBytecode='35' primary='true'><Message>At SnapshotDiffReportListing.java:[line 61]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='e22094cca992fd98bf571690edc28a63' cweid='374' rank='18' abbrev='EI' category='MALICIOUS_CODE' priority='2' type='EI_EXPOSE_REP' instanceOccurrenceMax='0'><ShortMessage>May expose internal representation by returning reference to mutable object</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.SnapshottableDirectoryStatus.getParentFullPath() may expose internal representation by returning SnapshottableDirectoryStatus.parentFullPath</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.SnapshottableDirectoryStatus' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.SnapshottableDirectoryStatus' start='33' end='185' sourcepath='org/apache/hadoop/hdfs/protocol/SnapshottableDirectoryStatus.java' sourcefile='SnapshottableDirectoryStatus.java'><Message>At SnapshottableDirectoryStatus.java:[lines 33-185]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.SnapshottableDirectoryStatus</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.SnapshottableDirectoryStatus' signature='()[B' name='getParentFullPath' primary='true'><SourceLine endBytecode='46' classname='org.apache.hadoop.hdfs.protocol.SnapshottableDirectoryStatus' start='108' end='108' sourcepath='org/apache/hadoop/hdfs/protocol/SnapshottableDirectoryStatus.java' sourcefile='SnapshottableDirectoryStatus.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.SnapshottableDirectoryStatus.getParentFullPath()</Message></Method><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.SnapshottableDirectoryStatus' signature='[B' name='parentFullPath' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.SnapshottableDirectoryStatus' sourcepath='org/apache/hadoop/hdfs/protocol/SnapshottableDirectoryStatus.java' sourcefile='SnapshottableDirectoryStatus.java'><Message>In SnapshottableDirectoryStatus.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.SnapshottableDirectoryStatus.parentFullPath</Message></Field><SourceLine endBytecode='4' classname='org.apache.hadoop.hdfs.protocol.SnapshottableDirectoryStatus' start='108' end='108' sourcepath='org/apache/hadoop/hdfs/protocol/SnapshottableDirectoryStatus.java' sourcefile='SnapshottableDirectoryStatus.java' startBytecode='4' primary='true'><Message>At SnapshottableDirectoryStatus.java:[line 108]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='58d463562f2d88c6fc6e9cb2265af32c' cweid='374' rank='18' abbrev='EI2' category='MALICIOUS_CODE' priority='2' type='EI_EXPOSE_REP2' instanceOccurrenceMax='0'><ShortMessage>May expose internal representation by incorporating reference to mutable object</ShortMessage><LongMessage>new org.apache.hadoop.hdfs.protocol.SnapshottableDirectoryStatus(long, long, FsPermission, EnumSet, String, String, byte[], long, int, int, int, byte[]) may expose internal representation by storing an externally mutable object into SnapshottableDirectoryStatus.parentFullPath</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.SnapshottableDirectoryStatus' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.SnapshottableDirectoryStatus' start='33' end='185' sourcepath='org/apache/hadoop/hdfs/protocol/SnapshottableDirectoryStatus.java' sourcefile='SnapshottableDirectoryStatus.java'><Message>At SnapshottableDirectoryStatus.java:[lines 33-185]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.SnapshottableDirectoryStatus</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.SnapshottableDirectoryStatus' signature='(JJLorg/apache/hadoop/fs/permission/FsPermission;Ljava/util/EnumSet;Ljava/lang/String;Ljava/lang/String;[BJIII[B)V' name='&lt;init&gt;' primary='true'><SourceLine endBytecode='327' classname='org.apache.hadoop.hdfs.protocol.SnapshottableDirectoryStatus' start='64' end='80' sourcepath='org/apache/hadoop/hdfs/protocol/SnapshottableDirectoryStatus.java' sourcefile='SnapshottableDirectoryStatus.java' startBytecode='0'></SourceLine><Message>In method new org.apache.hadoop.hdfs.protocol.SnapshottableDirectoryStatus(long, long, FsPermission, EnumSet, String, String, byte[], long, int, int, int, byte[])</Message></Method><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.SnapshottableDirectoryStatus' signature='[B' name='parentFullPath' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.SnapshottableDirectoryStatus' sourcepath='org/apache/hadoop/hdfs/protocol/SnapshottableDirectoryStatus.java' sourcefile='SnapshottableDirectoryStatus.java'><Message>In SnapshottableDirectoryStatus.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.SnapshottableDirectoryStatus.parentFullPath</Message></Field><LocalVariable role='LOCAL_VARIABLE_NAMED' pc='80' name='parentFullPath' register='15'><Message>Local variable named parentFullPath</Message></LocalVariable><SourceLine endBytecode='80' classname='org.apache.hadoop.hdfs.protocol.SnapshottableDirectoryStatus' start='79' end='79' sourcepath='org/apache/hadoop/hdfs/protocol/SnapshottableDirectoryStatus.java' sourcefile='SnapshottableDirectoryStatus.java' startBytecode='80' primary='true'><Message>At SnapshottableDirectoryStatus.java:[line 79]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='bae23fc3870afc5673776d35689545ac' cweid='374' rank='18' abbrev='EI2' category='MALICIOUS_CODE' priority='2' type='EI_EXPOSE_REP2' instanceOccurrenceMax='0'><ShortMessage>May expose internal representation by incorporating reference to mutable object</ShortMessage><LongMessage>new org.apache.hadoop.hdfs.protocol.SnapshottableDirectoryStatus(HdfsFileStatus, int, int, byte[]) may expose internal representation by storing an externally mutable object into SnapshottableDirectoryStatus.parentFullPath</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.SnapshottableDirectoryStatus' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.SnapshottableDirectoryStatus' start='33' end='185' sourcepath='org/apache/hadoop/hdfs/protocol/SnapshottableDirectoryStatus.java' sourcefile='SnapshottableDirectoryStatus.java'><Message>At SnapshottableDirectoryStatus.java:[lines 33-185]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.SnapshottableDirectoryStatus</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.SnapshottableDirectoryStatus' signature='(Lorg/apache/hadoop/hdfs/protocol/HdfsFileStatus;II[B)V' name='&lt;init&gt;' primary='true'><SourceLine endBytecode='127' classname='org.apache.hadoop.hdfs.protocol.SnapshottableDirectoryStatus' start='83' end='88' sourcepath='org/apache/hadoop/hdfs/protocol/SnapshottableDirectoryStatus.java' sourcefile='SnapshottableDirectoryStatus.java' startBytecode='0'></SourceLine><Message>In method new org.apache.hadoop.hdfs.protocol.SnapshottableDirectoryStatus(HdfsFileStatus, int, int, byte[])</Message></Method><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.SnapshottableDirectoryStatus' signature='[B' name='parentFullPath' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.SnapshottableDirectoryStatus' sourcepath='org/apache/hadoop/hdfs/protocol/SnapshottableDirectoryStatus.java' sourcefile='SnapshottableDirectoryStatus.java'><Message>In SnapshottableDirectoryStatus.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.SnapshottableDirectoryStatus.parentFullPath</Message></Field><LocalVariable role='LOCAL_VARIABLE_NAMED' pc='22' name='parentFullPath' register='4'><Message>Local variable named parentFullPath</Message></LocalVariable><SourceLine endBytecode='22' classname='org.apache.hadoop.hdfs.protocol.SnapshottableDirectoryStatus' start='87' end='87' sourcepath='org/apache/hadoop/hdfs/protocol/SnapshottableDirectoryStatus.java' sourcefile='SnapshottableDirectoryStatus.java' startBytecode='22' primary='true'><Message>At SnapshottableDirectoryStatus.java:[line 87]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='5a97cbac76f2c3fba83390fa6913a33e' cweid='374' rank='18' abbrev='EI' category='MALICIOUS_CODE' priority='2' type='EI_EXPOSE_REP' instanceOccurrenceMax='0'><ShortMessage>May expose internal representation by returning reference to mutable object</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.StripedBlockInfo.getBlockIndices() may expose internal representation by returning StripedBlockInfo.blockIndices</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.StripedBlockInfo' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.StripedBlockInfo' start='40' end='65' sourcepath='org/apache/hadoop/hdfs/protocol/StripedBlockInfo.java' sourcefile='StripedBlockInfo.java'><Message>At StripedBlockInfo.java:[lines 40-65]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.StripedBlockInfo</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.StripedBlockInfo' signature='()[B' name='getBlockIndices' primary='true'><SourceLine endBytecode='46' classname='org.apache.hadoop.hdfs.protocol.StripedBlockInfo' start='61' end='61' sourcepath='org/apache/hadoop/hdfs/protocol/StripedBlockInfo.java' sourcefile='StripedBlockInfo.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.StripedBlockInfo.getBlockIndices()</Message></Method><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.StripedBlockInfo' signature='[B' name='blockIndices' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.StripedBlockInfo' sourcepath='org/apache/hadoop/hdfs/protocol/StripedBlockInfo.java' sourcefile='StripedBlockInfo.java'><Message>In StripedBlockInfo.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.StripedBlockInfo.blockIndices</Message></Field><SourceLine endBytecode='4' classname='org.apache.hadoop.hdfs.protocol.StripedBlockInfo' start='61' end='61' sourcepath='org/apache/hadoop/hdfs/protocol/StripedBlockInfo.java' sourcefile='StripedBlockInfo.java' startBytecode='4' primary='true'><Message>At StripedBlockInfo.java:[line 61]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='eb8458c9528aa0b9bec8b350b5847b42' cweid='374' rank='18' abbrev='EI' category='MALICIOUS_CODE' priority='2' type='EI_EXPOSE_REP' instanceOccurrenceMax='0'><ShortMessage>May expose internal representation by returning reference to mutable object</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.StripedBlockInfo.getBlockTokens() may expose internal representation by returning StripedBlockInfo.blockTokens</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.StripedBlockInfo' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.StripedBlockInfo' start='40' end='65' sourcepath='org/apache/hadoop/hdfs/protocol/StripedBlockInfo.java' sourcefile='StripedBlockInfo.java'><Message>At StripedBlockInfo.java:[lines 40-65]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.StripedBlockInfo</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.StripedBlockInfo' signature='()[Lorg/apache/hadoop/security/token/Token;' name='getBlockTokens' primary='true'><SourceLine endBytecode='46' classname='org.apache.hadoop.hdfs.protocol.StripedBlockInfo' start='57' end='57' sourcepath='org/apache/hadoop/hdfs/protocol/StripedBlockInfo.java' sourcefile='StripedBlockInfo.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.StripedBlockInfo.getBlockTokens()</Message></Method><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.StripedBlockInfo' signature='[Lorg/apache/hadoop/security/token/Token;' name='blockTokens' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.StripedBlockInfo' sourcepath='org/apache/hadoop/hdfs/protocol/StripedBlockInfo.java' sourcefile='StripedBlockInfo.java'><Message>In StripedBlockInfo.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.StripedBlockInfo.blockTokens</Message></Field><SourceLine endBytecode='4' classname='org.apache.hadoop.hdfs.protocol.StripedBlockInfo' start='57' end='57' sourcepath='org/apache/hadoop/hdfs/protocol/StripedBlockInfo.java' sourcefile='StripedBlockInfo.java' startBytecode='4' primary='true'><Message>At StripedBlockInfo.java:[line 57]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='445e8c22a23c1a276146da3e1d715966' cweid='374' rank='18' abbrev='EI' category='MALICIOUS_CODE' priority='2' type='EI_EXPOSE_REP' instanceOccurrenceMax='0'><ShortMessage>May expose internal representation by returning reference to mutable object</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.StripedBlockInfo.getDatanodes() may expose internal representation by returning StripedBlockInfo.datanodes</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.StripedBlockInfo' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.StripedBlockInfo' start='40' end='65' sourcepath='org/apache/hadoop/hdfs/protocol/StripedBlockInfo.java' sourcefile='StripedBlockInfo.java'><Message>At StripedBlockInfo.java:[lines 40-65]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.StripedBlockInfo</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.StripedBlockInfo' signature='()[Lorg/apache/hadoop/hdfs/protocol/DatanodeInfo;' name='getDatanodes' primary='true'><SourceLine endBytecode='46' classname='org.apache.hadoop.hdfs.protocol.StripedBlockInfo' start='53' end='53' sourcepath='org/apache/hadoop/hdfs/protocol/StripedBlockInfo.java' sourcefile='StripedBlockInfo.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.StripedBlockInfo.getDatanodes()</Message></Method><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.StripedBlockInfo' signature='[Lorg/apache/hadoop/hdfs/protocol/DatanodeInfo;' name='datanodes' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.StripedBlockInfo' sourcepath='org/apache/hadoop/hdfs/protocol/StripedBlockInfo.java' sourcefile='StripedBlockInfo.java'><Message>In StripedBlockInfo.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.StripedBlockInfo.datanodes</Message></Field><SourceLine endBytecode='4' classname='org.apache.hadoop.hdfs.protocol.StripedBlockInfo' start='53' end='53' sourcepath='org/apache/hadoop/hdfs/protocol/StripedBlockInfo.java' sourcefile='StripedBlockInfo.java' startBytecode='4' primary='true'><Message>At StripedBlockInfo.java:[line 53]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='5e855cff8f74a16b0a159bf7c510c14' cweid='374' rank='18' abbrev='EI2' category='MALICIOUS_CODE' priority='2' type='EI_EXPOSE_REP2' instanceOccurrenceMax='0'><ShortMessage>May expose internal representation by incorporating reference to mutable object</ShortMessage><LongMessage>new org.apache.hadoop.hdfs.protocol.StripedBlockInfo(ExtendedBlock, DatanodeInfo[], Token[], byte[], ErasureCodingPolicy) may expose internal representation by storing an externally mutable object into StripedBlockInfo.blockIndices</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.StripedBlockInfo' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.StripedBlockInfo' start='40' end='65' sourcepath='org/apache/hadoop/hdfs/protocol/StripedBlockInfo.java' sourcefile='StripedBlockInfo.java'><Message>At StripedBlockInfo.java:[lines 40-65]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.StripedBlockInfo</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.StripedBlockInfo' signature='(Lorg/apache/hadoop/hdfs/protocol/ExtendedBlock;[Lorg/apache/hadoop/hdfs/protocol/DatanodeInfo;[Lorg/apache/hadoop/security/token/Token;[BLorg/apache/hadoop/hdfs/protocol/ErasureCodingPolicy;)V' name='&lt;init&gt;' primary='true'><SourceLine endBytecode='165' classname='org.apache.hadoop.hdfs.protocol.StripedBlockInfo' start='40' end='46' sourcepath='org/apache/hadoop/hdfs/protocol/StripedBlockInfo.java' sourcefile='StripedBlockInfo.java' startBytecode='0'></SourceLine><Message>In method new org.apache.hadoop.hdfs.protocol.StripedBlockInfo(ExtendedBlock, DatanodeInfo[], Token[], byte[], ErasureCodingPolicy)</Message></Method><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.StripedBlockInfo' signature='[B' name='blockIndices' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.StripedBlockInfo' sourcepath='org/apache/hadoop/hdfs/protocol/StripedBlockInfo.java' sourcefile='StripedBlockInfo.java'><Message>In StripedBlockInfo.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.StripedBlockInfo.blockIndices</Message></Field><LocalVariable role='LOCAL_VARIABLE_NAMED' pc='22' name='blockIndices' register='4'><Message>Local variable named blockIndices</Message></LocalVariable><SourceLine endBytecode='22' classname='org.apache.hadoop.hdfs.protocol.StripedBlockInfo' start='44' end='44' sourcepath='org/apache/hadoop/hdfs/protocol/StripedBlockInfo.java' sourcefile='StripedBlockInfo.java' startBytecode='22' primary='true'><Message>At StripedBlockInfo.java:[line 44]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='fb48d9e24441766d2ad3e236d95b7b67' cweid='374' rank='18' abbrev='EI2' category='MALICIOUS_CODE' priority='2' type='EI_EXPOSE_REP2' instanceOccurrenceMax='0'><ShortMessage>May expose internal representation by incorporating reference to mutable object</ShortMessage><LongMessage>new org.apache.hadoop.hdfs.protocol.StripedBlockInfo(ExtendedBlock, DatanodeInfo[], Token[], byte[], ErasureCodingPolicy) may expose internal representation by storing an externally mutable object into StripedBlockInfo.blockTokens</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.StripedBlockInfo' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.StripedBlockInfo' start='40' end='65' sourcepath='org/apache/hadoop/hdfs/protocol/StripedBlockInfo.java' sourcefile='StripedBlockInfo.java'><Message>At StripedBlockInfo.java:[lines 40-65]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.StripedBlockInfo</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.StripedBlockInfo' signature='(Lorg/apache/hadoop/hdfs/protocol/ExtendedBlock;[Lorg/apache/hadoop/hdfs/protocol/DatanodeInfo;[Lorg/apache/hadoop/security/token/Token;[BLorg/apache/hadoop/hdfs/protocol/ErasureCodingPolicy;)V' name='&lt;init&gt;' primary='true'><SourceLine endBytecode='165' classname='org.apache.hadoop.hdfs.protocol.StripedBlockInfo' start='40' end='46' sourcepath='org/apache/hadoop/hdfs/protocol/StripedBlockInfo.java' sourcefile='StripedBlockInfo.java' startBytecode='0'></SourceLine><Message>In method new org.apache.hadoop.hdfs.protocol.StripedBlockInfo(ExtendedBlock, DatanodeInfo[], Token[], byte[], ErasureCodingPolicy)</Message></Method><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.StripedBlockInfo' signature='[Lorg/apache/hadoop/security/token/Token;' name='blockTokens' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.StripedBlockInfo' sourcepath='org/apache/hadoop/hdfs/protocol/StripedBlockInfo.java' sourcefile='StripedBlockInfo.java'><Message>In StripedBlockInfo.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.StripedBlockInfo.blockTokens</Message></Field><LocalVariable role='LOCAL_VARIABLE_NAMED' pc='16' name='blockTokens' register='3'><Message>Local variable named blockTokens</Message></LocalVariable><SourceLine endBytecode='16' classname='org.apache.hadoop.hdfs.protocol.StripedBlockInfo' start='43' end='43' sourcepath='org/apache/hadoop/hdfs/protocol/StripedBlockInfo.java' sourcefile='StripedBlockInfo.java' startBytecode='16' primary='true'><Message>At StripedBlockInfo.java:[line 43]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='6ac40150b948e904e47026d8a6aee4ba' cweid='374' rank='18' abbrev='EI2' category='MALICIOUS_CODE' priority='2' type='EI_EXPOSE_REP2' instanceOccurrenceMax='0'><ShortMessage>May expose internal representation by incorporating reference to mutable object</ShortMessage><LongMessage>new org.apache.hadoop.hdfs.protocol.StripedBlockInfo(ExtendedBlock, DatanodeInfo[], Token[], byte[], ErasureCodingPolicy) may expose internal representation by storing an externally mutable object into StripedBlockInfo.datanodes</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.StripedBlockInfo' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.StripedBlockInfo' start='40' end='65' sourcepath='org/apache/hadoop/hdfs/protocol/StripedBlockInfo.java' sourcefile='StripedBlockInfo.java'><Message>At StripedBlockInfo.java:[lines 40-65]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.StripedBlockInfo</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.StripedBlockInfo' signature='(Lorg/apache/hadoop/hdfs/protocol/ExtendedBlock;[Lorg/apache/hadoop/hdfs/protocol/DatanodeInfo;[Lorg/apache/hadoop/security/token/Token;[BLorg/apache/hadoop/hdfs/protocol/ErasureCodingPolicy;)V' name='&lt;init&gt;' primary='true'><SourceLine endBytecode='165' classname='org.apache.hadoop.hdfs.protocol.StripedBlockInfo' start='40' end='46' sourcepath='org/apache/hadoop/hdfs/protocol/StripedBlockInfo.java' sourcefile='StripedBlockInfo.java' startBytecode='0'></SourceLine><Message>In method new org.apache.hadoop.hdfs.protocol.StripedBlockInfo(ExtendedBlock, DatanodeInfo[], Token[], byte[], ErasureCodingPolicy)</Message></Method><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.StripedBlockInfo' signature='[Lorg/apache/hadoop/hdfs/protocol/DatanodeInfo;' name='datanodes' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.StripedBlockInfo' sourcepath='org/apache/hadoop/hdfs/protocol/StripedBlockInfo.java' sourcefile='StripedBlockInfo.java'><Message>In StripedBlockInfo.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.StripedBlockInfo.datanodes</Message></Field><LocalVariable role='LOCAL_VARIABLE_NAMED' pc='11' name='datanodes' register='2'><Message>Local variable named datanodes</Message></LocalVariable><SourceLine endBytecode='11' classname='org.apache.hadoop.hdfs.protocol.StripedBlockInfo' start='42' end='42' sourcepath='org/apache/hadoop/hdfs/protocol/StripedBlockInfo.java' sourcefile='StripedBlockInfo.java' startBytecode='11' primary='true'><Message>At StripedBlockInfo.java:[line 42]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='84b64932ee8f3acf10b5d22ffaba63a7' cweid='374' rank='18' abbrev='EI2' category='MALICIOUS_CODE' priority='2' type='EI_EXPOSE_REP2' instanceOccurrenceMax='0'><ShortMessage>May expose internal representation by incorporating reference to mutable object</ShortMessage><LongMessage>new org.apache.hadoop.hdfs.protocol.datatransfer.sasl.SaslResponseWithNegotiatedCipherOption(byte[], CipherOption) may expose internal representation by storing an externally mutable object into SaslResponseWithNegotiatedCipherOption.payload</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.datatransfer.sasl.SaslResponseWithNegotiatedCipherOption' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.datatransfer.sasl.SaslResponseWithNegotiatedCipherOption' start='29' end='32' sourcepath='org/apache/hadoop/hdfs/protocol/datatransfer/sasl/SaslResponseWithNegotiatedCipherOption.java' sourcefile='SaslResponseWithNegotiatedCipherOption.java'><Message>At SaslResponseWithNegotiatedCipherOption.java:[lines 29-32]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.datatransfer.sasl.SaslResponseWithNegotiatedCipherOption</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.datatransfer.sasl.SaslResponseWithNegotiatedCipherOption' signature='([BLorg/apache/hadoop/crypto/CipherOption;)V' name='&lt;init&gt;' primary='true'><SourceLine endBytecode='88' classname='org.apache.hadoop.hdfs.protocol.datatransfer.sasl.SaslResponseWithNegotiatedCipherOption' start='29' end='32' sourcepath='org/apache/hadoop/hdfs/protocol/datatransfer/sasl/SaslResponseWithNegotiatedCipherOption.java' sourcefile='SaslResponseWithNegotiatedCipherOption.java' startBytecode='0'></SourceLine><Message>In method new org.apache.hadoop.hdfs.protocol.datatransfer.sasl.SaslResponseWithNegotiatedCipherOption(byte[], CipherOption)</Message></Method><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.datatransfer.sasl.SaslResponseWithNegotiatedCipherOption' signature='[B' name='payload' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.datatransfer.sasl.SaslResponseWithNegotiatedCipherOption' sourcepath='org/apache/hadoop/hdfs/protocol/datatransfer/sasl/SaslResponseWithNegotiatedCipherOption.java' sourcefile='SaslResponseWithNegotiatedCipherOption.java'><Message>In SaslResponseWithNegotiatedCipherOption.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.datatransfer.sasl.SaslResponseWithNegotiatedCipherOption.payload</Message></Field><LocalVariable role='LOCAL_VARIABLE_NAMED' pc='6' name='payload' register='1'><Message>Local variable named payload</Message></LocalVariable><SourceLine endBytecode='6' classname='org.apache.hadoop.hdfs.protocol.datatransfer.sasl.SaslResponseWithNegotiatedCipherOption' start='30' end='30' sourcepath='org/apache/hadoop/hdfs/protocol/datatransfer/sasl/SaslResponseWithNegotiatedCipherOption.java' sourcefile='SaslResponseWithNegotiatedCipherOption.java' startBytecode='6' primary='true'><Message>At SaslResponseWithNegotiatedCipherOption.java:[line 30]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='6c91eef62cddbbf74e5eddc7f1cce0d2' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.AclProtos$AclEntryProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$AclEntryProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$AclEntryProto' start='546' end='1638' sourcepath='org/apache/hadoop/hdfs/protocol/proto/AclProtos.java' sourcefile='AclProtos.java'><Message>At AclProtos.java:[lines 546-1638]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.AclProtos$AclEntryProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$AclEntryProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$AclEntryProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/AclProtos.java' sourcefile='AclProtos.java'><Message>In AclProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.AclProtos$AclEntryProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$AclEntryProto' start='656' end='656' sourcepath='org/apache/hadoop/hdfs/protocol/proto/AclProtos.java' sourcefile='AclProtos.java' startBytecode='7' primary='true'><Message>At AclProtos.java:[line 656]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='ed26d395b3cbca9497c13f7ae092dc4d' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.AclProtos$AclEntryProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$AclEntryProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$AclEntryProto' start='546' end='1638' sourcepath='org/apache/hadoop/hdfs/protocol/proto/AclProtos.java' sourcefile='AclProtos.java'><Message>At AclProtos.java:[lines 546-1638]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.AclProtos$AclEntryProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$AclEntryProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$AclEntryProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/AclProtos.java' sourcefile='AclProtos.java'><Message>In AclProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.AclProtos$AclEntryProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$AclEntryProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/AclProtos.java' sourcefile='AclProtos.java'><Message>In AclProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='af3f2617e2b7acc9166807c1e71ef78a' rank='17' abbrev='UCF' category='STYLE' priority='2' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.AclProtos$AclEntryProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$AclEntryProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$AclEntryProto$Builder' start='1294' end='1629' sourcepath='org/apache/hadoop/hdfs/protocol/proto/AclProtos.java' sourcefile='AclProtos.java'><Message>At AclProtos.java:[lines 1294-1629]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.AclProtos$AclEntryProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$AclEntryProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine endBytecode='61' classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$AclEntryProto$Builder' start='1320' end='1322' sourcepath='org/apache/hadoop/hdfs/protocol/proto/AclProtos.java' sourcefile='AclProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.AclProtos$AclEntryProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$AclEntryProto$Builder' start='1320' end='1320' sourcepath='org/apache/hadoop/hdfs/protocol/proto/AclProtos.java' sourcefile='AclProtos.java' startBytecode='3' primary='true'><Message>At AclProtos.java:[line 1320]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='dd9ec8994f8b0ac43445352550230b68' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.AclProtos$AclStatusProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$AclStatusProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$AclStatusProto' start='1728' end='3019' sourcepath='org/apache/hadoop/hdfs/protocol/proto/AclProtos.java' sourcefile='AclProtos.java'><Message>At AclProtos.java:[lines 1728-3019]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.AclProtos$AclStatusProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$AclStatusProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$AclStatusProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/AclProtos.java' sourcefile='AclProtos.java'><Message>In AclProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.AclProtos$AclStatusProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$AclStatusProto' start='1839' end='1839' sourcepath='org/apache/hadoop/hdfs/protocol/proto/AclProtos.java' sourcefile='AclProtos.java' startBytecode='7' primary='true'><Message>At AclProtos.java:[line 1839]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='97fdefd652de625469a19252fbfa11cc' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.AclProtos$AclStatusProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$AclStatusProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$AclStatusProto' start='1728' end='3019' sourcepath='org/apache/hadoop/hdfs/protocol/proto/AclProtos.java' sourcefile='AclProtos.java'><Message>At AclProtos.java:[lines 1728-3019]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.AclProtos$AclStatusProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$AclStatusProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$AclStatusProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/AclProtos.java' sourcefile='AclProtos.java'><Message>In AclProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.AclProtos$AclStatusProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$AclStatusProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/AclProtos.java' sourcefile='AclProtos.java'><Message>In AclProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='db28f09b87a82ac1f2feb02d72c8e9bc' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.AclProtos$FsPermissionProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$FsPermissionProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$FsPermissionProto' start='40' end='490' sourcepath='org/apache/hadoop/hdfs/protocol/proto/AclProtos.java' sourcefile='AclProtos.java'><Message>At AclProtos.java:[lines 40-490]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.AclProtos$FsPermissionProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$FsPermissionProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$FsPermissionProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/AclProtos.java' sourcefile='AclProtos.java'><Message>In AclProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.AclProtos$FsPermissionProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$FsPermissionProto' start='117' end='117' sourcepath='org/apache/hadoop/hdfs/protocol/proto/AclProtos.java' sourcefile='AclProtos.java' startBytecode='7' primary='true'><Message>At AclProtos.java:[line 117]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='33f118badc206c2cb2ab7616bd9fcfa2' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.AclProtos$FsPermissionProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$FsPermissionProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$FsPermissionProto' start='40' end='490' sourcepath='org/apache/hadoop/hdfs/protocol/proto/AclProtos.java' sourcefile='AclProtos.java'><Message>At AclProtos.java:[lines 40-490]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.AclProtos$FsPermissionProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$FsPermissionProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$FsPermissionProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/AclProtos.java' sourcefile='AclProtos.java'><Message>In AclProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.AclProtos$FsPermissionProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$FsPermissionProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/AclProtos.java' sourcefile='AclProtos.java'><Message>In AclProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='62d038699bcd8821d0a3ef5b76ad3e20' rank='17' abbrev='UCF' category='STYLE' priority='2' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.AclProtos$FsPermissionProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$FsPermissionProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$FsPermissionProto$Builder' start='316' end='481' sourcepath='org/apache/hadoop/hdfs/protocol/proto/AclProtos.java' sourcefile='AclProtos.java'><Message>At AclProtos.java:[lines 316-481]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.AclProtos$FsPermissionProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$FsPermissionProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine endBytecode='61' classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$FsPermissionProto$Builder' start='342' end='344' sourcepath='org/apache/hadoop/hdfs/protocol/proto/AclProtos.java' sourcefile='AclProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.AclProtos$FsPermissionProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$FsPermissionProto$Builder' start='342' end='342' sourcepath='org/apache/hadoop/hdfs/protocol/proto/AclProtos.java' sourcefile='AclProtos.java' startBytecode='3' primary='true'><Message>At AclProtos.java:[line 342]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='c60543eff057eb016d323099abb461df' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.AclProtos$GetAclStatusRequestProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$GetAclStatusRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$GetAclStatusRequestProto' start='8460' end='8951' sourcepath='org/apache/hadoop/hdfs/protocol/proto/AclProtos.java' sourcefile='AclProtos.java'><Message>At AclProtos.java:[lines 8460-8951]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.AclProtos$GetAclStatusRequestProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$GetAclStatusRequestProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$GetAclStatusRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/AclProtos.java' sourcefile='AclProtos.java'><Message>In AclProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.AclProtos$GetAclStatusRequestProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$GetAclStatusRequestProto' start='8537' end='8537' sourcepath='org/apache/hadoop/hdfs/protocol/proto/AclProtos.java' sourcefile='AclProtos.java' startBytecode='7' primary='true'><Message>At AclProtos.java:[line 8537]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='56daa9205ff1cea6ebd0049e96176b65' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.AclProtos$GetAclStatusRequestProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$GetAclStatusRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$GetAclStatusRequestProto' start='8460' end='8951' sourcepath='org/apache/hadoop/hdfs/protocol/proto/AclProtos.java' sourcefile='AclProtos.java'><Message>At AclProtos.java:[lines 8460-8951]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.AclProtos$GetAclStatusRequestProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$GetAclStatusRequestProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$GetAclStatusRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/AclProtos.java' sourcefile='AclProtos.java'><Message>In AclProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.AclProtos$GetAclStatusRequestProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$GetAclStatusRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/AclProtos.java' sourcefile='AclProtos.java'><Message>In AclProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='daa2d91496c12f5e689aaf8250fc3dd2' rank='17' abbrev='UCF' category='STYLE' priority='2' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.AclProtos$GetAclStatusRequestProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$GetAclStatusRequestProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$GetAclStatusRequestProto$Builder' start='8750' end='8942' sourcepath='org/apache/hadoop/hdfs/protocol/proto/AclProtos.java' sourcefile='AclProtos.java'><Message>At AclProtos.java:[lines 8750-8942]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.AclProtos$GetAclStatusRequestProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$GetAclStatusRequestProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine endBytecode='61' classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$GetAclStatusRequestProto$Builder' start='8776' end='8778' sourcepath='org/apache/hadoop/hdfs/protocol/proto/AclProtos.java' sourcefile='AclProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.AclProtos$GetAclStatusRequestProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$GetAclStatusRequestProto$Builder' start='8776' end='8776' sourcepath='org/apache/hadoop/hdfs/protocol/proto/AclProtos.java' sourcefile='AclProtos.java' startBytecode='3' primary='true'><Message>At AclProtos.java:[line 8776]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='aa61780c4c42d2efa36606f78e0d1d5f' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.AclProtos$GetAclStatusResponseProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$GetAclStatusResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$GetAclStatusResponseProto' start='8976' end='9512' sourcepath='org/apache/hadoop/hdfs/protocol/proto/AclProtos.java' sourcefile='AclProtos.java'><Message>At AclProtos.java:[lines 8976-9512]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.AclProtos$GetAclStatusResponseProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$GetAclStatusResponseProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$GetAclStatusResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/AclProtos.java' sourcefile='AclProtos.java'><Message>In AclProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.AclProtos$GetAclStatusResponseProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$GetAclStatusResponseProto' start='9061' end='9061' sourcepath='org/apache/hadoop/hdfs/protocol/proto/AclProtos.java' sourcefile='AclProtos.java' startBytecode='7' primary='true'><Message>At AclProtos.java:[line 9061]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='27a0b513874aba8e3bf623abaa51396a' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.AclProtos$GetAclStatusResponseProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$GetAclStatusResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$GetAclStatusResponseProto' start='8976' end='9512' sourcepath='org/apache/hadoop/hdfs/protocol/proto/AclProtos.java' sourcefile='AclProtos.java'><Message>At AclProtos.java:[lines 8976-9512]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.AclProtos$GetAclStatusResponseProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$GetAclStatusResponseProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$GetAclStatusResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/AclProtos.java' sourcefile='AclProtos.java'><Message>In AclProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.AclProtos$GetAclStatusResponseProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$GetAclStatusResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/AclProtos.java' sourcefile='AclProtos.java'><Message>In AclProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='f2862712c0d6f616928223b0d13c136' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.AclProtos$ModifyAclEntriesRequestProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$ModifyAclEntriesRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$ModifyAclEntriesRequestProto' start='3070' end='3916' sourcepath='org/apache/hadoop/hdfs/protocol/proto/AclProtos.java' sourcefile='AclProtos.java'><Message>At AclProtos.java:[lines 3070-3916]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.AclProtos$ModifyAclEntriesRequestProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$ModifyAclEntriesRequestProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$ModifyAclEntriesRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/AclProtos.java' sourcefile='AclProtos.java'><Message>In AclProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.AclProtos$ModifyAclEntriesRequestProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$ModifyAclEntriesRequestProto' start='3158' end='3158' sourcepath='org/apache/hadoop/hdfs/protocol/proto/AclProtos.java' sourcefile='AclProtos.java' startBytecode='7' primary='true'><Message>At AclProtos.java:[line 3158]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='d1845bc4f88446a47efffbcb155166fe' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.AclProtos$ModifyAclEntriesRequestProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$ModifyAclEntriesRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$ModifyAclEntriesRequestProto' start='3070' end='3916' sourcepath='org/apache/hadoop/hdfs/protocol/proto/AclProtos.java' sourcefile='AclProtos.java'><Message>At AclProtos.java:[lines 3070-3916]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.AclProtos$ModifyAclEntriesRequestProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$ModifyAclEntriesRequestProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$ModifyAclEntriesRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/AclProtos.java' sourcefile='AclProtos.java'><Message>In AclProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.AclProtos$ModifyAclEntriesRequestProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$ModifyAclEntriesRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/AclProtos.java' sourcefile='AclProtos.java'><Message>In AclProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='85ba32648d2cc530a055e4211779fb56' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.AclProtos$ModifyAclEntriesResponseProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$ModifyAclEntriesResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$ModifyAclEntriesResponseProto' start='3927' end='4254' sourcepath='org/apache/hadoop/hdfs/protocol/proto/AclProtos.java' sourcefile='AclProtos.java'><Message>At AclProtos.java:[lines 3927-4254]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.AclProtos$ModifyAclEntriesResponseProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$ModifyAclEntriesResponseProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$ModifyAclEntriesResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/AclProtos.java' sourcefile='AclProtos.java'><Message>In AclProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.AclProtos$ModifyAclEntriesResponseProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$ModifyAclEntriesResponseProto' start='3998' end='3998' sourcepath='org/apache/hadoop/hdfs/protocol/proto/AclProtos.java' sourcefile='AclProtos.java' startBytecode='7' primary='true'><Message>At AclProtos.java:[line 3998]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='3afd3068cf906333566c85212bd5aa90' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.AclProtos$ModifyAclEntriesResponseProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$ModifyAclEntriesResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$ModifyAclEntriesResponseProto' start='3927' end='4254' sourcepath='org/apache/hadoop/hdfs/protocol/proto/AclProtos.java' sourcefile='AclProtos.java'><Message>At AclProtos.java:[lines 3927-4254]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.AclProtos$ModifyAclEntriesResponseProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$ModifyAclEntriesResponseProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$ModifyAclEntriesResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/AclProtos.java' sourcefile='AclProtos.java'><Message>In AclProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.AclProtos$ModifyAclEntriesResponseProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$ModifyAclEntriesResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/AclProtos.java' sourcefile='AclProtos.java'><Message>In AclProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='aa7a2581aa85ad1f3afc294fa6002372' rank='17' abbrev='UCF' category='STYLE' priority='2' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.AclProtos$ModifyAclEntriesResponseProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$ModifyAclEntriesResponseProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$ModifyAclEntriesResponseProto$Builder' start='4146' end='4245' sourcepath='org/apache/hadoop/hdfs/protocol/proto/AclProtos.java' sourcefile='AclProtos.java'><Message>At AclProtos.java:[lines 4146-4245]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.AclProtos$ModifyAclEntriesResponseProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$ModifyAclEntriesResponseProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine endBytecode='61' classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$ModifyAclEntriesResponseProto$Builder' start='4172' end='4174' sourcepath='org/apache/hadoop/hdfs/protocol/proto/AclProtos.java' sourcefile='AclProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.AclProtos$ModifyAclEntriesResponseProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$ModifyAclEntriesResponseProto$Builder' start='4172' end='4172' sourcepath='org/apache/hadoop/hdfs/protocol/proto/AclProtos.java' sourcefile='AclProtos.java' startBytecode='3' primary='true'><Message>At AclProtos.java:[line 4172]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='8038811f20141d6d46be3a40808ea037' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveAclEntriesRequestProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveAclEntriesRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveAclEntriesRequestProto' start='5160' end='6006' sourcepath='org/apache/hadoop/hdfs/protocol/proto/AclProtos.java' sourcefile='AclProtos.java'><Message>At AclProtos.java:[lines 5160-6006]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveAclEntriesRequestProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveAclEntriesRequestProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveAclEntriesRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/AclProtos.java' sourcefile='AclProtos.java'><Message>In AclProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveAclEntriesRequestProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveAclEntriesRequestProto' start='5248' end='5248' sourcepath='org/apache/hadoop/hdfs/protocol/proto/AclProtos.java' sourcefile='AclProtos.java' startBytecode='7' primary='true'><Message>At AclProtos.java:[line 5248]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='bd6b5cac27ae4da107b029803150363b' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveAclEntriesRequestProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveAclEntriesRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveAclEntriesRequestProto' start='5160' end='6006' sourcepath='org/apache/hadoop/hdfs/protocol/proto/AclProtos.java' sourcefile='AclProtos.java'><Message>At AclProtos.java:[lines 5160-6006]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveAclEntriesRequestProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveAclEntriesRequestProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveAclEntriesRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/AclProtos.java' sourcefile='AclProtos.java'><Message>In AclProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveAclEntriesRequestProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveAclEntriesRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/AclProtos.java' sourcefile='AclProtos.java'><Message>In AclProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='31014eb3a0c289f2a3cc7063f6e11b40' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveAclEntriesResponseProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveAclEntriesResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveAclEntriesResponseProto' start='6017' end='6344' sourcepath='org/apache/hadoop/hdfs/protocol/proto/AclProtos.java' sourcefile='AclProtos.java'><Message>At AclProtos.java:[lines 6017-6344]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveAclEntriesResponseProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveAclEntriesResponseProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveAclEntriesResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/AclProtos.java' sourcefile='AclProtos.java'><Message>In AclProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveAclEntriesResponseProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveAclEntriesResponseProto' start='6088' end='6088' sourcepath='org/apache/hadoop/hdfs/protocol/proto/AclProtos.java' sourcefile='AclProtos.java' startBytecode='7' primary='true'><Message>At AclProtos.java:[line 6088]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='1c37cee3ef032332a54e035031d184f0' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveAclEntriesResponseProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveAclEntriesResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveAclEntriesResponseProto' start='6017' end='6344' sourcepath='org/apache/hadoop/hdfs/protocol/proto/AclProtos.java' sourcefile='AclProtos.java'><Message>At AclProtos.java:[lines 6017-6344]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveAclEntriesResponseProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveAclEntriesResponseProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveAclEntriesResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/AclProtos.java' sourcefile='AclProtos.java'><Message>In AclProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveAclEntriesResponseProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveAclEntriesResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/AclProtos.java' sourcefile='AclProtos.java'><Message>In AclProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='4f032f822197ba00aaa54627164f3bdd' rank='17' abbrev='UCF' category='STYLE' priority='2' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveAclEntriesResponseProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveAclEntriesResponseProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveAclEntriesResponseProto$Builder' start='6236' end='6335' sourcepath='org/apache/hadoop/hdfs/protocol/proto/AclProtos.java' sourcefile='AclProtos.java'><Message>At AclProtos.java:[lines 6236-6335]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveAclEntriesResponseProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveAclEntriesResponseProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine endBytecode='61' classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveAclEntriesResponseProto$Builder' start='6262' end='6264' sourcepath='org/apache/hadoop/hdfs/protocol/proto/AclProtos.java' sourcefile='AclProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveAclEntriesResponseProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveAclEntriesResponseProto$Builder' start='6262' end='6262' sourcepath='org/apache/hadoop/hdfs/protocol/proto/AclProtos.java' sourcefile='AclProtos.java' startBytecode='3' primary='true'><Message>At AclProtos.java:[line 6262]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='fe145396aa917a858b4db2d7c37ba5d8' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveAclRequestProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveAclRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveAclRequestProto' start='4280' end='4771' sourcepath='org/apache/hadoop/hdfs/protocol/proto/AclProtos.java' sourcefile='AclProtos.java'><Message>At AclProtos.java:[lines 4280-4771]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveAclRequestProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveAclRequestProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveAclRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/AclProtos.java' sourcefile='AclProtos.java'><Message>In AclProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveAclRequestProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveAclRequestProto' start='4357' end='4357' sourcepath='org/apache/hadoop/hdfs/protocol/proto/AclProtos.java' sourcefile='AclProtos.java' startBytecode='7' primary='true'><Message>At AclProtos.java:[line 4357]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='ca870430d9aca54fb8624a66bf959128' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveAclRequestProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveAclRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveAclRequestProto' start='4280' end='4771' sourcepath='org/apache/hadoop/hdfs/protocol/proto/AclProtos.java' sourcefile='AclProtos.java'><Message>At AclProtos.java:[lines 4280-4771]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveAclRequestProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveAclRequestProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveAclRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/AclProtos.java' sourcefile='AclProtos.java'><Message>In AclProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveAclRequestProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveAclRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/AclProtos.java' sourcefile='AclProtos.java'><Message>In AclProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='2241de9e94f87bd02c3e0ea30dbfface' rank='17' abbrev='UCF' category='STYLE' priority='2' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveAclRequestProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveAclRequestProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveAclRequestProto$Builder' start='4570' end='4762' sourcepath='org/apache/hadoop/hdfs/protocol/proto/AclProtos.java' sourcefile='AclProtos.java'><Message>At AclProtos.java:[lines 4570-4762]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveAclRequestProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveAclRequestProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine endBytecode='61' classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveAclRequestProto$Builder' start='4596' end='4598' sourcepath='org/apache/hadoop/hdfs/protocol/proto/AclProtos.java' sourcefile='AclProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveAclRequestProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveAclRequestProto$Builder' start='4596' end='4596' sourcepath='org/apache/hadoop/hdfs/protocol/proto/AclProtos.java' sourcefile='AclProtos.java' startBytecode='3' primary='true'><Message>At AclProtos.java:[line 4596]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='1378bd464a33d075217291d83a340b49' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveAclResponseProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveAclResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveAclResponseProto' start='4782' end='5109' sourcepath='org/apache/hadoop/hdfs/protocol/proto/AclProtos.java' sourcefile='AclProtos.java'><Message>At AclProtos.java:[lines 4782-5109]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveAclResponseProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveAclResponseProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveAclResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/AclProtos.java' sourcefile='AclProtos.java'><Message>In AclProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveAclResponseProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveAclResponseProto' start='4853' end='4853' sourcepath='org/apache/hadoop/hdfs/protocol/proto/AclProtos.java' sourcefile='AclProtos.java' startBytecode='7' primary='true'><Message>At AclProtos.java:[line 4853]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='62fead711f7eefe9aa8400f3e0282c3c' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveAclResponseProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveAclResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveAclResponseProto' start='4782' end='5109' sourcepath='org/apache/hadoop/hdfs/protocol/proto/AclProtos.java' sourcefile='AclProtos.java'><Message>At AclProtos.java:[lines 4782-5109]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveAclResponseProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveAclResponseProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveAclResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/AclProtos.java' sourcefile='AclProtos.java'><Message>In AclProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveAclResponseProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveAclResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/AclProtos.java' sourcefile='AclProtos.java'><Message>In AclProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='4ed115255a0395871124309aca1f9163' rank='17' abbrev='UCF' category='STYLE' priority='2' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveAclResponseProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveAclResponseProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveAclResponseProto$Builder' start='5001' end='5100' sourcepath='org/apache/hadoop/hdfs/protocol/proto/AclProtos.java' sourcefile='AclProtos.java'><Message>At AclProtos.java:[lines 5001-5100]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveAclResponseProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveAclResponseProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine endBytecode='61' classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveAclResponseProto$Builder' start='5027' end='5029' sourcepath='org/apache/hadoop/hdfs/protocol/proto/AclProtos.java' sourcefile='AclProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveAclResponseProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveAclResponseProto$Builder' start='5027' end='5027' sourcepath='org/apache/hadoop/hdfs/protocol/proto/AclProtos.java' sourcefile='AclProtos.java' startBytecode='3' primary='true'><Message>At AclProtos.java:[line 5027]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='c7c50f36fe80f7ec6f7b31d3d63da0d5' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveDefaultAclRequestProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveDefaultAclRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveDefaultAclRequestProto' start='6370' end='6861' sourcepath='org/apache/hadoop/hdfs/protocol/proto/AclProtos.java' sourcefile='AclProtos.java'><Message>At AclProtos.java:[lines 6370-6861]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveDefaultAclRequestProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveDefaultAclRequestProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveDefaultAclRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/AclProtos.java' sourcefile='AclProtos.java'><Message>In AclProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveDefaultAclRequestProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveDefaultAclRequestProto' start='6447' end='6447' sourcepath='org/apache/hadoop/hdfs/protocol/proto/AclProtos.java' sourcefile='AclProtos.java' startBytecode='7' primary='true'><Message>At AclProtos.java:[line 6447]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='abac43fab6a433d6337c76a1a3f6748f' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveDefaultAclRequestProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveDefaultAclRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveDefaultAclRequestProto' start='6370' end='6861' sourcepath='org/apache/hadoop/hdfs/protocol/proto/AclProtos.java' sourcefile='AclProtos.java'><Message>At AclProtos.java:[lines 6370-6861]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveDefaultAclRequestProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveDefaultAclRequestProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveDefaultAclRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/AclProtos.java' sourcefile='AclProtos.java'><Message>In AclProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveDefaultAclRequestProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveDefaultAclRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/AclProtos.java' sourcefile='AclProtos.java'><Message>In AclProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='6b6308858b28c244b7215bdc412bd5e4' rank='17' abbrev='UCF' category='STYLE' priority='2' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveDefaultAclRequestProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveDefaultAclRequestProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveDefaultAclRequestProto$Builder' start='6660' end='6852' sourcepath='org/apache/hadoop/hdfs/protocol/proto/AclProtos.java' sourcefile='AclProtos.java'><Message>At AclProtos.java:[lines 6660-6852]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveDefaultAclRequestProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveDefaultAclRequestProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine endBytecode='61' classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveDefaultAclRequestProto$Builder' start='6686' end='6688' sourcepath='org/apache/hadoop/hdfs/protocol/proto/AclProtos.java' sourcefile='AclProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveDefaultAclRequestProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveDefaultAclRequestProto$Builder' start='6686' end='6686' sourcepath='org/apache/hadoop/hdfs/protocol/proto/AclProtos.java' sourcefile='AclProtos.java' startBytecode='3' primary='true'><Message>At AclProtos.java:[line 6686]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='827a5c1409d17b14d07d8601c32a11fa' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveDefaultAclResponseProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveDefaultAclResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveDefaultAclResponseProto' start='6872' end='7199' sourcepath='org/apache/hadoop/hdfs/protocol/proto/AclProtos.java' sourcefile='AclProtos.java'><Message>At AclProtos.java:[lines 6872-7199]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveDefaultAclResponseProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveDefaultAclResponseProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveDefaultAclResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/AclProtos.java' sourcefile='AclProtos.java'><Message>In AclProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveDefaultAclResponseProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveDefaultAclResponseProto' start='6943' end='6943' sourcepath='org/apache/hadoop/hdfs/protocol/proto/AclProtos.java' sourcefile='AclProtos.java' startBytecode='7' primary='true'><Message>At AclProtos.java:[line 6943]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='a8435d293cdd7786d337663b793ce52e' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveDefaultAclResponseProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveDefaultAclResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveDefaultAclResponseProto' start='6872' end='7199' sourcepath='org/apache/hadoop/hdfs/protocol/proto/AclProtos.java' sourcefile='AclProtos.java'><Message>At AclProtos.java:[lines 6872-7199]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveDefaultAclResponseProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveDefaultAclResponseProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveDefaultAclResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/AclProtos.java' sourcefile='AclProtos.java'><Message>In AclProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveDefaultAclResponseProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveDefaultAclResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/AclProtos.java' sourcefile='AclProtos.java'><Message>In AclProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='cca67d7d397c4d51b735b29f35dba1ab' rank='17' abbrev='UCF' category='STYLE' priority='2' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveDefaultAclResponseProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveDefaultAclResponseProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveDefaultAclResponseProto$Builder' start='7091' end='7190' sourcepath='org/apache/hadoop/hdfs/protocol/proto/AclProtos.java' sourcefile='AclProtos.java'><Message>At AclProtos.java:[lines 7091-7190]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveDefaultAclResponseProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveDefaultAclResponseProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine endBytecode='61' classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveDefaultAclResponseProto$Builder' start='7117' end='7119' sourcepath='org/apache/hadoop/hdfs/protocol/proto/AclProtos.java' sourcefile='AclProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveDefaultAclResponseProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveDefaultAclResponseProto$Builder' start='7117' end='7117' sourcepath='org/apache/hadoop/hdfs/protocol/proto/AclProtos.java' sourcefile='AclProtos.java' startBytecode='3' primary='true'><Message>At AclProtos.java:[line 7117]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='f539d089a041c23fed71bb48858c1651' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.AclProtos$SetAclRequestProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$SetAclRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$SetAclRequestProto' start='7250' end='8096' sourcepath='org/apache/hadoop/hdfs/protocol/proto/AclProtos.java' sourcefile='AclProtos.java'><Message>At AclProtos.java:[lines 7250-8096]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.AclProtos$SetAclRequestProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$SetAclRequestProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$SetAclRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/AclProtos.java' sourcefile='AclProtos.java'><Message>In AclProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.AclProtos$SetAclRequestProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$SetAclRequestProto' start='7338' end='7338' sourcepath='org/apache/hadoop/hdfs/protocol/proto/AclProtos.java' sourcefile='AclProtos.java' startBytecode='7' primary='true'><Message>At AclProtos.java:[line 7338]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='466076ccc971797030029d4f2fe77c91' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.AclProtos$SetAclRequestProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$SetAclRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$SetAclRequestProto' start='7250' end='8096' sourcepath='org/apache/hadoop/hdfs/protocol/proto/AclProtos.java' sourcefile='AclProtos.java'><Message>At AclProtos.java:[lines 7250-8096]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.AclProtos$SetAclRequestProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$SetAclRequestProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$SetAclRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/AclProtos.java' sourcefile='AclProtos.java'><Message>In AclProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.AclProtos$SetAclRequestProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$SetAclRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/AclProtos.java' sourcefile='AclProtos.java'><Message>In AclProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='81610b9e196ef4f6ee7b52cf61dd4565' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.AclProtos$SetAclResponseProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$SetAclResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$SetAclResponseProto' start='8107' end='8434' sourcepath='org/apache/hadoop/hdfs/protocol/proto/AclProtos.java' sourcefile='AclProtos.java'><Message>At AclProtos.java:[lines 8107-8434]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.AclProtos$SetAclResponseProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$SetAclResponseProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$SetAclResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/AclProtos.java' sourcefile='AclProtos.java'><Message>In AclProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.AclProtos$SetAclResponseProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$SetAclResponseProto' start='8178' end='8178' sourcepath='org/apache/hadoop/hdfs/protocol/proto/AclProtos.java' sourcefile='AclProtos.java' startBytecode='7' primary='true'><Message>At AclProtos.java:[line 8178]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='f35184d8f5a72375f186d713532d6267' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.AclProtos$SetAclResponseProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$SetAclResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$SetAclResponseProto' start='8107' end='8434' sourcepath='org/apache/hadoop/hdfs/protocol/proto/AclProtos.java' sourcefile='AclProtos.java'><Message>At AclProtos.java:[lines 8107-8434]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.AclProtos$SetAclResponseProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$SetAclResponseProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$SetAclResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/AclProtos.java' sourcefile='AclProtos.java'><Message>In AclProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.AclProtos$SetAclResponseProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$SetAclResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/AclProtos.java' sourcefile='AclProtos.java'><Message>In AclProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='884e2466d5fc00c80b05b11c128d7634' rank='17' abbrev='UCF' category='STYLE' priority='2' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.AclProtos$SetAclResponseProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$SetAclResponseProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$SetAclResponseProto$Builder' start='8326' end='8425' sourcepath='org/apache/hadoop/hdfs/protocol/proto/AclProtos.java' sourcefile='AclProtos.java'><Message>At AclProtos.java:[lines 8326-8425]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.AclProtos$SetAclResponseProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$SetAclResponseProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine endBytecode='61' classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$SetAclResponseProto$Builder' start='8352' end='8354' sourcepath='org/apache/hadoop/hdfs/protocol/proto/AclProtos.java' sourcefile='AclProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.AclProtos$SetAclResponseProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$SetAclResponseProto$Builder' start='8352' end='8352' sourcepath='org/apache/hadoop/hdfs/protocol/proto/AclProtos.java' sourcefile='AclProtos.java' startBytecode='3' primary='true'><Message>At AclProtos.java:[line 8352]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='a627b722c946b4636bc07681f15848bd' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$CancelPlanRequestProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$CancelPlanRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$CancelPlanRequestProto' start='11082' end='11579' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>At ClientDatanodeProtocolProtos.java:[lines 11082-11579]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$CancelPlanRequestProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$CancelPlanRequestProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$CancelPlanRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>In ClientDatanodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$CancelPlanRequestProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$CancelPlanRequestProto' start='11159' end='11159' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java' startBytecode='7' primary='true'><Message>At ClientDatanodeProtocolProtos.java:[line 11159]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='b2a52b43c3ac12365c535511b0f726c5' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$CancelPlanRequestProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$CancelPlanRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$CancelPlanRequestProto' start='11082' end='11579' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>At ClientDatanodeProtocolProtos.java:[lines 11082-11579]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$CancelPlanRequestProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$CancelPlanRequestProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$CancelPlanRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>In ClientDatanodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$CancelPlanRequestProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$CancelPlanRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>In ClientDatanodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='997f9dba988175b1fdc653d7d9f6505f' rank='17' abbrev='UCF' category='STYLE' priority='2' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$CancelPlanRequestProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$CancelPlanRequestProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$CancelPlanRequestProto$Builder' start='11378' end='11570' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>At ClientDatanodeProtocolProtos.java:[lines 11378-11570]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$CancelPlanRequestProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$CancelPlanRequestProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine endBytecode='61' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$CancelPlanRequestProto$Builder' start='11404' end='11406' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$CancelPlanRequestProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$CancelPlanRequestProto$Builder' start='11404' end='11404' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java' startBytecode='3' primary='true'><Message>At ClientDatanodeProtocolProtos.java:[line 11404]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='c58d94a0dc083aa80a7f926a4e33ed3a' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$CancelPlanResponseProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$CancelPlanResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$CancelPlanResponseProto' start='11595' end='11927' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>At ClientDatanodeProtocolProtos.java:[lines 11595-11927]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$CancelPlanResponseProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$CancelPlanResponseProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$CancelPlanResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>In ClientDatanodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$CancelPlanResponseProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$CancelPlanResponseProto' start='11666' end='11666' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java' startBytecode='7' primary='true'><Message>At ClientDatanodeProtocolProtos.java:[line 11666]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='928de677ba43173e5adb130867024fb9' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$CancelPlanResponseProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$CancelPlanResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$CancelPlanResponseProto' start='11595' end='11927' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>At ClientDatanodeProtocolProtos.java:[lines 11595-11927]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$CancelPlanResponseProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$CancelPlanResponseProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$CancelPlanResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>In ClientDatanodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$CancelPlanResponseProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$CancelPlanResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>In ClientDatanodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='8fc2f9fc9647708f18a9b4f621a0971b' rank='17' abbrev='UCF' category='STYLE' priority='2' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$CancelPlanResponseProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$CancelPlanResponseProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$CancelPlanResponseProto$Builder' start='11819' end='11918' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>At ClientDatanodeProtocolProtos.java:[lines 11819-11918]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$CancelPlanResponseProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$CancelPlanResponseProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine endBytecode='61' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$CancelPlanResponseProto$Builder' start='11845' end='11847' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$CancelPlanResponseProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$CancelPlanResponseProto$Builder' start='11845' end='11845' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java' startBytecode='3' primary='true'><Message>At ClientDatanodeProtocolProtos.java:[line 11845]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='929955d4bf533d6db34736fee948f448' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$CancelPlanRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService' start='14290' end='15442' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>At ClientDatanodeProtocolProtos.java:[lines 14290-15442]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/RpcCallback;)V' name='callMethod' primary='true'><SourceLine endBytecode='152' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService' start='14976' end='15068' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$CancelPlanRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$CancelPlanRequestProto' start='11082' end='11579' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>At ClientDatanodeProtocolProtos.java:[lines 11082-11579]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$CancelPlanRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='320' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='321' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService' start='15053' end='15053' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java' startBytecode='321' primary='true'><Message>At ClientDatanodeProtocolProtos.java:[line 15053]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='f75f24edba4bd22ef26abe2022b8fbe8' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$DeleteBlockPoolRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService' start='14290' end='15442' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>At ClientDatanodeProtocolProtos.java:[lines 14290-15442]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/RpcCallback;)V' name='callMethod' primary='true'><SourceLine endBytecode='152' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService' start='14976' end='15068' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$DeleteBlockPoolRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$DeleteBlockPoolRequestProto' start='1768' end='2354' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>At ClientDatanodeProtocolProtos.java:[lines 1768-2354]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$DeleteBlockPoolRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='140' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='141' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService' start='14993' end='14993' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java' startBytecode='141' primary='true'><Message>At ClientDatanodeProtocolProtos.java:[line 14993]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='e47ad40cb6031365f6515692be5a341d' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$DiskBalancerSettingRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService' start='14290' end='15442' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>At ClientDatanodeProtocolProtos.java:[lines 14290-15442]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/RpcCallback;)V' name='callMethod' primary='true'><SourceLine endBytecode='152' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService' start='14976' end='15068' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$DiskBalancerSettingRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$DiskBalancerSettingRequestProto' start='13250' end='13747' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>At ClientDatanodeProtocolProtos.java:[lines 13250-13747]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$DiskBalancerSettingRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='350' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='351' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService' start='15063' end='15063' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java' startBytecode='351' primary='true'><Message>At ClientDatanodeProtocolProtos.java:[line 15063]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='89cbc431b44a183e3e900c7867703601' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$EvictWritersRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService' start='14290' end='15442' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>At ClientDatanodeProtocolProtos.java:[lines 14290-15442]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/RpcCallback;)V' name='callMethod' primary='true'><SourceLine endBytecode='152' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService' start='14976' end='15068' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$EvictWritersRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$EvictWritersRequestProto' start='5232' end='5563' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>At ClientDatanodeProtocolProtos.java:[lines 5232-5563]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$EvictWritersRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='185' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='186' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService' start='15008' end='15008' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java' startBytecode='186' primary='true'><Message>At ClientDatanodeProtocolProtos.java:[line 15008]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='77612e8455d5f3912df0409872c41ef4' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetBalancerBandwidthRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService' start='14290' end='15442' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>At ClientDatanodeProtocolProtos.java:[lines 14290-15442]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/RpcCallback;)V' name='callMethod' primary='true'><SourceLine endBytecode='152' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService' start='14976' end='15068' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$GetBalancerBandwidthRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetBalancerBandwidthRequestProto' start='8660' end='8987' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>At ClientDatanodeProtocolProtos.java:[lines 8660-8987]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetBalancerBandwidthRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='290' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='291' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService' start='15043' end='15043' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java' startBytecode='291' primary='true'><Message>At ClientDatanodeProtocolProtos.java:[line 15043]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='ffa0fc8002fdf6b9af64352508149462' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetBlockLocalPathInfoRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService' start='14290' end='15442' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>At ClientDatanodeProtocolProtos.java:[lines 14290-15442]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/RpcCallback;)V' name='callMethod' primary='true'><SourceLine endBytecode='152' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService' start='14976' end='15068' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$GetBlockLocalPathInfoRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetBlockLocalPathInfoRequestProto' start='2750' end='3498' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>At ClientDatanodeProtocolProtos.java:[lines 2750-3498]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetBlockLocalPathInfoRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='155' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='156' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService' start='14998' end='14998' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java' startBytecode='156' primary='true'><Message>At ClientDatanodeProtocolProtos.java:[line 14998]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='745556128a6c5723e253cffdaf6c5750' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetDatanodeInfoRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService' start='14290' end='15442' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>At ClientDatanodeProtocolProtos.java:[lines 14290-15442]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/RpcCallback;)V' name='callMethod' primary='true'><SourceLine endBytecode='152' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService' start='14976' end='15068' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$GetDatanodeInfoRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetDatanodeInfoRequestProto' start='5917' end='6249' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>At ClientDatanodeProtocolProtos.java:[lines 5917-6249]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetDatanodeInfoRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='200' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='201' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService' start='15013' end='15013' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java' startBytecode='201' primary='true'><Message>At ClientDatanodeProtocolProtos.java:[line 15013]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='2d611de52234d06d06ac1b747ba7298' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetReplicaVisibleLengthRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService' start='14290' end='15442' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>At ClientDatanodeProtocolProtos.java:[lines 14290-15442]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/RpcCallback;)V' name='callMethod' primary='true'><SourceLine endBytecode='152' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService' start='14976' end='15068' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$GetReplicaVisibleLengthRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetReplicaVisibleLengthRequestProto' start='36' end='577' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>At ClientDatanodeProtocolProtos.java:[lines 36-577]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetReplicaVisibleLengthRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='110' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='111' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService' start='14983' end='14983' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java' startBytecode='111' primary='true'><Message>At ClientDatanodeProtocolProtos.java:[line 14983]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='a78902c63efeeb091d1b1d53f029bc5' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetVolumeReportRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService' start='14290' end='15442' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>At ClientDatanodeProtocolProtos.java:[lines 14290-15442]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/RpcCallback;)V' name='callMethod' primary='true'><SourceLine endBytecode='152' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService' start='14976' end='15068' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$GetVolumeReportRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetVolumeReportRequestProto' start='6821' end='7148' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>At ClientDatanodeProtocolProtos.java:[lines 6821-7148]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetVolumeReportRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='215' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='216' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService' start='15018' end='15018' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java' startBytecode='216' primary='true'><Message>At ClientDatanodeProtocolProtos.java:[line 15018]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='62fab93638c394cbe8f980e96a4d81b1' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$QueryPlanStatusRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService' start='14290' end='15442' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>At ClientDatanodeProtocolProtos.java:[lines 14290-15442]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/RpcCallback;)V' name='callMethod' primary='true'><SourceLine endBytecode='152' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService' start='14976' end='15068' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$QueryPlanStatusRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$QueryPlanStatusRequestProto' start='11945' end='12279' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>At ClientDatanodeProtocolProtos.java:[lines 11945-12279]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$QueryPlanStatusRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='335' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='336' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService' start='15058' end='15058' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java' startBytecode='336' primary='true'><Message>At ClientDatanodeProtocolProtos.java:[line 15058]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='8efc267a9725a50e07acc3a10c357c05' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$RefreshNamenodesRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService' start='14290' end='15442' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>At ClientDatanodeProtocolProtos.java:[lines 14290-15442]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/RpcCallback;)V' name='callMethod' primary='true'><SourceLine endBytecode='152' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService' start='14976' end='15068' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$RefreshNamenodesRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$RefreshNamenodesRequestProto' start='1045' end='1377' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>At ClientDatanodeProtocolProtos.java:[lines 1045-1377]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$RefreshNamenodesRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='125' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='126' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService' start='14988' end='14988' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java' startBytecode='126' primary='true'><Message>At ClientDatanodeProtocolProtos.java:[line 14988]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='60a78dc91c6bc5ec2f858d7341475000' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ShutdownDatanodeRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService' start='14290' end='15442' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>At ClientDatanodeProtocolProtos.java:[lines 14290-15442]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/RpcCallback;)V' name='callMethod' primary='true'><SourceLine endBytecode='152' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService' start='14976' end='15068' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$ShutdownDatanodeRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ShutdownDatanodeRequestProto' start='4451' end='4879' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>At ClientDatanodeProtocolProtos.java:[lines 4451-4879]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ShutdownDatanodeRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='170' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='171' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService' start='15003' end='15003' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java' startBytecode='171' primary='true'><Message>At ClientDatanodeProtocolProtos.java:[line 15003]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='40a40c3e7953846f976096b71a5992ad' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$SubmitDiskBalancerPlanRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService' start='14290' end='15442' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>At ClientDatanodeProtocolProtos.java:[lines 14290-15442]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/RpcCallback;)V' name='callMethod' primary='true'><SourceLine endBytecode='152' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService' start='14976' end='15068' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$SubmitDiskBalancerPlanRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$SubmitDiskBalancerPlanRequestProto' start='9573' end='10702' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>At ClientDatanodeProtocolProtos.java:[lines 9573-10702]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$SubmitDiskBalancerPlanRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='305' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='306' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService' start='15048' end='15048' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java' startBytecode='306' primary='true'><Message>At ClientDatanodeProtocolProtos.java:[line 15048]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='f1bd68fbc05cb82f1df7526e51e2125f' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$TriggerBlockReportRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService' start='14290' end='15442' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>At ClientDatanodeProtocolProtos.java:[lines 14290-15442]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/RpcCallback;)V' name='callMethod' primary='true'><SourceLine endBytecode='152' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService' start='14976' end='15068' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$TriggerBlockReportRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$TriggerBlockReportRequestProto' start='7890' end='8311' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>At ClientDatanodeProtocolProtos.java:[lines 7890-8311]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$TriggerBlockReportRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='275' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='276' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService' start='15038' end='15038' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java' startBytecode='276' primary='true'><Message>At ClientDatanodeProtocolProtos.java:[line 15038]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='589300109e58a57c2d9f71a0e484ff7' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$GetReconfigurationStatusRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService' start='14290' end='15442' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>At ClientDatanodeProtocolProtos.java:[lines 14290-15442]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/RpcCallback;)V' name='callMethod' primary='true'><SourceLine endBytecode='152' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService' start='14976' end='15068' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ReconfigurationProtocolProtos$GetReconfigurationStatusRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$GetReconfigurationStatusRequestProto' start='705' end='1036' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ReconfigurationProtocolProtos.java' sourcefile='ReconfigurationProtocolProtos.java'><Message>At ReconfigurationProtocolProtos.java:[lines 705-1036]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$GetReconfigurationStatusRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='230' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='231' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService' start='15023' end='15023' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java' startBytecode='231' primary='true'><Message>At ClientDatanodeProtocolProtos.java:[line 15023]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='ec675166cf8c79b5ba5a6e8392c63b86' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$ListReconfigurablePropertiesRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService' start='14290' end='15442' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>At ClientDatanodeProtocolProtos.java:[lines 14290-15442]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/RpcCallback;)V' name='callMethod' primary='true'><SourceLine endBytecode='152' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService' start='14976' end='15068' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ReconfigurationProtocolProtos$ListReconfigurablePropertiesRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$ListReconfigurablePropertiesRequestProto' start='3031' end='3362' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ReconfigurationProtocolProtos.java' sourcefile='ReconfigurationProtocolProtos.java'><Message>At ReconfigurationProtocolProtos.java:[lines 3031-3362]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$ListReconfigurablePropertiesRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='260' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='261' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService' start='15033' end='15033' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java' startBytecode='261' primary='true'><Message>At ClientDatanodeProtocolProtos.java:[line 15033]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='b02a2d01a0396c08790f628214b985d3' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$StartReconfigurationRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService' start='14290' end='15442' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>At ClientDatanodeProtocolProtos.java:[lines 14290-15442]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/RpcCallback;)V' name='callMethod' primary='true'><SourceLine endBytecode='152' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService' start='14976' end='15068' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ReconfigurationProtocolProtos$StartReconfigurationRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$StartReconfigurationRequestProto' start='21' end='352' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ReconfigurationProtocolProtos.java' sourcefile='ReconfigurationProtocolProtos.java'><Message>At ReconfigurationProtocolProtos.java:[lines 21-352]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$StartReconfigurationRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='245' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='246' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService' start='15028' end='15028' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java' startBytecode='246' primary='true'><Message>At ClientDatanodeProtocolProtos.java:[line 15028]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='bb7f68b9aaab0b8376efab066c3f67a5' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$CancelPlanRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService$2' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService$2' start='14622' end='14770' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>At ClientDatanodeProtocolProtos.java:[lines 14622-14770]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService$2</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService$2' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;' name='callBlockingMethod' primary='true'><SourceLine endBytecode='135' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService$2' start='14633' end='14674' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$CancelPlanRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$CancelPlanRequestProto' start='11082' end='11579' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>At ClientDatanodeProtocolProtos.java:[lines 11082-11579]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$CancelPlanRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='323' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='324' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService$2' start='14668' end='14668' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java' startBytecode='324' primary='true'><Message>At ClientDatanodeProtocolProtos.java:[line 14668]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='2e3c06f1863d48a94262f088965b283f' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$DeleteBlockPoolRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService$2' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService$2' start='14622' end='14770' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>At ClientDatanodeProtocolProtos.java:[lines 14622-14770]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService$2</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService$2' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;' name='callBlockingMethod' primary='true'><SourceLine endBytecode='135' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService$2' start='14633' end='14674' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$DeleteBlockPoolRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$DeleteBlockPoolRequestProto' start='1768' end='2354' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>At ClientDatanodeProtocolProtos.java:[lines 1768-2354]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$DeleteBlockPoolRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='143' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='144' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService$2' start='14644' end='14644' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java' startBytecode='144' primary='true'><Message>At ClientDatanodeProtocolProtos.java:[line 14644]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='e00d7edf69e3722048072d4faec19366' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$DiskBalancerSettingRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService$2' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService$2' start='14622' end='14770' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>At ClientDatanodeProtocolProtos.java:[lines 14622-14770]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService$2</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService$2' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;' name='callBlockingMethod' primary='true'><SourceLine endBytecode='135' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService$2' start='14633' end='14674' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$DiskBalancerSettingRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$DiskBalancerSettingRequestProto' start='13250' end='13747' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>At ClientDatanodeProtocolProtos.java:[lines 13250-13747]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$DiskBalancerSettingRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='353' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='354' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService$2' start='14672' end='14672' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java' startBytecode='354' primary='true'><Message>At ClientDatanodeProtocolProtos.java:[line 14672]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='c521922290e22d6ce1141c260fd3e561' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$EvictWritersRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService$2' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService$2' start='14622' end='14770' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>At ClientDatanodeProtocolProtos.java:[lines 14622-14770]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService$2</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService$2' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;' name='callBlockingMethod' primary='true'><SourceLine endBytecode='135' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService$2' start='14633' end='14674' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$EvictWritersRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$EvictWritersRequestProto' start='5232' end='5563' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>At ClientDatanodeProtocolProtos.java:[lines 5232-5563]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$EvictWritersRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='188' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='189' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService$2' start='14650' end='14650' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java' startBytecode='189' primary='true'><Message>At ClientDatanodeProtocolProtos.java:[line 14650]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='643f2d9eaaa8bf229b1e684ba189b46b' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetBalancerBandwidthRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService$2' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService$2' start='14622' end='14770' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>At ClientDatanodeProtocolProtos.java:[lines 14622-14770]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService$2</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService$2' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;' name='callBlockingMethod' primary='true'><SourceLine endBytecode='135' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService$2' start='14633' end='14674' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$GetBalancerBandwidthRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetBalancerBandwidthRequestProto' start='8660' end='8987' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>At ClientDatanodeProtocolProtos.java:[lines 8660-8987]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetBalancerBandwidthRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='293' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='294' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService$2' start='14664' end='14664' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java' startBytecode='294' primary='true'><Message>At ClientDatanodeProtocolProtos.java:[line 14664]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='63be6a687c67290f0bdf42a8360e04cf' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetBlockLocalPathInfoRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService$2' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService$2' start='14622' end='14770' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>At ClientDatanodeProtocolProtos.java:[lines 14622-14770]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService$2</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService$2' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;' name='callBlockingMethod' primary='true'><SourceLine endBytecode='135' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService$2' start='14633' end='14674' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$GetBlockLocalPathInfoRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetBlockLocalPathInfoRequestProto' start='2750' end='3498' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>At ClientDatanodeProtocolProtos.java:[lines 2750-3498]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetBlockLocalPathInfoRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='158' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='159' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService$2' start='14646' end='14646' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java' startBytecode='159' primary='true'><Message>At ClientDatanodeProtocolProtos.java:[line 14646]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='c0b956420ae819b230e173fee5734a47' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetDatanodeInfoRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService$2' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService$2' start='14622' end='14770' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>At ClientDatanodeProtocolProtos.java:[lines 14622-14770]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService$2</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService$2' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;' name='callBlockingMethod' primary='true'><SourceLine endBytecode='135' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService$2' start='14633' end='14674' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$GetDatanodeInfoRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetDatanodeInfoRequestProto' start='5917' end='6249' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>At ClientDatanodeProtocolProtos.java:[lines 5917-6249]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetDatanodeInfoRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='203' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='204' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService$2' start='14652' end='14652' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java' startBytecode='204' primary='true'><Message>At ClientDatanodeProtocolProtos.java:[line 14652]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='fda065795843f3bfaf4fc0e6f1f6b36a' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetReplicaVisibleLengthRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService$2' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService$2' start='14622' end='14770' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>At ClientDatanodeProtocolProtos.java:[lines 14622-14770]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService$2</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService$2' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;' name='callBlockingMethod' primary='true'><SourceLine endBytecode='135' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService$2' start='14633' end='14674' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$GetReplicaVisibleLengthRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetReplicaVisibleLengthRequestProto' start='36' end='577' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>At ClientDatanodeProtocolProtos.java:[lines 36-577]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetReplicaVisibleLengthRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='113' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='114' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService$2' start='14640' end='14640' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java' startBytecode='114' primary='true'><Message>At ClientDatanodeProtocolProtos.java:[line 14640]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='416aab293008de2df2aeb6f64bd0cee7' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetVolumeReportRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService$2' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService$2' start='14622' end='14770' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>At ClientDatanodeProtocolProtos.java:[lines 14622-14770]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService$2</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService$2' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;' name='callBlockingMethod' primary='true'><SourceLine endBytecode='135' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService$2' start='14633' end='14674' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$GetVolumeReportRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetVolumeReportRequestProto' start='6821' end='7148' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>At ClientDatanodeProtocolProtos.java:[lines 6821-7148]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetVolumeReportRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='218' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='219' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService$2' start='14654' end='14654' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java' startBytecode='219' primary='true'><Message>At ClientDatanodeProtocolProtos.java:[line 14654]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='bd15cf299d2dde0b189527baba1fe7c4' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$QueryPlanStatusRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService$2' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService$2' start='14622' end='14770' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>At ClientDatanodeProtocolProtos.java:[lines 14622-14770]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService$2</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService$2' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;' name='callBlockingMethod' primary='true'><SourceLine endBytecode='135' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService$2' start='14633' end='14674' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$QueryPlanStatusRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$QueryPlanStatusRequestProto' start='11945' end='12279' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>At ClientDatanodeProtocolProtos.java:[lines 11945-12279]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$QueryPlanStatusRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='338' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='339' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService$2' start='14670' end='14670' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java' startBytecode='339' primary='true'><Message>At ClientDatanodeProtocolProtos.java:[line 14670]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='3b345a94fa7a919532863c14ba6e45f7' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$RefreshNamenodesRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService$2' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService$2' start='14622' end='14770' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>At ClientDatanodeProtocolProtos.java:[lines 14622-14770]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService$2</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService$2' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;' name='callBlockingMethod' primary='true'><SourceLine endBytecode='135' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService$2' start='14633' end='14674' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$RefreshNamenodesRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$RefreshNamenodesRequestProto' start='1045' end='1377' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>At ClientDatanodeProtocolProtos.java:[lines 1045-1377]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$RefreshNamenodesRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='128' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='129' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService$2' start='14642' end='14642' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java' startBytecode='129' primary='true'><Message>At ClientDatanodeProtocolProtos.java:[line 14642]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='e535c1e0e4df978c655a5af0ed146808' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ShutdownDatanodeRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService$2' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService$2' start='14622' end='14770' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>At ClientDatanodeProtocolProtos.java:[lines 14622-14770]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService$2</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService$2' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;' name='callBlockingMethod' primary='true'><SourceLine endBytecode='135' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService$2' start='14633' end='14674' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$ShutdownDatanodeRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ShutdownDatanodeRequestProto' start='4451' end='4879' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>At ClientDatanodeProtocolProtos.java:[lines 4451-4879]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ShutdownDatanodeRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='173' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='174' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService$2' start='14648' end='14648' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java' startBytecode='174' primary='true'><Message>At ClientDatanodeProtocolProtos.java:[line 14648]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='4bcc278f4be2dd6a89fc24ead874141' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$SubmitDiskBalancerPlanRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService$2' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService$2' start='14622' end='14770' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>At ClientDatanodeProtocolProtos.java:[lines 14622-14770]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService$2</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService$2' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;' name='callBlockingMethod' primary='true'><SourceLine endBytecode='135' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService$2' start='14633' end='14674' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$SubmitDiskBalancerPlanRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$SubmitDiskBalancerPlanRequestProto' start='9573' end='10702' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>At ClientDatanodeProtocolProtos.java:[lines 9573-10702]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$SubmitDiskBalancerPlanRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='308' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='309' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService$2' start='14666' end='14666' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java' startBytecode='309' primary='true'><Message>At ClientDatanodeProtocolProtos.java:[line 14666]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='31575cc4ca928d58488c534b42c7997e' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$TriggerBlockReportRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService$2' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService$2' start='14622' end='14770' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>At ClientDatanodeProtocolProtos.java:[lines 14622-14770]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService$2</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService$2' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;' name='callBlockingMethod' primary='true'><SourceLine endBytecode='135' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService$2' start='14633' end='14674' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$TriggerBlockReportRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$TriggerBlockReportRequestProto' start='7890' end='8311' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>At ClientDatanodeProtocolProtos.java:[lines 7890-8311]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$TriggerBlockReportRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='278' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='279' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService$2' start='14662' end='14662' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java' startBytecode='279' primary='true'><Message>At ClientDatanodeProtocolProtos.java:[line 14662]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='7ef3d5963f9a341cb98d38447cd7e987' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$GetReconfigurationStatusRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService$2' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService$2' start='14622' end='14770' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>At ClientDatanodeProtocolProtos.java:[lines 14622-14770]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService$2</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService$2' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;' name='callBlockingMethod' primary='true'><SourceLine endBytecode='135' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService$2' start='14633' end='14674' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ReconfigurationProtocolProtos$GetReconfigurationStatusRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$GetReconfigurationStatusRequestProto' start='705' end='1036' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ReconfigurationProtocolProtos.java' sourcefile='ReconfigurationProtocolProtos.java'><Message>At ReconfigurationProtocolProtos.java:[lines 705-1036]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$GetReconfigurationStatusRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='233' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='234' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService$2' start='14656' end='14656' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java' startBytecode='234' primary='true'><Message>At ClientDatanodeProtocolProtos.java:[line 14656]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='c2713d9378d416cf7b48fc20de44cc52' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$ListReconfigurablePropertiesRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService$2' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService$2' start='14622' end='14770' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>At ClientDatanodeProtocolProtos.java:[lines 14622-14770]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService$2</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService$2' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;' name='callBlockingMethod' primary='true'><SourceLine endBytecode='135' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService$2' start='14633' end='14674' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ReconfigurationProtocolProtos$ListReconfigurablePropertiesRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$ListReconfigurablePropertiesRequestProto' start='3031' end='3362' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ReconfigurationProtocolProtos.java' sourcefile='ReconfigurationProtocolProtos.java'><Message>At ReconfigurationProtocolProtos.java:[lines 3031-3362]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$ListReconfigurablePropertiesRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='263' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='264' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService$2' start='14660' end='14660' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java' startBytecode='264' primary='true'><Message>At ClientDatanodeProtocolProtos.java:[line 14660]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='e869ed11f830ac1baa61be01dc5ac543' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$StartReconfigurationRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService$2' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService$2' start='14622' end='14770' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>At ClientDatanodeProtocolProtos.java:[lines 14622-14770]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService$2</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService$2' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;' name='callBlockingMethod' primary='true'><SourceLine endBytecode='135' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService$2' start='14633' end='14674' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ReconfigurationProtocolProtos$StartReconfigurationRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$StartReconfigurationRequestProto' start='21' end='352' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ReconfigurationProtocolProtos.java' sourcefile='ReconfigurationProtocolProtos.java'><Message>At ReconfigurationProtocolProtos.java:[lines 21-352]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$StartReconfigurationRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='248' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='249' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService$2' start='14658' end='14658' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java' startBytecode='249' primary='true'><Message>At ClientDatanodeProtocolProtos.java:[line 14658]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='ec5ccadcea014a66d95ea169a197a560' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$DeleteBlockPoolRequestProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$DeleteBlockPoolRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$DeleteBlockPoolRequestProto' start='1768' end='2354' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>At ClientDatanodeProtocolProtos.java:[lines 1768-2354]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$DeleteBlockPoolRequestProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$DeleteBlockPoolRequestProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$DeleteBlockPoolRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>In ClientDatanodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$DeleteBlockPoolRequestProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$DeleteBlockPoolRequestProto' start='1850' end='1850' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java' startBytecode='7' primary='true'><Message>At ClientDatanodeProtocolProtos.java:[line 1850]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='e9412cc5ad2b29d6059053b4e47db859' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$DeleteBlockPoolRequestProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$DeleteBlockPoolRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$DeleteBlockPoolRequestProto' start='1768' end='2354' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>At ClientDatanodeProtocolProtos.java:[lines 1768-2354]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$DeleteBlockPoolRequestProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$DeleteBlockPoolRequestProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$DeleteBlockPoolRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>In ClientDatanodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$DeleteBlockPoolRequestProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$DeleteBlockPoolRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>In ClientDatanodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='36df436cffed913d765fe77aa2e62b01' rank='17' abbrev='UCF' category='STYLE' priority='2' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$DeleteBlockPoolRequestProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$DeleteBlockPoolRequestProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$DeleteBlockPoolRequestProto$Builder' start='2107' end='2345' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>At ClientDatanodeProtocolProtos.java:[lines 2107-2345]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$DeleteBlockPoolRequestProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$DeleteBlockPoolRequestProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine endBytecode='61' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$DeleteBlockPoolRequestProto$Builder' start='2133' end='2135' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$DeleteBlockPoolRequestProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$DeleteBlockPoolRequestProto$Builder' start='2133' end='2133' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java' startBytecode='3' primary='true'><Message>At ClientDatanodeProtocolProtos.java:[line 2133]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='d296f3ed8ce0b329128c123af07292dc' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$DeleteBlockPoolResponseProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$DeleteBlockPoolResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$DeleteBlockPoolResponseProto' start='2370' end='2702' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>At ClientDatanodeProtocolProtos.java:[lines 2370-2702]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$DeleteBlockPoolResponseProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$DeleteBlockPoolResponseProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$DeleteBlockPoolResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>In ClientDatanodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$DeleteBlockPoolResponseProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$DeleteBlockPoolResponseProto' start='2441' end='2441' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java' startBytecode='7' primary='true'><Message>At ClientDatanodeProtocolProtos.java:[line 2441]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='1a83770502317a4304e63ff73c1d57ac' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$DeleteBlockPoolResponseProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$DeleteBlockPoolResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$DeleteBlockPoolResponseProto' start='2370' end='2702' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>At ClientDatanodeProtocolProtos.java:[lines 2370-2702]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$DeleteBlockPoolResponseProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$DeleteBlockPoolResponseProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$DeleteBlockPoolResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>In ClientDatanodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$DeleteBlockPoolResponseProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$DeleteBlockPoolResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>In ClientDatanodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='6cf14ff1178fafa4dc6be5fa90c10c42' rank='17' abbrev='UCF' category='STYLE' priority='2' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$DeleteBlockPoolResponseProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$DeleteBlockPoolResponseProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$DeleteBlockPoolResponseProto$Builder' start='2594' end='2693' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>At ClientDatanodeProtocolProtos.java:[lines 2594-2693]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$DeleteBlockPoolResponseProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$DeleteBlockPoolResponseProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine endBytecode='61' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$DeleteBlockPoolResponseProto$Builder' start='2620' end='2622' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$DeleteBlockPoolResponseProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$DeleteBlockPoolResponseProto$Builder' start='2620' end='2620' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java' startBytecode='3' primary='true'><Message>At ClientDatanodeProtocolProtos.java:[line 2620]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='5fd6ffedef22fe80b0f4507431df319c' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$DiskBalancerSettingRequestProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$DiskBalancerSettingRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$DiskBalancerSettingRequestProto' start='13250' end='13747' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>At ClientDatanodeProtocolProtos.java:[lines 13250-13747]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$DiskBalancerSettingRequestProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$DiskBalancerSettingRequestProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$DiskBalancerSettingRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>In ClientDatanodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$DiskBalancerSettingRequestProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$DiskBalancerSettingRequestProto' start='13327' end='13327' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java' startBytecode='7' primary='true'><Message>At ClientDatanodeProtocolProtos.java:[line 13327]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='2c121c69ae761006cc65ac00b8f3cbd9' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$DiskBalancerSettingRequestProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$DiskBalancerSettingRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$DiskBalancerSettingRequestProto' start='13250' end='13747' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>At ClientDatanodeProtocolProtos.java:[lines 13250-13747]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$DiskBalancerSettingRequestProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$DiskBalancerSettingRequestProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$DiskBalancerSettingRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>In ClientDatanodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$DiskBalancerSettingRequestProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$DiskBalancerSettingRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>In ClientDatanodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='182d5f33e04a7b470f49294580ede14f' rank='17' abbrev='UCF' category='STYLE' priority='2' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$DiskBalancerSettingRequestProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$DiskBalancerSettingRequestProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$DiskBalancerSettingRequestProto$Builder' start='13546' end='13738' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>At ClientDatanodeProtocolProtos.java:[lines 13546-13738]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$DiskBalancerSettingRequestProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$DiskBalancerSettingRequestProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine endBytecode='61' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$DiskBalancerSettingRequestProto$Builder' start='13572' end='13574' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$DiskBalancerSettingRequestProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$DiskBalancerSettingRequestProto$Builder' start='13572' end='13572' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java' startBytecode='3' primary='true'><Message>At ClientDatanodeProtocolProtos.java:[line 13572]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='51ed45d7334ddab2604fef62fcacfb33' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$DiskBalancerSettingResponseProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$DiskBalancerSettingResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$DiskBalancerSettingResponseProto' start='13778' end='14274' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>At ClientDatanodeProtocolProtos.java:[lines 13778-14274]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$DiskBalancerSettingResponseProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$DiskBalancerSettingResponseProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$DiskBalancerSettingResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>In ClientDatanodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$DiskBalancerSettingResponseProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$DiskBalancerSettingResponseProto' start='13855' end='13855' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java' startBytecode='7' primary='true'><Message>At ClientDatanodeProtocolProtos.java:[line 13855]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='8487d7549d83073247e501e20a626b34' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$DiskBalancerSettingResponseProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$DiskBalancerSettingResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$DiskBalancerSettingResponseProto' start='13778' end='14274' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>At ClientDatanodeProtocolProtos.java:[lines 13778-14274]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$DiskBalancerSettingResponseProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$DiskBalancerSettingResponseProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$DiskBalancerSettingResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>In ClientDatanodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$DiskBalancerSettingResponseProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$DiskBalancerSettingResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>In ClientDatanodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='e77cf9c3d49e2448e9774347e4880927' rank='17' abbrev='UCF' category='STYLE' priority='2' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$DiskBalancerSettingResponseProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$DiskBalancerSettingResponseProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$DiskBalancerSettingResponseProto$Builder' start='14073' end='14265' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>At ClientDatanodeProtocolProtos.java:[lines 14073-14265]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$DiskBalancerSettingResponseProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$DiskBalancerSettingResponseProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine endBytecode='61' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$DiskBalancerSettingResponseProto$Builder' start='14099' end='14101' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$DiskBalancerSettingResponseProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$DiskBalancerSettingResponseProto$Builder' start='14099' end='14099' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java' startBytecode='3' primary='true'><Message>At ClientDatanodeProtocolProtos.java:[line 14099]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='dc479bdb3cd21d14f59c315b92ac67c8' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$EvictWritersRequestProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$EvictWritersRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$EvictWritersRequestProto' start='5232' end='5563' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>At ClientDatanodeProtocolProtos.java:[lines 5232-5563]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$EvictWritersRequestProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$EvictWritersRequestProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$EvictWritersRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>In ClientDatanodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$EvictWritersRequestProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$EvictWritersRequestProto' start='5303' end='5303' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java' startBytecode='7' primary='true'><Message>At ClientDatanodeProtocolProtos.java:[line 5303]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='20d57260ef577c23771ffd8e0621b19f' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$EvictWritersRequestProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$EvictWritersRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$EvictWritersRequestProto' start='5232' end='5563' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>At ClientDatanodeProtocolProtos.java:[lines 5232-5563]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$EvictWritersRequestProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$EvictWritersRequestProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$EvictWritersRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>In ClientDatanodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$EvictWritersRequestProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$EvictWritersRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>In ClientDatanodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='c2dc7f42124f2864b9458cc767ecf6b0' rank='17' abbrev='UCF' category='STYLE' priority='2' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$EvictWritersRequestProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$EvictWritersRequestProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$EvictWritersRequestProto$Builder' start='5455' end='5554' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>At ClientDatanodeProtocolProtos.java:[lines 5455-5554]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$EvictWritersRequestProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$EvictWritersRequestProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine endBytecode='61' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$EvictWritersRequestProto$Builder' start='5481' end='5483' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$EvictWritersRequestProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$EvictWritersRequestProto$Builder' start='5481' end='5481' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java' startBytecode='3' primary='true'><Message>At ClientDatanodeProtocolProtos.java:[line 5481]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='2a34264e4836650259ec7e721bdd3fe' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$EvictWritersResponseProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$EvictWritersResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$EvictWritersResponseProto' start='5574' end='5901' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>At ClientDatanodeProtocolProtos.java:[lines 5574-5901]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$EvictWritersResponseProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$EvictWritersResponseProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$EvictWritersResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>In ClientDatanodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$EvictWritersResponseProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$EvictWritersResponseProto' start='5645' end='5645' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java' startBytecode='7' primary='true'><Message>At ClientDatanodeProtocolProtos.java:[line 5645]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='23995064d8f07ff044413b255a3a36a7' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$EvictWritersResponseProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$EvictWritersResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$EvictWritersResponseProto' start='5574' end='5901' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>At ClientDatanodeProtocolProtos.java:[lines 5574-5901]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$EvictWritersResponseProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$EvictWritersResponseProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$EvictWritersResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>In ClientDatanodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$EvictWritersResponseProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$EvictWritersResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>In ClientDatanodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='7a5406aa6963d01ee6707ed38150613' rank='17' abbrev='UCF' category='STYLE' priority='2' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$EvictWritersResponseProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$EvictWritersResponseProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$EvictWritersResponseProto$Builder' start='5793' end='5892' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>At ClientDatanodeProtocolProtos.java:[lines 5793-5892]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$EvictWritersResponseProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$EvictWritersResponseProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine endBytecode='61' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$EvictWritersResponseProto$Builder' start='5819' end='5821' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$EvictWritersResponseProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$EvictWritersResponseProto$Builder' start='5819' end='5819' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java' startBytecode='3' primary='true'><Message>At ClientDatanodeProtocolProtos.java:[line 5819]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='202bf4fa39ca7d9a00917f1937aa39fc' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetBalancerBandwidthRequestProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetBalancerBandwidthRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetBalancerBandwidthRequestProto' start='8660' end='8987' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>At ClientDatanodeProtocolProtos.java:[lines 8660-8987]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetBalancerBandwidthRequestProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetBalancerBandwidthRequestProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetBalancerBandwidthRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>In ClientDatanodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetBalancerBandwidthRequestProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetBalancerBandwidthRequestProto' start='8731' end='8731' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java' startBytecode='7' primary='true'><Message>At ClientDatanodeProtocolProtos.java:[line 8731]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='c00b55f1c5bbb385377d048b755571d0' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetBalancerBandwidthRequestProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetBalancerBandwidthRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetBalancerBandwidthRequestProto' start='8660' end='8987' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>At ClientDatanodeProtocolProtos.java:[lines 8660-8987]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetBalancerBandwidthRequestProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetBalancerBandwidthRequestProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetBalancerBandwidthRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>In ClientDatanodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetBalancerBandwidthRequestProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetBalancerBandwidthRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>In ClientDatanodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='a7aaafd4f404946f601aa8cc4f64e696' rank='17' abbrev='UCF' category='STYLE' priority='2' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetBalancerBandwidthRequestProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetBalancerBandwidthRequestProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetBalancerBandwidthRequestProto$Builder' start='8879' end='8978' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>At ClientDatanodeProtocolProtos.java:[lines 8879-8978]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetBalancerBandwidthRequestProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetBalancerBandwidthRequestProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine endBytecode='61' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetBalancerBandwidthRequestProto$Builder' start='8905' end='8907' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetBalancerBandwidthRequestProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetBalancerBandwidthRequestProto$Builder' start='8905' end='8905' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java' startBytecode='3' primary='true'><Message>At ClientDatanodeProtocolProtos.java:[line 8905]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='6dec725fc09442fb19a33952a44598be' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetBalancerBandwidthResponseProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetBalancerBandwidthResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetBalancerBandwidthResponseProto' start='9013' end='9439' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>At ClientDatanodeProtocolProtos.java:[lines 9013-9439]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetBalancerBandwidthResponseProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetBalancerBandwidthResponseProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetBalancerBandwidthResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>In ClientDatanodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetBalancerBandwidthResponseProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetBalancerBandwidthResponseProto' start='9090' end='9090' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java' startBytecode='7' primary='true'><Message>At ClientDatanodeProtocolProtos.java:[line 9090]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='3876c6d3f1a11ae38564ca436e540938' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetBalancerBandwidthResponseProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetBalancerBandwidthResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetBalancerBandwidthResponseProto' start='9013' end='9439' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>At ClientDatanodeProtocolProtos.java:[lines 9013-9439]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetBalancerBandwidthResponseProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetBalancerBandwidthResponseProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetBalancerBandwidthResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>In ClientDatanodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetBalancerBandwidthResponseProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetBalancerBandwidthResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>In ClientDatanodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='5b712567ae1588e6ab8368f3de9e2e01' rank='17' abbrev='UCF' category='STYLE' priority='2' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetBalancerBandwidthResponseProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetBalancerBandwidthResponseProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetBalancerBandwidthResponseProto$Builder' start='9281' end='9430' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>At ClientDatanodeProtocolProtos.java:[lines 9281-9430]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetBalancerBandwidthResponseProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetBalancerBandwidthResponseProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine endBytecode='61' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetBalancerBandwidthResponseProto$Builder' start='9307' end='9309' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetBalancerBandwidthResponseProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetBalancerBandwidthResponseProto$Builder' start='9307' end='9307' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java' startBytecode='3' primary='true'><Message>At ClientDatanodeProtocolProtos.java:[line 9307]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='338eed581a771c426edb603126bce7b4' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetBlockLocalPathInfoRequestProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetBlockLocalPathInfoRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetBlockLocalPathInfoRequestProto' start='2750' end='3498' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>At ClientDatanodeProtocolProtos.java:[lines 2750-3498]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetBlockLocalPathInfoRequestProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetBlockLocalPathInfoRequestProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetBlockLocalPathInfoRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>In ClientDatanodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetBlockLocalPathInfoRequestProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetBlockLocalPathInfoRequestProto' start='2848' end='2848' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java' startBytecode='7' primary='true'><Message>At ClientDatanodeProtocolProtos.java:[line 2848]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='2b8fef7b465eaa7da7925eedfe1a7d9c' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetBlockLocalPathInfoRequestProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetBlockLocalPathInfoRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetBlockLocalPathInfoRequestProto' start='2750' end='3498' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>At ClientDatanodeProtocolProtos.java:[lines 2750-3498]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetBlockLocalPathInfoRequestProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetBlockLocalPathInfoRequestProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetBlockLocalPathInfoRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>In ClientDatanodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetBlockLocalPathInfoRequestProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetBlockLocalPathInfoRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>In ClientDatanodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='febae91ce900a0002441fef73c33832c' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetBlockLocalPathInfoResponseProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetBlockLocalPathInfoResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetBlockLocalPathInfoResponseProto' start='3562' end='4423' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>At ClientDatanodeProtocolProtos.java:[lines 3562-4423]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetBlockLocalPathInfoResponseProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetBlockLocalPathInfoResponseProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetBlockLocalPathInfoResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>In ClientDatanodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetBlockLocalPathInfoResponseProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetBlockLocalPathInfoResponseProto' start='3657' end='3657' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java' startBytecode='7' primary='true'><Message>At ClientDatanodeProtocolProtos.java:[line 3657]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='b5253837b25334793706bfb0e43a07df' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetBlockLocalPathInfoResponseProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetBlockLocalPathInfoResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetBlockLocalPathInfoResponseProto' start='3562' end='4423' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>At ClientDatanodeProtocolProtos.java:[lines 3562-4423]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetBlockLocalPathInfoResponseProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetBlockLocalPathInfoResponseProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetBlockLocalPathInfoResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>In ClientDatanodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetBlockLocalPathInfoResponseProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetBlockLocalPathInfoResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>In ClientDatanodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='9ebfa27688916d0fb0b12fa95620e87b' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetDatanodeInfoRequestProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetDatanodeInfoRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetDatanodeInfoRequestProto' start='5917' end='6249' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>At ClientDatanodeProtocolProtos.java:[lines 5917-6249]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetDatanodeInfoRequestProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetDatanodeInfoRequestProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetDatanodeInfoRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>In ClientDatanodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetDatanodeInfoRequestProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetDatanodeInfoRequestProto' start='5988' end='5988' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java' startBytecode='7' primary='true'><Message>At ClientDatanodeProtocolProtos.java:[line 5988]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='565ec5224131600d876bd00ff3f56b1a' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetDatanodeInfoRequestProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetDatanodeInfoRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetDatanodeInfoRequestProto' start='5917' end='6249' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>At ClientDatanodeProtocolProtos.java:[lines 5917-6249]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetDatanodeInfoRequestProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetDatanodeInfoRequestProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetDatanodeInfoRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>In ClientDatanodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetDatanodeInfoRequestProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetDatanodeInfoRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>In ClientDatanodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='8ae222e82a129bc1520e5a57f25bbbd8' rank='17' abbrev='UCF' category='STYLE' priority='2' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetDatanodeInfoRequestProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetDatanodeInfoRequestProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetDatanodeInfoRequestProto$Builder' start='6141' end='6240' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>At ClientDatanodeProtocolProtos.java:[lines 6141-6240]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetDatanodeInfoRequestProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetDatanodeInfoRequestProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine endBytecode='61' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetDatanodeInfoRequestProto$Builder' start='6167' end='6169' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetDatanodeInfoRequestProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetDatanodeInfoRequestProto$Builder' start='6167' end='6167' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java' startBytecode='3' primary='true'><Message>At ClientDatanodeProtocolProtos.java:[line 6167]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='dc197a70982e24bd6e070a1669cf08e1' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetDatanodeInfoResponseProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetDatanodeInfoResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetDatanodeInfoResponseProto' start='6274' end='6810' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>At ClientDatanodeProtocolProtos.java:[lines 6274-6810]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetDatanodeInfoResponseProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetDatanodeInfoResponseProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetDatanodeInfoResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>In ClientDatanodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetDatanodeInfoResponseProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetDatanodeInfoResponseProto' start='6359' end='6359' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java' startBytecode='7' primary='true'><Message>At ClientDatanodeProtocolProtos.java:[line 6359]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='da9fd8a714d72426c59049aaffd0a4cd' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetDatanodeInfoResponseProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetDatanodeInfoResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetDatanodeInfoResponseProto' start='6274' end='6810' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>At ClientDatanodeProtocolProtos.java:[lines 6274-6810]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetDatanodeInfoResponseProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetDatanodeInfoResponseProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetDatanodeInfoResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>In ClientDatanodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetDatanodeInfoResponseProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetDatanodeInfoResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>In ClientDatanodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='410fea97d7439fa5d01ad21911c3d3ff' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetReplicaVisibleLengthRequestProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetReplicaVisibleLengthRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetReplicaVisibleLengthRequestProto' start='36' end='577' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>At ClientDatanodeProtocolProtos.java:[lines 36-577]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetReplicaVisibleLengthRequestProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetReplicaVisibleLengthRequestProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetReplicaVisibleLengthRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>In ClientDatanodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetReplicaVisibleLengthRequestProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetReplicaVisibleLengthRequestProto' start='121' end='121' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java' startBytecode='7' primary='true'><Message>At ClientDatanodeProtocolProtos.java:[line 121]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='4456be20d411c71e047beff167033a18' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetReplicaVisibleLengthRequestProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetReplicaVisibleLengthRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetReplicaVisibleLengthRequestProto' start='36' end='577' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>At ClientDatanodeProtocolProtos.java:[lines 36-577]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetReplicaVisibleLengthRequestProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetReplicaVisibleLengthRequestProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetReplicaVisibleLengthRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>In ClientDatanodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetReplicaVisibleLengthRequestProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetReplicaVisibleLengthRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>In ClientDatanodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='27db23defb66a5a824554ba193a4eca1' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetReplicaVisibleLengthResponseProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetReplicaVisibleLengthResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetReplicaVisibleLengthResponseProto' start='603' end='1029' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>At ClientDatanodeProtocolProtos.java:[lines 603-1029]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetReplicaVisibleLengthResponseProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetReplicaVisibleLengthResponseProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetReplicaVisibleLengthResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>In ClientDatanodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetReplicaVisibleLengthResponseProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetReplicaVisibleLengthResponseProto' start='680' end='680' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java' startBytecode='7' primary='true'><Message>At ClientDatanodeProtocolProtos.java:[line 680]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='219199822f65a09ffaccfcf7c727334b' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetReplicaVisibleLengthResponseProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetReplicaVisibleLengthResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetReplicaVisibleLengthResponseProto' start='603' end='1029' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>At ClientDatanodeProtocolProtos.java:[lines 603-1029]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetReplicaVisibleLengthResponseProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetReplicaVisibleLengthResponseProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetReplicaVisibleLengthResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>In ClientDatanodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetReplicaVisibleLengthResponseProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetReplicaVisibleLengthResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>In ClientDatanodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='bec9fcd40c48ae0c87f03295b4ffae57' rank='17' abbrev='UCF' category='STYLE' priority='2' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetReplicaVisibleLengthResponseProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetReplicaVisibleLengthResponseProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetReplicaVisibleLengthResponseProto$Builder' start='871' end='1020' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>At ClientDatanodeProtocolProtos.java:[lines 871-1020]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetReplicaVisibleLengthResponseProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetReplicaVisibleLengthResponseProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine endBytecode='61' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetReplicaVisibleLengthResponseProto$Builder' start='897' end='899' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetReplicaVisibleLengthResponseProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetReplicaVisibleLengthResponseProto$Builder' start='897' end='897' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java' startBytecode='3' primary='true'><Message>At ClientDatanodeProtocolProtos.java:[line 897]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='927a455b34a4fb4fe02687994efa2fc3' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetVolumeReportRequestProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetVolumeReportRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetVolumeReportRequestProto' start='6821' end='7148' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>At ClientDatanodeProtocolProtos.java:[lines 6821-7148]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetVolumeReportRequestProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetVolumeReportRequestProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetVolumeReportRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>In ClientDatanodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetVolumeReportRequestProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetVolumeReportRequestProto' start='6892' end='6892' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java' startBytecode='7' primary='true'><Message>At ClientDatanodeProtocolProtos.java:[line 6892]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='80bf26edfad775dd5ee2b543da34b827' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetVolumeReportRequestProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetVolumeReportRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetVolumeReportRequestProto' start='6821' end='7148' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>At ClientDatanodeProtocolProtos.java:[lines 6821-7148]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetVolumeReportRequestProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetVolumeReportRequestProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetVolumeReportRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>In ClientDatanodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetVolumeReportRequestProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetVolumeReportRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>In ClientDatanodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='f92b1ef5fc9cb264c8a4a77f2dc43dbb' rank='17' abbrev='UCF' category='STYLE' priority='2' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetVolumeReportRequestProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetVolumeReportRequestProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetVolumeReportRequestProto$Builder' start='7040' end='7139' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>At ClientDatanodeProtocolProtos.java:[lines 7040-7139]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetVolumeReportRequestProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetVolumeReportRequestProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine endBytecode='61' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetVolumeReportRequestProto$Builder' start='7066' end='7068' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetVolumeReportRequestProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetVolumeReportRequestProto$Builder' start='7066' end='7066' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java' startBytecode='3' primary='true'><Message>At ClientDatanodeProtocolProtos.java:[line 7066]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='b5a9099aeefd1c51c23eb40d507de1c8' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetVolumeReportResponseProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetVolumeReportResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetVolumeReportResponseProto' start='7184' end='7869' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>At ClientDatanodeProtocolProtos.java:[lines 7184-7869]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetVolumeReportResponseProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetVolumeReportResponseProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetVolumeReportResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>In ClientDatanodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetVolumeReportResponseProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetVolumeReportResponseProto' start='7267' end='7267' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java' startBytecode='7' primary='true'><Message>At ClientDatanodeProtocolProtos.java:[line 7267]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='f3bd6d4f4f8c6597a11a2fa6c546e93f' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetVolumeReportResponseProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetVolumeReportResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetVolumeReportResponseProto' start='7184' end='7869' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>At ClientDatanodeProtocolProtos.java:[lines 7184-7869]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetVolumeReportResponseProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetVolumeReportResponseProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetVolumeReportResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>In ClientDatanodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetVolumeReportResponseProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetVolumeReportResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>In ClientDatanodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='4c8b2503a735a38f5671d51912426545' cweid='563' rank='20' abbrev='DLS' category='STYLE' priority='3' type='DLS_DEAD_LOCAL_STORE' instanceOccurrenceMax='0'><ShortMessage>Dead store to local variable</ShortMessage><LongMessage>Dead store to from_bitField0_ in org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetVolumeReportResponseProto$Builder.buildPartial()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetVolumeReportResponseProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetVolumeReportResponseProto$Builder' start='7471' end='7860' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>At ClientDatanodeProtocolProtos.java:[lines 7471-7860]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetVolumeReportResponseProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetVolumeReportResponseProto$Builder' signature='()Lorg/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos$GetVolumeReportResponseProto;' name='buildPartial' primary='true'><SourceLine endBytecode='44' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetVolumeReportResponseProto$Builder' start='7538' end='7550' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetVolumeReportResponseProto$Builder.buildPartial()</Message></Method><LocalVariable role='LOCAL_VARIABLE_NAMED' pc='15' name='from_bitField0_' register='2'><Message>Local variable named from_bitField0_</Message></LocalVariable><SourceLine endBytecode='14' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetVolumeReportResponseProto$Builder' start='7539' end='7539' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java' startBytecode='14' primary='true'><Message>At ClientDatanodeProtocolProtos.java:[line 7539]</Message></SourceLine><Property name='edu.umd.cs.findbugs.detect.DeadLocalStoreProperty.BASE_VALUE' value='true'></Property><Property name='edu.umd.cs.findbugs.detect.DeadLocalStoreProperty.CACHING_VALUE' value='true'></Property><Property name='edu.umd.cs.findbugs.detect.DeadLocalStoreProperty.LOCAL_NAME' value='from_bitField0_'></Property><Property name='edu.umd.cs.findbugs.detect.DeadLocalStoreProperty.NO_LOADS' value='true'></Property></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='d4c47091082cadffeb7f3d828062d227' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$QueryPlanStatusRequestProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$QueryPlanStatusRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$QueryPlanStatusRequestProto' start='11945' end='12279' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>At ClientDatanodeProtocolProtos.java:[lines 11945-12279]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$QueryPlanStatusRequestProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$QueryPlanStatusRequestProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$QueryPlanStatusRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>In ClientDatanodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$QueryPlanStatusRequestProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$QueryPlanStatusRequestProto' start='12016' end='12016' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java' startBytecode='7' primary='true'><Message>At ClientDatanodeProtocolProtos.java:[line 12016]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='138f959a9b496c717ca1d3488966c875' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$QueryPlanStatusRequestProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$QueryPlanStatusRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$QueryPlanStatusRequestProto' start='11945' end='12279' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>At ClientDatanodeProtocolProtos.java:[lines 11945-12279]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$QueryPlanStatusRequestProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$QueryPlanStatusRequestProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$QueryPlanStatusRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>In ClientDatanodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$QueryPlanStatusRequestProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$QueryPlanStatusRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>In ClientDatanodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='fc463a9de2caec7f1b33f07e30c63dfd' rank='17' abbrev='UCF' category='STYLE' priority='2' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$QueryPlanStatusRequestProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$QueryPlanStatusRequestProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$QueryPlanStatusRequestProto$Builder' start='12171' end='12270' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>At ClientDatanodeProtocolProtos.java:[lines 12171-12270]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$QueryPlanStatusRequestProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$QueryPlanStatusRequestProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine endBytecode='61' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$QueryPlanStatusRequestProto$Builder' start='12197' end='12199' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$QueryPlanStatusRequestProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$QueryPlanStatusRequestProto$Builder' start='12197' end='12197' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java' startBytecode='3' primary='true'><Message>At ClientDatanodeProtocolProtos.java:[line 12197]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='e1df73d725ec8a5e0dfcbcb6d5f82a78' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$QueryPlanStatusResponseProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$QueryPlanStatusResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$QueryPlanStatusResponseProto' start='12350' end='13218' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>At ClientDatanodeProtocolProtos.java:[lines 12350-13218]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$QueryPlanStatusResponseProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$QueryPlanStatusResponseProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$QueryPlanStatusResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>In ClientDatanodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$QueryPlanStatusResponseProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$QueryPlanStatusResponseProto' start='12442' end='12442' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java' startBytecode='7' primary='true'><Message>At ClientDatanodeProtocolProtos.java:[line 12442]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='e905ef2a88de4931a23b90aec776c9af' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$QueryPlanStatusResponseProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$QueryPlanStatusResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$QueryPlanStatusResponseProto' start='12350' end='13218' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>At ClientDatanodeProtocolProtos.java:[lines 12350-13218]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$QueryPlanStatusResponseProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$QueryPlanStatusResponseProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$QueryPlanStatusResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>In ClientDatanodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$QueryPlanStatusResponseProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$QueryPlanStatusResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>In ClientDatanodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='b39c962c38285a795a305e62ee1ebe63' rank='17' abbrev='UCF' category='STYLE' priority='2' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$QueryPlanStatusResponseProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$QueryPlanStatusResponseProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$QueryPlanStatusResponseProto$Builder' start='12809' end='13209' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>At ClientDatanodeProtocolProtos.java:[lines 12809-13209]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$QueryPlanStatusResponseProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$QueryPlanStatusResponseProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine endBytecode='61' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$QueryPlanStatusResponseProto$Builder' start='12835' end='12837' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$QueryPlanStatusResponseProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$QueryPlanStatusResponseProto$Builder' start='12835' end='12835' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java' startBytecode='3' primary='true'><Message>At ClientDatanodeProtocolProtos.java:[line 12835]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='7eb4651f5b471a8fb0ee7614cfa06e91' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$RefreshNamenodesRequestProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$RefreshNamenodesRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$RefreshNamenodesRequestProto' start='1045' end='1377' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>At ClientDatanodeProtocolProtos.java:[lines 1045-1377]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$RefreshNamenodesRequestProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$RefreshNamenodesRequestProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$RefreshNamenodesRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>In ClientDatanodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$RefreshNamenodesRequestProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$RefreshNamenodesRequestProto' start='1116' end='1116' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java' startBytecode='7' primary='true'><Message>At ClientDatanodeProtocolProtos.java:[line 1116]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='ecdeb06da10fca7666d07eccaef7e10a' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$RefreshNamenodesRequestProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$RefreshNamenodesRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$RefreshNamenodesRequestProto' start='1045' end='1377' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>At ClientDatanodeProtocolProtos.java:[lines 1045-1377]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$RefreshNamenodesRequestProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$RefreshNamenodesRequestProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$RefreshNamenodesRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>In ClientDatanodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$RefreshNamenodesRequestProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$RefreshNamenodesRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>In ClientDatanodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='459b72343124048711e5e2337ec7b1f2' rank='17' abbrev='UCF' category='STYLE' priority='2' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$RefreshNamenodesRequestProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$RefreshNamenodesRequestProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$RefreshNamenodesRequestProto$Builder' start='1269' end='1368' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>At ClientDatanodeProtocolProtos.java:[lines 1269-1368]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$RefreshNamenodesRequestProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$RefreshNamenodesRequestProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine endBytecode='61' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$RefreshNamenodesRequestProto$Builder' start='1295' end='1297' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$RefreshNamenodesRequestProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$RefreshNamenodesRequestProto$Builder' start='1295' end='1295' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java' startBytecode='3' primary='true'><Message>At ClientDatanodeProtocolProtos.java:[line 1295]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='432993bbcfd47a7c1ec71ad6678f1262' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$RefreshNamenodesResponseProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$RefreshNamenodesResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$RefreshNamenodesResponseProto' start='1393' end='1725' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>At ClientDatanodeProtocolProtos.java:[lines 1393-1725]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$RefreshNamenodesResponseProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$RefreshNamenodesResponseProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$RefreshNamenodesResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>In ClientDatanodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$RefreshNamenodesResponseProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$RefreshNamenodesResponseProto' start='1464' end='1464' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java' startBytecode='7' primary='true'><Message>At ClientDatanodeProtocolProtos.java:[line 1464]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='7dbbf942858758596325b296c1a227da' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$RefreshNamenodesResponseProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$RefreshNamenodesResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$RefreshNamenodesResponseProto' start='1393' end='1725' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>At ClientDatanodeProtocolProtos.java:[lines 1393-1725]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$RefreshNamenodesResponseProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$RefreshNamenodesResponseProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$RefreshNamenodesResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>In ClientDatanodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$RefreshNamenodesResponseProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$RefreshNamenodesResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>In ClientDatanodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='f10bc005270e14e157eefc15c1de1eb0' rank='17' abbrev='UCF' category='STYLE' priority='2' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$RefreshNamenodesResponseProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$RefreshNamenodesResponseProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$RefreshNamenodesResponseProto$Builder' start='1617' end='1716' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>At ClientDatanodeProtocolProtos.java:[lines 1617-1716]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$RefreshNamenodesResponseProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$RefreshNamenodesResponseProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine endBytecode='61' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$RefreshNamenodesResponseProto$Builder' start='1643' end='1645' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$RefreshNamenodesResponseProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$RefreshNamenodesResponseProto$Builder' start='1643' end='1643' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java' startBytecode='3' primary='true'><Message>At ClientDatanodeProtocolProtos.java:[line 1643]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='f31a39113d4f51a40f83e682692efa24' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ShutdownDatanodeRequestProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ShutdownDatanodeRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ShutdownDatanodeRequestProto' start='4451' end='4879' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>At ClientDatanodeProtocolProtos.java:[lines 4451-4879]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ShutdownDatanodeRequestProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ShutdownDatanodeRequestProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ShutdownDatanodeRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>In ClientDatanodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ShutdownDatanodeRequestProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ShutdownDatanodeRequestProto' start='4528' end='4528' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java' startBytecode='7' primary='true'><Message>At ClientDatanodeProtocolProtos.java:[line 4528]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='251471c7249d287f07230e053479347d' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ShutdownDatanodeRequestProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ShutdownDatanodeRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ShutdownDatanodeRequestProto' start='4451' end='4879' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>At ClientDatanodeProtocolProtos.java:[lines 4451-4879]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ShutdownDatanodeRequestProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ShutdownDatanodeRequestProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ShutdownDatanodeRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>In ClientDatanodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ShutdownDatanodeRequestProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ShutdownDatanodeRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>In ClientDatanodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='358f93e17512cfddc07fcea34a5f12af' rank='17' abbrev='UCF' category='STYLE' priority='2' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ShutdownDatanodeRequestProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ShutdownDatanodeRequestProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ShutdownDatanodeRequestProto$Builder' start='4721' end='4870' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>At ClientDatanodeProtocolProtos.java:[lines 4721-4870]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ShutdownDatanodeRequestProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ShutdownDatanodeRequestProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine endBytecode='61' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ShutdownDatanodeRequestProto$Builder' start='4747' end='4749' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ShutdownDatanodeRequestProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ShutdownDatanodeRequestProto$Builder' start='4747' end='4747' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java' startBytecode='3' primary='true'><Message>At ClientDatanodeProtocolProtos.java:[line 4747]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='b496ef13e33fb779404c2e4b26a3defb' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ShutdownDatanodeResponseProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ShutdownDatanodeResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ShutdownDatanodeResponseProto' start='4890' end='5217' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>At ClientDatanodeProtocolProtos.java:[lines 4890-5217]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ShutdownDatanodeResponseProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ShutdownDatanodeResponseProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ShutdownDatanodeResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>In ClientDatanodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ShutdownDatanodeResponseProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ShutdownDatanodeResponseProto' start='4961' end='4961' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java' startBytecode='7' primary='true'><Message>At ClientDatanodeProtocolProtos.java:[line 4961]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='13f23acbc015b454e0ac5694048c7e5a' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ShutdownDatanodeResponseProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ShutdownDatanodeResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ShutdownDatanodeResponseProto' start='4890' end='5217' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>At ClientDatanodeProtocolProtos.java:[lines 4890-5217]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ShutdownDatanodeResponseProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ShutdownDatanodeResponseProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ShutdownDatanodeResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>In ClientDatanodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ShutdownDatanodeResponseProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ShutdownDatanodeResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>In ClientDatanodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='6c2f2c3214495e211ab73a6c5aade457' rank='17' abbrev='UCF' category='STYLE' priority='2' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ShutdownDatanodeResponseProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ShutdownDatanodeResponseProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ShutdownDatanodeResponseProto$Builder' start='5109' end='5208' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>At ClientDatanodeProtocolProtos.java:[lines 5109-5208]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ShutdownDatanodeResponseProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ShutdownDatanodeResponseProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine endBytecode='61' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ShutdownDatanodeResponseProto$Builder' start='5135' end='5137' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ShutdownDatanodeResponseProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ShutdownDatanodeResponseProto$Builder' start='5135' end='5135' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java' startBytecode='3' primary='true'><Message>At ClientDatanodeProtocolProtos.java:[line 5135]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='52763ad4da336c35d3b2f7c6505a74a3' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$SubmitDiskBalancerPlanRequestProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$SubmitDiskBalancerPlanRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$SubmitDiskBalancerPlanRequestProto' start='9573' end='10702' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>At ClientDatanodeProtocolProtos.java:[lines 9573-10702]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$SubmitDiskBalancerPlanRequestProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$SubmitDiskBalancerPlanRequestProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$SubmitDiskBalancerPlanRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>In ClientDatanodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$SubmitDiskBalancerPlanRequestProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$SubmitDiskBalancerPlanRequestProto' start='9670' end='9670' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java' startBytecode='7' primary='true'><Message>At ClientDatanodeProtocolProtos.java:[line 9670]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='d8fa96ea4d0fad4900dc0724822bd443' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$SubmitDiskBalancerPlanRequestProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$SubmitDiskBalancerPlanRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$SubmitDiskBalancerPlanRequestProto' start='9573' end='10702' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>At ClientDatanodeProtocolProtos.java:[lines 9573-10702]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$SubmitDiskBalancerPlanRequestProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$SubmitDiskBalancerPlanRequestProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$SubmitDiskBalancerPlanRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>In ClientDatanodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$SubmitDiskBalancerPlanRequestProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$SubmitDiskBalancerPlanRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>In ClientDatanodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='df42f093ffab45b9eb9856f006772c5b' rank='17' abbrev='UCF' category='STYLE' priority='2' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$SubmitDiskBalancerPlanRequestProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$SubmitDiskBalancerPlanRequestProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$SubmitDiskBalancerPlanRequestProto$Builder' start='10135' end='10693' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>At ClientDatanodeProtocolProtos.java:[lines 10135-10693]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$SubmitDiskBalancerPlanRequestProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$SubmitDiskBalancerPlanRequestProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine endBytecode='61' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$SubmitDiskBalancerPlanRequestProto$Builder' start='10161' end='10163' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$SubmitDiskBalancerPlanRequestProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$SubmitDiskBalancerPlanRequestProto$Builder' start='10161' end='10161' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java' startBytecode='3' primary='true'><Message>At ClientDatanodeProtocolProtos.java:[line 10161]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='9666538316563d3129f7011bfb4b3644' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$SubmitDiskBalancerPlanResponseProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$SubmitDiskBalancerPlanResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$SubmitDiskBalancerPlanResponseProto' start='10718' end='11050' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>At ClientDatanodeProtocolProtos.java:[lines 10718-11050]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$SubmitDiskBalancerPlanResponseProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$SubmitDiskBalancerPlanResponseProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$SubmitDiskBalancerPlanResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>In ClientDatanodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$SubmitDiskBalancerPlanResponseProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$SubmitDiskBalancerPlanResponseProto' start='10789' end='10789' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java' startBytecode='7' primary='true'><Message>At ClientDatanodeProtocolProtos.java:[line 10789]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='a9aff9a51e7d2f43430e397222436d9' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$SubmitDiskBalancerPlanResponseProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$SubmitDiskBalancerPlanResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$SubmitDiskBalancerPlanResponseProto' start='10718' end='11050' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>At ClientDatanodeProtocolProtos.java:[lines 10718-11050]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$SubmitDiskBalancerPlanResponseProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$SubmitDiskBalancerPlanResponseProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$SubmitDiskBalancerPlanResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>In ClientDatanodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$SubmitDiskBalancerPlanResponseProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$SubmitDiskBalancerPlanResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>In ClientDatanodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='1849d0eb73a81cadf2c9c991d0d5ce00' rank='17' abbrev='UCF' category='STYLE' priority='2' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$SubmitDiskBalancerPlanResponseProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$SubmitDiskBalancerPlanResponseProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$SubmitDiskBalancerPlanResponseProto$Builder' start='10942' end='11041' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>At ClientDatanodeProtocolProtos.java:[lines 10942-11041]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$SubmitDiskBalancerPlanResponseProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$SubmitDiskBalancerPlanResponseProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine endBytecode='61' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$SubmitDiskBalancerPlanResponseProto$Builder' start='10968' end='10970' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$SubmitDiskBalancerPlanResponseProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$SubmitDiskBalancerPlanResponseProto$Builder' start='10968' end='10968' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java' startBytecode='3' primary='true'><Message>At ClientDatanodeProtocolProtos.java:[line 10968]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='26a4349e4a9ee252890cd5441c438353' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$TriggerBlockReportRequestProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$TriggerBlockReportRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$TriggerBlockReportRequestProto' start='7890' end='8311' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>At ClientDatanodeProtocolProtos.java:[lines 7890-8311]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$TriggerBlockReportRequestProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$TriggerBlockReportRequestProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$TriggerBlockReportRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>In ClientDatanodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$TriggerBlockReportRequestProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$TriggerBlockReportRequestProto' start='7967' end='7967' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java' startBytecode='7' primary='true'><Message>At ClientDatanodeProtocolProtos.java:[line 7967]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='edb62e138821999f7f83a44432bb0d19' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$TriggerBlockReportRequestProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$TriggerBlockReportRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$TriggerBlockReportRequestProto' start='7890' end='8311' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>At ClientDatanodeProtocolProtos.java:[lines 7890-8311]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$TriggerBlockReportRequestProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$TriggerBlockReportRequestProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$TriggerBlockReportRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>In ClientDatanodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$TriggerBlockReportRequestProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$TriggerBlockReportRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>In ClientDatanodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='97616663a65675bc99a8f89a4d5628f4' rank='17' abbrev='UCF' category='STYLE' priority='2' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$TriggerBlockReportRequestProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$TriggerBlockReportRequestProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$TriggerBlockReportRequestProto$Builder' start='8153' end='8302' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>At ClientDatanodeProtocolProtos.java:[lines 8153-8302]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$TriggerBlockReportRequestProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$TriggerBlockReportRequestProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine endBytecode='61' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$TriggerBlockReportRequestProto$Builder' start='8179' end='8181' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$TriggerBlockReportRequestProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$TriggerBlockReportRequestProto$Builder' start='8179' end='8179' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java' startBytecode='3' primary='true'><Message>At ClientDatanodeProtocolProtos.java:[line 8179]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='8e7a392d5cb3c913bf75b278f84740a1' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$TriggerBlockReportResponseProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$TriggerBlockReportResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$TriggerBlockReportResponseProto' start='8322' end='8649' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>At ClientDatanodeProtocolProtos.java:[lines 8322-8649]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$TriggerBlockReportResponseProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$TriggerBlockReportResponseProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$TriggerBlockReportResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>In ClientDatanodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$TriggerBlockReportResponseProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$TriggerBlockReportResponseProto' start='8393' end='8393' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java' startBytecode='7' primary='true'><Message>At ClientDatanodeProtocolProtos.java:[line 8393]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='700c7db7d5017d6bf556fc272edcdcbe' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$TriggerBlockReportResponseProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$TriggerBlockReportResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$TriggerBlockReportResponseProto' start='8322' end='8649' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>At ClientDatanodeProtocolProtos.java:[lines 8322-8649]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$TriggerBlockReportResponseProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$TriggerBlockReportResponseProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$TriggerBlockReportResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>In ClientDatanodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$TriggerBlockReportResponseProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$TriggerBlockReportResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>In ClientDatanodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='259c9b886eb990833b780c0a3160d17d' rank='17' abbrev='UCF' category='STYLE' priority='2' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$TriggerBlockReportResponseProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$TriggerBlockReportResponseProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$TriggerBlockReportResponseProto$Builder' start='8541' end='8640' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java'><Message>At ClientDatanodeProtocolProtos.java:[lines 8541-8640]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$TriggerBlockReportResponseProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$TriggerBlockReportResponseProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine endBytecode='61' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$TriggerBlockReportResponseProto$Builder' start='8567' end='8569' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$TriggerBlockReportResponseProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$TriggerBlockReportResponseProto$Builder' start='8567' end='8567' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' sourcefile='ClientDatanodeProtocolProtos.java' startBytecode='3' primary='true'><Message>At ClientDatanodeProtocolProtos.java:[line 8567]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='70eb04734a387ec606a0dbfbd708c0a4' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AbandonBlockRequestProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AbandonBlockRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AbandonBlockRequestProto' start='14549' end='15505' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 14549-15505]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AbandonBlockRequestProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AbandonBlockRequestProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AbandonBlockRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AbandonBlockRequestProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AbandonBlockRequestProto' start='14649' end='14649' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='7' primary='true'><Message>At ClientNamenodeProtocolProtos.java:[line 14649]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='1ba6265b01d8d98a0bfea6bd5dab7bd0' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AbandonBlockRequestProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AbandonBlockRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AbandonBlockRequestProto' start='14549' end='15505' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 14549-15505]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AbandonBlockRequestProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AbandonBlockRequestProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AbandonBlockRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AbandonBlockRequestProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AbandonBlockRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='625a11a60c26375142ed0cfb88230189' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AbandonBlockResponseProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AbandonBlockResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AbandonBlockResponseProto' start='15520' end='15851' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 15520-15851]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AbandonBlockResponseProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AbandonBlockResponseProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AbandonBlockResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AbandonBlockResponseProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AbandonBlockResponseProto' start='15591' end='15591' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='7' primary='true'><Message>At ClientNamenodeProtocolProtos.java:[line 15591]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='ff00f40adc8d0b35ac6f31c7800fd936' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AbandonBlockResponseProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AbandonBlockResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AbandonBlockResponseProto' start='15520' end='15851' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 15520-15851]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AbandonBlockResponseProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AbandonBlockResponseProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AbandonBlockResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AbandonBlockResponseProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AbandonBlockResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='b5cc1cf29320d5bbefa783b0a3e2d148' rank='17' abbrev='UCF' category='STYLE' priority='2' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AbandonBlockResponseProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AbandonBlockResponseProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AbandonBlockResponseProto$Builder' start='15743' end='15842' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 15743-15842]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AbandonBlockResponseProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AbandonBlockResponseProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine endBytecode='61' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AbandonBlockResponseProto$Builder' start='15769' end='15771' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AbandonBlockResponseProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AbandonBlockResponseProto$Builder' start='15769' end='15769' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='3' primary='true'><Message>At ClientNamenodeProtocolProtos.java:[line 15769]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='4d6d71976cd0b05c97bea282cd74ed92' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AddBlockRequestProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AddBlockRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AddBlockRequestProto' start='16011' end='17747' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 16011-17747]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AddBlockRequestProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AddBlockRequestProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AddBlockRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AddBlockRequestProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AddBlockRequestProto' start='16169' end='16169' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='7' primary='true'><Message>At ClientNamenodeProtocolProtos.java:[line 16169]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='7e23b686b02159cfcc913d321e55e1f0' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AddBlockRequestProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AddBlockRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AddBlockRequestProto' start='16011' end='17747' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 16011-17747]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AddBlockRequestProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AddBlockRequestProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AddBlockRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AddBlockRequestProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AddBlockRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='797541b57430f44e15009ad2f06b1275' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AddBlockResponseProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AddBlockResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AddBlockResponseProto' start='17772' end='18308' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 17772-18308]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AddBlockResponseProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AddBlockResponseProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AddBlockResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AddBlockResponseProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AddBlockResponseProto' start='17857' end='17857' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='7' primary='true'><Message>At ClientNamenodeProtocolProtos.java:[line 17857]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='ac2951a17324af1c0905462d97594f1d' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AddBlockResponseProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AddBlockResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AddBlockResponseProto' start='17772' end='18308' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 17772-18308]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AddBlockResponseProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AddBlockResponseProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AddBlockResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AddBlockResponseProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AddBlockResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='a105d47c268bb50f85f3d15703da05ac' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AddCacheDirectiveRequestProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AddCacheDirectiveRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AddCacheDirectiveRequestProto' start='61665' end='62305' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 61665-62305]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AddCacheDirectiveRequestProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AddCacheDirectiveRequestProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AddCacheDirectiveRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AddCacheDirectiveRequestProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AddCacheDirectiveRequestProto' start='61755' end='61755' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='7' primary='true'><Message>At ClientNamenodeProtocolProtos.java:[line 61755]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='e0c01ed71406a648def093961b43d0ee' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AddCacheDirectiveRequestProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AddCacheDirectiveRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AddCacheDirectiveRequestProto' start='61665' end='62305' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 61665-62305]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AddCacheDirectiveRequestProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AddCacheDirectiveRequestProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AddCacheDirectiveRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AddCacheDirectiveRequestProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AddCacheDirectiveRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='67621ec273ebe94982dbdbdf5407a065' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AddCacheDirectiveResponseProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AddCacheDirectiveResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AddCacheDirectiveResponseProto' start='62326' end='62747' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 62326-62747]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AddCacheDirectiveResponseProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AddCacheDirectiveResponseProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AddCacheDirectiveResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AddCacheDirectiveResponseProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AddCacheDirectiveResponseProto' start='62403' end='62403' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='7' primary='true'><Message>At ClientNamenodeProtocolProtos.java:[line 62403]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='f94cecccc20a8365300681ec7899096d' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AddCacheDirectiveResponseProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AddCacheDirectiveResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AddCacheDirectiveResponseProto' start='62326' end='62747' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 62326-62747]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AddCacheDirectiveResponseProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AddCacheDirectiveResponseProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AddCacheDirectiveResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AddCacheDirectiveResponseProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AddCacheDirectiveResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='219d24ef8378fa52a4a61394e9b33f9d' rank='17' abbrev='UCF' category='STYLE' priority='2' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AddCacheDirectiveResponseProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AddCacheDirectiveResponseProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AddCacheDirectiveResponseProto$Builder' start='62589' end='62738' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 62589-62738]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AddCacheDirectiveResponseProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AddCacheDirectiveResponseProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine endBytecode='61' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AddCacheDirectiveResponseProto$Builder' start='62615' end='62617' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AddCacheDirectiveResponseProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AddCacheDirectiveResponseProto$Builder' start='62615' end='62615' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='3' primary='true'><Message>At ClientNamenodeProtocolProtos.java:[line 62615]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='259cd092adada107964f1b5c4237e0ba' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AddCachePoolRequestProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AddCachePoolRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AddCachePoolRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AddCachePoolRequestProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AddCachePoolRequestProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AddCachePoolRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AddCachePoolRequestProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AddCachePoolRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='7'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='ad13a1617f0606e6646dc381a4a6b368' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AddCachePoolRequestProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AddCachePoolRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AddCachePoolRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AddCachePoolRequestProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AddCachePoolRequestProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AddCachePoolRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AddCachePoolRequestProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AddCachePoolRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='cfd7994e66851191fb0bf82df89c6bc1' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AddCachePoolResponseProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AddCachePoolResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AddCachePoolResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AddCachePoolResponseProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AddCachePoolResponseProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AddCachePoolResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AddCachePoolResponseProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AddCachePoolResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='7'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='253325492789787ef109d18b461e1638' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AddCachePoolResponseProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AddCachePoolResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AddCachePoolResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AddCachePoolResponseProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AddCachePoolResponseProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AddCachePoolResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AddCachePoolResponseProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AddCachePoolResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='f73a073db0e6c7e80fd68baa6f0c5bd5' rank='20' abbrev='UCF' category='STYLE' priority='3' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AddCachePoolResponseProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AddCachePoolResponseProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AddCachePoolResponseProto$Builder' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AddCachePoolResponseProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AddCachePoolResponseProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AddCachePoolResponseProto$Builder' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AddCachePoolResponseProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AddCachePoolResponseProto$Builder' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='3'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='f40e1cc4a8fef8746075bd55578d5966' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AllowSnapshotRequestProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AllowSnapshotRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AllowSnapshotRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AllowSnapshotRequestProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AllowSnapshotRequestProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AllowSnapshotRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AllowSnapshotRequestProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AllowSnapshotRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='7'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='1c547ecc600279e873d81aa07d200fae' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AllowSnapshotRequestProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AllowSnapshotRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AllowSnapshotRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AllowSnapshotRequestProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AllowSnapshotRequestProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AllowSnapshotRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AllowSnapshotRequestProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AllowSnapshotRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='ed367fa8da26ad2859003327cdbf3054' rank='20' abbrev='UCF' category='STYLE' priority='3' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AllowSnapshotRequestProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AllowSnapshotRequestProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AllowSnapshotRequestProto$Builder' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AllowSnapshotRequestProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AllowSnapshotRequestProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AllowSnapshotRequestProto$Builder' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AllowSnapshotRequestProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AllowSnapshotRequestProto$Builder' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='3'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='54655955aee0c04beea4ae389d9be973' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AllowSnapshotResponseProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AllowSnapshotResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AllowSnapshotResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AllowSnapshotResponseProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AllowSnapshotResponseProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AllowSnapshotResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AllowSnapshotResponseProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AllowSnapshotResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='7'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='667e5b9dcd51f824c943a6d7f0095e18' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AllowSnapshotResponseProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AllowSnapshotResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AllowSnapshotResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AllowSnapshotResponseProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AllowSnapshotResponseProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AllowSnapshotResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AllowSnapshotResponseProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AllowSnapshotResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='e8c90a16291b89424ebf29420fe10999' rank='20' abbrev='UCF' category='STYLE' priority='3' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AllowSnapshotResponseProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AllowSnapshotResponseProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AllowSnapshotResponseProto$Builder' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AllowSnapshotResponseProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AllowSnapshotResponseProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AllowSnapshotResponseProto$Builder' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AllowSnapshotResponseProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AllowSnapshotResponseProto$Builder' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='3'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='dc33f7d5129fadd8cf10294873039d38' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AppendRequestProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AppendRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AppendRequestProto' start='5555' end='6308' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 5555-6308]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AppendRequestProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AppendRequestProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AppendRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AppendRequestProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AppendRequestProto' start='5642' end='5642' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='7' primary='true'><Message>At ClientNamenodeProtocolProtos.java:[line 5642]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='284e11c161599cb724185991bba0ff92' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AppendRequestProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AppendRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AppendRequestProto' start='5555' end='6308' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 5555-6308]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AppendRequestProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AppendRequestProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AppendRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AppendRequestProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AppendRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='ac19013a5393caa93114b13f113a2ef2' rank='17' abbrev='UCF' category='STYLE' priority='2' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AppendRequestProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AppendRequestProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AppendRequestProto$Builder' start='5960' end='6299' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 5960-6299]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AppendRequestProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AppendRequestProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine endBytecode='61' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AppendRequestProto$Builder' start='5986' end='5988' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AppendRequestProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AppendRequestProto$Builder' start='5986' end='5986' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='3' primary='true'><Message>At ClientNamenodeProtocolProtos.java:[line 5986]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='607dda934c54ad680d47cbb4641c11b4' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AppendResponseProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AppendResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AppendResponseProto' start='6347' end='7078' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 6347-7078]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AppendResponseProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AppendResponseProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AppendResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AppendResponseProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AppendResponseProto' start='6445' end='6445' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='7' primary='true'><Message>At ClientNamenodeProtocolProtos.java:[line 6445]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='1c02319614a441c68afd5a91f8e18f51' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AppendResponseProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AppendResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AppendResponseProto' start='6347' end='7078' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 6347-7078]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AppendResponseProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AppendResponseProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AppendResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AppendResponseProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AppendResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='e8a5c0b3b24e421c60eea021c5f47d31' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CacheDirectiveEntryProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CacheDirectiveEntryProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CacheDirectiveEntryProto' start='65246' end='65531' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 65246-65531]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CacheDirectiveEntryProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CacheDirectiveEntryProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CacheDirectiveEntryProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CacheDirectiveEntryProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CacheDirectiveEntryProto' start='65344' end='65344' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='7' primary='true'><Message>At ClientNamenodeProtocolProtos.java:[line 65344]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='e37a416b63ef3fa62f76b0cd3edb080' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CacheDirectiveEntryProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CacheDirectiveEntryProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CacheDirectiveEntryProto' start='65246' end='65531' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 65246-65531]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CacheDirectiveEntryProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CacheDirectiveEntryProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CacheDirectiveEntryProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CacheDirectiveEntryProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CacheDirectiveEntryProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='31b3272662dc52a3c00f53b5bf5e6ba6' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CacheDirectiveInfoExpirationProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CacheDirectiveInfoExpirationProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CacheDirectiveInfoExpirationProto' start='60279' end='60788' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 60279-60788]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CacheDirectiveInfoExpirationProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CacheDirectiveInfoExpirationProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CacheDirectiveInfoExpirationProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CacheDirectiveInfoExpirationProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CacheDirectiveInfoExpirationProto' start='60361' end='60361' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='7' primary='true'><Message>At ClientNamenodeProtocolProtos.java:[line 60361]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='fbfd9e46c4fafa218a1fd265660ef351' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CacheDirectiveInfoExpirationProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CacheDirectiveInfoExpirationProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CacheDirectiveInfoExpirationProto' start='60279' end='60788' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 60279-60788]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CacheDirectiveInfoExpirationProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CacheDirectiveInfoExpirationProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CacheDirectiveInfoExpirationProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CacheDirectiveInfoExpirationProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CacheDirectiveInfoExpirationProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='bb47380975b5c7753a334b5a6a0e7c6e' rank='17' abbrev='UCF' category='STYLE' priority='2' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CacheDirectiveInfoExpirationProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CacheDirectiveInfoExpirationProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CacheDirectiveInfoExpirationProto$Builder' start='60584' end='60779' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 60584-60779]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CacheDirectiveInfoExpirationProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CacheDirectiveInfoExpirationProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine endBytecode='61' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CacheDirectiveInfoExpirationProto$Builder' start='60610' end='60612' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CacheDirectiveInfoExpirationProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CacheDirectiveInfoExpirationProto$Builder' start='60610' end='60610' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='3' primary='true'><Message>At ClientNamenodeProtocolProtos.java:[line 60610]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='a568a346077de7b9d026e20c4ff9c954' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CacheDirectiveInfoProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CacheDirectiveInfoProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CacheDirectiveInfoProto' start='59256' end='60248' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 59256-60248]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CacheDirectiveInfoProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CacheDirectiveInfoProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CacheDirectiveInfoProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CacheDirectiveInfoProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CacheDirectiveInfoProto' start='59361' end='59361' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='7' primary='true'><Message>At ClientNamenodeProtocolProtos.java:[line 59361]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='b411b74292f6066881474b7aa9d9425b' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CacheDirectiveInfoProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CacheDirectiveInfoProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CacheDirectiveInfoProto' start='59256' end='60248' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 59256-60248]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CacheDirectiveInfoProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CacheDirectiveInfoProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CacheDirectiveInfoProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CacheDirectiveInfoProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CacheDirectiveInfoProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='e0d4f47ca92e15c06b0cb2dd8d369587' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CacheDirectiveStatsProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CacheDirectiveStatsProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CacheDirectiveStatsProto' start='60849' end='61622' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 60849-61622]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CacheDirectiveStatsProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CacheDirectiveStatsProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CacheDirectiveStatsProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CacheDirectiveStatsProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CacheDirectiveStatsProto' start='60946' end='60946' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='7' primary='true'><Message>At ClientNamenodeProtocolProtos.java:[line 60946]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='bcdead1208220ab153331976290a8aa0' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CacheDirectiveStatsProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CacheDirectiveStatsProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CacheDirectiveStatsProto' start='60849' end='61622' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 60849-61622]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CacheDirectiveStatsProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CacheDirectiveStatsProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CacheDirectiveStatsProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CacheDirectiveStatsProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CacheDirectiveStatsProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='9106c27a5a9e0b8d16c0bd864b915057' rank='17' abbrev='UCF' category='STYLE' priority='2' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CacheDirectiveStatsProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CacheDirectiveStatsProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CacheDirectiveStatsProto$Builder' start='61280' end='61613' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 61280-61613]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CacheDirectiveStatsProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CacheDirectiveStatsProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine endBytecode='61' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CacheDirectiveStatsProto$Builder' start='61306' end='61308' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CacheDirectiveStatsProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CacheDirectiveStatsProto$Builder' start='61306' end='61306' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='3' primary='true'><Message>At ClientNamenodeProtocolProtos.java:[line 61306]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='7d345abb75b271cd65c6f958ee53d78f' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CachePoolEntryProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CachePoolEntryProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CachePoolEntryProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CachePoolEntryProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CachePoolEntryProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CachePoolEntryProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CachePoolEntryProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CachePoolEntryProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='7'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='ff511dafccc0982122e6b456118f2324' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CachePoolEntryProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CachePoolEntryProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CachePoolEntryProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CachePoolEntryProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CachePoolEntryProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CachePoolEntryProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CachePoolEntryProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CachePoolEntryProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='5b1b7b81ea5a57ccce0bb8188e1bc720' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CachePoolInfoProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CachePoolInfoProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CachePoolInfoProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CachePoolInfoProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CachePoolInfoProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CachePoolInfoProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CachePoolInfoProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CachePoolInfoProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='7'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='6291b6f8576511a799525044e8426f1a' rank='19' abbrev='Nm' category='BAD_PRACTICE' priority='3' type='NM_CONFUSING' instanceOccurrenceMax='0'><ShortMessage>Confusing method names</ShortMessage><LongMessage>Confusing to have methods org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CachePoolInfoProto.getGroupNameBytes() and org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetOwnerRequestProto.getGroupnameBytes()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CachePoolInfoProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CachePoolInfoProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CachePoolInfoProto</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CachePoolInfoProto' signature='()Lcom/google/protobuf/ByteString;' name='getGroupNameBytes' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CachePoolInfoProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CachePoolInfoProto.getGroupNameBytes()</Message></Method><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetOwnerRequestProto'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetOwnerRequestProto' start='13339' end='14130' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 13339-14130]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetOwnerRequestProto</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetOwnerRequestProto' signature='()Lcom/google/protobuf/ByteString;' name='getGroupnameBytes'><SourceLine endBytecode='131' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetOwnerRequestProto' start='13559' end='13567' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetOwnerRequestProto.getGroupnameBytes()</Message></Method><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CachePoolInfoProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='f4a969f107d2940682b5aee27934fd09' rank='19' abbrev='Nm' category='BAD_PRACTICE' priority='3' type='NM_CONFUSING' instanceOccurrenceMax='0'><ShortMessage>Confusing method names</ShortMessage><LongMessage>Confusing to have methods org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CachePoolInfoProto.hasGroupName() and org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetOwnerRequestProto.hasGroupname()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CachePoolInfoProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CachePoolInfoProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CachePoolInfoProto</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CachePoolInfoProto' signature='()Z' name='hasGroupName' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CachePoolInfoProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CachePoolInfoProto.hasGroupName()</Message></Method><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetOwnerRequestProto'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetOwnerRequestProto' start='13339' end='14130' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 13339-14130]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetOwnerRequestProto</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetOwnerRequestProto' signature='()Z' name='hasGroupname'><SourceLine endBytecode='68' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetOwnerRequestProto' start='13535' end='13535' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetOwnerRequestProto.hasGroupname()</Message></Method><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CachePoolInfoProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='ddb45ef3da39d615fcbf23c3f0898dcc' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CachePoolInfoProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CachePoolInfoProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CachePoolInfoProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CachePoolInfoProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CachePoolInfoProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CachePoolInfoProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CachePoolInfoProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CachePoolInfoProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='57463674b7bfe18776faa09beab731db' rank='20' abbrev='UCF' category='STYLE' priority='3' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CachePoolInfoProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CachePoolInfoProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CachePoolInfoProto$Builder' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CachePoolInfoProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CachePoolInfoProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CachePoolInfoProto$Builder' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CachePoolInfoProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CachePoolInfoProto$Builder' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='3'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='daa98c575de3672de46b465526276c01' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CachePoolStatsProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CachePoolStatsProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CachePoolStatsProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CachePoolStatsProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CachePoolStatsProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CachePoolStatsProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CachePoolStatsProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CachePoolStatsProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='7'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='9ed4c272d73c047b9726b2df3c311898' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CachePoolStatsProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CachePoolStatsProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CachePoolStatsProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CachePoolStatsProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CachePoolStatsProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CachePoolStatsProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CachePoolStatsProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CachePoolStatsProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='284b26125ac0932f9bfb6b918e415908' rank='20' abbrev='UCF' category='STYLE' priority='3' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CachePoolStatsProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CachePoolStatsProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CachePoolStatsProto$Builder' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CachePoolStatsProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CachePoolStatsProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CachePoolStatsProto$Builder' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CachePoolStatsProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CachePoolStatsProto$Builder' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='3'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='fb92d9cb8d7d57eb00ed916e3d4188c' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CheckAccessRequestProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CheckAccessRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CheckAccessRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CheckAccessRequestProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CheckAccessRequestProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CheckAccessRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CheckAccessRequestProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CheckAccessRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='7'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='1a00e19adfcf6ac6ea1597e0f716803' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CheckAccessRequestProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CheckAccessRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CheckAccessRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CheckAccessRequestProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CheckAccessRequestProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CheckAccessRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CheckAccessRequestProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CheckAccessRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='936bfa881b1b9ccb926415cfac34a14e' rank='20' abbrev='UCF' category='STYLE' priority='3' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CheckAccessRequestProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CheckAccessRequestProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CheckAccessRequestProto$Builder' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CheckAccessRequestProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CheckAccessRequestProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CheckAccessRequestProto$Builder' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CheckAccessRequestProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CheckAccessRequestProto$Builder' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='3'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='93d507bc1600fc9909d706f022769585' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CheckAccessResponseProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CheckAccessResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CheckAccessResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CheckAccessResponseProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CheckAccessResponseProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CheckAccessResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CheckAccessResponseProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CheckAccessResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='7'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='9b5751e3bf40df640456624413a06be8' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CheckAccessResponseProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CheckAccessResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CheckAccessResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CheckAccessResponseProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CheckAccessResponseProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CheckAccessResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CheckAccessResponseProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CheckAccessResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='e004ec8fec9238e57b82a9530c06ed7e' rank='20' abbrev='UCF' category='STYLE' priority='3' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CheckAccessResponseProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CheckAccessResponseProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CheckAccessResponseProto$Builder' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CheckAccessResponseProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CheckAccessResponseProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CheckAccessResponseProto$Builder' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CheckAccessResponseProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CheckAccessResponseProto$Builder' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='3'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='49cf23cbb21754447781740382adda35' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.AclProtos$GetAclStatusRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/RpcCallback;)V' name='callMethod' primary='true'><SourceLine endBytecode='840' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/AclProtos$GetAclStatusRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$GetAclStatusRequestProto' start='8460' end='8951' sourcepath='org/apache/hadoop/hdfs/protocol/proto/AclProtos.java' sourcefile='AclProtos.java'><Message>At AclProtos.java:[lines 8460-8951]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.AclProtos$GetAclStatusRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='1639' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='1640' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='1640'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='3592885bb227602ed09997fc57741ed9' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.AclProtos$ModifyAclEntriesRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/RpcCallback;)V' name='callMethod' primary='true'><SourceLine endBytecode='840' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/AclProtos$ModifyAclEntriesRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$ModifyAclEntriesRequestProto' start='3070' end='3916' sourcepath='org/apache/hadoop/hdfs/protocol/proto/AclProtos.java' sourcefile='AclProtos.java'><Message>At AclProtos.java:[lines 3070-3916]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.AclProtos$ModifyAclEntriesRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='1564' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='1565' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='1565'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='3467d1b74b38630c0e7f57543b1eaed5' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveAclEntriesRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/RpcCallback;)V' name='callMethod' primary='true'><SourceLine endBytecode='840' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/AclProtos$RemoveAclEntriesRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveAclEntriesRequestProto' start='5160' end='6006' sourcepath='org/apache/hadoop/hdfs/protocol/proto/AclProtos.java' sourcefile='AclProtos.java'><Message>At AclProtos.java:[lines 5160-6006]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveAclEntriesRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='1579' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='1580' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='1580'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='5943ddf0294f2c34d2e74c297db042c6' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveAclRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/RpcCallback;)V' name='callMethod' primary='true'><SourceLine endBytecode='840' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/AclProtos$RemoveAclRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveAclRequestProto' start='4280' end='4771' sourcepath='org/apache/hadoop/hdfs/protocol/proto/AclProtos.java' sourcefile='AclProtos.java'><Message>At AclProtos.java:[lines 4280-4771]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveAclRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='1609' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='1610' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='1610'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='564cb1c6d207315351fe1dfe0a0963ce' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveDefaultAclRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/RpcCallback;)V' name='callMethod' primary='true'><SourceLine endBytecode='840' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/AclProtos$RemoveDefaultAclRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveDefaultAclRequestProto' start='6370' end='6861' sourcepath='org/apache/hadoop/hdfs/protocol/proto/AclProtos.java' sourcefile='AclProtos.java'><Message>At AclProtos.java:[lines 6370-6861]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveDefaultAclRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='1594' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='1595' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='1595'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='a66f60e40230a3bac29fec2e5cd78e01' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.AclProtos$SetAclRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/RpcCallback;)V' name='callMethod' primary='true'><SourceLine endBytecode='840' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/AclProtos$SetAclRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$SetAclRequestProto' start='7250' end='8096' sourcepath='org/apache/hadoop/hdfs/protocol/proto/AclProtos.java' sourcefile='AclProtos.java'><Message>At AclProtos.java:[lines 7250-8096]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.AclProtos$SetAclRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='1624' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='1625' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='1625'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='4a563d8c9e67c6f8e9a243b0b166ca53' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AbandonBlockRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/RpcCallback;)V' name='callMethod' primary='true'><SourceLine endBytecode='840' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$AbandonBlockRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AbandonBlockRequestProto' start='14549' end='15505' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 14549-15505]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AbandonBlockRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='619' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='620' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='620'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='dd30c9f5a1244686dffbb075465c326a' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AddBlockRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/RpcCallback;)V' name='callMethod' primary='true'><SourceLine endBytecode='840' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$AddBlockRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AddBlockRequestProto' start='16011' end='17747' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 16011-17747]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AddBlockRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='634' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='635' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='635'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='d626dcc54af47eb9fbebda58632d8e46' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AddCacheDirectiveRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/RpcCallback;)V' name='callMethod' primary='true'><SourceLine endBytecode='840' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$AddCacheDirectiveRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AddCacheDirectiveRequestProto' start='61665' end='62305' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 61665-62305]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AddCacheDirectiveRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='1099' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='1100' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='1100'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='3416c97b32cc0956ce9f57f2d5d4267e' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AddCachePoolRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/RpcCallback;)V' name='callMethod' primary='true'><SourceLine endBytecode='840' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$AddCachePoolRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AddCachePoolRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AddCachePoolRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='1159' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='1160' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='1160'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='7257807f6a87b4c649e5ecb3c1beb7cb' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AllowSnapshotRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/RpcCallback;)V' name='callMethod' primary='true'><SourceLine endBytecode='840' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$AllowSnapshotRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AllowSnapshotRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AllowSnapshotRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='1459' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='1460' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='1460'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='b4e2d4273082ee5c2893ddfff0c810c8' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AppendRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/RpcCallback;)V' name='callMethod' primary='true'><SourceLine endBytecode='840' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$AppendRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AppendRequestProto' start='5555' end='6308' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 5555-6308]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AppendRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='499' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='500' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='500'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='50b43b00346240608d7499d7eb0b0282' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CheckAccessRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/RpcCallback;)V' name='callMethod' primary='true'><SourceLine endBytecode='840' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$CheckAccessRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CheckAccessRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CheckAccessRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='1714' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='1715' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='1715'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='1aa974665b24efc00ba0c7ca420ccd0e' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CompleteRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/RpcCallback;)V' name='callMethod' primary='true'><SourceLine endBytecode='840' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$CompleteRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CompleteRequestProto' start='21020' end='21972' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 21020-21972]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CompleteRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='664' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='665' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='665'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='76da7f36504a9a4e2fea1c19d2417607' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ConcatRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/RpcCallback;)V' name='callMethod' primary='true'><SourceLine endBytecode='840' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ConcatRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ConcatRequestProto' start='23527' end='24189' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 23527-24189]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ConcatRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='694' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='695' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='695'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='3b27bba44bd22b8da448cbe3f307eb68' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/RpcCallback;)V' name='callMethod' primary='true'><SourceLine endBytecode='840' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$CreateRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateRequestProto' start='3172' end='4939' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 3172-4939]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='484' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='485' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='485'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='278abbbe8d6f5fdd2e0fef3a0c6991bd' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateSnapshotRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/RpcCallback;)V' name='callMethod' primary='true'><SourceLine endBytecode='840' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$CreateSnapshotRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateSnapshotRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateSnapshotRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='1429' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='1430' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='1430'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='c8fa983aaf5293680f6c2b590253e37e' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateSymlinkRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/RpcCallback;)V' name='callMethod' primary='true'><SourceLine endBytecode='840' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$CreateSymlinkRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateSymlinkRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateSymlinkRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='1294' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='1295' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='1295'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='49473e9d8d1879e99754efc81851be5f' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DeleteRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/RpcCallback;)V' name='callMethod' primary='true'><SourceLine endBytecode='840' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$DeleteRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DeleteRequestProto' start='28157' end='28736' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 28157-28736]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DeleteRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='754' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='755' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='755'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='12b4a4830a0b84dd1c172dc4327a2862' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DeleteSnapshotRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/RpcCallback;)V' name='callMethod' primary='true'><SourceLine endBytecode='840' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$DeleteSnapshotRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DeleteSnapshotRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DeleteSnapshotRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='1504' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='1505' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='1505'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='2b7e34e463a81d099e20aa8f99c7fca0' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DisallowSnapshotRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/RpcCallback;)V' name='callMethod' primary='true'><SourceLine endBytecode='840' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$DisallowSnapshotRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DisallowSnapshotRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DisallowSnapshotRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='1474' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='1475' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='1475'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='776e2ef646c7f85c880e09b4eb8dd091' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$FinalizeUpgradeRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/RpcCallback;)V' name='callMethod' primary='true'><SourceLine endBytecode='840' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$FinalizeUpgradeRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$FinalizeUpgradeRequestProto' start='50558' end='50889' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 50558-50889]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$FinalizeUpgradeRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='994' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='995' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='995'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='155dde85fbd484ce65b08d9e84ad2e11' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$FsyncRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/RpcCallback;)V' name='callMethod' primary='true'><SourceLine endBytecode='840' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$FsyncRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$FsyncRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$FsyncRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='1264' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='1265' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='1265'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='a1df49c4d64aeda6eb5a8cfbcf0257dd' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetAdditionalDatanodeRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/RpcCallback;)V' name='callMethod' primary='true'><SourceLine endBytecode='840' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$GetAdditionalDatanodeRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetAdditionalDatanodeRequestProto' start='18461' end='20386' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 18461-20386]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetAdditionalDatanodeRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='649' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='650' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='650'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='b32175af2fed1f9f0bdcbced50dbba0' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetBlockLocationsRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/RpcCallback;)V' name='callMethod' primary='true'><SourceLine endBytecode='840' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$GetBlockLocationsRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetBlockLocationsRequestProto' start='803' end='1554' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 803-1554]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetBlockLocationsRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='454' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='455' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='455'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='479be28dc701a8e935fae9419988377c' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetContentSummaryRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/RpcCallback;)V' name='callMethod' primary='true'><SourceLine endBytecode='840' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$GetContentSummaryRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetContentSummaryRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetContentSummaryRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='1234' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='1235' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='1235'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='2af2fe92340e40d3104d2311abec1f5b' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetCurrentEditLogTxidRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/RpcCallback;)V' name='callMethod' primary='true'><SourceLine endBytecode='840' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$GetCurrentEditLogTxidRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetCurrentEditLogTxidRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetCurrentEditLogTxidRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='1834' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='1835' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='1835'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='9faac1a7d48c59ee0556f8021c65cefe' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDataEncryptionKeyRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/RpcCallback;)V' name='callMethod' primary='true'><SourceLine endBytecode='840' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$GetDataEncryptionKeyRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDataEncryptionKeyRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDataEncryptionKeyRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='1414' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='1415' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='1415'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='961f2e61bae2ef6e5df9d809c0f17571' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDatanodeReportRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/RpcCallback;)V' name='callMethod' primary='true'><SourceLine endBytecode='840' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$GetDatanodeReportRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDatanodeReportRequestProto' start='41924' end='42354' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 41924-42354]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDatanodeReportRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='874' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='875' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='875'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='e848bb8bb69499322d1ba3f52c342d4e' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDatanodeStorageReportRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/RpcCallback;)V' name='callMethod' primary='true'><SourceLine endBytecode='840' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$GetDatanodeStorageReportRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDatanodeStorageReportRequestProto' start='43096' end='43526' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 43096-43526]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDatanodeStorageReportRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='889' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='890' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='890'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='dd007aad061b315b6bc48dc3ebe63750' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetEditsFromTxidRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/RpcCallback;)V' name='callMethod' primary='true'><SourceLine endBytecode='840' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$GetEditsFromTxidRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetEditsFromTxidRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetEditsFromTxidRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='1849' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='1850' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='1850'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='b1df95f652bdc83b321410033fc20554' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFileInfoRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/RpcCallback;)V' name='callMethod' primary='true'><SourceLine endBytecode='840' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$GetFileInfoRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFileInfoRequestProto' start='56018' end='56509' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 56018-56509]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFileInfoRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='1069' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='1070' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='1070'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='3412b9d3df724e7c6da66507bbad2a92' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFileLinkInfoRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/RpcCallback;)V' name='callMethod' primary='true'><SourceLine endBytecode='840' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$GetFileLinkInfoRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFileLinkInfoRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFileLinkInfoRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='1219' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='1220' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='1220'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='b212f5df35c9f4c952c70fdedbdc1fa2' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsECBlockGroupStatsRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/RpcCallback;)V' name='callMethod' primary='true'><SourceLine endBytecode='840' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$GetFsECBlockGroupStatsRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsECBlockGroupStatsRequestProto' start='40738' end='41069' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 40738-41069]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsECBlockGroupStatsRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='859' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='860' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='860'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='2727b6dbbef116fbdb7ee178d6a4bb0f' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsReplicatedBlockStatsRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/RpcCallback;)V' name='callMethod' primary='true'><SourceLine endBytecode='840' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$GetFsReplicatedBlockStatsRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsReplicatedBlockStatsRequestProto' start='39460' end='39791' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 39460-39791]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsReplicatedBlockStatsRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='844' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='845' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='845'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='6d2f9b554da850de1ff640b78c0bd427' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsStatusRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/RpcCallback;)V' name='callMethod' primary='true'><SourceLine endBytecode='840' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$GetFsStatusRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsStatusRequestProto' start='37912' end='38243' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 37912-38243]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsStatusRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='829' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='830' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='830'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='da2cecb9921719973d46ce249c4598b8' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetLinkTargetRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/RpcCallback;)V' name='callMethod' primary='true'><SourceLine endBytecode='840' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$GetLinkTargetRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetLinkTargetRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetLinkTargetRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='1309' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='1310' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='1310'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='37615677e97b927f0724e7674a2abb11' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetListingRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/RpcCallback;)V' name='callMethod' primary='true'><SourceLine endBytecode='840' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$GetListingRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetListingRequestProto' start='30711' end='31381' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 30711-31381]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetListingRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='784' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='785' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='785'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='1201b1811ab7702646d291c5ffacb2b5' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetLocatedFileInfoRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/RpcCallback;)V' name='callMethod' primary='true'><SourceLine endBytecode='840' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$GetLocatedFileInfoRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetLocatedFileInfoRequestProto' start='57102' end='57665' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 57102-57665]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetLocatedFileInfoRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='1084' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='1085' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='1085'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='91f47e824ded31b12675adfb559c9ae' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetPreferredBlockSizeRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/RpcCallback;)V' name='callMethod' primary='true'><SourceLine endBytecode='840' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$GetPreferredBlockSizeRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetPreferredBlockSizeRequestProto' start='45214' end='45705' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 45214-45705]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetPreferredBlockSizeRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='904' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='905' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='905'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='372e3db09e46ebab344c26c4f005ea59' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetQuotaUsageRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/RpcCallback;)V' name='callMethod' primary='true'><SourceLine endBytecode='840' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$GetQuotaUsageRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetQuotaUsageRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetQuotaUsageRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='1969' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='1970' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='1970'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='6788d4a0d730e7440c9ba51109b9d698' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetServerDefaultsRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/RpcCallback;)V' name='callMethod' primary='true'><SourceLine endBytecode='840' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$GetServerDefaultsRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetServerDefaultsRequestProto' start='2126' end='2457' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 2126-2457]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetServerDefaultsRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='469' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='470' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='470'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='2841b102a82d35a286f9ceb1cf64f467' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshotDiffReportListingRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/RpcCallback;)V' name='callMethod' primary='true'><SourceLine endBytecode='840' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$GetSnapshotDiffReportListingRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshotDiffReportListingRequestProto' start='34335' end='35341' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 34335-35341]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshotDiffReportListingRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='1534' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='1535' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='1535'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='b5bc682f2526e7736d46dc1c85aee004' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshotDiffReportRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/RpcCallback;)V' name='callMethod' primary='true'><SourceLine endBytecode='840' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$GetSnapshotDiffReportRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshotDiffReportRequestProto' start='32897' end='33704' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 32897-33704]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshotDiffReportRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='1519' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='1520' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='1520'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='c06340705565fbf84b3f0c49beafe941' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshottableDirListingRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/RpcCallback;)V' name='callMethod' primary='true'><SourceLine endBytecode='840' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$GetSnapshottableDirListingRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshottableDirListingRequestProto' start='31953' end='32284' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 31953-32284]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshottableDirListingRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='1489' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='1490' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='1490'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='48dfda04c77ebe7fc85b6e24e2781a33' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetStoragePoliciesRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/RpcCallback;)V' name='callMethod' primary='true'><SourceLine endBytecode='840' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$GetStoragePoliciesRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetStoragePoliciesRequestProto' start='11151' end='11482' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 11151-11482]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetStoragePoliciesRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='574' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='575' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='575'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='aa933bbf7ac3a24a2824eca41ccbc3b1' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetStoragePolicyRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/RpcCallback;)V' name='callMethod' primary='true'><SourceLine endBytecode='840' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$GetStoragePolicyRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetStoragePolicyRequestProto' start='10084' end='10575' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 10084-10575]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetStoragePolicyRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='559' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='560' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='560'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='5faa7325ec1eb1347c5ec92e1acfb27a' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$IsFileClosedRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/RpcCallback;)V' name='callMethod' primary='true'><SourceLine endBytecode='840' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$IsFileClosedRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$IsFileClosedRequestProto' start='58248' end='58739' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 58248-58739]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$IsFileClosedRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='1549' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='1550' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='1550'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='d173c36615159ed0826c0efa7406780b' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListCacheDirectivesRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/RpcCallback;)V' name='callMethod' primary='true'><SourceLine endBytecode='840' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ListCacheDirectivesRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListCacheDirectivesRequestProto' start='64583' end='65207' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 64583-65207]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListCacheDirectivesRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='1144' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='1145' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='1145'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='fa26d590c5c877f772f9fc19e5b5aab3' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListCachePoolsRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/RpcCallback;)V' name='callMethod' primary='true'><SourceLine endBytecode='840' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ListCachePoolsRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListCachePoolsRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListCachePoolsRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='1204' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='1205' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='1205'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='dca98e3ccf889d819dc00605a63fef65' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListCorruptFileBlocksRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/RpcCallback;)V' name='callMethod' primary='true'><SourceLine endBytecode='840' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ListCorruptFileBlocksRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListCorruptFileBlocksRequestProto' start='53927' end='54568' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 53927-54568]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListCorruptFileBlocksRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='1039' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='1040' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='1040'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='6442889ff6b7b501e6e183cf87833f1d' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListOpenFilesRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/RpcCallback;)V' name='callMethod' primary='true'><SourceLine endBytecode='840' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ListOpenFilesRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListOpenFilesRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListOpenFilesRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='1984' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='1985' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='1985'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='44792795c165d335c23fd1a0c6fb1c0d' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$MetaSaveRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/RpcCallback;)V' name='callMethod' primary='true'><SourceLine endBytecode='840' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$MetaSaveRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$MetaSaveRequestProto' start='55155' end='55646' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 55155-55646]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$MetaSaveRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='1054' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='1055' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='1055'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='cdf0a085653f550581286ecedacafe73' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$MkdirsRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/RpcCallback;)V' name='callMethod' primary='true'><SourceLine endBytecode='840' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$MkdirsRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$MkdirsRequestProto' start='29242' end='30223' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 29242-30223]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$MkdirsRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='769' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='770' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='770'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='da4c8271a8fab3c468bf16b17d0a25af' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ModifyCacheDirectiveRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/RpcCallback;)V' name='callMethod' primary='true'><SourceLine endBytecode='840' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ModifyCacheDirectiveRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ModifyCacheDirectiveRequestProto' start='62790' end='63430' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 62790-63430]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ModifyCacheDirectiveRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='1114' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='1115' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='1115'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='d40165deb4c2f8513be016d401c0e037' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ModifyCachePoolRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/RpcCallback;)V' name='callMethod' primary='true'><SourceLine endBytecode='840' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ModifyCachePoolRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ModifyCachePoolRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ModifyCachePoolRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='1174' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='1175' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='1175'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='38758ea236412b03126ad92872a6fd92' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RecoverLeaseRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/RpcCallback;)V' name='callMethod' primary='true'><SourceLine endBytecode='840' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$RecoverLeaseRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RecoverLeaseRequestProto' start='36806' end='37455' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 36806-37455]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RecoverLeaseRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='814' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='815' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='815'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='3529603f8c8b5714147260b3e6edd959' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RefreshNodesRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/RpcCallback;)V' name='callMethod' primary='true'><SourceLine endBytecode='840' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$RefreshNodesRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RefreshNodesRequestProto' start='49866' end='50197' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 49866-50197]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RefreshNodesRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='979' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='980' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='980'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='54902421bee88a51d7253ed9e53aa3de' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RemoveCacheDirectiveRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/RpcCallback;)V' name='callMethod' primary='true'><SourceLine endBytecode='840' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$RemoveCacheDirectiveRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RemoveCacheDirectiveRequestProto' start='63789' end='64210' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 63789-64210]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RemoveCacheDirectiveRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='1129' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='1130' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='1130'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='3a5432fde02c15df599da8a413bbd991' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RemoveCachePoolRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/RpcCallback;)V' name='callMethod' primary='true'><SourceLine endBytecode='840' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$RemoveCachePoolRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RemoveCachePoolRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RemoveCachePoolRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='1189' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='1190' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='1190'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='70208f0d4542add87a6313b7344ec890' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$Rename2RequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/RpcCallback;)V' name='callMethod' primary='true'><SourceLine endBytecode='840' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$Rename2RequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$Rename2RequestProto' start='26958' end='27775' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 26958-27775]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$Rename2RequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='739' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='740' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='740'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='257076d52fea076644ecf4b6f748183b' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenameRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/RpcCallback;)V' name='callMethod' primary='true'><SourceLine endBytecode='840' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$RenameRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenameRequestProto' start='25806' end='26455' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 25806-26455]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenameRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='724' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='725' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='725'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='9c433de9bb26e6a3abf19d482c9855bd' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenameSnapshotRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/RpcCallback;)V' name='callMethod' primary='true'><SourceLine endBytecode='840' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$RenameSnapshotRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenameSnapshotRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenameSnapshotRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='1444' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='1445' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='1445'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='8e18e9c05575cf17f789b39135e8cd77' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenewLeaseRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/RpcCallback;)V' name='callMethod' primary='true'><SourceLine endBytecode='840' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$RenewLeaseRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenewLeaseRequestProto' start='35928' end='36419' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 35928-36419]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenewLeaseRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='799' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='800' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='800'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='1ee37a17b384fa84bf25927909225de8' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ReportBadBlocksRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/RpcCallback;)V' name='callMethod' primary='true'><SourceLine endBytecode='840' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ReportBadBlocksRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ReportBadBlocksRequestProto' start='22450' end='23135' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 22450-23135]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ReportBadBlocksRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='679' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='680' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='680'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='249659d3a5b38910ffc351d6c65d685c' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RestoreFailedStorageRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/RpcCallback;)V' name='callMethod' primary='true'><SourceLine endBytecode='840' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$RestoreFailedStorageRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RestoreFailedStorageRequestProto' start='48918' end='49409' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 48918-49409]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RestoreFailedStorageRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='964' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='965' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='965'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='fda9d741f8848989fbcb0b8722ba2956' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RollEditsRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/RpcCallback;)V' name='callMethod' primary='true'><SourceLine endBytecode='840' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$RollEditsRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RollEditsRequestProto' start='48111' end='48442' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 48111-48442]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RollEditsRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='949' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='950' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='950'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='1aa937cda34826a7df330631397c5fc6' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RollingUpgradeRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/RpcCallback;)V' name='callMethod' primary='true'><SourceLine endBytecode='840' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$RollingUpgradeRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RollingUpgradeRequestProto' start='52044' end='52474' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 52044-52474]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RollingUpgradeRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='1024' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='1025' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='1025'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='eceab9cae7d47856411d17dbc31c503f' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SaveNamespaceRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/RpcCallback;)V' name='callMethod' primary='true'><SourceLine endBytecode='840' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$SaveNamespaceRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SaveNamespaceRequestProto' start='47161' end='47654' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 47161-47654]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SaveNamespaceRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='934' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='935' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='935'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='c4aa217136a46bc406ec30f1733a5fac' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetBalancerBandwidthRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/RpcCallback;)V' name='callMethod' primary='true'><SourceLine endBytecode='840' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$SetBalancerBandwidthRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetBalancerBandwidthRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetBalancerBandwidthRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='1399' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='1400' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='1400'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='ed0af2f6cefca66e7e70df34edc96ba5' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetOwnerRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/RpcCallback;)V' name='callMethod' primary='true'><SourceLine endBytecode='840' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$SetOwnerRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetOwnerRequestProto' start='13339' end='14130' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 13339-14130]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetOwnerRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='604' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='605' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='605'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='95c3206df5371fc320580d83c395ba31' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetPermissionRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/RpcCallback;)V' name='callMethod' primary='true'><SourceLine endBytecode='840' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$SetPermissionRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetPermissionRequestProto' start='12243' end='12937' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 12243-12937]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetPermissionRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='589' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='590' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='590'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='728edc308370bf64efa9f02e11e8bb1' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetQuotaRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/RpcCallback;)V' name='callMethod' primary='true'><SourceLine endBytecode='840' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$SetQuotaRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetQuotaRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetQuotaRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='1249' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='1250' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='1250'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='3a74437fde96f27dec5a496f0c8edf5a' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetReplicationRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/RpcCallback;)V' name='callMethod' primary='true'><SourceLine endBytecode='840' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$SetReplicationRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetReplicationRequestProto' start='7122' end='7725' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 7122-7725]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetReplicationRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='514' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='515' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='515'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='122c257ba15488298239400787b250d5' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetSafeModeRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/RpcCallback;)V' name='callMethod' primary='true'><SourceLine endBytecode='840' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$SetSafeModeRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetSafeModeRequestProto' start='46178' end='46688' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 46178-46688]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetSafeModeRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='919' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='920' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='920'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='eb46bd82c9aca76d64065b67a24b3b8e' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetStoragePolicyRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/RpcCallback;)V' name='callMethod' primary='true'><SourceLine endBytecode='840' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$SetStoragePolicyRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetStoragePolicyRequestProto' start='8208' end='8857' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 8208-8857]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetStoragePolicyRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='529' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='530' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='530'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='d1a8802fa6ef4ff16f09e38e220aed46' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetTimesRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/RpcCallback;)V' name='callMethod' primary='true'><SourceLine endBytecode='840' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$SetTimesRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetTimesRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetTimesRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='1279' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='1280' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='1280'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='a4c087d7863ca0a1425bb22796a2c2a7' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$TruncateRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/RpcCallback;)V' name='callMethod' primary='true'><SourceLine endBytecode='840' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$TruncateRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$TruncateRequestProto' start='24586' end='25323' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 24586-25323]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$TruncateRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='709' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='710' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='710'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='3f3bfd98c02b869f88df5a2d538195b0' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UnsetStoragePolicyRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/RpcCallback;)V' name='callMethod' primary='true'><SourceLine endBytecode='840' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$UnsetStoragePolicyRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UnsetStoragePolicyRequestProto' start='9229' end='9720' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 9229-9720]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UnsetStoragePolicyRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='544' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='545' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='545'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='6dd21055ac75ce9c3ef91491546b2451' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpdateBlockForPipelineRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/RpcCallback;)V' name='callMethod' primary='true'><SourceLine endBytecode='840' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$UpdateBlockForPipelineRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpdateBlockForPipelineRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpdateBlockForPipelineRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='1324' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='1325' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='1325'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='ddfbc968cee29acc91d0bb649f7fc6fe' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpdatePipelineRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/RpcCallback;)V' name='callMethod' primary='true'><SourceLine endBytecode='840' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$UpdatePipelineRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpdatePipelineRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpdatePipelineRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='1339' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='1340' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='1340'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='25b90bc7dc82580f95b46ff5a727bd47' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpgradeStatusRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/RpcCallback;)V' name='callMethod' primary='true'><SourceLine endBytecode='840' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$UpgradeStatusRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpgradeStatusRequestProto' start='51250' end='51581' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 51250-51581]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpgradeStatusRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='1009' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='1010' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='1010'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='ab0cb98c4dce98ee36fa64962308163d' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$CreateEncryptionZoneRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/RpcCallback;)V' name='callMethod' primary='true'><SourceLine endBytecode='840' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/EncryptionZonesProtos$CreateEncryptionZoneRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$CreateEncryptionZoneRequestProto' start='220' end='861' sourcepath='org/apache/hadoop/hdfs/protocol/proto/EncryptionZonesProtos.java' sourcefile='EncryptionZonesProtos.java'><Message>At EncryptionZonesProtos.java:[lines 220-861]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$CreateEncryptionZoneRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='1729' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='1730' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='1730'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='3437264bd5cc579db0c444f43815f330' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$GetEZForPathRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/RpcCallback;)V' name='callMethod' primary='true'><SourceLine endBytecode='840' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/EncryptionZonesProtos$GetEZForPathRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$GetEZForPathRequestProto' start='7259' end='7750' sourcepath='org/apache/hadoop/hdfs/protocol/proto/EncryptionZonesProtos.java' sourcefile='EncryptionZonesProtos.java'><Message>At EncryptionZonesProtos.java:[lines 7259-7750]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$GetEZForPathRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='1789' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='1790' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='1790'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='16c077230a9eaf1c8a056d00ba58ab69' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ListEncryptionZonesRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/RpcCallback;)V' name='callMethod' primary='true'><SourceLine endBytecode='840' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/EncryptionZonesProtos$ListEncryptionZonesRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ListEncryptionZonesRequestProto' start='1220' end='1641' sourcepath='org/apache/hadoop/hdfs/protocol/proto/EncryptionZonesProtos.java' sourcefile='EncryptionZonesProtos.java'><Message>At EncryptionZonesProtos.java:[lines 1220-1641]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ListEncryptionZonesRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='1744' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='1745' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='1745'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='85bbfa380c3cf1cd5de7078e89432dc' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ListReencryptionStatusRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/RpcCallback;)V' name='callMethod' primary='true'><SourceLine endBytecode='840' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/EncryptionZonesProtos$ListReencryptionStatusRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ListReencryptionStatusRequestProto' start='4448' end='4869' sourcepath='org/apache/hadoop/hdfs/protocol/proto/EncryptionZonesProtos.java' sourcefile='EncryptionZonesProtos.java'><Message>At EncryptionZonesProtos.java:[lines 4448-4869]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ListReencryptionStatusRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='1774' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='1775' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='1775'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='a72aaefdfa52091c283e4614b59ced7' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ReencryptEncryptionZoneRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/RpcCallback;)V' name='callMethod' primary='true'><SourceLine endBytecode='840' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/EncryptionZonesProtos$ReencryptEncryptionZoneRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ReencryptEncryptionZoneRequestProto' start='3501' end='4089' sourcepath='org/apache/hadoop/hdfs/protocol/proto/EncryptionZonesProtos.java' sourcefile='EncryptionZonesProtos.java'><Message>At EncryptionZonesProtos.java:[lines 3501-4089]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ReencryptEncryptionZoneRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='1759' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='1760' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='1760'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='784b9cafd9e4badbac6d88067c6f0fb' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$AddErasureCodingPoliciesRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/RpcCallback;)V' name='callMethod' primary='true'><SourceLine endBytecode='840' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos$AddErasureCodingPoliciesRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$AddErasureCodingPoliciesRequestProto' start='4318' end='5003' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' sourcefile='ErasureCodingProtos.java'><Message>At ErasureCodingProtos.java:[lines 4318-5003]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$AddErasureCodingPoliciesRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='1879' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='1880' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='1880'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='f45647d6cd0e626c300e59375e1fb8a5' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$DisableErasureCodingPolicyRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/RpcCallback;)V' name='callMethod' primary='true'><SourceLine endBytecode='840' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos$DisableErasureCodingPolicyRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$DisableErasureCodingPolicyRequestProto' start='7460' end='7951' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' sourcefile='ErasureCodingProtos.java'><Message>At ErasureCodingProtos.java:[lines 7460-7951]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$DisableErasureCodingPolicyRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='1924' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='1925' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='1925'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='f50adf4e955337717970203ceebe6303' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$EnableErasureCodingPolicyRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/RpcCallback;)V' name='callMethod' primary='true'><SourceLine endBytecode='840' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos$EnableErasureCodingPolicyRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$EnableErasureCodingPolicyRequestProto' start='6605' end='7096' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' sourcefile='ErasureCodingProtos.java'><Message>At ErasureCodingProtos.java:[lines 6605-7096]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$EnableErasureCodingPolicyRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='1909' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='1910' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='1910'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='c11197214ebc7c9f6f7382a231815abf' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingCodecsRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/RpcCallback;)V' name='callMethod' primary='true'><SourceLine endBytecode='840' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos$GetErasureCodingCodecsRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingCodecsRequestProto' start='2108' end='2439' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' sourcefile='ErasureCodingProtos.java'><Message>At ErasureCodingProtos.java:[lines 2108-2439]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingCodecsRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='1954' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='1955' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='1955'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='b11f1585f353c972917512c29a60859e' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingPoliciesRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/RpcCallback;)V' name='callMethod' primary='true'><SourceLine endBytecode='840' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos$GetErasureCodingPoliciesRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingPoliciesRequestProto' start='1041' end='1372' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' sourcefile='ErasureCodingProtos.java'><Message>At ErasureCodingProtos.java:[lines 1041-1372]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingPoliciesRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='1864' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='1865' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='1865'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='db14ecaa40e632bdab53c7e5728eda3d' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingPolicyRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/RpcCallback;)V' name='callMethod' primary='true'><SourceLine endBytecode='840' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos$GetErasureCodingPolicyRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingPolicyRequestProto' start='3198' end='3725' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' sourcefile='ErasureCodingProtos.java'><Message>At ErasureCodingProtos.java:[lines 3198-3725]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingPolicyRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='1939' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='1940' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='1940'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='85b49a2f4d5819cd7fbc6f394fe8a7f2' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$RemoveErasureCodingPolicyRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/RpcCallback;)V' name='callMethod' primary='true'><SourceLine endBytecode='840' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos$RemoveErasureCodingPolicyRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$RemoveErasureCodingPolicyRequestProto' start='5750' end='6241' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' sourcefile='ErasureCodingProtos.java'><Message>At ErasureCodingProtos.java:[lines 5750-6241]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$RemoveErasureCodingPolicyRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='1894' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='1895' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='1895'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='df89fc2f30a6c14c8202ca25ba6ac0c3' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$SetErasureCodingPolicyRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/RpcCallback;)V' name='callMethod' primary='true'><SourceLine endBytecode='840' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos$SetErasureCodingPolicyRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$SetErasureCodingPolicyRequestProto' start='47' end='688' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' sourcefile='ErasureCodingProtos.java'><Message>At ErasureCodingProtos.java:[lines 47-688]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$SetErasureCodingPolicyRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='1804' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='1805' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='1805'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='5a4838e65b116cb22ec2db56d91bce60' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$UnsetErasureCodingPolicyRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/RpcCallback;)V' name='callMethod' primary='true'><SourceLine endBytecode='840' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos$UnsetErasureCodingPolicyRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$UnsetErasureCodingPolicyRequestProto' start='8315' end='8806' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' sourcefile='ErasureCodingProtos.java'><Message>At ErasureCodingProtos.java:[lines 8315-8806]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$UnsetErasureCodingPolicyRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='1819' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='1820' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='1820'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='b43c1c81a72e7502d0dd05d612cf3564' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$GetXAttrsRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/RpcCallback;)V' name='callMethod' primary='true'><SourceLine endBytecode='840' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/XAttrProtos$GetXAttrsRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$GetXAttrsRequestProto' start='2155' end='3001' sourcepath='org/apache/hadoop/hdfs/protocol/proto/XAttrProtos.java' sourcefile='XAttrProtos.java'><Message>At XAttrProtos.java:[lines 2155-3001]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$GetXAttrsRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='1669' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='1670' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='1670'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='83b3f08931d475b5c233e1fa0512cfba' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$ListXAttrsRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/RpcCallback;)V' name='callMethod' primary='true'><SourceLine endBytecode='840' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/XAttrProtos$ListXAttrsRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$ListXAttrsRequestProto' start='3748' end='4239' sourcepath='org/apache/hadoop/hdfs/protocol/proto/XAttrProtos.java' sourcefile='XAttrProtos.java'><Message>At XAttrProtos.java:[lines 3748-4239]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$ListXAttrsRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='1684' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='1685' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='1685'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='8f333e3081e2b73cf3e1b6d9771e9083' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$RemoveXAttrRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/RpcCallback;)V' name='callMethod' primary='true'><SourceLine endBytecode='840' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/XAttrProtos$RemoveXAttrRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$RemoveXAttrRequestProto' start='5000' end='5690' sourcepath='org/apache/hadoop/hdfs/protocol/proto/XAttrProtos.java' sourcefile='XAttrProtos.java'><Message>At XAttrProtos.java:[lines 5000-5690]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$RemoveXAttrRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='1699' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='1700' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='1700'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='608b8a1194286ed0d93bc5559ed49d33' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$SetXAttrRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/RpcCallback;)V' name='callMethod' primary='true'><SourceLine endBytecode='840' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/XAttrProtos$SetXAttrRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$SetXAttrRequestProto' start='972' end='1766' sourcepath='org/apache/hadoop/hdfs/protocol/proto/XAttrProtos.java' sourcefile='XAttrProtos.java'><Message>At XAttrProtos.java:[lines 972-1766]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$SetXAttrRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='1654' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='1655' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='1655'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='d62782a682133dd7b83aeeab7d02727a' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.security.proto.SecurityProtos$CancelDelegationTokenRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/RpcCallback;)V' name='callMethod' primary='true'><SourceLine endBytecode='840' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/security/proto/SecurityProtos$CancelDelegationTokenRequestProto;'><SourceLine classname='org.apache.hadoop.security.proto.SecurityProtos$CancelDelegationTokenRequestProto' start='4934' end='5470' sourcepath='org/apache/hadoop/security/proto/SecurityProtos.java' sourcefile='SecurityProtos.java'><Message>At SecurityProtos.java:[lines 4934-5470]</Message></SourceLine><Message>Expected org.apache.hadoop.security.proto.SecurityProtos$CancelDelegationTokenRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='1384' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='1385' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='1385'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='380b30e6825e9f7c338b9255645c7af0' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.security.proto.SecurityProtos$GetDelegationTokenRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/RpcCallback;)V' name='callMethod' primary='true'><SourceLine endBytecode='840' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/security/proto/SecurityProtos$GetDelegationTokenRequestProto;'><SourceLine classname='org.apache.hadoop.security.proto.SecurityProtos$GetDelegationTokenRequestProto' start='2858' end='3349' sourcepath='org/apache/hadoop/security/proto/SecurityProtos.java' sourcefile='SecurityProtos.java'><Message>At SecurityProtos.java:[lines 2858-3349]</Message></SourceLine><Message>Expected org.apache.hadoop.security.proto.SecurityProtos$GetDelegationTokenRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='1354' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='1355' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='1355'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='fb215e5441210a30e1712cb9f6a04c39' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.security.proto.SecurityProtos$RenewDelegationTokenRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/RpcCallback;)V' name='callMethod' primary='true'><SourceLine endBytecode='840' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/security/proto/SecurityProtos$RenewDelegationTokenRequestProto;'><SourceLine classname='org.apache.hadoop.security.proto.SecurityProtos$RenewDelegationTokenRequestProto' start='3931' end='4467' sourcepath='org/apache/hadoop/security/proto/SecurityProtos.java' sourcefile='SecurityProtos.java'><Message>At SecurityProtos.java:[lines 3931-4467]</Message></SourceLine><Message>Expected org.apache.hadoop.security.proto.SecurityProtos$RenewDelegationTokenRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='1369' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='1370' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='1370'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='7cd438a0075744fbbb14d48c4f1cce95' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.AclProtos$GetAclStatusRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;' name='callBlockingMethod' primary='true'><SourceLine endBytecode='737' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/AclProtos$GetAclStatusRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$GetAclStatusRequestProto' start='8460' end='8951' sourcepath='org/apache/hadoop/hdfs/protocol/proto/AclProtos.java' sourcefile='AclProtos.java'><Message>At AclProtos.java:[lines 8460-8951]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.AclProtos$GetAclStatusRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='1642' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='1643' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='1643'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='c1f07256b0050142240f9ad4a9bc570f' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.AclProtos$ModifyAclEntriesRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;' name='callBlockingMethod' primary='true'><SourceLine endBytecode='737' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/AclProtos$ModifyAclEntriesRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$ModifyAclEntriesRequestProto' start='3070' end='3916' sourcepath='org/apache/hadoop/hdfs/protocol/proto/AclProtos.java' sourcefile='AclProtos.java'><Message>At AclProtos.java:[lines 3070-3916]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.AclProtos$ModifyAclEntriesRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='1567' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='1568' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='1568'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='996b602b1154bd59695ad0f5126a1a61' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveAclEntriesRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;' name='callBlockingMethod' primary='true'><SourceLine endBytecode='737' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/AclProtos$RemoveAclEntriesRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveAclEntriesRequestProto' start='5160' end='6006' sourcepath='org/apache/hadoop/hdfs/protocol/proto/AclProtos.java' sourcefile='AclProtos.java'><Message>At AclProtos.java:[lines 5160-6006]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveAclEntriesRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='1582' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='1583' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='1583'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='cc056819d869fddb6ff43f9ec277ee6' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveAclRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;' name='callBlockingMethod' primary='true'><SourceLine endBytecode='737' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/AclProtos$RemoveAclRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveAclRequestProto' start='4280' end='4771' sourcepath='org/apache/hadoop/hdfs/protocol/proto/AclProtos.java' sourcefile='AclProtos.java'><Message>At AclProtos.java:[lines 4280-4771]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveAclRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='1612' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='1613' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='1613'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='1bebc70d2ba8dd66e2f84735470e54b2' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveDefaultAclRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;' name='callBlockingMethod' primary='true'><SourceLine endBytecode='737' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/AclProtos$RemoveDefaultAclRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveDefaultAclRequestProto' start='6370' end='6861' sourcepath='org/apache/hadoop/hdfs/protocol/proto/AclProtos.java' sourcefile='AclProtos.java'><Message>At AclProtos.java:[lines 6370-6861]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveDefaultAclRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='1597' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='1598' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='1598'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='515dbe65cc8782a7bb4195ffd160e14c' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.AclProtos$SetAclRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;' name='callBlockingMethod' primary='true'><SourceLine endBytecode='737' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/AclProtos$SetAclRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.AclProtos$SetAclRequestProto' start='7250' end='8096' sourcepath='org/apache/hadoop/hdfs/protocol/proto/AclProtos.java' sourcefile='AclProtos.java'><Message>At AclProtos.java:[lines 7250-8096]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.AclProtos$SetAclRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='1627' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='1628' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='1628'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='a8478575375d97fef1db5b200ea033b7' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AbandonBlockRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;' name='callBlockingMethod' primary='true'><SourceLine endBytecode='737' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$AbandonBlockRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AbandonBlockRequestProto' start='14549' end='15505' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 14549-15505]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AbandonBlockRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='622' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='623' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='623'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='df9b29fef1b5ca0ff4768faffb0ad488' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AddBlockRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;' name='callBlockingMethod' primary='true'><SourceLine endBytecode='737' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$AddBlockRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AddBlockRequestProto' start='16011' end='17747' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 16011-17747]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AddBlockRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='637' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='638' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='638'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='1fdbc6d5d68d86c376535fac483db6f6' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AddCacheDirectiveRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;' name='callBlockingMethod' primary='true'><SourceLine endBytecode='737' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$AddCacheDirectiveRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AddCacheDirectiveRequestProto' start='61665' end='62305' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 61665-62305]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AddCacheDirectiveRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='1102' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='1103' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='1103'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='d40ad447264edf8de640ec5eb422c95' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AddCachePoolRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;' name='callBlockingMethod' primary='true'><SourceLine endBytecode='737' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$AddCachePoolRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AddCachePoolRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AddCachePoolRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='1162' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='1163' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='1163'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='3651d922c5872e6bde51c0a554846452' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AllowSnapshotRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;' name='callBlockingMethod' primary='true'><SourceLine endBytecode='737' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$AllowSnapshotRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AllowSnapshotRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AllowSnapshotRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='1462' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='1463' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='1463'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='4345eb63f32540f4d4bccf5e91d16edd' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AppendRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;' name='callBlockingMethod' primary='true'><SourceLine endBytecode='737' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$AppendRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AppendRequestProto' start='5555' end='6308' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 5555-6308]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AppendRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='502' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='503' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='503'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='83d2af25936112752e24d3b8bf059226' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CheckAccessRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;' name='callBlockingMethod' primary='true'><SourceLine endBytecode='737' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$CheckAccessRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CheckAccessRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CheckAccessRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='1717' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='1718' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='1718'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='4408f7c2b5276b37df2b0166720b87ac' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CompleteRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;' name='callBlockingMethod' primary='true'><SourceLine endBytecode='737' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$CompleteRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CompleteRequestProto' start='21020' end='21972' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 21020-21972]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CompleteRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='667' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='668' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='668'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='b6b3eb915f58a21fa3f5731e552f3e49' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ConcatRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;' name='callBlockingMethod' primary='true'><SourceLine endBytecode='737' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ConcatRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ConcatRequestProto' start='23527' end='24189' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 23527-24189]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ConcatRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='697' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='698' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='698'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='3b7b2517827aa74599ef3c3964539002' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;' name='callBlockingMethod' primary='true'><SourceLine endBytecode='737' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$CreateRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateRequestProto' start='3172' end='4939' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 3172-4939]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='487' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='488' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='488'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='cc11b6526cfff7ec9b1cb8c0a82cd0e1' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateSnapshotRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;' name='callBlockingMethod' primary='true'><SourceLine endBytecode='737' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$CreateSnapshotRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateSnapshotRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateSnapshotRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='1432' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='1433' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='1433'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='bcfd9172821c998a304208942276731a' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateSymlinkRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;' name='callBlockingMethod' primary='true'><SourceLine endBytecode='737' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$CreateSymlinkRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateSymlinkRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateSymlinkRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='1297' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='1298' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='1298'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='710664d77cea34ee938c337e8051eb6e' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DeleteRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;' name='callBlockingMethod' primary='true'><SourceLine endBytecode='737' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$DeleteRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DeleteRequestProto' start='28157' end='28736' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 28157-28736]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DeleteRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='757' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='758' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='758'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='6fbbe8711ed7d6226fbbb41e86dbf8e7' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DeleteSnapshotRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;' name='callBlockingMethod' primary='true'><SourceLine endBytecode='737' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$DeleteSnapshotRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DeleteSnapshotRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DeleteSnapshotRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='1507' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='1508' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='1508'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='128f28db909215ce4431dbb319a6e628' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DisallowSnapshotRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;' name='callBlockingMethod' primary='true'><SourceLine endBytecode='737' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$DisallowSnapshotRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DisallowSnapshotRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DisallowSnapshotRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='1477' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='1478' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='1478'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='84371e6d47182928456306f13d7b2be3' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$FinalizeUpgradeRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;' name='callBlockingMethod' primary='true'><SourceLine endBytecode='737' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$FinalizeUpgradeRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$FinalizeUpgradeRequestProto' start='50558' end='50889' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 50558-50889]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$FinalizeUpgradeRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='997' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='998' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='998'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='1d244929c275555779bd640b51748801' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$FsyncRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;' name='callBlockingMethod' primary='true'><SourceLine endBytecode='737' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$FsyncRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$FsyncRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$FsyncRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='1267' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='1268' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='1268'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='3a68f0500a62bff2890f5b3fe8149849' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetAdditionalDatanodeRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;' name='callBlockingMethod' primary='true'><SourceLine endBytecode='737' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$GetAdditionalDatanodeRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetAdditionalDatanodeRequestProto' start='18461' end='20386' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 18461-20386]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetAdditionalDatanodeRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='652' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='653' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='653'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='b6af10a68c76ae9603939d561b7cbea' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetBlockLocationsRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;' name='callBlockingMethod' primary='true'><SourceLine endBytecode='737' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$GetBlockLocationsRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetBlockLocationsRequestProto' start='803' end='1554' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 803-1554]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetBlockLocationsRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='457' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='458' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='458'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='88af634dcb8495998a970715c74efb17' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetContentSummaryRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;' name='callBlockingMethod' primary='true'><SourceLine endBytecode='737' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$GetContentSummaryRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetContentSummaryRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetContentSummaryRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='1237' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='1238' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='1238'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='9dc8dde735811ff084795de3ebbba38b' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetCurrentEditLogTxidRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;' name='callBlockingMethod' primary='true'><SourceLine endBytecode='737' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$GetCurrentEditLogTxidRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetCurrentEditLogTxidRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetCurrentEditLogTxidRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='1837' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='1838' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='1838'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='3cd638dcac7afbef425e9e55aff1d2dd' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDataEncryptionKeyRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;' name='callBlockingMethod' primary='true'><SourceLine endBytecode='737' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$GetDataEncryptionKeyRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDataEncryptionKeyRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDataEncryptionKeyRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='1417' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='1418' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='1418'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='eda22b131228ee202c851e2e41b77eca' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDatanodeReportRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;' name='callBlockingMethod' primary='true'><SourceLine endBytecode='737' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$GetDatanodeReportRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDatanodeReportRequestProto' start='41924' end='42354' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 41924-42354]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDatanodeReportRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='877' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='878' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='878'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='b3d6812748ca6ec3115371e6652dc638' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDatanodeStorageReportRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;' name='callBlockingMethod' primary='true'><SourceLine endBytecode='737' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$GetDatanodeStorageReportRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDatanodeStorageReportRequestProto' start='43096' end='43526' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 43096-43526]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDatanodeStorageReportRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='892' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='893' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='893'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='e34653ef5b50630cd71805b8fddf6c97' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetEditsFromTxidRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;' name='callBlockingMethod' primary='true'><SourceLine endBytecode='737' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$GetEditsFromTxidRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetEditsFromTxidRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetEditsFromTxidRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='1852' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='1853' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='1853'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='f4f743002a66e8b0d4dd0c7efe9941d1' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFileInfoRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;' name='callBlockingMethod' primary='true'><SourceLine endBytecode='737' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$GetFileInfoRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFileInfoRequestProto' start='56018' end='56509' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 56018-56509]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFileInfoRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='1072' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='1073' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='1073'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='2af159f32ff4504705cfd088d4653eb5' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFileLinkInfoRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;' name='callBlockingMethod' primary='true'><SourceLine endBytecode='737' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$GetFileLinkInfoRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFileLinkInfoRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFileLinkInfoRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='1222' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='1223' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='1223'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='9ad88c429847037d02c3f28e9d250e6a' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsECBlockGroupStatsRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;' name='callBlockingMethod' primary='true'><SourceLine endBytecode='737' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$GetFsECBlockGroupStatsRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsECBlockGroupStatsRequestProto' start='40738' end='41069' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 40738-41069]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsECBlockGroupStatsRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='862' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='863' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='863'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='a9456469f3cc615121c0897977773b62' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsReplicatedBlockStatsRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;' name='callBlockingMethod' primary='true'><SourceLine endBytecode='737' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$GetFsReplicatedBlockStatsRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsReplicatedBlockStatsRequestProto' start='39460' end='39791' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 39460-39791]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsReplicatedBlockStatsRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='847' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='848' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='848'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='9279b59d62c317848a6b120b5dc9e438' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsStatusRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;' name='callBlockingMethod' primary='true'><SourceLine endBytecode='737' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$GetFsStatusRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsStatusRequestProto' start='37912' end='38243' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 37912-38243]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsStatusRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='832' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='833' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='833'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='ecd62b6af2e931c26e5c0259bdbb107c' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetLinkTargetRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;' name='callBlockingMethod' primary='true'><SourceLine endBytecode='737' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$GetLinkTargetRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetLinkTargetRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetLinkTargetRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='1312' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='1313' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='1313'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='7ea99bff7e0daa24576f79de4a9bce5e' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetListingRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;' name='callBlockingMethod' primary='true'><SourceLine endBytecode='737' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$GetListingRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetListingRequestProto' start='30711' end='31381' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 30711-31381]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetListingRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='787' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='788' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='788'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='94c7bca2c9edc33f06109158b73be020' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetLocatedFileInfoRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;' name='callBlockingMethod' primary='true'><SourceLine endBytecode='737' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$GetLocatedFileInfoRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetLocatedFileInfoRequestProto' start='57102' end='57665' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 57102-57665]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetLocatedFileInfoRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='1087' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='1088' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='1088'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='ec2b335c67cf20e7941139925c134b85' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetPreferredBlockSizeRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;' name='callBlockingMethod' primary='true'><SourceLine endBytecode='737' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$GetPreferredBlockSizeRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetPreferredBlockSizeRequestProto' start='45214' end='45705' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 45214-45705]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetPreferredBlockSizeRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='907' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='908' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='908'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='4b69e4a8f9d101e631724221adcae5b2' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetQuotaUsageRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;' name='callBlockingMethod' primary='true'><SourceLine endBytecode='737' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$GetQuotaUsageRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetQuotaUsageRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetQuotaUsageRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='1972' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='1973' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='1973'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='9c792b68d409beda6be34c3925bcd1fd' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetServerDefaultsRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;' name='callBlockingMethod' primary='true'><SourceLine endBytecode='737' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$GetServerDefaultsRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetServerDefaultsRequestProto' start='2126' end='2457' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 2126-2457]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetServerDefaultsRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='472' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='473' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='473'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='40b574385299804f629b05351bbde5d0' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshotDiffReportListingRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;' name='callBlockingMethod' primary='true'><SourceLine endBytecode='737' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$GetSnapshotDiffReportListingRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshotDiffReportListingRequestProto' start='34335' end='35341' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 34335-35341]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshotDiffReportListingRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='1537' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='1538' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='1538'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='db594506638700262732c6e89032874' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshotDiffReportRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;' name='callBlockingMethod' primary='true'><SourceLine endBytecode='737' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$GetSnapshotDiffReportRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshotDiffReportRequestProto' start='32897' end='33704' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 32897-33704]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshotDiffReportRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='1522' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='1523' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='1523'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='132c09d00e55af8f1eee3f6f03601db9' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshottableDirListingRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;' name='callBlockingMethod' primary='true'><SourceLine endBytecode='737' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$GetSnapshottableDirListingRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshottableDirListingRequestProto' start='31953' end='32284' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 31953-32284]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshottableDirListingRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='1492' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='1493' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='1493'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='a3f8d2c0fe2b8484c6b5d0a6ba8f425e' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetStoragePoliciesRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;' name='callBlockingMethod' primary='true'><SourceLine endBytecode='737' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$GetStoragePoliciesRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetStoragePoliciesRequestProto' start='11151' end='11482' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 11151-11482]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetStoragePoliciesRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='577' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='578' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='578'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='74dfe7f30cecc0adef4b45910065a6b0' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetStoragePolicyRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;' name='callBlockingMethod' primary='true'><SourceLine endBytecode='737' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$GetStoragePolicyRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetStoragePolicyRequestProto' start='10084' end='10575' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 10084-10575]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetStoragePolicyRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='562' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='563' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='563'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='3df01a12e61f03cd452930c863fc0e82' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$IsFileClosedRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;' name='callBlockingMethod' primary='true'><SourceLine endBytecode='737' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$IsFileClosedRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$IsFileClosedRequestProto' start='58248' end='58739' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 58248-58739]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$IsFileClosedRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='1552' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='1553' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='1553'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='bce8df9d11bb18517a1f07e58ce66bb4' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListCacheDirectivesRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;' name='callBlockingMethod' primary='true'><SourceLine endBytecode='737' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ListCacheDirectivesRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListCacheDirectivesRequestProto' start='64583' end='65207' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 64583-65207]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListCacheDirectivesRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='1147' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='1148' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='1148'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='d774564a32ed9ff7f19d10e358a230a0' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListCachePoolsRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;' name='callBlockingMethod' primary='true'><SourceLine endBytecode='737' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ListCachePoolsRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListCachePoolsRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListCachePoolsRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='1207' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='1208' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='1208'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='89bce57081ca830892403bc58a2869b9' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListCorruptFileBlocksRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;' name='callBlockingMethod' primary='true'><SourceLine endBytecode='737' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ListCorruptFileBlocksRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListCorruptFileBlocksRequestProto' start='53927' end='54568' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 53927-54568]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListCorruptFileBlocksRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='1042' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='1043' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='1043'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='5841ca66402fb12bbb545dfc7a3b81' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListOpenFilesRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;' name='callBlockingMethod' primary='true'><SourceLine endBytecode='737' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ListOpenFilesRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListOpenFilesRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListOpenFilesRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='1987' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='1988' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='1988'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='eb5ecebf0b2d307bb1cfed6bb4ea9bc6' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$MetaSaveRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;' name='callBlockingMethod' primary='true'><SourceLine endBytecode='737' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$MetaSaveRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$MetaSaveRequestProto' start='55155' end='55646' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 55155-55646]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$MetaSaveRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='1057' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='1058' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='1058'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='e394654834c93f549cc270bcb840d562' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$MkdirsRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;' name='callBlockingMethod' primary='true'><SourceLine endBytecode='737' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$MkdirsRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$MkdirsRequestProto' start='29242' end='30223' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 29242-30223]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$MkdirsRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='772' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='773' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='773'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='c1b686928407ba660a58a2c225e175b7' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ModifyCacheDirectiveRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;' name='callBlockingMethod' primary='true'><SourceLine endBytecode='737' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ModifyCacheDirectiveRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ModifyCacheDirectiveRequestProto' start='62790' end='63430' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 62790-63430]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ModifyCacheDirectiveRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='1117' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='1118' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='1118'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='fd4d37ad958bbc2eaf5565c2a2ca0697' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ModifyCachePoolRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;' name='callBlockingMethod' primary='true'><SourceLine endBytecode='737' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ModifyCachePoolRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ModifyCachePoolRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ModifyCachePoolRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='1177' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='1178' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='1178'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='345a3e9307836a2125e12f04b4e97a39' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RecoverLeaseRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;' name='callBlockingMethod' primary='true'><SourceLine endBytecode='737' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$RecoverLeaseRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RecoverLeaseRequestProto' start='36806' end='37455' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 36806-37455]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RecoverLeaseRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='817' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='818' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='818'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='af297a837fbfa31db9e0821b92a3183d' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RefreshNodesRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;' name='callBlockingMethod' primary='true'><SourceLine endBytecode='737' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$RefreshNodesRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RefreshNodesRequestProto' start='49866' end='50197' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 49866-50197]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RefreshNodesRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='982' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='983' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='983'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='367554470d4d787b3092bf8bfffb4c68' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RemoveCacheDirectiveRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;' name='callBlockingMethod' primary='true'><SourceLine endBytecode='737' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$RemoveCacheDirectiveRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RemoveCacheDirectiveRequestProto' start='63789' end='64210' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 63789-64210]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RemoveCacheDirectiveRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='1132' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='1133' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='1133'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='36659ae2eb61a0e16d72e759f2c65ad0' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RemoveCachePoolRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;' name='callBlockingMethod' primary='true'><SourceLine endBytecode='737' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$RemoveCachePoolRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RemoveCachePoolRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RemoveCachePoolRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='1192' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='1193' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='1193'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='197bc9ba1ec54e8baba6bf5fbbe42637' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$Rename2RequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;' name='callBlockingMethod' primary='true'><SourceLine endBytecode='737' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$Rename2RequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$Rename2RequestProto' start='26958' end='27775' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 26958-27775]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$Rename2RequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='742' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='743' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='743'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='b39586d1966963f67e16e3ea363a7e62' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenameRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;' name='callBlockingMethod' primary='true'><SourceLine endBytecode='737' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$RenameRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenameRequestProto' start='25806' end='26455' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 25806-26455]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenameRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='727' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='728' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='728'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='77df5cac2ff7a9ca8fad28bad7060e63' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenameSnapshotRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;' name='callBlockingMethod' primary='true'><SourceLine endBytecode='737' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$RenameSnapshotRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenameSnapshotRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenameSnapshotRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='1447' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='1448' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='1448'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='9f18a282872ed49ab56dd55f9a4f27d5' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenewLeaseRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;' name='callBlockingMethod' primary='true'><SourceLine endBytecode='737' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$RenewLeaseRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenewLeaseRequestProto' start='35928' end='36419' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 35928-36419]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenewLeaseRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='802' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='803' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='803'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='819b5f7d46438e490dfa86d80bd14860' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ReportBadBlocksRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;' name='callBlockingMethod' primary='true'><SourceLine endBytecode='737' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ReportBadBlocksRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ReportBadBlocksRequestProto' start='22450' end='23135' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 22450-23135]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ReportBadBlocksRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='682' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='683' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='683'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='c1cff3c4693de3b27c8f6591ea3cdb3d' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RestoreFailedStorageRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;' name='callBlockingMethod' primary='true'><SourceLine endBytecode='737' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$RestoreFailedStorageRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RestoreFailedStorageRequestProto' start='48918' end='49409' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 48918-49409]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RestoreFailedStorageRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='967' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='968' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='968'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='c10ec4b18468108499a09f25d2295db4' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RollEditsRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;' name='callBlockingMethod' primary='true'><SourceLine endBytecode='737' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$RollEditsRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RollEditsRequestProto' start='48111' end='48442' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 48111-48442]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RollEditsRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='952' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='953' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='953'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='92cb72212796274ead71f0f23d30170d' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RollingUpgradeRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;' name='callBlockingMethod' primary='true'><SourceLine endBytecode='737' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$RollingUpgradeRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RollingUpgradeRequestProto' start='52044' end='52474' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 52044-52474]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RollingUpgradeRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='1027' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='1028' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='1028'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='6789e24d4314a02f5d3c1647b0faa5a1' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SaveNamespaceRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;' name='callBlockingMethod' primary='true'><SourceLine endBytecode='737' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$SaveNamespaceRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SaveNamespaceRequestProto' start='47161' end='47654' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 47161-47654]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SaveNamespaceRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='937' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='938' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='938'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='c85a3612f784f86730ab027c82a897fd' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetBalancerBandwidthRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;' name='callBlockingMethod' primary='true'><SourceLine endBytecode='737' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$SetBalancerBandwidthRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetBalancerBandwidthRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetBalancerBandwidthRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='1402' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='1403' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='1403'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='4959c98a86517bf34e3e97cd2f438c22' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetOwnerRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;' name='callBlockingMethod' primary='true'><SourceLine endBytecode='737' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$SetOwnerRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetOwnerRequestProto' start='13339' end='14130' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 13339-14130]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetOwnerRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='607' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='608' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='608'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='b83f903a7aadc83776909b689932b6d2' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetPermissionRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;' name='callBlockingMethod' primary='true'><SourceLine endBytecode='737' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$SetPermissionRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetPermissionRequestProto' start='12243' end='12937' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 12243-12937]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetPermissionRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='592' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='593' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='593'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='61cc8badf1e5ff69322b7879b7a1b2c6' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetQuotaRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;' name='callBlockingMethod' primary='true'><SourceLine endBytecode='737' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$SetQuotaRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetQuotaRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetQuotaRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='1252' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='1253' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='1253'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='23f7173ff200ce31d305688bd13da6f8' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetReplicationRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;' name='callBlockingMethod' primary='true'><SourceLine endBytecode='737' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$SetReplicationRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetReplicationRequestProto' start='7122' end='7725' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 7122-7725]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetReplicationRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='517' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='518' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='518'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='35dd2889e871efe6abeb65934bf94f6c' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetSafeModeRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;' name='callBlockingMethod' primary='true'><SourceLine endBytecode='737' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$SetSafeModeRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetSafeModeRequestProto' start='46178' end='46688' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 46178-46688]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetSafeModeRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='922' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='923' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='923'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='7cb811de7a466971d08c37f87f44b88a' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetStoragePolicyRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;' name='callBlockingMethod' primary='true'><SourceLine endBytecode='737' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$SetStoragePolicyRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetStoragePolicyRequestProto' start='8208' end='8857' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 8208-8857]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetStoragePolicyRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='532' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='533' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='533'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='c19c853817b845f339702eb8e19d1246' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetTimesRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;' name='callBlockingMethod' primary='true'><SourceLine endBytecode='737' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$SetTimesRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetTimesRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetTimesRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='1282' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='1283' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='1283'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='d5d61302b2aeb336c228effdb46540b1' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$TruncateRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;' name='callBlockingMethod' primary='true'><SourceLine endBytecode='737' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$TruncateRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$TruncateRequestProto' start='24586' end='25323' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 24586-25323]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$TruncateRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='712' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='713' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='713'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='dccb43be7d2aed6d456a6594cdb245cb' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UnsetStoragePolicyRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;' name='callBlockingMethod' primary='true'><SourceLine endBytecode='737' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$UnsetStoragePolicyRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UnsetStoragePolicyRequestProto' start='9229' end='9720' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 9229-9720]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UnsetStoragePolicyRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='547' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='548' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='548'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='98be779fd783591cfade87bb1de0ebc8' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpdateBlockForPipelineRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;' name='callBlockingMethod' primary='true'><SourceLine endBytecode='737' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$UpdateBlockForPipelineRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpdateBlockForPipelineRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpdateBlockForPipelineRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='1327' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='1328' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='1328'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='3a93c4a8d3ea634e487b2a107aaa567a' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpdatePipelineRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;' name='callBlockingMethod' primary='true'><SourceLine endBytecode='737' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$UpdatePipelineRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpdatePipelineRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpdatePipelineRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='1342' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='1343' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='1343'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='753e4fa6d53bc482687807fc57f20314' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpgradeStatusRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;' name='callBlockingMethod' primary='true'><SourceLine endBytecode='737' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$UpgradeStatusRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpgradeStatusRequestProto' start='51250' end='51581' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 51250-51581]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpgradeStatusRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='1012' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='1013' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='1013'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='4f459a279ade1685e548d1419c0f85b6' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$CreateEncryptionZoneRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;' name='callBlockingMethod' primary='true'><SourceLine endBytecode='737' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/EncryptionZonesProtos$CreateEncryptionZoneRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$CreateEncryptionZoneRequestProto' start='220' end='861' sourcepath='org/apache/hadoop/hdfs/protocol/proto/EncryptionZonesProtos.java' sourcefile='EncryptionZonesProtos.java'><Message>At EncryptionZonesProtos.java:[lines 220-861]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$CreateEncryptionZoneRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='1732' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='1733' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='1733'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='adba772dd52c4e5e8d9ef9d97735ce7d' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$GetEZForPathRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;' name='callBlockingMethod' primary='true'><SourceLine endBytecode='737' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/EncryptionZonesProtos$GetEZForPathRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$GetEZForPathRequestProto' start='7259' end='7750' sourcepath='org/apache/hadoop/hdfs/protocol/proto/EncryptionZonesProtos.java' sourcefile='EncryptionZonesProtos.java'><Message>At EncryptionZonesProtos.java:[lines 7259-7750]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$GetEZForPathRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='1792' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='1793' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='1793'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='623621cf3803667a616971f16c28c10b' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ListEncryptionZonesRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;' name='callBlockingMethod' primary='true'><SourceLine endBytecode='737' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/EncryptionZonesProtos$ListEncryptionZonesRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ListEncryptionZonesRequestProto' start='1220' end='1641' sourcepath='org/apache/hadoop/hdfs/protocol/proto/EncryptionZonesProtos.java' sourcefile='EncryptionZonesProtos.java'><Message>At EncryptionZonesProtos.java:[lines 1220-1641]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ListEncryptionZonesRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='1747' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='1748' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='1748'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='560bb560247506f718d37e73564aeed6' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ListReencryptionStatusRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;' name='callBlockingMethod' primary='true'><SourceLine endBytecode='737' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/EncryptionZonesProtos$ListReencryptionStatusRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ListReencryptionStatusRequestProto' start='4448' end='4869' sourcepath='org/apache/hadoop/hdfs/protocol/proto/EncryptionZonesProtos.java' sourcefile='EncryptionZonesProtos.java'><Message>At EncryptionZonesProtos.java:[lines 4448-4869]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ListReencryptionStatusRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='1777' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='1778' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='1778'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='985ff938c650e026fef4f81a6f88285d' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ReencryptEncryptionZoneRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;' name='callBlockingMethod' primary='true'><SourceLine endBytecode='737' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/EncryptionZonesProtos$ReencryptEncryptionZoneRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ReencryptEncryptionZoneRequestProto' start='3501' end='4089' sourcepath='org/apache/hadoop/hdfs/protocol/proto/EncryptionZonesProtos.java' sourcefile='EncryptionZonesProtos.java'><Message>At EncryptionZonesProtos.java:[lines 3501-4089]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ReencryptEncryptionZoneRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='1762' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='1763' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='1763'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='d0ea3a1e8f2f2779666a936ffc2409fe' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$AddErasureCodingPoliciesRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;' name='callBlockingMethod' primary='true'><SourceLine endBytecode='737' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos$AddErasureCodingPoliciesRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$AddErasureCodingPoliciesRequestProto' start='4318' end='5003' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' sourcefile='ErasureCodingProtos.java'><Message>At ErasureCodingProtos.java:[lines 4318-5003]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$AddErasureCodingPoliciesRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='1882' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='1883' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='1883'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='91d2f874f5d2ba769b96308c73aa4dc1' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$DisableErasureCodingPolicyRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;' name='callBlockingMethod' primary='true'><SourceLine endBytecode='737' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos$DisableErasureCodingPolicyRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$DisableErasureCodingPolicyRequestProto' start='7460' end='7951' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' sourcefile='ErasureCodingProtos.java'><Message>At ErasureCodingProtos.java:[lines 7460-7951]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$DisableErasureCodingPolicyRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='1927' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='1928' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='1928'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='aca2c12506bdb56ff86e286d8117f86f' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$EnableErasureCodingPolicyRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;' name='callBlockingMethod' primary='true'><SourceLine endBytecode='737' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos$EnableErasureCodingPolicyRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$EnableErasureCodingPolicyRequestProto' start='6605' end='7096' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' sourcefile='ErasureCodingProtos.java'><Message>At ErasureCodingProtos.java:[lines 6605-7096]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$EnableErasureCodingPolicyRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='1912' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='1913' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='1913'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='d8994293f8efc7466521d3da3ba593bf' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingCodecsRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;' name='callBlockingMethod' primary='true'><SourceLine endBytecode='737' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos$GetErasureCodingCodecsRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingCodecsRequestProto' start='2108' end='2439' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' sourcefile='ErasureCodingProtos.java'><Message>At ErasureCodingProtos.java:[lines 2108-2439]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingCodecsRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='1957' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='1958' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='1958'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='a0fdb24ffdb5fd2d41e89af7015489fa' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingPoliciesRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;' name='callBlockingMethod' primary='true'><SourceLine endBytecode='737' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos$GetErasureCodingPoliciesRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingPoliciesRequestProto' start='1041' end='1372' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' sourcefile='ErasureCodingProtos.java'><Message>At ErasureCodingProtos.java:[lines 1041-1372]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingPoliciesRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='1867' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='1868' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='1868'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='84655d2e1a992142c315499b96baf305' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingPolicyRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;' name='callBlockingMethod' primary='true'><SourceLine endBytecode='737' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos$GetErasureCodingPolicyRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingPolicyRequestProto' start='3198' end='3725' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' sourcefile='ErasureCodingProtos.java'><Message>At ErasureCodingProtos.java:[lines 3198-3725]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingPolicyRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='1942' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='1943' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='1943'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='b469e06494e6583b1aea97bb5375a272' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$RemoveErasureCodingPolicyRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;' name='callBlockingMethod' primary='true'><SourceLine endBytecode='737' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos$RemoveErasureCodingPolicyRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$RemoveErasureCodingPolicyRequestProto' start='5750' end='6241' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' sourcefile='ErasureCodingProtos.java'><Message>At ErasureCodingProtos.java:[lines 5750-6241]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$RemoveErasureCodingPolicyRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='1897' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='1898' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='1898'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='8540fa3ef07149c79bd8ed852f99337c' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$SetErasureCodingPolicyRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;' name='callBlockingMethod' primary='true'><SourceLine endBytecode='737' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos$SetErasureCodingPolicyRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$SetErasureCodingPolicyRequestProto' start='47' end='688' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' sourcefile='ErasureCodingProtos.java'><Message>At ErasureCodingProtos.java:[lines 47-688]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$SetErasureCodingPolicyRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='1807' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='1808' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='1808'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='16bc31763d980559a56ce6214a612b57' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$UnsetErasureCodingPolicyRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;' name='callBlockingMethod' primary='true'><SourceLine endBytecode='737' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos$UnsetErasureCodingPolicyRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$UnsetErasureCodingPolicyRequestProto' start='8315' end='8806' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' sourcefile='ErasureCodingProtos.java'><Message>At ErasureCodingProtos.java:[lines 8315-8806]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$UnsetErasureCodingPolicyRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='1822' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='1823' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='1823'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='4ff1a094dda1363f6f957a1944d466dc' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$GetXAttrsRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;' name='callBlockingMethod' primary='true'><SourceLine endBytecode='737' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/XAttrProtos$GetXAttrsRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$GetXAttrsRequestProto' start='2155' end='3001' sourcepath='org/apache/hadoop/hdfs/protocol/proto/XAttrProtos.java' sourcefile='XAttrProtos.java'><Message>At XAttrProtos.java:[lines 2155-3001]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$GetXAttrsRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='1672' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='1673' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='1673'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='33a4e203537dcf7cfa54666d8f4d56d9' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$ListXAttrsRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;' name='callBlockingMethod' primary='true'><SourceLine endBytecode='737' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/XAttrProtos$ListXAttrsRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$ListXAttrsRequestProto' start='3748' end='4239' sourcepath='org/apache/hadoop/hdfs/protocol/proto/XAttrProtos.java' sourcefile='XAttrProtos.java'><Message>At XAttrProtos.java:[lines 3748-4239]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$ListXAttrsRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='1687' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='1688' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='1688'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='15182b213f0f75fb8c2f3e9a04e1ced3' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$RemoveXAttrRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;' name='callBlockingMethod' primary='true'><SourceLine endBytecode='737' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/XAttrProtos$RemoveXAttrRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$RemoveXAttrRequestProto' start='5000' end='5690' sourcepath='org/apache/hadoop/hdfs/protocol/proto/XAttrProtos.java' sourcefile='XAttrProtos.java'><Message>At XAttrProtos.java:[lines 5000-5690]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$RemoveXAttrRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='1702' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='1703' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='1703'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='2377972494bf2a849928e9ec862023cf' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$SetXAttrRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;' name='callBlockingMethod' primary='true'><SourceLine endBytecode='737' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/XAttrProtos$SetXAttrRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$SetXAttrRequestProto' start='972' end='1766' sourcepath='org/apache/hadoop/hdfs/protocol/proto/XAttrProtos.java' sourcefile='XAttrProtos.java'><Message>At XAttrProtos.java:[lines 972-1766]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$SetXAttrRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='1657' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='1658' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='1658'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='be62e76b10a1f6878812fa56e64115ab' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.security.proto.SecurityProtos$CancelDelegationTokenRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;' name='callBlockingMethod' primary='true'><SourceLine endBytecode='737' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/security/proto/SecurityProtos$CancelDelegationTokenRequestProto;'><SourceLine classname='org.apache.hadoop.security.proto.SecurityProtos$CancelDelegationTokenRequestProto' start='4934' end='5470' sourcepath='org/apache/hadoop/security/proto/SecurityProtos.java' sourcefile='SecurityProtos.java'><Message>At SecurityProtos.java:[lines 4934-5470]</Message></SourceLine><Message>Expected org.apache.hadoop.security.proto.SecurityProtos$CancelDelegationTokenRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='1387' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='1388' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='1388'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='31a74360f47c70367304e514c32c74c4' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.security.proto.SecurityProtos$GetDelegationTokenRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;' name='callBlockingMethod' primary='true'><SourceLine endBytecode='737' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/security/proto/SecurityProtos$GetDelegationTokenRequestProto;'><SourceLine classname='org.apache.hadoop.security.proto.SecurityProtos$GetDelegationTokenRequestProto' start='2858' end='3349' sourcepath='org/apache/hadoop/security/proto/SecurityProtos.java' sourcefile='SecurityProtos.java'><Message>At SecurityProtos.java:[lines 2858-3349]</Message></SourceLine><Message>Expected org.apache.hadoop.security.proto.SecurityProtos$GetDelegationTokenRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='1357' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='1358' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='1358'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='bd7aafe665a33edf70a8be3eba74f4a2' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.security.proto.SecurityProtos$RenewDelegationTokenRequestProto in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;' name='callBlockingMethod' primary='true'><SourceLine endBytecode='737' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/security/proto/SecurityProtos$RenewDelegationTokenRequestProto;'><SourceLine classname='org.apache.hadoop.security.proto.SecurityProtos$RenewDelegationTokenRequestProto' start='3931' end='4467' sourcepath='org/apache/hadoop/security/proto/SecurityProtos.java' sourcefile='SecurityProtos.java'><Message>At SecurityProtos.java:[lines 3931-4467]</Message></SourceLine><Message>Expected org.apache.hadoop.security.proto.SecurityProtos$RenewDelegationTokenRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='1372' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='1373' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='1373'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='eefa477a1a30179427f6b8a5701cabbf' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CompleteRequestProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CompleteRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CompleteRequestProto' start='21020' end='21972' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 21020-21972]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CompleteRequestProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CompleteRequestProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CompleteRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CompleteRequestProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CompleteRequestProto' start='21120' end='21120' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='7' primary='true'><Message>At ClientNamenodeProtocolProtos.java:[line 21120]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='fdf9e8b45093bd2858b95a29d10491a' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CompleteRequestProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CompleteRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CompleteRequestProto' start='21020' end='21972' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 21020-21972]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CompleteRequestProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CompleteRequestProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CompleteRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CompleteRequestProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CompleteRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='816dffc62fe75afa03a837cc3c86485c' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CompleteResponseProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CompleteResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CompleteResponseProto' start='21993' end='22414' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 21993-22414]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CompleteResponseProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CompleteResponseProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CompleteResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CompleteResponseProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CompleteResponseProto' start='22070' end='22070' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='7' primary='true'><Message>At ClientNamenodeProtocolProtos.java:[line 22070]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='687f4e871638bc5e3f0e760f5a887cb' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CompleteResponseProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CompleteResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CompleteResponseProto' start='21993' end='22414' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 21993-22414]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CompleteResponseProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CompleteResponseProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CompleteResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CompleteResponseProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CompleteResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='59776c4515a002103f2405d98d61452a' rank='17' abbrev='UCF' category='STYLE' priority='2' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CompleteResponseProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CompleteResponseProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CompleteResponseProto$Builder' start='22256' end='22405' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 22256-22405]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CompleteResponseProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CompleteResponseProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine endBytecode='61' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CompleteResponseProto$Builder' start='22282' end='22284' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CompleteResponseProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CompleteResponseProto$Builder' start='22282' end='22282' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='3' primary='true'><Message>At ClientNamenodeProtocolProtos.java:[line 22282]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='4addeae21e74fe8b096278f272bb7fca' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ConcatRequestProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ConcatRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ConcatRequestProto' start='23527' end='24189' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 23527-24189]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ConcatRequestProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ConcatRequestProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ConcatRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ConcatRequestProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ConcatRequestProto' start='23615' end='23615' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='7' primary='true'><Message>At ClientNamenodeProtocolProtos.java:[line 23615]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='644974027fad0f76e23f1bdb355d525b' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ConcatRequestProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ConcatRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ConcatRequestProto' start='23527' end='24189' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 23527-24189]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ConcatRequestProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ConcatRequestProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ConcatRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ConcatRequestProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ConcatRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='5626e5cf4eddd9befa18f62b62752a8c' rank='17' abbrev='UCF' category='STYLE' priority='2' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ConcatRequestProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ConcatRequestProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ConcatRequestProto$Builder' start='23877' end='24180' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 23877-24180]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ConcatRequestProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ConcatRequestProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine endBytecode='61' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ConcatRequestProto$Builder' start='23903' end='23905' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ConcatRequestProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ConcatRequestProto$Builder' start='23903' end='23903' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='3' primary='true'><Message>At ClientNamenodeProtocolProtos.java:[line 23903]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='b2ff4c317354aca4e15d5793490c3b0f' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ConcatResponseProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ConcatResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ConcatResponseProto' start='24204' end='24535' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 24204-24535]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ConcatResponseProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ConcatResponseProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ConcatResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ConcatResponseProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ConcatResponseProto' start='24275' end='24275' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='7' primary='true'><Message>At ClientNamenodeProtocolProtos.java:[line 24275]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='5555ccebaf0210a8cae71e934650becb' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ConcatResponseProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ConcatResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ConcatResponseProto' start='24204' end='24535' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 24204-24535]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ConcatResponseProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ConcatResponseProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ConcatResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ConcatResponseProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ConcatResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='731e5b258eabab782d1f50c29a72a786' rank='17' abbrev='UCF' category='STYLE' priority='2' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ConcatResponseProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ConcatResponseProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ConcatResponseProto$Builder' start='24427' end='24526' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 24427-24526]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ConcatResponseProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ConcatResponseProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine endBytecode='61' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ConcatResponseProto$Builder' start='24453' end='24455' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ConcatResponseProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ConcatResponseProto$Builder' start='24453' end='24453' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='3' primary='true'><Message>At ClientNamenodeProtocolProtos.java:[line 24453]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='573a1afe13748542e7db86a09c180f7e' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateRequestProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateRequestProto' start='3172' end='4939' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 3172-4939]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateRequestProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateRequestProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateRequestProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateRequestProto' start='3341' end='3341' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='7' primary='true'><Message>At ClientNamenodeProtocolProtos.java:[line 3341]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='9796d0a10f78e342fbc300df576ee923' rank='19' abbrev='Nm' category='BAD_PRACTICE' priority='3' type='NM_CONFUSING' instanceOccurrenceMax='0'><ShortMessage>Confusing method names</ShortMessage><LongMessage>Confusing to have methods org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateRequestProto.hasBlockSize() and org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$HdfsFileStatusProto.hasBlocksize()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateRequestProto' start='3172' end='4939' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 3172-4939]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateRequestProto</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateRequestProto' signature='()Z' name='hasBlockSize' primary='true'><SourceLine endBytecode='70' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateRequestProto' start='3536' end='3536' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateRequestProto.hasBlockSize()</Message></Method><Class classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$HdfsFileStatusProto'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$HdfsFileStatusProto' start='32811' end='35792' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>At HdfsProtos.java:[lines 32811-35792]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$HdfsFileStatusProto</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$HdfsFileStatusProto' signature='()Z' name='hasBlocksize'><SourceLine endBytecode='72' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$HdfsFileStatusProto' start='33501' end='33501' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$HdfsFileStatusProto.hasBlocksize()</Message></Method><SourceLine synthetic='true' endBytecode='70' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateRequestProto' start='3536' end='3536' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'><Message>At ClientNamenodeProtocolProtos.java:[line 3536]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='677f7ad19aac04e0977777d6d18d87ac' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateRequestProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateRequestProto' start='3172' end='4939' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 3172-4939]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateRequestProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateRequestProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateRequestProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='f8b21087f0acce714a4f97ce3a6b587a' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateResponseProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateResponseProto' start='4964' end='5496' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 4964-5496]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateResponseProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateResponseProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateResponseProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateResponseProto' start='5049' end='5049' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='7' primary='true'><Message>At ClientNamenodeProtocolProtos.java:[line 5049]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='62f92a4dbea03f836772a04580f53b48' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateResponseProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateResponseProto' start='4964' end='5496' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 4964-5496]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateResponseProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateResponseProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateResponseProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='952951638b1d4ec82e9fcb88fbefe943' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateSnapshotRequestProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateSnapshotRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateSnapshotRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateSnapshotRequestProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateSnapshotRequestProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateSnapshotRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateSnapshotRequestProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateSnapshotRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='7'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='a62d43a89c36e984b6b63287396fac00' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateSnapshotRequestProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateSnapshotRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateSnapshotRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateSnapshotRequestProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateSnapshotRequestProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateSnapshotRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateSnapshotRequestProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateSnapshotRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='9e68091e61c18117e7628a1cef06c2e' rank='20' abbrev='UCF' category='STYLE' priority='3' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateSnapshotRequestProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateSnapshotRequestProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateSnapshotRequestProto$Builder' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateSnapshotRequestProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateSnapshotRequestProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateSnapshotRequestProto$Builder' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateSnapshotRequestProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateSnapshotRequestProto$Builder' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='3'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='7c0fb977286de3ebe09a964dc05d49f6' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateSnapshotResponseProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateSnapshotResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateSnapshotResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateSnapshotResponseProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateSnapshotResponseProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateSnapshotResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateSnapshotResponseProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateSnapshotResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='7'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='15312be04b6cdc4e91f22b7271c3263f' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateSnapshotResponseProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateSnapshotResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateSnapshotResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateSnapshotResponseProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateSnapshotResponseProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateSnapshotResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateSnapshotResponseProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateSnapshotResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='6b897c2ce6b6e38977dabdeabed9fdaa' rank='20' abbrev='UCF' category='STYLE' priority='3' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateSnapshotResponseProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateSnapshotResponseProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateSnapshotResponseProto$Builder' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateSnapshotResponseProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateSnapshotResponseProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateSnapshotResponseProto$Builder' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateSnapshotResponseProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateSnapshotResponseProto$Builder' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='3'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='4a494dba5b575d096e3561339c47cae0' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateSymlinkRequestProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateSymlinkRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateSymlinkRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateSymlinkRequestProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateSymlinkRequestProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateSymlinkRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateSymlinkRequestProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateSymlinkRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='7'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='c11c3ac9739371e77eddd47e26fb4278' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateSymlinkRequestProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateSymlinkRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateSymlinkRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateSymlinkRequestProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateSymlinkRequestProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateSymlinkRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateSymlinkRequestProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateSymlinkRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='cbf8373e731dd8a2848cf20c0084ab2a' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateSymlinkResponseProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateSymlinkResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateSymlinkResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateSymlinkResponseProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateSymlinkResponseProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateSymlinkResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateSymlinkResponseProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateSymlinkResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='7'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='4879bf169da0d480ac49c5270efa78ad' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateSymlinkResponseProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateSymlinkResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateSymlinkResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateSymlinkResponseProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateSymlinkResponseProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateSymlinkResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateSymlinkResponseProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateSymlinkResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='610a033821180d7e5f603fd17dcbac69' rank='20' abbrev='UCF' category='STYLE' priority='3' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateSymlinkResponseProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateSymlinkResponseProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateSymlinkResponseProto$Builder' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateSymlinkResponseProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateSymlinkResponseProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateSymlinkResponseProto$Builder' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateSymlinkResponseProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateSymlinkResponseProto$Builder' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='3'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='1545664e8429e73e7a5935827747eccc' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DatanodeStorageReportProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DatanodeStorageReportProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DatanodeStorageReportProto' start='43576' end='44467' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 43576-44467]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DatanodeStorageReportProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DatanodeStorageReportProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DatanodeStorageReportProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DatanodeStorageReportProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DatanodeStorageReportProto' start='43672' end='43672' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='7' primary='true'><Message>At ClientNamenodeProtocolProtos.java:[line 43672]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='ff848d8ddee9c37f2f45aa6b8ab5a84f' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DatanodeStorageReportProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DatanodeStorageReportProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DatanodeStorageReportProto' start='43576' end='44467' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 43576-44467]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DatanodeStorageReportProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DatanodeStorageReportProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DatanodeStorageReportProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DatanodeStorageReportProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DatanodeStorageReportProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='55ecb429ecb43b42d21437ec2f77c652' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DeleteRequestProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DeleteRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DeleteRequestProto' start='28157' end='28736' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 28157-28736]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DeleteRequestProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DeleteRequestProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DeleteRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DeleteRequestProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DeleteRequestProto' start='28239' end='28239' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='7' primary='true'><Message>At ClientNamenodeProtocolProtos.java:[line 28239]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='bafeae2b98ce48896c5d98fa8f53db89' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DeleteRequestProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DeleteRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DeleteRequestProto' start='28157' end='28736' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 28157-28736]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DeleteRequestProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DeleteRequestProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DeleteRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DeleteRequestProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DeleteRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='2a94f4a8b68fb3082b592d1cdc9c30ea' rank='17' abbrev='UCF' category='STYLE' priority='2' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DeleteRequestProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DeleteRequestProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DeleteRequestProto$Builder' start='28489' end='28727' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 28489-28727]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DeleteRequestProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DeleteRequestProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine endBytecode='61' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DeleteRequestProto$Builder' start='28515' end='28517' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DeleteRequestProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DeleteRequestProto$Builder' start='28515' end='28515' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='3' primary='true'><Message>At ClientNamenodeProtocolProtos.java:[line 28515]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='f5141b556bc9bd0b75ce14d00e7cb65e' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DeleteResponseProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DeleteResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DeleteResponseProto' start='28757' end='29178' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 28757-29178]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DeleteResponseProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DeleteResponseProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DeleteResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DeleteResponseProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DeleteResponseProto' start='28834' end='28834' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='7' primary='true'><Message>At ClientNamenodeProtocolProtos.java:[line 28834]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='901ba6758613e0e6d821a15defc4790d' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DeleteResponseProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DeleteResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DeleteResponseProto' start='28757' end='29178' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 28757-29178]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DeleteResponseProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DeleteResponseProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DeleteResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DeleteResponseProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DeleteResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='11d126219238d3701f95b57261c8bef7' rank='17' abbrev='UCF' category='STYLE' priority='2' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DeleteResponseProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DeleteResponseProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DeleteResponseProto$Builder' start='29020' end='29169' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 29020-29169]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DeleteResponseProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DeleteResponseProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine endBytecode='61' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DeleteResponseProto$Builder' start='29046' end='29048' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DeleteResponseProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DeleteResponseProto$Builder' start='29046' end='29046' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='3' primary='true'><Message>At ClientNamenodeProtocolProtos.java:[line 29046]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='7a59cd20bb641d61c838b643e3dfce64' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DeleteSnapshotRequestProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DeleteSnapshotRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DeleteSnapshotRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DeleteSnapshotRequestProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DeleteSnapshotRequestProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DeleteSnapshotRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DeleteSnapshotRequestProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DeleteSnapshotRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='7'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='dc2692028a1189a855f4ce7c2cb67183' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DeleteSnapshotRequestProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DeleteSnapshotRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DeleteSnapshotRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DeleteSnapshotRequestProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DeleteSnapshotRequestProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DeleteSnapshotRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DeleteSnapshotRequestProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DeleteSnapshotRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='19e37c3471b4106899e69f83e01b957d' rank='20' abbrev='UCF' category='STYLE' priority='3' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DeleteSnapshotRequestProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DeleteSnapshotRequestProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DeleteSnapshotRequestProto$Builder' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DeleteSnapshotRequestProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DeleteSnapshotRequestProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DeleteSnapshotRequestProto$Builder' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DeleteSnapshotRequestProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DeleteSnapshotRequestProto$Builder' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='3'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='1e43b2c3c25abd09bdcbda213992c426' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DeleteSnapshotResponseProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DeleteSnapshotResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DeleteSnapshotResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DeleteSnapshotResponseProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DeleteSnapshotResponseProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DeleteSnapshotResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DeleteSnapshotResponseProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DeleteSnapshotResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='7'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='107435bee77cf3539619bc9ee30ed5ca' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DeleteSnapshotResponseProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DeleteSnapshotResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DeleteSnapshotResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DeleteSnapshotResponseProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DeleteSnapshotResponseProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DeleteSnapshotResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DeleteSnapshotResponseProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DeleteSnapshotResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='f63009ca7759ed01dc329589f829cb18' rank='20' abbrev='UCF' category='STYLE' priority='3' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DeleteSnapshotResponseProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DeleteSnapshotResponseProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DeleteSnapshotResponseProto$Builder' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DeleteSnapshotResponseProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DeleteSnapshotResponseProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DeleteSnapshotResponseProto$Builder' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DeleteSnapshotResponseProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DeleteSnapshotResponseProto$Builder' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='3'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='1791fcc0e81bbcdf729b7b7af2c102b7' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DisallowSnapshotRequestProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DisallowSnapshotRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DisallowSnapshotRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DisallowSnapshotRequestProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DisallowSnapshotRequestProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DisallowSnapshotRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DisallowSnapshotRequestProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DisallowSnapshotRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='7'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='e8711b34cae961e96b34345711823b8d' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DisallowSnapshotRequestProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DisallowSnapshotRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DisallowSnapshotRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DisallowSnapshotRequestProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DisallowSnapshotRequestProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DisallowSnapshotRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DisallowSnapshotRequestProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DisallowSnapshotRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='dffb45e6f56ab8251c5557d67abd95aa' rank='20' abbrev='UCF' category='STYLE' priority='3' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DisallowSnapshotRequestProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DisallowSnapshotRequestProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DisallowSnapshotRequestProto$Builder' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DisallowSnapshotRequestProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DisallowSnapshotRequestProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DisallowSnapshotRequestProto$Builder' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DisallowSnapshotRequestProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DisallowSnapshotRequestProto$Builder' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='3'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='48b82a8be16a7916d8afa7fc51844654' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DisallowSnapshotResponseProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DisallowSnapshotResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DisallowSnapshotResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DisallowSnapshotResponseProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DisallowSnapshotResponseProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DisallowSnapshotResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DisallowSnapshotResponseProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DisallowSnapshotResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='7'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='ab8343f04dbc7025eb44c07913cc579f' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DisallowSnapshotResponseProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DisallowSnapshotResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DisallowSnapshotResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DisallowSnapshotResponseProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DisallowSnapshotResponseProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DisallowSnapshotResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DisallowSnapshotResponseProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DisallowSnapshotResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='5f8b2897b262875155af288055942030' rank='20' abbrev='UCF' category='STYLE' priority='3' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DisallowSnapshotResponseProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DisallowSnapshotResponseProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DisallowSnapshotResponseProto$Builder' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DisallowSnapshotResponseProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DisallowSnapshotResponseProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DisallowSnapshotResponseProto$Builder' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DisallowSnapshotResponseProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DisallowSnapshotResponseProto$Builder' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='3'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='38991f2001ff2afd28ff5852a187335d' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$FinalizeUpgradeRequestProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$FinalizeUpgradeRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$FinalizeUpgradeRequestProto' start='50558' end='50889' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 50558-50889]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$FinalizeUpgradeRequestProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$FinalizeUpgradeRequestProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$FinalizeUpgradeRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$FinalizeUpgradeRequestProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$FinalizeUpgradeRequestProto' start='50629' end='50629' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='7' primary='true'><Message>At ClientNamenodeProtocolProtos.java:[line 50629]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='7161d785b14fd22c00ba882e5e0a1d96' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$FinalizeUpgradeRequestProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$FinalizeUpgradeRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$FinalizeUpgradeRequestProto' start='50558' end='50889' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 50558-50889]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$FinalizeUpgradeRequestProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$FinalizeUpgradeRequestProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$FinalizeUpgradeRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$FinalizeUpgradeRequestProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$FinalizeUpgradeRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='10029d8fa0d8c631eeefdad23adb2c16' rank='17' abbrev='UCF' category='STYLE' priority='2' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$FinalizeUpgradeRequestProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$FinalizeUpgradeRequestProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$FinalizeUpgradeRequestProto$Builder' start='50781' end='50880' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 50781-50880]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$FinalizeUpgradeRequestProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$FinalizeUpgradeRequestProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine endBytecode='61' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$FinalizeUpgradeRequestProto$Builder' start='50807' end='50809' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$FinalizeUpgradeRequestProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$FinalizeUpgradeRequestProto$Builder' start='50807' end='50807' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='3' primary='true'><Message>At ClientNamenodeProtocolProtos.java:[line 50807]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='fc9e56dc99c97dab85d451554308407e' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$FinalizeUpgradeResponseProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$FinalizeUpgradeResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$FinalizeUpgradeResponseProto' start='50904' end='51235' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 50904-51235]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$FinalizeUpgradeResponseProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$FinalizeUpgradeResponseProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$FinalizeUpgradeResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$FinalizeUpgradeResponseProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$FinalizeUpgradeResponseProto' start='50975' end='50975' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='7' primary='true'><Message>At ClientNamenodeProtocolProtos.java:[line 50975]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='ac7172fc6552feaf16607af6e81b4474' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$FinalizeUpgradeResponseProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$FinalizeUpgradeResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$FinalizeUpgradeResponseProto' start='50904' end='51235' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 50904-51235]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$FinalizeUpgradeResponseProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$FinalizeUpgradeResponseProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$FinalizeUpgradeResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$FinalizeUpgradeResponseProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$FinalizeUpgradeResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='2e736749c408f07640671b7820dd1061' rank='17' abbrev='UCF' category='STYLE' priority='2' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$FinalizeUpgradeResponseProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$FinalizeUpgradeResponseProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$FinalizeUpgradeResponseProto$Builder' start='51127' end='51226' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 51127-51226]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$FinalizeUpgradeResponseProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$FinalizeUpgradeResponseProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine endBytecode='61' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$FinalizeUpgradeResponseProto$Builder' start='51153' end='51155' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$FinalizeUpgradeResponseProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$FinalizeUpgradeResponseProto$Builder' start='51153' end='51153' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='3' primary='true'><Message>At ClientNamenodeProtocolProtos.java:[line 51153]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='4946b47f0a4c09b8020df20dce903850' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$FsyncRequestProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$FsyncRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$FsyncRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$FsyncRequestProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$FsyncRequestProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$FsyncRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$FsyncRequestProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$FsyncRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='7'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='8c710e2302c8165d4fb1f8b1c9fd10aa' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$FsyncRequestProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$FsyncRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$FsyncRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$FsyncRequestProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$FsyncRequestProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$FsyncRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$FsyncRequestProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$FsyncRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='67518ff9bae3bb1f2928afa3713da0d6' rank='20' abbrev='UCF' category='STYLE' priority='3' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$FsyncRequestProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$FsyncRequestProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$FsyncRequestProto$Builder' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$FsyncRequestProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$FsyncRequestProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$FsyncRequestProto$Builder' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$FsyncRequestProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$FsyncRequestProto$Builder' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='3'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='b7148a57e1417203279b46f25818d6fc' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$FsyncResponseProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$FsyncResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$FsyncResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$FsyncResponseProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$FsyncResponseProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$FsyncResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$FsyncResponseProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$FsyncResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='7'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='e91a31b3e42f28797bf8fc97e8dc4b0e' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$FsyncResponseProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$FsyncResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$FsyncResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$FsyncResponseProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$FsyncResponseProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$FsyncResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$FsyncResponseProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$FsyncResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='57699f5e1107ee1333865a1458fca35c' rank='20' abbrev='UCF' category='STYLE' priority='3' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$FsyncResponseProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$FsyncResponseProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$FsyncResponseProto$Builder' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$FsyncResponseProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$FsyncResponseProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$FsyncResponseProto$Builder' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$FsyncResponseProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$FsyncResponseProto$Builder' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='3'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='f4c6f0f1b6a98b1f51d094b0ebdc9474' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetAdditionalDatanodeRequestProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetAdditionalDatanodeRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetAdditionalDatanodeRequestProto' start='18461' end='20386' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 18461-20386]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetAdditionalDatanodeRequestProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetAdditionalDatanodeRequestProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetAdditionalDatanodeRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetAdditionalDatanodeRequestProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetAdditionalDatanodeRequestProto' start='18599' end='18599' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='7' primary='true'><Message>At ClientNamenodeProtocolProtos.java:[line 18599]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='b846e5d4b24abd3407da64af4ce3f4a3' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetAdditionalDatanodeRequestProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetAdditionalDatanodeRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetAdditionalDatanodeRequestProto' start='18461' end='20386' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 18461-20386]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetAdditionalDatanodeRequestProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetAdditionalDatanodeRequestProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetAdditionalDatanodeRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetAdditionalDatanodeRequestProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetAdditionalDatanodeRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='c9a50840b465e59a62ec4b6f19f4d60d' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetAdditionalDatanodeResponseProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetAdditionalDatanodeResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetAdditionalDatanodeResponseProto' start='20411' end='20947' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 20411-20947]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetAdditionalDatanodeResponseProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetAdditionalDatanodeResponseProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetAdditionalDatanodeResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetAdditionalDatanodeResponseProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetAdditionalDatanodeResponseProto' start='20496' end='20496' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='7' primary='true'><Message>At ClientNamenodeProtocolProtos.java:[line 20496]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='b5429a1bbbdc46198696c6dd80ed3588' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetAdditionalDatanodeResponseProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetAdditionalDatanodeResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetAdditionalDatanodeResponseProto' start='20411' end='20947' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 20411-20947]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetAdditionalDatanodeResponseProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetAdditionalDatanodeResponseProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetAdditionalDatanodeResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetAdditionalDatanodeResponseProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetAdditionalDatanodeResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='23e9500145ea239622a0afc00c4f8395' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetBlockLocationsRequestProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetBlockLocationsRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetBlockLocationsRequestProto' start='803' end='1554' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 803-1554]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetBlockLocationsRequestProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetBlockLocationsRequestProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetBlockLocationsRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetBlockLocationsRequestProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetBlockLocationsRequestProto' start='890' end='890' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='7' primary='true'><Message>At ClientNamenodeProtocolProtos.java:[line 890]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='f4db399f12f2c45c9e3339ad75081530' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetBlockLocationsRequestProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetBlockLocationsRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetBlockLocationsRequestProto' start='803' end='1554' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 803-1554]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetBlockLocationsRequestProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetBlockLocationsRequestProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetBlockLocationsRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetBlockLocationsRequestProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetBlockLocationsRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='3705180bef8086a53bd8e24910c7c846' rank='17' abbrev='UCF' category='STYLE' priority='2' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetBlockLocationsRequestProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetBlockLocationsRequestProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetBlockLocationsRequestProto$Builder' start='1205' end='1545' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 1205-1545]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetBlockLocationsRequestProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetBlockLocationsRequestProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine endBytecode='61' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetBlockLocationsRequestProto$Builder' start='1231' end='1233' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetBlockLocationsRequestProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetBlockLocationsRequestProto$Builder' start='1231' end='1231' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='3' primary='true'><Message>At ClientNamenodeProtocolProtos.java:[line 1231]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='7775fb451e3c641833e0c3f43bc205ff' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetBlockLocationsResponseProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetBlockLocationsResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetBlockLocationsResponseProto' start='1579' end='2111' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 1579-2111]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetBlockLocationsResponseProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetBlockLocationsResponseProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetBlockLocationsResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetBlockLocationsResponseProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetBlockLocationsResponseProto' start='1664' end='1664' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='7' primary='true'><Message>At ClientNamenodeProtocolProtos.java:[line 1664]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='f33261ad9cd1265ca12b2a6b5f7c04d4' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetBlockLocationsResponseProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetBlockLocationsResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetBlockLocationsResponseProto' start='1579' end='2111' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 1579-2111]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetBlockLocationsResponseProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetBlockLocationsResponseProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetBlockLocationsResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetBlockLocationsResponseProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetBlockLocationsResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='d6840b09f6500ac075c629b94564e810' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetContentSummaryRequestProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetContentSummaryRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetContentSummaryRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetContentSummaryRequestProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetContentSummaryRequestProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetContentSummaryRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetContentSummaryRequestProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetContentSummaryRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='7'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='4f62c7575d32de8ff84c92af11b88ed5' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetContentSummaryRequestProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetContentSummaryRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetContentSummaryRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetContentSummaryRequestProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetContentSummaryRequestProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetContentSummaryRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetContentSummaryRequestProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetContentSummaryRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='a18ea2209c266d8539cb130faf05c1ac' rank='20' abbrev='UCF' category='STYLE' priority='3' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetContentSummaryRequestProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetContentSummaryRequestProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetContentSummaryRequestProto$Builder' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetContentSummaryRequestProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetContentSummaryRequestProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetContentSummaryRequestProto$Builder' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetContentSummaryRequestProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetContentSummaryRequestProto$Builder' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='3'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='3ea85410aaf879e35f3d49e6ff9c8100' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetContentSummaryResponseProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetContentSummaryResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetContentSummaryResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetContentSummaryResponseProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetContentSummaryResponseProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetContentSummaryResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetContentSummaryResponseProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetContentSummaryResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='7'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='1831a6e43708e8fafe822ead14d2c53c' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetContentSummaryResponseProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetContentSummaryResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetContentSummaryResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetContentSummaryResponseProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetContentSummaryResponseProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetContentSummaryResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetContentSummaryResponseProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetContentSummaryResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='5eea614355171a791dcee111f0c285ea' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetCurrentEditLogTxidRequestProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetCurrentEditLogTxidRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetCurrentEditLogTxidRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetCurrentEditLogTxidRequestProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetCurrentEditLogTxidRequestProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetCurrentEditLogTxidRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetCurrentEditLogTxidRequestProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetCurrentEditLogTxidRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='7'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='1c54c52793b052c1925a85117ba64a32' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetCurrentEditLogTxidRequestProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetCurrentEditLogTxidRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetCurrentEditLogTxidRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetCurrentEditLogTxidRequestProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetCurrentEditLogTxidRequestProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetCurrentEditLogTxidRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetCurrentEditLogTxidRequestProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetCurrentEditLogTxidRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='77cc03385558dafb6dbdd1ec586efcf0' rank='20' abbrev='UCF' category='STYLE' priority='3' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetCurrentEditLogTxidRequestProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetCurrentEditLogTxidRequestProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetCurrentEditLogTxidRequestProto$Builder' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetCurrentEditLogTxidRequestProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetCurrentEditLogTxidRequestProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetCurrentEditLogTxidRequestProto$Builder' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetCurrentEditLogTxidRequestProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetCurrentEditLogTxidRequestProto$Builder' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='3'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='e5c8f643c4fd4b1d6dd4d71b425ca8f8' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetCurrentEditLogTxidResponseProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetCurrentEditLogTxidResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetCurrentEditLogTxidResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetCurrentEditLogTxidResponseProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetCurrentEditLogTxidResponseProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetCurrentEditLogTxidResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetCurrentEditLogTxidResponseProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetCurrentEditLogTxidResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='7'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='be60112fc132e79e18d68523ff63e3e3' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetCurrentEditLogTxidResponseProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetCurrentEditLogTxidResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetCurrentEditLogTxidResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetCurrentEditLogTxidResponseProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetCurrentEditLogTxidResponseProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetCurrentEditLogTxidResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetCurrentEditLogTxidResponseProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetCurrentEditLogTxidResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='686366f4b0dae5e77a1e3afacc52199b' rank='20' abbrev='UCF' category='STYLE' priority='3' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetCurrentEditLogTxidResponseProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetCurrentEditLogTxidResponseProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetCurrentEditLogTxidResponseProto$Builder' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetCurrentEditLogTxidResponseProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetCurrentEditLogTxidResponseProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetCurrentEditLogTxidResponseProto$Builder' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetCurrentEditLogTxidResponseProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetCurrentEditLogTxidResponseProto$Builder' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='3'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='87920216f53b899307a70313de61726e' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDataEncryptionKeyRequestProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDataEncryptionKeyRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDataEncryptionKeyRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDataEncryptionKeyRequestProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDataEncryptionKeyRequestProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDataEncryptionKeyRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDataEncryptionKeyRequestProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDataEncryptionKeyRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='7'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='7f4d877bfc0eebb0e2d18d8dfc9a7643' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDataEncryptionKeyRequestProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDataEncryptionKeyRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDataEncryptionKeyRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDataEncryptionKeyRequestProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDataEncryptionKeyRequestProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDataEncryptionKeyRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDataEncryptionKeyRequestProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDataEncryptionKeyRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='d65eac1f45f1034dc31e86ebd5284672' rank='20' abbrev='UCF' category='STYLE' priority='3' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDataEncryptionKeyRequestProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDataEncryptionKeyRequestProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDataEncryptionKeyRequestProto$Builder' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDataEncryptionKeyRequestProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDataEncryptionKeyRequestProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDataEncryptionKeyRequestProto$Builder' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDataEncryptionKeyRequestProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDataEncryptionKeyRequestProto$Builder' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='3'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='8522581d9e1a74c54772d5ab1ad0ff7d' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDataEncryptionKeyResponseProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDataEncryptionKeyResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDataEncryptionKeyResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDataEncryptionKeyResponseProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDataEncryptionKeyResponseProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDataEncryptionKeyResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDataEncryptionKeyResponseProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDataEncryptionKeyResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='7'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='ec2b929f6b2e90daa39ff13f428987ee' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDataEncryptionKeyResponseProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDataEncryptionKeyResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDataEncryptionKeyResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDataEncryptionKeyResponseProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDataEncryptionKeyResponseProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDataEncryptionKeyResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDataEncryptionKeyResponseProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDataEncryptionKeyResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='ed43184b80a7eb5c54231d2fc0ab1bf4' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDatanodeReportRequestProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDatanodeReportRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDatanodeReportRequestProto' start='41924' end='42354' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 41924-42354]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDatanodeReportRequestProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDatanodeReportRequestProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDatanodeReportRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDatanodeReportRequestProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDatanodeReportRequestProto' start='42007' end='42007' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='7' primary='true'><Message>At ClientNamenodeProtocolProtos.java:[line 42007]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='c06069ff82b7b5dd0e4f239d4717da4f' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDatanodeReportRequestProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDatanodeReportRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDatanodeReportRequestProto' start='41924' end='42354' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 41924-42354]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDatanodeReportRequestProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDatanodeReportRequestProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDatanodeReportRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDatanodeReportRequestProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDatanodeReportRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='5b54f90711bff6de697eeda15882c440' rank='17' abbrev='UCF' category='STYLE' priority='2' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDatanodeReportRequestProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDatanodeReportRequestProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDatanodeReportRequestProto$Builder' start='42193' end='42345' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 42193-42345]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDatanodeReportRequestProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDatanodeReportRequestProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine endBytecode='61' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDatanodeReportRequestProto$Builder' start='42219' end='42221' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDatanodeReportRequestProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDatanodeReportRequestProto$Builder' start='42219' end='42219' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='3' primary='true'><Message>At ClientNamenodeProtocolProtos.java:[line 42219]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='d365737f1a837f9c8c6124eb754c9025' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDatanodeReportResponseProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDatanodeReportResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDatanodeReportResponseProto' start='42390' end='43075' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 42390-43075]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDatanodeReportResponseProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDatanodeReportResponseProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDatanodeReportResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDatanodeReportResponseProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDatanodeReportResponseProto' start='42473' end='42473' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='7' primary='true'><Message>At ClientNamenodeProtocolProtos.java:[line 42473]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='4757c20af78948f7a6b856dfc8602c65' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDatanodeReportResponseProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDatanodeReportResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDatanodeReportResponseProto' start='42390' end='43075' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 42390-43075]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDatanodeReportResponseProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDatanodeReportResponseProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDatanodeReportResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDatanodeReportResponseProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDatanodeReportResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='7ae7003313f3901d7c47f26a74d4e6f3' cweid='563' rank='20' abbrev='DLS' category='STYLE' priority='3' type='DLS_DEAD_LOCAL_STORE' instanceOccurrenceMax='0'><ShortMessage>Dead store to local variable</ShortMessage><LongMessage>Dead store to from_bitField0_ in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDatanodeReportResponseProto$Builder.buildPartial()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDatanodeReportResponseProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDatanodeReportResponseProto$Builder' start='42677' end='43066' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 42677-43066]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDatanodeReportResponseProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDatanodeReportResponseProto$Builder' signature='()Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$GetDatanodeReportResponseProto;' name='buildPartial' primary='true'><SourceLine endBytecode='44' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDatanodeReportResponseProto$Builder' start='42744' end='42756' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDatanodeReportResponseProto$Builder.buildPartial()</Message></Method><LocalVariable role='LOCAL_VARIABLE_NAMED' pc='15' name='from_bitField0_' register='2'><Message>Local variable named from_bitField0_</Message></LocalVariable><SourceLine endBytecode='14' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDatanodeReportResponseProto$Builder' start='42745' end='42745' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='14' primary='true'><Message>At ClientNamenodeProtocolProtos.java:[line 42745]</Message></SourceLine><Property name='edu.umd.cs.findbugs.detect.DeadLocalStoreProperty.BASE_VALUE' value='true'></Property><Property name='edu.umd.cs.findbugs.detect.DeadLocalStoreProperty.CACHING_VALUE' value='true'></Property><Property name='edu.umd.cs.findbugs.detect.DeadLocalStoreProperty.LOCAL_NAME' value='from_bitField0_'></Property><Property name='edu.umd.cs.findbugs.detect.DeadLocalStoreProperty.NO_LOADS' value='true'></Property></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='f67adbe7b7188c655c82a78ff24323f0' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDatanodeStorageReportRequestProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDatanodeStorageReportRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDatanodeStorageReportRequestProto' start='43096' end='43526' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 43096-43526]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDatanodeStorageReportRequestProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDatanodeStorageReportRequestProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDatanodeStorageReportRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDatanodeStorageReportRequestProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDatanodeStorageReportRequestProto' start='43179' end='43179' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='7' primary='true'><Message>At ClientNamenodeProtocolProtos.java:[line 43179]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='c6bea800fe66cff1a4d61b10e688aca' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDatanodeStorageReportRequestProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDatanodeStorageReportRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDatanodeStorageReportRequestProto' start='43096' end='43526' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 43096-43526]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDatanodeStorageReportRequestProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDatanodeStorageReportRequestProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDatanodeStorageReportRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDatanodeStorageReportRequestProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDatanodeStorageReportRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='76ad9c7cc68e9c5f9d3adbf3b51a5f53' rank='17' abbrev='UCF' category='STYLE' priority='2' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDatanodeStorageReportRequestProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDatanodeStorageReportRequestProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDatanodeStorageReportRequestProto$Builder' start='43365' end='43517' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 43365-43517]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDatanodeStorageReportRequestProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDatanodeStorageReportRequestProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine endBytecode='61' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDatanodeStorageReportRequestProto$Builder' start='43391' end='43393' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDatanodeStorageReportRequestProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDatanodeStorageReportRequestProto$Builder' start='43391' end='43391' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='3' primary='true'><Message>At ClientNamenodeProtocolProtos.java:[line 43391]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='fbf0cc923fd7783d59cc8b7588f94cfa' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDatanodeStorageReportResponseProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDatanodeStorageReportResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDatanodeStorageReportResponseProto' start='44503' end='45188' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 44503-45188]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDatanodeStorageReportResponseProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDatanodeStorageReportResponseProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDatanodeStorageReportResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDatanodeStorageReportResponseProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDatanodeStorageReportResponseProto' start='44586' end='44586' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='7' primary='true'><Message>At ClientNamenodeProtocolProtos.java:[line 44586]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='7f8c430eab2cdb899d01a35df51c0884' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDatanodeStorageReportResponseProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDatanodeStorageReportResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDatanodeStorageReportResponseProto' start='44503' end='45188' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 44503-45188]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDatanodeStorageReportResponseProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDatanodeStorageReportResponseProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDatanodeStorageReportResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDatanodeStorageReportResponseProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDatanodeStorageReportResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='9d62343c92a7c388f00d6f72e7a70bc1' cweid='563' rank='20' abbrev='DLS' category='STYLE' priority='3' type='DLS_DEAD_LOCAL_STORE' instanceOccurrenceMax='0'><ShortMessage>Dead store to local variable</ShortMessage><LongMessage>Dead store to from_bitField0_ in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDatanodeStorageReportResponseProto$Builder.buildPartial()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDatanodeStorageReportResponseProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDatanodeStorageReportResponseProto$Builder' start='44790' end='45179' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 44790-45179]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDatanodeStorageReportResponseProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDatanodeStorageReportResponseProto$Builder' signature='()Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$GetDatanodeStorageReportResponseProto;' name='buildPartial' primary='true'><SourceLine endBytecode='44' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDatanodeStorageReportResponseProto$Builder' start='44857' end='44869' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDatanodeStorageReportResponseProto$Builder.buildPartial()</Message></Method><LocalVariable role='LOCAL_VARIABLE_NAMED' pc='15' name='from_bitField0_' register='2'><Message>Local variable named from_bitField0_</Message></LocalVariable><SourceLine endBytecode='14' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDatanodeStorageReportResponseProto$Builder' start='44858' end='44858' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='14' primary='true'><Message>At ClientNamenodeProtocolProtos.java:[line 44858]</Message></SourceLine><Property name='edu.umd.cs.findbugs.detect.DeadLocalStoreProperty.BASE_VALUE' value='true'></Property><Property name='edu.umd.cs.findbugs.detect.DeadLocalStoreProperty.CACHING_VALUE' value='true'></Property><Property name='edu.umd.cs.findbugs.detect.DeadLocalStoreProperty.LOCAL_NAME' value='from_bitField0_'></Property><Property name='edu.umd.cs.findbugs.detect.DeadLocalStoreProperty.NO_LOADS' value='true'></Property></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='500d68a33082a5f5ffa27f51b61d736e' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetEditsFromTxidRequestProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetEditsFromTxidRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetEditsFromTxidRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetEditsFromTxidRequestProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetEditsFromTxidRequestProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetEditsFromTxidRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetEditsFromTxidRequestProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetEditsFromTxidRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='7'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='25e397aea6693fb10da5c0e4bf480035' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetEditsFromTxidRequestProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetEditsFromTxidRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetEditsFromTxidRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetEditsFromTxidRequestProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetEditsFromTxidRequestProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetEditsFromTxidRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetEditsFromTxidRequestProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetEditsFromTxidRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='5dc17ca2201679f09b3d3ad4a4321f91' rank='20' abbrev='UCF' category='STYLE' priority='3' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetEditsFromTxidRequestProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetEditsFromTxidRequestProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetEditsFromTxidRequestProto$Builder' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetEditsFromTxidRequestProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetEditsFromTxidRequestProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetEditsFromTxidRequestProto$Builder' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetEditsFromTxidRequestProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetEditsFromTxidRequestProto$Builder' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='3'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='35823cae6c55c81ff462b9e329832521' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetEditsFromTxidResponseProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetEditsFromTxidResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetEditsFromTxidResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetEditsFromTxidResponseProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetEditsFromTxidResponseProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetEditsFromTxidResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetEditsFromTxidResponseProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetEditsFromTxidResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='7'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='86fa69d29f0715053407468453ee96a8' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetEditsFromTxidResponseProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetEditsFromTxidResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetEditsFromTxidResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetEditsFromTxidResponseProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetEditsFromTxidResponseProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetEditsFromTxidResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetEditsFromTxidResponseProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetEditsFromTxidResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='e57f149c6f026f9f6210dfe7205f3afd' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFileInfoRequestProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFileInfoRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFileInfoRequestProto' start='56018' end='56509' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 56018-56509]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFileInfoRequestProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFileInfoRequestProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFileInfoRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFileInfoRequestProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFileInfoRequestProto' start='56095' end='56095' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='7' primary='true'><Message>At ClientNamenodeProtocolProtos.java:[line 56095]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='3352cb623ee4fbaf220238fa203f04f0' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFileInfoRequestProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFileInfoRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFileInfoRequestProto' start='56018' end='56509' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 56018-56509]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFileInfoRequestProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFileInfoRequestProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFileInfoRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFileInfoRequestProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFileInfoRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='9183efd29cd3a5cd8c611a943b8de427' rank='17' abbrev='UCF' category='STYLE' priority='2' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFileInfoRequestProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFileInfoRequestProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFileInfoRequestProto$Builder' start='56308' end='56500' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 56308-56500]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFileInfoRequestProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFileInfoRequestProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine endBytecode='61' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFileInfoRequestProto$Builder' start='56334' end='56336' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFileInfoRequestProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFileInfoRequestProto$Builder' start='56334' end='56334' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='3' primary='true'><Message>At ClientNamenodeProtocolProtos.java:[line 56334]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='35ceaedf9fe6e3b1f9fbe9cf9344816d' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFileInfoResponseProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFileInfoResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFileInfoResponseProto' start='56534' end='57066' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 56534-57066]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFileInfoResponseProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFileInfoResponseProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFileInfoResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFileInfoResponseProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFileInfoResponseProto' start='56619' end='56619' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='7' primary='true'><Message>At ClientNamenodeProtocolProtos.java:[line 56619]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='66a436bce0aa1dd46efd0a13f77547f5' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFileInfoResponseProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFileInfoResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFileInfoResponseProto' start='56534' end='57066' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 56534-57066]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFileInfoResponseProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFileInfoResponseProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFileInfoResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFileInfoResponseProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFileInfoResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='2695e3137194fb685a4ef47f23a2da1' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFileLinkInfoRequestProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFileLinkInfoRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFileLinkInfoRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFileLinkInfoRequestProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFileLinkInfoRequestProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFileLinkInfoRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFileLinkInfoRequestProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFileLinkInfoRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='7'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='e770d53d65a5d855904f90c712822672' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFileLinkInfoRequestProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFileLinkInfoRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFileLinkInfoRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFileLinkInfoRequestProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFileLinkInfoRequestProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFileLinkInfoRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFileLinkInfoRequestProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFileLinkInfoRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='9bd624cb96eb34ad0c0d310aeef9c8b4' rank='20' abbrev='UCF' category='STYLE' priority='3' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFileLinkInfoRequestProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFileLinkInfoRequestProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFileLinkInfoRequestProto$Builder' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFileLinkInfoRequestProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFileLinkInfoRequestProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFileLinkInfoRequestProto$Builder' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFileLinkInfoRequestProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFileLinkInfoRequestProto$Builder' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='3'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='be057061cc57b0eb9e64edfa4b87d75c' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFileLinkInfoResponseProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFileLinkInfoResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFileLinkInfoResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFileLinkInfoResponseProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFileLinkInfoResponseProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFileLinkInfoResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFileLinkInfoResponseProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFileLinkInfoResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='7'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='f17df988b6af200035642f1739e7a444' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFileLinkInfoResponseProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFileLinkInfoResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFileLinkInfoResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFileLinkInfoResponseProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFileLinkInfoResponseProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFileLinkInfoResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFileLinkInfoResponseProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFileLinkInfoResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='a425c2e2561ec09accb67bc231f633e8' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsECBlockGroupStatsRequestProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsECBlockGroupStatsRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsECBlockGroupStatsRequestProto' start='40738' end='41069' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 40738-41069]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsECBlockGroupStatsRequestProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsECBlockGroupStatsRequestProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsECBlockGroupStatsRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsECBlockGroupStatsRequestProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsECBlockGroupStatsRequestProto' start='40809' end='40809' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='7' primary='true'><Message>At ClientNamenodeProtocolProtos.java:[line 40809]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='6cb95c6cec9a5a9c45700a3e2d9391e8' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsECBlockGroupStatsRequestProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsECBlockGroupStatsRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsECBlockGroupStatsRequestProto' start='40738' end='41069' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 40738-41069]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsECBlockGroupStatsRequestProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsECBlockGroupStatsRequestProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsECBlockGroupStatsRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsECBlockGroupStatsRequestProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsECBlockGroupStatsRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='392737b667b2466944dd72019e5622bc' rank='17' abbrev='UCF' category='STYLE' priority='2' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsECBlockGroupStatsRequestProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsECBlockGroupStatsRequestProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsECBlockGroupStatsRequestProto$Builder' start='40961' end='41060' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 40961-41060]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsECBlockGroupStatsRequestProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsECBlockGroupStatsRequestProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine endBytecode='61' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsECBlockGroupStatsRequestProto$Builder' start='40987' end='40989' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsECBlockGroupStatsRequestProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsECBlockGroupStatsRequestProto$Builder' start='40987' end='40987' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='3' primary='true'><Message>At ClientNamenodeProtocolProtos.java:[line 40987]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='6556c6176c2f4eda307f504926a24953' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsECBlockGroupStatsResponseProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsECBlockGroupStatsResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsECBlockGroupStatsResponseProto' start='41130' end='41903' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 41130-41903]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsECBlockGroupStatsResponseProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsECBlockGroupStatsResponseProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsECBlockGroupStatsResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsECBlockGroupStatsResponseProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsECBlockGroupStatsResponseProto' start='41227' end='41227' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='7' primary='true'><Message>At ClientNamenodeProtocolProtos.java:[line 41227]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='cdac3bb898fc2880413a8ed3e6d201f4' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsECBlockGroupStatsResponseProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsECBlockGroupStatsResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsECBlockGroupStatsResponseProto' start='41130' end='41903' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 41130-41903]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsECBlockGroupStatsResponseProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsECBlockGroupStatsResponseProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsECBlockGroupStatsResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsECBlockGroupStatsResponseProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsECBlockGroupStatsResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='6cc60552e3acc85ee271358ce2e31d2c' rank='17' abbrev='UCF' category='STYLE' priority='2' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsECBlockGroupStatsResponseProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsECBlockGroupStatsResponseProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsECBlockGroupStatsResponseProto$Builder' start='41561' end='41894' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 41561-41894]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsECBlockGroupStatsResponseProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsECBlockGroupStatsResponseProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine endBytecode='61' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsECBlockGroupStatsResponseProto$Builder' start='41587' end='41589' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsECBlockGroupStatsResponseProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsECBlockGroupStatsResponseProto$Builder' start='41587' end='41587' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='3' primary='true'><Message>At ClientNamenodeProtocolProtos.java:[line 41587]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='f5251236578cc700bc62aff9d8a5ad1a' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsReplicatedBlockStatsRequestProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsReplicatedBlockStatsRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsReplicatedBlockStatsRequestProto' start='39460' end='39791' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 39460-39791]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsReplicatedBlockStatsRequestProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsReplicatedBlockStatsRequestProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsReplicatedBlockStatsRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsReplicatedBlockStatsRequestProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsReplicatedBlockStatsRequestProto' start='39531' end='39531' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='7' primary='true'><Message>At ClientNamenodeProtocolProtos.java:[line 39531]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='c869e25c66968afb61ee88c707131546' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsReplicatedBlockStatsRequestProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsReplicatedBlockStatsRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsReplicatedBlockStatsRequestProto' start='39460' end='39791' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 39460-39791]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsReplicatedBlockStatsRequestProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsReplicatedBlockStatsRequestProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsReplicatedBlockStatsRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsReplicatedBlockStatsRequestProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsReplicatedBlockStatsRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='446ca2a41be712a925fc5c6b9aabc8b5' rank='17' abbrev='UCF' category='STYLE' priority='2' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsReplicatedBlockStatsRequestProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsReplicatedBlockStatsRequestProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsReplicatedBlockStatsRequestProto$Builder' start='39683' end='39782' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 39683-39782]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsReplicatedBlockStatsRequestProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsReplicatedBlockStatsRequestProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine endBytecode='61' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsReplicatedBlockStatsRequestProto$Builder' start='39709' end='39711' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsReplicatedBlockStatsRequestProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsReplicatedBlockStatsRequestProto$Builder' start='39709' end='39709' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='3' primary='true'><Message>At ClientNamenodeProtocolProtos.java:[line 39709]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='49ba4471060844f429a43094def1baa2' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsReplicatedBlockStatsResponseProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsReplicatedBlockStatsResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsReplicatedBlockStatsResponseProto' start='39862' end='40723' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 39862-40723]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsReplicatedBlockStatsResponseProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsReplicatedBlockStatsResponseProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsReplicatedBlockStatsResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsReplicatedBlockStatsResponseProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsReplicatedBlockStatsResponseProto' start='39964' end='39964' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='7' primary='true'><Message>At ClientNamenodeProtocolProtos.java:[line 39964]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='9b620b0b2d7c8de4c8a6d039c6f3a2f0' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsReplicatedBlockStatsResponseProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsReplicatedBlockStatsResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsReplicatedBlockStatsResponseProto' start='39862' end='40723' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 39862-40723]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsReplicatedBlockStatsResponseProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsReplicatedBlockStatsResponseProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsReplicatedBlockStatsResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsReplicatedBlockStatsResponseProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsReplicatedBlockStatsResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='a2c6178f05254a22255d56cd5796d230' rank='17' abbrev='UCF' category='STYLE' priority='2' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsReplicatedBlockStatsResponseProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsReplicatedBlockStatsResponseProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsReplicatedBlockStatsResponseProto$Builder' start='40335' end='40714' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 40335-40714]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsReplicatedBlockStatsResponseProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsReplicatedBlockStatsResponseProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine endBytecode='61' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsReplicatedBlockStatsResponseProto$Builder' start='40361' end='40363' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsReplicatedBlockStatsResponseProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsReplicatedBlockStatsResponseProto$Builder' start='40361' end='40361' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='3' primary='true'><Message>At ClientNamenodeProtocolProtos.java:[line 40361]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='daf0168c080c407e79492935509e964e' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsStatsResponseProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsStatsResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsStatsResponseProto' start='38344' end='39445' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 38344-39445]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsStatsResponseProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsStatsResponseProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsStatsResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsStatsResponseProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsStatsResponseProto' start='38461' end='38461' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='7' primary='true'><Message>At ClientNamenodeProtocolProtos.java:[line 38461]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='6df5e2f54c97431a8198f39c9a35050a' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsStatsResponseProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsStatsResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsStatsResponseProto' start='38344' end='39445' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 38344-39445]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsStatsResponseProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsStatsResponseProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsStatsResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsStatsResponseProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsStatsResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='e3dfcff2ebb336363a7c92ef64bbaf31' rank='17' abbrev='UCF' category='STYLE' priority='2' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsStatsResponseProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsStatsResponseProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsStatsResponseProto$Builder' start='38931' end='39436' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 38931-39436]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsStatsResponseProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsStatsResponseProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine endBytecode='61' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsStatsResponseProto$Builder' start='38957' end='38959' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsStatsResponseProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsStatsResponseProto$Builder' start='38957' end='38957' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='3' primary='true'><Message>At ClientNamenodeProtocolProtos.java:[line 38957]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='8886508d42637e046c852a260eb42f9b' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsStatusRequestProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsStatusRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsStatusRequestProto' start='37912' end='38243' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 37912-38243]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsStatusRequestProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsStatusRequestProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsStatusRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsStatusRequestProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsStatusRequestProto' start='37983' end='37983' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='7' primary='true'><Message>At ClientNamenodeProtocolProtos.java:[line 37983]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='b6675e7eb989e65acc5149b52fcaf37f' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsStatusRequestProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsStatusRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsStatusRequestProto' start='37912' end='38243' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 37912-38243]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsStatusRequestProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsStatusRequestProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsStatusRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsStatusRequestProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsStatusRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='750ed7d427b913d46173cd483fd65c45' rank='17' abbrev='UCF' category='STYLE' priority='2' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsStatusRequestProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsStatusRequestProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsStatusRequestProto$Builder' start='38135' end='38234' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 38135-38234]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsStatusRequestProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsStatusRequestProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine endBytecode='61' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsStatusRequestProto$Builder' start='38161' end='38163' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsStatusRequestProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsStatusRequestProto$Builder' start='38161' end='38161' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='3' primary='true'><Message>At ClientNamenodeProtocolProtos.java:[line 38161]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='14581026516ef5ee9f8afb1d74763e7c' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetLinkTargetRequestProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetLinkTargetRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetLinkTargetRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetLinkTargetRequestProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetLinkTargetRequestProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetLinkTargetRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetLinkTargetRequestProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetLinkTargetRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='7'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='2fb3537779ad3e83e12417cb8baab152' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetLinkTargetRequestProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetLinkTargetRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetLinkTargetRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetLinkTargetRequestProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetLinkTargetRequestProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetLinkTargetRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetLinkTargetRequestProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetLinkTargetRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='7ba81fcd0b9ff8d09b63f3397697d1f1' rank='20' abbrev='UCF' category='STYLE' priority='3' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetLinkTargetRequestProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetLinkTargetRequestProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetLinkTargetRequestProto$Builder' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetLinkTargetRequestProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetLinkTargetRequestProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetLinkTargetRequestProto$Builder' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetLinkTargetRequestProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetLinkTargetRequestProto$Builder' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='3'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='171100a4397b164dde445348901439d5' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetLinkTargetResponseProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetLinkTargetResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetLinkTargetResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetLinkTargetResponseProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetLinkTargetResponseProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetLinkTargetResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetLinkTargetResponseProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetLinkTargetResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='7'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='596f92af2942597c816f3ac881ff601a' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetLinkTargetResponseProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetLinkTargetResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetLinkTargetResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetLinkTargetResponseProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetLinkTargetResponseProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetLinkTargetResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetLinkTargetResponseProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetLinkTargetResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='4b621a420d404d107d09cd0347dda90b' rank='20' abbrev='UCF' category='STYLE' priority='3' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetLinkTargetResponseProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetLinkTargetResponseProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetLinkTargetResponseProto$Builder' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetLinkTargetResponseProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetLinkTargetResponseProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetLinkTargetResponseProto$Builder' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetLinkTargetResponseProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetLinkTargetResponseProto$Builder' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='3'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='f10ac71faaaf17cf3dcc3728e40ecaf2' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetListingRequestProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetListingRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetListingRequestProto' start='30711' end='31381' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 30711-31381]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetListingRequestProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetListingRequestProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetListingRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetListingRequestProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetListingRequestProto' start='30798' end='30798' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='7' primary='true'><Message>At ClientNamenodeProtocolProtos.java:[line 30798]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='69ecb34c64cb00e8603526f613f4be9b' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetListingRequestProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetListingRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetListingRequestProto' start='30711' end='31381' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 30711-31381]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetListingRequestProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetListingRequestProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetListingRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetListingRequestProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetListingRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='1fbd84ead7583eb7ee5b3282cce029d4' rank='19' abbrev='Se' category='BAD_PRACTICE' priority='3' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetListingRequestProto defines non-transient non-serializable instance field startAfter_</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetListingRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetListingRequestProto' start='30711' end='31381' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 30711-31381]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetListingRequestProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetListingRequestProto' signature='Lcom/google/protobuf/ByteString;' name='startAfter_' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetListingRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetListingRequestProto.startAfter_</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/ByteString;'><SourceLine classname='com.google.protobuf.ByteString' start='60' end='967' sourcepath='com/google/protobuf/ByteString.java' sourcefile='ByteString.java'><Message>At ByteString.java:[lines 60-967]</Message></SourceLine><Message>Actual type com.google.protobuf.ByteString</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetListingRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='74d97fb85c56967401b217de1e0b718e' rank='17' abbrev='UCF' category='STYLE' priority='2' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetListingRequestProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetListingRequestProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetListingRequestProto$Builder' start='31085' end='31372' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 31085-31372]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetListingRequestProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetListingRequestProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine endBytecode='61' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetListingRequestProto$Builder' start='31111' end='31113' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetListingRequestProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetListingRequestProto$Builder' start='31111' end='31111' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='3' primary='true'><Message>At ClientNamenodeProtocolProtos.java:[line 31111]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='5167030b535b7f5eb75edd6d96ceb6f6' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetListingResponseProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetListingResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetListingResponseProto' start='31406' end='31938' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 31406-31938]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetListingResponseProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetListingResponseProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetListingResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetListingResponseProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetListingResponseProto' start='31491' end='31491' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='7' primary='true'><Message>At ClientNamenodeProtocolProtos.java:[line 31491]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='36d31d12b1e3570f0447fe0200a52c0d' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetListingResponseProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetListingResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetListingResponseProto' start='31406' end='31938' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 31406-31938]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetListingResponseProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetListingResponseProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetListingResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetListingResponseProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetListingResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='c8ae2d8818748d9afc94d1dc42ead1f1' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetLocatedFileInfoRequestProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetLocatedFileInfoRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetLocatedFileInfoRequestProto' start='57102' end='57665' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 57102-57665]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetLocatedFileInfoRequestProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetLocatedFileInfoRequestProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetLocatedFileInfoRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetLocatedFileInfoRequestProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetLocatedFileInfoRequestProto' start='57184' end='57184' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='7' primary='true'><Message>At ClientNamenodeProtocolProtos.java:[line 57184]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='d34c10d79287ac44b42b0ddbbecdca98' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetLocatedFileInfoRequestProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetLocatedFileInfoRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetLocatedFileInfoRequestProto' start='57102' end='57665' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 57102-57665]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetLocatedFileInfoRequestProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetLocatedFileInfoRequestProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetLocatedFileInfoRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetLocatedFileInfoRequestProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetLocatedFileInfoRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='2abb36975727e706ca1e554c906c952c' rank='17' abbrev='UCF' category='STYLE' priority='2' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetLocatedFileInfoRequestProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetLocatedFileInfoRequestProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetLocatedFileInfoRequestProto$Builder' start='57426' end='57656' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 57426-57656]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetLocatedFileInfoRequestProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetLocatedFileInfoRequestProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine endBytecode='61' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetLocatedFileInfoRequestProto$Builder' start='57452' end='57454' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetLocatedFileInfoRequestProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetLocatedFileInfoRequestProto$Builder' start='57452' end='57452' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='3' primary='true'><Message>At ClientNamenodeProtocolProtos.java:[line 57452]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='2071504a32c38708e0836610b3637a0' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetLocatedFileInfoResponseProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetLocatedFileInfoResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetLocatedFileInfoResponseProto' start='57690' end='58222' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 57690-58222]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetLocatedFileInfoResponseProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetLocatedFileInfoResponseProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetLocatedFileInfoResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetLocatedFileInfoResponseProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetLocatedFileInfoResponseProto' start='57775' end='57775' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='7' primary='true'><Message>At ClientNamenodeProtocolProtos.java:[line 57775]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='afadff9001082c3228f5a74a026e0444' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetLocatedFileInfoResponseProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetLocatedFileInfoResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetLocatedFileInfoResponseProto' start='57690' end='58222' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 57690-58222]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetLocatedFileInfoResponseProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetLocatedFileInfoResponseProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetLocatedFileInfoResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetLocatedFileInfoResponseProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetLocatedFileInfoResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='8b38d519e0c5f69bb1f27084d33dae11' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetPreferredBlockSizeRequestProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetPreferredBlockSizeRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetPreferredBlockSizeRequestProto' start='45214' end='45705' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 45214-45705]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetPreferredBlockSizeRequestProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetPreferredBlockSizeRequestProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetPreferredBlockSizeRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetPreferredBlockSizeRequestProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetPreferredBlockSizeRequestProto' start='45291' end='45291' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='7' primary='true'><Message>At ClientNamenodeProtocolProtos.java:[line 45291]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='ea6fbf5439510116dfd85326d40c436' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetPreferredBlockSizeRequestProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetPreferredBlockSizeRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetPreferredBlockSizeRequestProto' start='45214' end='45705' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 45214-45705]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetPreferredBlockSizeRequestProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetPreferredBlockSizeRequestProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetPreferredBlockSizeRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetPreferredBlockSizeRequestProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetPreferredBlockSizeRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='9ec8ff152cf799c0d19a3f8fb0fdf507' rank='17' abbrev='UCF' category='STYLE' priority='2' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetPreferredBlockSizeRequestProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetPreferredBlockSizeRequestProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetPreferredBlockSizeRequestProto$Builder' start='45504' end='45696' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 45504-45696]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetPreferredBlockSizeRequestProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetPreferredBlockSizeRequestProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine endBytecode='61' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetPreferredBlockSizeRequestProto$Builder' start='45530' end='45532' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetPreferredBlockSizeRequestProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetPreferredBlockSizeRequestProto$Builder' start='45530' end='45530' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='3' primary='true'><Message>At ClientNamenodeProtocolProtos.java:[line 45530]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='1069b753b0f263e0cadd23c5c1266a1c' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetPreferredBlockSizeResponseProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetPreferredBlockSizeResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetPreferredBlockSizeResponseProto' start='45726' end='46147' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 45726-46147]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetPreferredBlockSizeResponseProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetPreferredBlockSizeResponseProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetPreferredBlockSizeResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetPreferredBlockSizeResponseProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetPreferredBlockSizeResponseProto' start='45803' end='45803' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='7' primary='true'><Message>At ClientNamenodeProtocolProtos.java:[line 45803]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='9e880f3484be56bd153e188c13ad87ad' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetPreferredBlockSizeResponseProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetPreferredBlockSizeResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetPreferredBlockSizeResponseProto' start='45726' end='46147' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 45726-46147]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetPreferredBlockSizeResponseProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetPreferredBlockSizeResponseProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetPreferredBlockSizeResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetPreferredBlockSizeResponseProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetPreferredBlockSizeResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='a5bdb56dce363b16957299ff1e205fa6' rank='17' abbrev='UCF' category='STYLE' priority='2' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetPreferredBlockSizeResponseProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetPreferredBlockSizeResponseProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetPreferredBlockSizeResponseProto$Builder' start='45989' end='46138' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 45989-46138]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetPreferredBlockSizeResponseProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetPreferredBlockSizeResponseProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine endBytecode='61' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetPreferredBlockSizeResponseProto$Builder' start='46015' end='46017' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetPreferredBlockSizeResponseProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetPreferredBlockSizeResponseProto$Builder' start='46015' end='46015' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='3' primary='true'><Message>At ClientNamenodeProtocolProtos.java:[line 46015]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='cdbf6eaa1d82f5618d318cc04b135a0a' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetQuotaUsageRequestProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetQuotaUsageRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetQuotaUsageRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetQuotaUsageRequestProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetQuotaUsageRequestProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetQuotaUsageRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetQuotaUsageRequestProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetQuotaUsageRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='7'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='4ca4ca8465fe4d4d48798553f1fd7442' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetQuotaUsageRequestProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetQuotaUsageRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetQuotaUsageRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetQuotaUsageRequestProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetQuotaUsageRequestProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetQuotaUsageRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetQuotaUsageRequestProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetQuotaUsageRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='cd7231cc34ec8703ca1895ebe62a58ef' rank='20' abbrev='UCF' category='STYLE' priority='3' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetQuotaUsageRequestProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetQuotaUsageRequestProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetQuotaUsageRequestProto$Builder' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetQuotaUsageRequestProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetQuotaUsageRequestProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetQuotaUsageRequestProto$Builder' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetQuotaUsageRequestProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetQuotaUsageRequestProto$Builder' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='3'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='f572cb3a245a051416063ac7bc2ae3b0' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetQuotaUsageResponseProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetQuotaUsageResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetQuotaUsageResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetQuotaUsageResponseProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetQuotaUsageResponseProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetQuotaUsageResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetQuotaUsageResponseProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetQuotaUsageResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='7'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='9480af082bd9c52819b95e6d0b844bbb' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetQuotaUsageResponseProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetQuotaUsageResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetQuotaUsageResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetQuotaUsageResponseProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetQuotaUsageResponseProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetQuotaUsageResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetQuotaUsageResponseProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetQuotaUsageResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='abe142e22e9c97917ac9dc91fc0c9d21' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetServerDefaultsRequestProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetServerDefaultsRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetServerDefaultsRequestProto' start='2126' end='2457' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 2126-2457]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetServerDefaultsRequestProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetServerDefaultsRequestProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetServerDefaultsRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetServerDefaultsRequestProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetServerDefaultsRequestProto' start='2197' end='2197' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='7' primary='true'><Message>At ClientNamenodeProtocolProtos.java:[line 2197]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='2c1126014a7ba8c8e6036741a9f6d21f' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetServerDefaultsRequestProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetServerDefaultsRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetServerDefaultsRequestProto' start='2126' end='2457' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 2126-2457]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetServerDefaultsRequestProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetServerDefaultsRequestProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetServerDefaultsRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetServerDefaultsRequestProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetServerDefaultsRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='2335835fbd066beb00930b845ea0de43' rank='17' abbrev='UCF' category='STYLE' priority='2' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetServerDefaultsRequestProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetServerDefaultsRequestProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetServerDefaultsRequestProto$Builder' start='2349' end='2448' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 2349-2448]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetServerDefaultsRequestProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetServerDefaultsRequestProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine endBytecode='61' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetServerDefaultsRequestProto$Builder' start='2375' end='2377' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetServerDefaultsRequestProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetServerDefaultsRequestProto$Builder' start='2375' end='2375' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='3' primary='true'><Message>At ClientNamenodeProtocolProtos.java:[line 2375]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='55c6e49e091a5c030f5645d34bceb4fe' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetServerDefaultsResponseProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetServerDefaultsResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetServerDefaultsResponseProto' start='2482' end='3018' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 2482-3018]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetServerDefaultsResponseProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetServerDefaultsResponseProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetServerDefaultsResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetServerDefaultsResponseProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetServerDefaultsResponseProto' start='2567' end='2567' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='7' primary='true'><Message>At ClientNamenodeProtocolProtos.java:[line 2567]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='e682417ed89bec70d6c4d62cab5c7a2c' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetServerDefaultsResponseProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetServerDefaultsResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetServerDefaultsResponseProto' start='2482' end='3018' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 2482-3018]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetServerDefaultsResponseProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetServerDefaultsResponseProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetServerDefaultsResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetServerDefaultsResponseProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetServerDefaultsResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='8d3b605a7f8f7a0c70ded1fe0fd6d78b' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshotDiffReportListingRequestProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshotDiffReportListingRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshotDiffReportListingRequestProto' start='34335' end='35341' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 34335-35341]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshotDiffReportListingRequestProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshotDiffReportListingRequestProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshotDiffReportListingRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshotDiffReportListingRequestProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshotDiffReportListingRequestProto' start='34435' end='34435' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='7' primary='true'><Message>At ClientNamenodeProtocolProtos.java:[line 34435]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='1f84ed4d55a6047483f21034ff79df51' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshotDiffReportListingRequestProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshotDiffReportListingRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshotDiffReportListingRequestProto' start='34335' end='35341' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 34335-35341]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshotDiffReportListingRequestProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshotDiffReportListingRequestProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshotDiffReportListingRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshotDiffReportListingRequestProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshotDiffReportListingRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='1365cd81e234ebf1e570ea3058be30c0' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshotDiffReportListingResponseProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshotDiffReportListingResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshotDiffReportListingResponseProto' start='35366' end='35902' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 35366-35902]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshotDiffReportListingResponseProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshotDiffReportListingResponseProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshotDiffReportListingResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshotDiffReportListingResponseProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshotDiffReportListingResponseProto' start='35451' end='35451' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='7' primary='true'><Message>At ClientNamenodeProtocolProtos.java:[line 35451]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='d2a214d1db8939380e6bc913756b83c7' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshotDiffReportListingResponseProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshotDiffReportListingResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshotDiffReportListingResponseProto' start='35366' end='35902' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 35366-35902]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshotDiffReportListingResponseProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshotDiffReportListingResponseProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshotDiffReportListingResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshotDiffReportListingResponseProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshotDiffReportListingResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='4ff2f1ce937e33c4763d057c043dae78' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshotDiffReportRequestProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshotDiffReportRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshotDiffReportRequestProto' start='32897' end='33704' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 32897-33704]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshotDiffReportRequestProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshotDiffReportRequestProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshotDiffReportRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshotDiffReportRequestProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshotDiffReportRequestProto' start='32984' end='32984' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='7' primary='true'><Message>At ClientNamenodeProtocolProtos.java:[line 32984]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='b31d916a760ebc4495ad9984cfdc4c87' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshotDiffReportRequestProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshotDiffReportRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshotDiffReportRequestProto' start='32897' end='33704' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 32897-33704]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshotDiffReportRequestProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshotDiffReportRequestProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshotDiffReportRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshotDiffReportRequestProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshotDiffReportRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='df8388411ca2e91fc31868b1056e8044' rank='17' abbrev='UCF' category='STYLE' priority='2' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshotDiffReportRequestProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshotDiffReportRequestProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshotDiffReportRequestProto$Builder' start='33325' end='33695' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 33325-33695]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshotDiffReportRequestProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshotDiffReportRequestProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine endBytecode='61' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshotDiffReportRequestProto$Builder' start='33351' end='33353' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshotDiffReportRequestProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshotDiffReportRequestProto$Builder' start='33351' end='33351' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='3' primary='true'><Message>At ClientNamenodeProtocolProtos.java:[line 33351]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='18de57fc3273de4f26e40b9701767a9c' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshotDiffReportResponseProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshotDiffReportResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshotDiffReportResponseProto' start='33729' end='34265' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 33729-34265]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshotDiffReportResponseProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshotDiffReportResponseProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshotDiffReportResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshotDiffReportResponseProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshotDiffReportResponseProto' start='33814' end='33814' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='7' primary='true'><Message>At ClientNamenodeProtocolProtos.java:[line 33814]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='8a1ffa3ce92a101f0ca96a8326ae5081' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshotDiffReportResponseProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshotDiffReportResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshotDiffReportResponseProto' start='33729' end='34265' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 33729-34265]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshotDiffReportResponseProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshotDiffReportResponseProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshotDiffReportResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshotDiffReportResponseProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshotDiffReportResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='f5010608082467cf37a7ba06184762a4' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshottableDirListingRequestProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshottableDirListingRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshottableDirListingRequestProto' start='31953' end='32284' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 31953-32284]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshottableDirListingRequestProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshottableDirListingRequestProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshottableDirListingRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshottableDirListingRequestProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshottableDirListingRequestProto' start='32024' end='32024' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='7' primary='true'><Message>At ClientNamenodeProtocolProtos.java:[line 32024]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='4cc77eff940d1a52d2e7605d7f86fc24' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshottableDirListingRequestProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshottableDirListingRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshottableDirListingRequestProto' start='31953' end='32284' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 31953-32284]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshottableDirListingRequestProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshottableDirListingRequestProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshottableDirListingRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshottableDirListingRequestProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshottableDirListingRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='6ca486577b8b7bab2d629f4e3c29f99e' rank='17' abbrev='UCF' category='STYLE' priority='2' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshottableDirListingRequestProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshottableDirListingRequestProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshottableDirListingRequestProto$Builder' start='32176' end='32275' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 32176-32275]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshottableDirListingRequestProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshottableDirListingRequestProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine endBytecode='61' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshottableDirListingRequestProto$Builder' start='32202' end='32204' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshottableDirListingRequestProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshottableDirListingRequestProto$Builder' start='32202' end='32202' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='3' primary='true'><Message>At ClientNamenodeProtocolProtos.java:[line 32202]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='a124ab005280b92d12df24aa2db03a2c' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshottableDirListingResponseProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshottableDirListingResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshottableDirListingResponseProto' start='32309' end='32841' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 32309-32841]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshottableDirListingResponseProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshottableDirListingResponseProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshottableDirListingResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshottableDirListingResponseProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshottableDirListingResponseProto' start='32394' end='32394' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='7' primary='true'><Message>At ClientNamenodeProtocolProtos.java:[line 32394]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='42bff5e2bca6e2c7f7879e33eb7a06e7' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshottableDirListingResponseProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshottableDirListingResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshottableDirListingResponseProto' start='32309' end='32841' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 32309-32841]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshottableDirListingResponseProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshottableDirListingResponseProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshottableDirListingResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshottableDirListingResponseProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshottableDirListingResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='7837da2eb2c6a17c8bddcfee2e6d389' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetStoragePoliciesRequestProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetStoragePoliciesRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetStoragePoliciesRequestProto' start='11151' end='11482' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 11151-11482]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetStoragePoliciesRequestProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetStoragePoliciesRequestProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetStoragePoliciesRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetStoragePoliciesRequestProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetStoragePoliciesRequestProto' start='11222' end='11222' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='7' primary='true'><Message>At ClientNamenodeProtocolProtos.java:[line 11222]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='912402a33742af860a928ed9d90fcef6' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetStoragePoliciesRequestProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetStoragePoliciesRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetStoragePoliciesRequestProto' start='11151' end='11482' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 11151-11482]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetStoragePoliciesRequestProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetStoragePoliciesRequestProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetStoragePoliciesRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetStoragePoliciesRequestProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetStoragePoliciesRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='70c48c109a40deaa9951affe6fa01030' rank='17' abbrev='UCF' category='STYLE' priority='2' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetStoragePoliciesRequestProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetStoragePoliciesRequestProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetStoragePoliciesRequestProto$Builder' start='11374' end='11473' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 11374-11473]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetStoragePoliciesRequestProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetStoragePoliciesRequestProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine endBytecode='61' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetStoragePoliciesRequestProto$Builder' start='11400' end='11402' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetStoragePoliciesRequestProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetStoragePoliciesRequestProto$Builder' start='11400' end='11400' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='3' primary='true'><Message>At ClientNamenodeProtocolProtos.java:[line 11400]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='160de1eafb27231f8789f76a10b2abc' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetStoragePoliciesResponseProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetStoragePoliciesResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetStoragePoliciesResponseProto' start='11518' end='12203' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 11518-12203]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetStoragePoliciesResponseProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetStoragePoliciesResponseProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetStoragePoliciesResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetStoragePoliciesResponseProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetStoragePoliciesResponseProto' start='11601' end='11601' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='7' primary='true'><Message>At ClientNamenodeProtocolProtos.java:[line 11601]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='5ded3014276ab9d09a53200bdc0744a8' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetStoragePoliciesResponseProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetStoragePoliciesResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetStoragePoliciesResponseProto' start='11518' end='12203' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 11518-12203]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetStoragePoliciesResponseProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetStoragePoliciesResponseProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetStoragePoliciesResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetStoragePoliciesResponseProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetStoragePoliciesResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='7576aa5aa6c75cf56b4344aa586c17bf' cweid='563' rank='20' abbrev='DLS' category='STYLE' priority='3' type='DLS_DEAD_LOCAL_STORE' instanceOccurrenceMax='0'><ShortMessage>Dead store to local variable</ShortMessage><LongMessage>Dead store to from_bitField0_ in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetStoragePoliciesResponseProto$Builder.buildPartial()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetStoragePoliciesResponseProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetStoragePoliciesResponseProto$Builder' start='11805' end='12194' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 11805-12194]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetStoragePoliciesResponseProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetStoragePoliciesResponseProto$Builder' signature='()Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$GetStoragePoliciesResponseProto;' name='buildPartial' primary='true'><SourceLine endBytecode='44' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetStoragePoliciesResponseProto$Builder' start='11872' end='11884' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetStoragePoliciesResponseProto$Builder.buildPartial()</Message></Method><LocalVariable role='LOCAL_VARIABLE_NAMED' pc='15' name='from_bitField0_' register='2'><Message>Local variable named from_bitField0_</Message></LocalVariable><SourceLine endBytecode='14' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetStoragePoliciesResponseProto$Builder' start='11873' end='11873' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='14' primary='true'><Message>At ClientNamenodeProtocolProtos.java:[line 11873]</Message></SourceLine><Property name='edu.umd.cs.findbugs.detect.DeadLocalStoreProperty.BASE_VALUE' value='true'></Property><Property name='edu.umd.cs.findbugs.detect.DeadLocalStoreProperty.CACHING_VALUE' value='true'></Property><Property name='edu.umd.cs.findbugs.detect.DeadLocalStoreProperty.LOCAL_NAME' value='from_bitField0_'></Property><Property name='edu.umd.cs.findbugs.detect.DeadLocalStoreProperty.NO_LOADS' value='true'></Property></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='dcc5412a39279022575fe5edccf6aa7a' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetStoragePolicyRequestProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetStoragePolicyRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetStoragePolicyRequestProto' start='10084' end='10575' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 10084-10575]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetStoragePolicyRequestProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetStoragePolicyRequestProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetStoragePolicyRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetStoragePolicyRequestProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetStoragePolicyRequestProto' start='10161' end='10161' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='7' primary='true'><Message>At ClientNamenodeProtocolProtos.java:[line 10161]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='6a291052c807b207557296216dd56fad' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetStoragePolicyRequestProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetStoragePolicyRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetStoragePolicyRequestProto' start='10084' end='10575' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 10084-10575]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetStoragePolicyRequestProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetStoragePolicyRequestProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetStoragePolicyRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetStoragePolicyRequestProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetStoragePolicyRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='4aa815c74aaa75d62d315972de09c452' rank='17' abbrev='UCF' category='STYLE' priority='2' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetStoragePolicyRequestProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetStoragePolicyRequestProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetStoragePolicyRequestProto$Builder' start='10374' end='10566' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 10374-10566]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetStoragePolicyRequestProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetStoragePolicyRequestProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine endBytecode='61' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetStoragePolicyRequestProto$Builder' start='10400' end='10402' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetStoragePolicyRequestProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetStoragePolicyRequestProto$Builder' start='10400' end='10400' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='3' primary='true'><Message>At ClientNamenodeProtocolProtos.java:[line 10400]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='8793db7fe40446d4aa46de2db5d95a57' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetStoragePolicyResponseProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetStoragePolicyResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetStoragePolicyResponseProto' start='10600' end='11136' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 10600-11136]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetStoragePolicyResponseProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetStoragePolicyResponseProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetStoragePolicyResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetStoragePolicyResponseProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetStoragePolicyResponseProto' start='10685' end='10685' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='7' primary='true'><Message>At ClientNamenodeProtocolProtos.java:[line 10685]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='96fdf92bc3ddd872dcc6258d69448ca2' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetStoragePolicyResponseProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetStoragePolicyResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetStoragePolicyResponseProto' start='10600' end='11136' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 10600-11136]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetStoragePolicyResponseProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetStoragePolicyResponseProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetStoragePolicyResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetStoragePolicyResponseProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetStoragePolicyResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='b9a7c9de70e5e596bb4a9985a93408b3' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$IsFileClosedRequestProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$IsFileClosedRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$IsFileClosedRequestProto' start='58248' end='58739' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 58248-58739]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$IsFileClosedRequestProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$IsFileClosedRequestProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$IsFileClosedRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$IsFileClosedRequestProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$IsFileClosedRequestProto' start='58325' end='58325' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='7' primary='true'><Message>At ClientNamenodeProtocolProtos.java:[line 58325]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='e1fe8be6ad008895aceef39a03741bc' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$IsFileClosedRequestProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$IsFileClosedRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$IsFileClosedRequestProto' start='58248' end='58739' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 58248-58739]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$IsFileClosedRequestProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$IsFileClosedRequestProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$IsFileClosedRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$IsFileClosedRequestProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$IsFileClosedRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='9a97f8a74095115c37c8c12e4947d363' rank='17' abbrev='UCF' category='STYLE' priority='2' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$IsFileClosedRequestProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$IsFileClosedRequestProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$IsFileClosedRequestProto$Builder' start='58538' end='58730' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 58538-58730]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$IsFileClosedRequestProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$IsFileClosedRequestProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine endBytecode='61' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$IsFileClosedRequestProto$Builder' start='58564' end='58566' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$IsFileClosedRequestProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$IsFileClosedRequestProto$Builder' start='58564' end='58564' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='3' primary='true'><Message>At ClientNamenodeProtocolProtos.java:[line 58564]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='cfba3f5acc9b078609238905094ba0dc' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$IsFileClosedResponseProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$IsFileClosedResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$IsFileClosedResponseProto' start='58760' end='59181' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 58760-59181]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$IsFileClosedResponseProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$IsFileClosedResponseProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$IsFileClosedResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$IsFileClosedResponseProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$IsFileClosedResponseProto' start='58837' end='58837' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='7' primary='true'><Message>At ClientNamenodeProtocolProtos.java:[line 58837]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='beb43a8e989f5bae0e6196d3a9dc8c22' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$IsFileClosedResponseProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$IsFileClosedResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$IsFileClosedResponseProto' start='58760' end='59181' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 58760-59181]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$IsFileClosedResponseProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$IsFileClosedResponseProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$IsFileClosedResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$IsFileClosedResponseProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$IsFileClosedResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='bae63d90a4766e78c514ab38c82d298c' rank='17' abbrev='UCF' category='STYLE' priority='2' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$IsFileClosedResponseProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$IsFileClosedResponseProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$IsFileClosedResponseProto$Builder' start='59023' end='59172' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 59023-59172]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$IsFileClosedResponseProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$IsFileClosedResponseProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine endBytecode='61' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$IsFileClosedResponseProto$Builder' start='59049' end='59051' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$IsFileClosedResponseProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$IsFileClosedResponseProto$Builder' start='59049' end='59049' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='3' primary='true'><Message>At ClientNamenodeProtocolProtos.java:[line 59049]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='30b3288d8d4b753bdee40083f646ea55' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListCacheDirectivesRequestProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListCacheDirectivesRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListCacheDirectivesRequestProto' start='64583' end='65207' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 64583-65207]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListCacheDirectivesRequestProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListCacheDirectivesRequestProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListCacheDirectivesRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListCacheDirectivesRequestProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListCacheDirectivesRequestProto' start='64673' end='64673' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='7' primary='true'><Message>At ClientNamenodeProtocolProtos.java:[line 64673]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='5c6a5c46b4b446ff09689e0276ba7479' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListCacheDirectivesRequestProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListCacheDirectivesRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListCacheDirectivesRequestProto' start='64583' end='65207' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 64583-65207]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListCacheDirectivesRequestProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListCacheDirectivesRequestProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListCacheDirectivesRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListCacheDirectivesRequestProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListCacheDirectivesRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='f3d7df04b24a798912639cc77411666d' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListCacheDirectivesResponseProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListCacheDirectivesResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListCacheDirectivesResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListCacheDirectivesResponseProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListCacheDirectivesResponseProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListCacheDirectivesResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListCacheDirectivesResponseProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListCacheDirectivesResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='7'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='87d370e501c07817703bd1e167a6f34b' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListCacheDirectivesResponseProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListCacheDirectivesResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListCacheDirectivesResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListCacheDirectivesResponseProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListCacheDirectivesResponseProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListCacheDirectivesResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListCacheDirectivesResponseProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListCacheDirectivesResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='fb5a41cf5910ba54ec2c3c21b6c4b40e' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListCachePoolsRequestProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListCachePoolsRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListCachePoolsRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListCachePoolsRequestProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListCachePoolsRequestProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListCachePoolsRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListCachePoolsRequestProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListCachePoolsRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='7'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='fa2577aa990c6b5b38608e6a7353b97f' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListCachePoolsRequestProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListCachePoolsRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListCachePoolsRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListCachePoolsRequestProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListCachePoolsRequestProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListCachePoolsRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListCachePoolsRequestProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListCachePoolsRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='2e1c040bb07812ec0d179337b31f100c' rank='20' abbrev='UCF' category='STYLE' priority='3' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListCachePoolsRequestProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListCachePoolsRequestProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListCachePoolsRequestProto$Builder' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListCachePoolsRequestProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListCachePoolsRequestProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListCachePoolsRequestProto$Builder' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListCachePoolsRequestProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListCachePoolsRequestProto$Builder' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='3'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='53d90c1dcedde50e965654a17a411424' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListCachePoolsResponseProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListCachePoolsResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListCachePoolsResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListCachePoolsResponseProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListCachePoolsResponseProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListCachePoolsResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListCachePoolsResponseProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListCachePoolsResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='7'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='3367977959565a1658853b75a7343697' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListCachePoolsResponseProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListCachePoolsResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListCachePoolsResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListCachePoolsResponseProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListCachePoolsResponseProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListCachePoolsResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListCachePoolsResponseProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListCachePoolsResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='43c5a662aeea6c7ced73b94cd81166e' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListCorruptFileBlocksRequestProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListCorruptFileBlocksRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListCorruptFileBlocksRequestProto' start='53927' end='54568' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 53927-54568]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListCorruptFileBlocksRequestProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListCorruptFileBlocksRequestProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListCorruptFileBlocksRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListCorruptFileBlocksRequestProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListCorruptFileBlocksRequestProto' start='54009' end='54009' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='7' primary='true'><Message>At ClientNamenodeProtocolProtos.java:[line 54009]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='f96988af631570faee8fed9bd3e58a1' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListCorruptFileBlocksRequestProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListCorruptFileBlocksRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListCorruptFileBlocksRequestProto' start='53927' end='54568' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 53927-54568]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListCorruptFileBlocksRequestProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListCorruptFileBlocksRequestProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListCorruptFileBlocksRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListCorruptFileBlocksRequestProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListCorruptFileBlocksRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='a61b0bbe118f7ab77a6e2010138df2a0' rank='17' abbrev='UCF' category='STYLE' priority='2' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListCorruptFileBlocksRequestProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListCorruptFileBlocksRequestProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListCorruptFileBlocksRequestProto$Builder' start='54282' end='54559' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 54282-54559]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListCorruptFileBlocksRequestProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListCorruptFileBlocksRequestProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine endBytecode='61' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListCorruptFileBlocksRequestProto$Builder' start='54308' end='54310' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListCorruptFileBlocksRequestProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListCorruptFileBlocksRequestProto$Builder' start='54308' end='54308' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='3' primary='true'><Message>At ClientNamenodeProtocolProtos.java:[line 54308]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='3b67fca305bbeaad0bce7c39a0e6b641' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListCorruptFileBlocksResponseProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListCorruptFileBlocksResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListCorruptFileBlocksResponseProto' start='54593' end='55129' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 54593-55129]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListCorruptFileBlocksResponseProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListCorruptFileBlocksResponseProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListCorruptFileBlocksResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListCorruptFileBlocksResponseProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListCorruptFileBlocksResponseProto' start='54678' end='54678' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='7' primary='true'><Message>At ClientNamenodeProtocolProtos.java:[line 54678]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='736e37b29365a2fc0ba278a0974accf3' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListCorruptFileBlocksResponseProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListCorruptFileBlocksResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListCorruptFileBlocksResponseProto' start='54593' end='55129' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 54593-55129]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListCorruptFileBlocksResponseProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListCorruptFileBlocksResponseProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListCorruptFileBlocksResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListCorruptFileBlocksResponseProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListCorruptFileBlocksResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='9312b934c4dfe33cf7722bb220a5f01d' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListOpenFilesRequestProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListOpenFilesRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListOpenFilesRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListOpenFilesRequestProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListOpenFilesRequestProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListOpenFilesRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListOpenFilesRequestProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListOpenFilesRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='7'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='abb6f215ad9daa0bc67e4e487c2cefb8' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListOpenFilesRequestProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListOpenFilesRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListOpenFilesRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListOpenFilesRequestProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListOpenFilesRequestProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListOpenFilesRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListOpenFilesRequestProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListOpenFilesRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='1d94f1c6811453f6a877bb5ceec8fa1' rank='20' abbrev='UCF' category='STYLE' priority='3' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListOpenFilesRequestProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListOpenFilesRequestProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListOpenFilesRequestProto$Builder' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListOpenFilesRequestProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListOpenFilesRequestProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListOpenFilesRequestProto$Builder' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListOpenFilesRequestProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListOpenFilesRequestProto$Builder' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='3'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='266b016b2e0b4bc9f0d777397bb46baf' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListOpenFilesResponseProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListOpenFilesResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListOpenFilesResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListOpenFilesResponseProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListOpenFilesResponseProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListOpenFilesResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListOpenFilesResponseProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListOpenFilesResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='7'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='8e9175a080b6c9245cf46ff3d8242a4f' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListOpenFilesResponseProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListOpenFilesResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListOpenFilesResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListOpenFilesResponseProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListOpenFilesResponseProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListOpenFilesResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListOpenFilesResponseProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListOpenFilesResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='820f3a8e896f07c92ba205bbbf38ae3b' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$MetaSaveRequestProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$MetaSaveRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$MetaSaveRequestProto' start='55155' end='55646' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 55155-55646]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$MetaSaveRequestProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$MetaSaveRequestProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$MetaSaveRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$MetaSaveRequestProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$MetaSaveRequestProto' start='55232' end='55232' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='7' primary='true'><Message>At ClientNamenodeProtocolProtos.java:[line 55232]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='ed4dc8b3de8f9bba2938e76d04257a60' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$MetaSaveRequestProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$MetaSaveRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$MetaSaveRequestProto' start='55155' end='55646' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 55155-55646]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$MetaSaveRequestProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$MetaSaveRequestProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$MetaSaveRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$MetaSaveRequestProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$MetaSaveRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='e8f48706f62c4cf433af51e86bf0febd' rank='17' abbrev='UCF' category='STYLE' priority='2' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$MetaSaveRequestProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$MetaSaveRequestProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$MetaSaveRequestProto$Builder' start='55445' end='55637' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 55445-55637]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$MetaSaveRequestProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$MetaSaveRequestProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine endBytecode='61' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$MetaSaveRequestProto$Builder' start='55471' end='55473' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$MetaSaveRequestProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$MetaSaveRequestProto$Builder' start='55471' end='55471' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='3' primary='true'><Message>At ClientNamenodeProtocolProtos.java:[line 55471]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='1db880cda882b81ce7b69d81702bbbff' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$MetaSaveResponseProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$MetaSaveResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$MetaSaveResponseProto' start='55661' end='55992' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 55661-55992]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$MetaSaveResponseProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$MetaSaveResponseProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$MetaSaveResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$MetaSaveResponseProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$MetaSaveResponseProto' start='55732' end='55732' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='7' primary='true'><Message>At ClientNamenodeProtocolProtos.java:[line 55732]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='471364b0908bd96b032aa445049d7111' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$MetaSaveResponseProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$MetaSaveResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$MetaSaveResponseProto' start='55661' end='55992' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 55661-55992]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$MetaSaveResponseProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$MetaSaveResponseProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$MetaSaveResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$MetaSaveResponseProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$MetaSaveResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='1cf8c460ff2fd4fe098b844f54e1b611' rank='17' abbrev='UCF' category='STYLE' priority='2' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$MetaSaveResponseProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$MetaSaveResponseProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$MetaSaveResponseProto$Builder' start='55884' end='55983' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 55884-55983]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$MetaSaveResponseProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$MetaSaveResponseProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine endBytecode='61' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$MetaSaveResponseProto$Builder' start='55910' end='55912' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$MetaSaveResponseProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$MetaSaveResponseProto$Builder' start='55910' end='55910' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='3' primary='true'><Message>At ClientNamenodeProtocolProtos.java:[line 55910]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='1dc6d7ad539b862791a30bf6041526a2' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$MkdirsRequestProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$MkdirsRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$MkdirsRequestProto' start='29242' end='30223' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 29242-30223]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$MkdirsRequestProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$MkdirsRequestProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$MkdirsRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$MkdirsRequestProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$MkdirsRequestProto' start='29350' end='29350' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='7' primary='true'><Message>At ClientNamenodeProtocolProtos.java:[line 29350]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='d08fa2612beefea16e266c1036b80b20' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$MkdirsRequestProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$MkdirsRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$MkdirsRequestProto' start='29242' end='30223' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 29242-30223]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$MkdirsRequestProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$MkdirsRequestProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$MkdirsRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$MkdirsRequestProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$MkdirsRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='2c31b190612533164ee325d1e0a4d5c6' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$MkdirsResponseProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$MkdirsResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$MkdirsResponseProto' start='30244' end='30665' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 30244-30665]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$MkdirsResponseProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$MkdirsResponseProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$MkdirsResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$MkdirsResponseProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$MkdirsResponseProto' start='30321' end='30321' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='7' primary='true'><Message>At ClientNamenodeProtocolProtos.java:[line 30321]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='96289935bc0f0a36906e78520eed397d' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$MkdirsResponseProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$MkdirsResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$MkdirsResponseProto' start='30244' end='30665' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 30244-30665]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$MkdirsResponseProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$MkdirsResponseProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$MkdirsResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$MkdirsResponseProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$MkdirsResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='650f68b911d80bb9aad4f4995b9592dc' rank='17' abbrev='UCF' category='STYLE' priority='2' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$MkdirsResponseProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$MkdirsResponseProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$MkdirsResponseProto$Builder' start='30507' end='30656' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 30507-30656]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$MkdirsResponseProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$MkdirsResponseProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine endBytecode='61' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$MkdirsResponseProto$Builder' start='30533' end='30535' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$MkdirsResponseProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$MkdirsResponseProto$Builder' start='30533' end='30533' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='3' primary='true'><Message>At ClientNamenodeProtocolProtos.java:[line 30533]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='cfb7a6e7e0ca369479708a6228c1efa3' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ModifyCacheDirectiveRequestProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ModifyCacheDirectiveRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ModifyCacheDirectiveRequestProto' start='62790' end='63430' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 62790-63430]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ModifyCacheDirectiveRequestProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ModifyCacheDirectiveRequestProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ModifyCacheDirectiveRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ModifyCacheDirectiveRequestProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ModifyCacheDirectiveRequestProto' start='62880' end='62880' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='7' primary='true'><Message>At ClientNamenodeProtocolProtos.java:[line 62880]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='2382016695d2597fc91d16f10db9c3c0' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ModifyCacheDirectiveRequestProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ModifyCacheDirectiveRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ModifyCacheDirectiveRequestProto' start='62790' end='63430' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 62790-63430]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ModifyCacheDirectiveRequestProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ModifyCacheDirectiveRequestProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ModifyCacheDirectiveRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ModifyCacheDirectiveRequestProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ModifyCacheDirectiveRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='6eefa328c035d29c9365b071cdd7893' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ModifyCacheDirectiveResponseProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ModifyCacheDirectiveResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ModifyCacheDirectiveResponseProto' start='63441' end='63768' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 63441-63768]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ModifyCacheDirectiveResponseProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ModifyCacheDirectiveResponseProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ModifyCacheDirectiveResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ModifyCacheDirectiveResponseProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ModifyCacheDirectiveResponseProto' start='63512' end='63512' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='7' primary='true'><Message>At ClientNamenodeProtocolProtos.java:[line 63512]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='b20238dee504b3fcdf99d5444d1f8b0f' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ModifyCacheDirectiveResponseProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ModifyCacheDirectiveResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ModifyCacheDirectiveResponseProto' start='63441' end='63768' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 63441-63768]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ModifyCacheDirectiveResponseProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ModifyCacheDirectiveResponseProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ModifyCacheDirectiveResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ModifyCacheDirectiveResponseProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ModifyCacheDirectiveResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='6b8979b4060667cfaa20aae1aabef659' rank='17' abbrev='UCF' category='STYLE' priority='2' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ModifyCacheDirectiveResponseProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ModifyCacheDirectiveResponseProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ModifyCacheDirectiveResponseProto$Builder' start='63660' end='63759' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 63660-63759]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ModifyCacheDirectiveResponseProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ModifyCacheDirectiveResponseProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine endBytecode='61' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ModifyCacheDirectiveResponseProto$Builder' start='63686' end='63688' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ModifyCacheDirectiveResponseProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ModifyCacheDirectiveResponseProto$Builder' start='63686' end='63686' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='3' primary='true'><Message>At ClientNamenodeProtocolProtos.java:[line 63686]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='645fde92d157450470d8f671ab2cf0a3' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ModifyCachePoolRequestProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ModifyCachePoolRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ModifyCachePoolRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ModifyCachePoolRequestProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ModifyCachePoolRequestProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ModifyCachePoolRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ModifyCachePoolRequestProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ModifyCachePoolRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='7'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='91af17de3dc9d4b72564c60327b9fd6' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ModifyCachePoolRequestProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ModifyCachePoolRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ModifyCachePoolRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ModifyCachePoolRequestProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ModifyCachePoolRequestProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ModifyCachePoolRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ModifyCachePoolRequestProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ModifyCachePoolRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='8808211172b60d2a5283fcf84dfdb509' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ModifyCachePoolResponseProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ModifyCachePoolResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ModifyCachePoolResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ModifyCachePoolResponseProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ModifyCachePoolResponseProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ModifyCachePoolResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ModifyCachePoolResponseProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ModifyCachePoolResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='7'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='ba7e36820cb3d66fca7f2b029e600974' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ModifyCachePoolResponseProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ModifyCachePoolResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ModifyCachePoolResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ModifyCachePoolResponseProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ModifyCachePoolResponseProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ModifyCachePoolResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ModifyCachePoolResponseProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ModifyCachePoolResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='b2254e26b5b2c8b2b45cf79e0d7e5cbd' rank='20' abbrev='UCF' category='STYLE' priority='3' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ModifyCachePoolResponseProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ModifyCachePoolResponseProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ModifyCachePoolResponseProto$Builder' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ModifyCachePoolResponseProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ModifyCachePoolResponseProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ModifyCachePoolResponseProto$Builder' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ModifyCachePoolResponseProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ModifyCachePoolResponseProto$Builder' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='3'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='1efa3b2c7ab31e519d4081656f87abd0' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$OpenFilesBatchResponseProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$OpenFilesBatchResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$OpenFilesBatchResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$OpenFilesBatchResponseProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$OpenFilesBatchResponseProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$OpenFilesBatchResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$OpenFilesBatchResponseProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$OpenFilesBatchResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='7'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='e722b68f839d2ab78f0663dbeffaf78c' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$OpenFilesBatchResponseProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$OpenFilesBatchResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$OpenFilesBatchResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$OpenFilesBatchResponseProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$OpenFilesBatchResponseProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$OpenFilesBatchResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$OpenFilesBatchResponseProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$OpenFilesBatchResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='83f0ecc87df05a24bb0f3eb96222f3cf' rank='20' abbrev='UCF' category='STYLE' priority='3' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$OpenFilesBatchResponseProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$OpenFilesBatchResponseProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$OpenFilesBatchResponseProto$Builder' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$OpenFilesBatchResponseProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$OpenFilesBatchResponseProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$OpenFilesBatchResponseProto$Builder' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$OpenFilesBatchResponseProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$OpenFilesBatchResponseProto$Builder' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='3'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='b0e7954cc3c7bfd43b58320e7f344b07' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RecoverLeaseRequestProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RecoverLeaseRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RecoverLeaseRequestProto' start='36806' end='37455' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 36806-37455]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RecoverLeaseRequestProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RecoverLeaseRequestProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RecoverLeaseRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RecoverLeaseRequestProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RecoverLeaseRequestProto' start='36888' end='36888' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='7' primary='true'><Message>At ClientNamenodeProtocolProtos.java:[line 36888]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='6213135c9000125647d9786594f889d7' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RecoverLeaseRequestProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RecoverLeaseRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RecoverLeaseRequestProto' start='36806' end='37455' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 36806-37455]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RecoverLeaseRequestProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RecoverLeaseRequestProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RecoverLeaseRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RecoverLeaseRequestProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RecoverLeaseRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='7e6cfb5d9ff935752f4e1e4654a7b8bf' rank='17' abbrev='UCF' category='STYLE' priority='2' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RecoverLeaseRequestProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RecoverLeaseRequestProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RecoverLeaseRequestProto$Builder' start='37165' end='37446' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 37165-37446]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RecoverLeaseRequestProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RecoverLeaseRequestProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine endBytecode='61' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RecoverLeaseRequestProto$Builder' start='37191' end='37193' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RecoverLeaseRequestProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RecoverLeaseRequestProto$Builder' start='37191' end='37191' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='3' primary='true'><Message>At ClientNamenodeProtocolProtos.java:[line 37191]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='814c066f299f89e094a0585ef0563069' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RecoverLeaseResponseProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RecoverLeaseResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RecoverLeaseResponseProto' start='37476' end='37897' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 37476-37897]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RecoverLeaseResponseProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RecoverLeaseResponseProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RecoverLeaseResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RecoverLeaseResponseProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RecoverLeaseResponseProto' start='37553' end='37553' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='7' primary='true'><Message>At ClientNamenodeProtocolProtos.java:[line 37553]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='8634db21c3a9b04054619094b1e41d14' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RecoverLeaseResponseProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RecoverLeaseResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RecoverLeaseResponseProto' start='37476' end='37897' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 37476-37897]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RecoverLeaseResponseProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RecoverLeaseResponseProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RecoverLeaseResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RecoverLeaseResponseProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RecoverLeaseResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='f2038b646ec8364b3fb7855de49d65cb' rank='17' abbrev='UCF' category='STYLE' priority='2' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RecoverLeaseResponseProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RecoverLeaseResponseProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RecoverLeaseResponseProto$Builder' start='37739' end='37888' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 37739-37888]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RecoverLeaseResponseProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RecoverLeaseResponseProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine endBytecode='61' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RecoverLeaseResponseProto$Builder' start='37765' end='37767' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RecoverLeaseResponseProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RecoverLeaseResponseProto$Builder' start='37765' end='37765' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='3' primary='true'><Message>At ClientNamenodeProtocolProtos.java:[line 37765]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='6ab7c7be7e571366c611971d6d0626ae' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RefreshNodesRequestProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RefreshNodesRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RefreshNodesRequestProto' start='49866' end='50197' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 49866-50197]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RefreshNodesRequestProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RefreshNodesRequestProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RefreshNodesRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RefreshNodesRequestProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RefreshNodesRequestProto' start='49937' end='49937' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='7' primary='true'><Message>At ClientNamenodeProtocolProtos.java:[line 49937]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='44d5decb78ae037eabf97de13cc768d0' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RefreshNodesRequestProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RefreshNodesRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RefreshNodesRequestProto' start='49866' end='50197' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 49866-50197]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RefreshNodesRequestProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RefreshNodesRequestProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RefreshNodesRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RefreshNodesRequestProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RefreshNodesRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='f34f8976d17357c4c595f4c57fdcc22c' rank='17' abbrev='UCF' category='STYLE' priority='2' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RefreshNodesRequestProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RefreshNodesRequestProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RefreshNodesRequestProto$Builder' start='50089' end='50188' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 50089-50188]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RefreshNodesRequestProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RefreshNodesRequestProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine endBytecode='61' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RefreshNodesRequestProto$Builder' start='50115' end='50117' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RefreshNodesRequestProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RefreshNodesRequestProto$Builder' start='50115' end='50115' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='3' primary='true'><Message>At ClientNamenodeProtocolProtos.java:[line 50115]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='5dfc73daec723e940641c496c5f5b852' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RefreshNodesResponseProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RefreshNodesResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RefreshNodesResponseProto' start='50212' end='50543' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 50212-50543]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RefreshNodesResponseProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RefreshNodesResponseProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RefreshNodesResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RefreshNodesResponseProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RefreshNodesResponseProto' start='50283' end='50283' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='7' primary='true'><Message>At ClientNamenodeProtocolProtos.java:[line 50283]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='15b77020590c88c3d3612c71105d2fbb' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RefreshNodesResponseProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RefreshNodesResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RefreshNodesResponseProto' start='50212' end='50543' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 50212-50543]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RefreshNodesResponseProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RefreshNodesResponseProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RefreshNodesResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RefreshNodesResponseProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RefreshNodesResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='2b3bf1c834c4b54d39889f8856611210' rank='17' abbrev='UCF' category='STYLE' priority='2' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RefreshNodesResponseProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RefreshNodesResponseProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RefreshNodesResponseProto$Builder' start='50435' end='50534' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 50435-50534]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RefreshNodesResponseProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RefreshNodesResponseProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine endBytecode='61' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RefreshNodesResponseProto$Builder' start='50461' end='50463' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RefreshNodesResponseProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RefreshNodesResponseProto$Builder' start='50461' end='50461' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='3' primary='true'><Message>At ClientNamenodeProtocolProtos.java:[line 50461]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='6dc6f3a29483cebea4912b26c08801ef' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RemoveCacheDirectiveRequestProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RemoveCacheDirectiveRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RemoveCacheDirectiveRequestProto' start='63789' end='64210' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 63789-64210]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RemoveCacheDirectiveRequestProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RemoveCacheDirectiveRequestProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RemoveCacheDirectiveRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RemoveCacheDirectiveRequestProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RemoveCacheDirectiveRequestProto' start='63866' end='63866' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='7' primary='true'><Message>At ClientNamenodeProtocolProtos.java:[line 63866]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='8564e9f3530952d47bf6cd08a0a3a90a' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RemoveCacheDirectiveRequestProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RemoveCacheDirectiveRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RemoveCacheDirectiveRequestProto' start='63789' end='64210' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 63789-64210]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RemoveCacheDirectiveRequestProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RemoveCacheDirectiveRequestProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RemoveCacheDirectiveRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RemoveCacheDirectiveRequestProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RemoveCacheDirectiveRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='593184ecfe1691749041c21fe2fa34ab' rank='17' abbrev='UCF' category='STYLE' priority='2' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RemoveCacheDirectiveRequestProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RemoveCacheDirectiveRequestProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RemoveCacheDirectiveRequestProto$Builder' start='64052' end='64201' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 64052-64201]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RemoveCacheDirectiveRequestProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RemoveCacheDirectiveRequestProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine endBytecode='61' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RemoveCacheDirectiveRequestProto$Builder' start='64078' end='64080' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RemoveCacheDirectiveRequestProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RemoveCacheDirectiveRequestProto$Builder' start='64078' end='64078' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='3' primary='true'><Message>At ClientNamenodeProtocolProtos.java:[line 64078]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='8449eaf4cdf4460c8fa9ed122c531b3' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RemoveCacheDirectiveResponseProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RemoveCacheDirectiveResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RemoveCacheDirectiveResponseProto' start='64221' end='64548' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 64221-64548]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RemoveCacheDirectiveResponseProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RemoveCacheDirectiveResponseProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RemoveCacheDirectiveResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RemoveCacheDirectiveResponseProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RemoveCacheDirectiveResponseProto' start='64292' end='64292' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='7' primary='true'><Message>At ClientNamenodeProtocolProtos.java:[line 64292]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='d803c07417efe5a5be34b00da4db421b' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RemoveCacheDirectiveResponseProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RemoveCacheDirectiveResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RemoveCacheDirectiveResponseProto' start='64221' end='64548' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 64221-64548]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RemoveCacheDirectiveResponseProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RemoveCacheDirectiveResponseProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RemoveCacheDirectiveResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RemoveCacheDirectiveResponseProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RemoveCacheDirectiveResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='769ce37926b7d1cfcd4d5cb923195563' rank='17' abbrev='UCF' category='STYLE' priority='2' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RemoveCacheDirectiveResponseProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RemoveCacheDirectiveResponseProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RemoveCacheDirectiveResponseProto$Builder' start='64440' end='64539' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 64440-64539]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RemoveCacheDirectiveResponseProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RemoveCacheDirectiveResponseProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine endBytecode='61' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RemoveCacheDirectiveResponseProto$Builder' start='64466' end='64468' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RemoveCacheDirectiveResponseProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RemoveCacheDirectiveResponseProto$Builder' start='64466' end='64466' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='3' primary='true'><Message>At ClientNamenodeProtocolProtos.java:[line 64466]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='a39419913220fca530dd96455c6a2378' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RemoveCachePoolRequestProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RemoveCachePoolRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RemoveCachePoolRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RemoveCachePoolRequestProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RemoveCachePoolRequestProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RemoveCachePoolRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RemoveCachePoolRequestProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RemoveCachePoolRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='7'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='ac7c92b5ba36881f93ed57ce459ea1f9' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RemoveCachePoolRequestProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RemoveCachePoolRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RemoveCachePoolRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RemoveCachePoolRequestProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RemoveCachePoolRequestProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RemoveCachePoolRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RemoveCachePoolRequestProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RemoveCachePoolRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='eb1da118dfa566bd7ca3576b1de59fce' rank='20' abbrev='UCF' category='STYLE' priority='3' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RemoveCachePoolRequestProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RemoveCachePoolRequestProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RemoveCachePoolRequestProto$Builder' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RemoveCachePoolRequestProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RemoveCachePoolRequestProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RemoveCachePoolRequestProto$Builder' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RemoveCachePoolRequestProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RemoveCachePoolRequestProto$Builder' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='3'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='46e135fbddd3cdd99722e60e1701d7ff' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RemoveCachePoolResponseProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RemoveCachePoolResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RemoveCachePoolResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RemoveCachePoolResponseProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RemoveCachePoolResponseProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RemoveCachePoolResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RemoveCachePoolResponseProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RemoveCachePoolResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='7'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='3b4a5e280e939a7204aaaa419f539e46' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RemoveCachePoolResponseProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RemoveCachePoolResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RemoveCachePoolResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RemoveCachePoolResponseProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RemoveCachePoolResponseProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RemoveCachePoolResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RemoveCachePoolResponseProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RemoveCachePoolResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='d8ca658d13f703a4d2cc578bdb4d4728' rank='20' abbrev='UCF' category='STYLE' priority='3' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RemoveCachePoolResponseProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RemoveCachePoolResponseProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RemoveCachePoolResponseProto$Builder' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RemoveCachePoolResponseProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RemoveCachePoolResponseProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RemoveCachePoolResponseProto$Builder' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RemoveCachePoolResponseProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RemoveCachePoolResponseProto$Builder' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='3'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='d12c5e25512ac0d1706daec2890e0203' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$Rename2RequestProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$Rename2RequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$Rename2RequestProto' start='26958' end='27775' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 26958-27775]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$Rename2RequestProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$Rename2RequestProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$Rename2RequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$Rename2RequestProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$Rename2RequestProto' start='27050' end='27050' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='7' primary='true'><Message>At ClientNamenodeProtocolProtos.java:[line 27050]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='76248330608c070e2d2ac52a20d5409' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$Rename2RequestProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$Rename2RequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$Rename2RequestProto' start='26958' end='27775' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 26958-27775]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$Rename2RequestProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$Rename2RequestProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$Rename2RequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$Rename2RequestProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$Rename2RequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='864692fc7376ba91e793c661d558696e' rank='17' abbrev='UCF' category='STYLE' priority='2' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$Rename2RequestProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$Rename2RequestProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$Rename2RequestProto$Builder' start='27397' end='27766' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 27397-27766]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$Rename2RequestProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$Rename2RequestProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine endBytecode='61' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$Rename2RequestProto$Builder' start='27423' end='27425' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$Rename2RequestProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$Rename2RequestProto$Builder' start='27423' end='27423' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='3' primary='true'><Message>At ClientNamenodeProtocolProtos.java:[line 27423]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='917e9c5cc92cedde9abc0966d4080291' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$Rename2ResponseProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$Rename2ResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$Rename2ResponseProto' start='27790' end='28121' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 27790-28121]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$Rename2ResponseProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$Rename2ResponseProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$Rename2ResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$Rename2ResponseProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$Rename2ResponseProto' start='27861' end='27861' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='7' primary='true'><Message>At ClientNamenodeProtocolProtos.java:[line 27861]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='1a207d02c4a4383fe715e371c18c1154' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$Rename2ResponseProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$Rename2ResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$Rename2ResponseProto' start='27790' end='28121' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 27790-28121]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$Rename2ResponseProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$Rename2ResponseProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$Rename2ResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$Rename2ResponseProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$Rename2ResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='4195e081b23545cc33c142345e3fe04b' rank='17' abbrev='UCF' category='STYLE' priority='2' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$Rename2ResponseProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$Rename2ResponseProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$Rename2ResponseProto$Builder' start='28013' end='28112' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 28013-28112]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$Rename2ResponseProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$Rename2ResponseProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine endBytecode='61' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$Rename2ResponseProto$Builder' start='28039' end='28041' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$Rename2ResponseProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$Rename2ResponseProto$Builder' start='28039' end='28039' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='3' primary='true'><Message>At ClientNamenodeProtocolProtos.java:[line 28039]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='c5c9d713cc4ab1e8f98f8a2f1ff80a9' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenameRequestProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenameRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenameRequestProto' start='25806' end='26455' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 25806-26455]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenameRequestProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenameRequestProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenameRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenameRequestProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenameRequestProto' start='25888' end='25888' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='7' primary='true'><Message>At ClientNamenodeProtocolProtos.java:[line 25888]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='e01ddff485ed604aa83db4867c03f182' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenameRequestProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenameRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenameRequestProto' start='25806' end='26455' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 25806-26455]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenameRequestProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenameRequestProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenameRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenameRequestProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenameRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='ad28300e80d11d884e0c0c3379b95633' rank='17' abbrev='UCF' category='STYLE' priority='2' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenameRequestProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenameRequestProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenameRequestProto$Builder' start='26165' end='26446' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 26165-26446]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenameRequestProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenameRequestProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine endBytecode='61' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenameRequestProto$Builder' start='26191' end='26193' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenameRequestProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenameRequestProto$Builder' start='26191' end='26191' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='3' primary='true'><Message>At ClientNamenodeProtocolProtos.java:[line 26191]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='1a7b6158f5ab5a8cf213dfdfbeb9d438' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenameResponseProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenameResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenameResponseProto' start='26476' end='26897' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 26476-26897]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenameResponseProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenameResponseProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenameResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenameResponseProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenameResponseProto' start='26553' end='26553' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='7' primary='true'><Message>At ClientNamenodeProtocolProtos.java:[line 26553]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='5c8292ac99bec6edb6a0de98e54329eb' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenameResponseProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenameResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenameResponseProto' start='26476' end='26897' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 26476-26897]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenameResponseProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenameResponseProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenameResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenameResponseProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenameResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='7df9eed3c02bdba989e65a30d7d1fdd1' rank='17' abbrev='UCF' category='STYLE' priority='2' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenameResponseProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenameResponseProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenameResponseProto$Builder' start='26739' end='26888' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 26739-26888]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenameResponseProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenameResponseProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine endBytecode='61' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenameResponseProto$Builder' start='26765' end='26767' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenameResponseProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenameResponseProto$Builder' start='26765' end='26765' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='3' primary='true'><Message>At ClientNamenodeProtocolProtos.java:[line 26765]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='18318a753a3458e9f4b35460567ee233' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenameSnapshotRequestProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenameSnapshotRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenameSnapshotRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenameSnapshotRequestProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenameSnapshotRequestProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenameSnapshotRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenameSnapshotRequestProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenameSnapshotRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='7'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='4394e370273ea6d15e082e87e05f627c' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenameSnapshotRequestProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenameSnapshotRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenameSnapshotRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenameSnapshotRequestProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenameSnapshotRequestProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenameSnapshotRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenameSnapshotRequestProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenameSnapshotRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='3f09f2ca4276394c9cfd7788aa5c2a03' rank='20' abbrev='UCF' category='STYLE' priority='3' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenameSnapshotRequestProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenameSnapshotRequestProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenameSnapshotRequestProto$Builder' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenameSnapshotRequestProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenameSnapshotRequestProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenameSnapshotRequestProto$Builder' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenameSnapshotRequestProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenameSnapshotRequestProto$Builder' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='3'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='b645bc260a32cde4992a58175cbb6ed1' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenameSnapshotResponseProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenameSnapshotResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenameSnapshotResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenameSnapshotResponseProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenameSnapshotResponseProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenameSnapshotResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenameSnapshotResponseProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenameSnapshotResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='7'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='6200b5db0eb268e35482afe1d4d5641c' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenameSnapshotResponseProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenameSnapshotResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenameSnapshotResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenameSnapshotResponseProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenameSnapshotResponseProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenameSnapshotResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenameSnapshotResponseProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenameSnapshotResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='7681b64dcb914c5c6115ccdb932760e4' rank='20' abbrev='UCF' category='STYLE' priority='3' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenameSnapshotResponseProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenameSnapshotResponseProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenameSnapshotResponseProto$Builder' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenameSnapshotResponseProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenameSnapshotResponseProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenameSnapshotResponseProto$Builder' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenameSnapshotResponseProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenameSnapshotResponseProto$Builder' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='3'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='c00763a568bdeb2f93e115e915b5dcc0' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenewLeaseRequestProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenewLeaseRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenewLeaseRequestProto' start='35928' end='36419' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 35928-36419]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenewLeaseRequestProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenewLeaseRequestProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenewLeaseRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenewLeaseRequestProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenewLeaseRequestProto' start='36005' end='36005' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='7' primary='true'><Message>At ClientNamenodeProtocolProtos.java:[line 36005]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='57e2b831b7070cc9c1460ba3e7dc3388' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenewLeaseRequestProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenewLeaseRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenewLeaseRequestProto' start='35928' end='36419' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 35928-36419]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenewLeaseRequestProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenewLeaseRequestProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenewLeaseRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenewLeaseRequestProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenewLeaseRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='758b0a011758eb1c307a68000c11e2f' rank='17' abbrev='UCF' category='STYLE' priority='2' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenewLeaseRequestProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenewLeaseRequestProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenewLeaseRequestProto$Builder' start='36218' end='36410' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 36218-36410]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenewLeaseRequestProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenewLeaseRequestProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine endBytecode='61' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenewLeaseRequestProto$Builder' start='36244' end='36246' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenewLeaseRequestProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenewLeaseRequestProto$Builder' start='36244' end='36244' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='3' primary='true'><Message>At ClientNamenodeProtocolProtos.java:[line 36244]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='c670e50dbac0f20953b97f97330b0ccd' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenewLeaseResponseProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenewLeaseResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenewLeaseResponseProto' start='36434' end='36765' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 36434-36765]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenewLeaseResponseProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenewLeaseResponseProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenewLeaseResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenewLeaseResponseProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenewLeaseResponseProto' start='36505' end='36505' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='7' primary='true'><Message>At ClientNamenodeProtocolProtos.java:[line 36505]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='3e58c5660114cc2f06f73f21906dc5c8' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenewLeaseResponseProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenewLeaseResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenewLeaseResponseProto' start='36434' end='36765' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 36434-36765]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenewLeaseResponseProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenewLeaseResponseProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenewLeaseResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenewLeaseResponseProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenewLeaseResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='d7cfe833f284a139e42a734dcc91ff12' rank='17' abbrev='UCF' category='STYLE' priority='2' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenewLeaseResponseProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenewLeaseResponseProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenewLeaseResponseProto$Builder' start='36657' end='36756' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 36657-36756]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenewLeaseResponseProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenewLeaseResponseProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine endBytecode='61' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenewLeaseResponseProto$Builder' start='36683' end='36685' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenewLeaseResponseProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenewLeaseResponseProto$Builder' start='36683' end='36683' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='3' primary='true'><Message>At ClientNamenodeProtocolProtos.java:[line 36683]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='b171cc8738a07fa86717e0ea26f9f616' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ReportBadBlocksRequestProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ReportBadBlocksRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ReportBadBlocksRequestProto' start='22450' end='23135' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 22450-23135]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ReportBadBlocksRequestProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ReportBadBlocksRequestProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ReportBadBlocksRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ReportBadBlocksRequestProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ReportBadBlocksRequestProto' start='22533' end='22533' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='7' primary='true'><Message>At ClientNamenodeProtocolProtos.java:[line 22533]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='8b0eaef45f99534331b20804f7a557b' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ReportBadBlocksRequestProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ReportBadBlocksRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ReportBadBlocksRequestProto' start='22450' end='23135' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 22450-23135]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ReportBadBlocksRequestProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ReportBadBlocksRequestProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ReportBadBlocksRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ReportBadBlocksRequestProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ReportBadBlocksRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='bb8377db0a91e0ebadd26e656f1d663d' cweid='563' rank='20' abbrev='DLS' category='STYLE' priority='3' type='DLS_DEAD_LOCAL_STORE' instanceOccurrenceMax='0'><ShortMessage>Dead store to local variable</ShortMessage><LongMessage>Dead store to from_bitField0_ in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ReportBadBlocksRequestProto$Builder.buildPartial()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ReportBadBlocksRequestProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ReportBadBlocksRequestProto$Builder' start='22737' end='23126' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 22737-23126]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ReportBadBlocksRequestProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ReportBadBlocksRequestProto$Builder' signature='()Lorg/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos$ReportBadBlocksRequestProto;' name='buildPartial' primary='true'><SourceLine endBytecode='44' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ReportBadBlocksRequestProto$Builder' start='22804' end='22816' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ReportBadBlocksRequestProto$Builder.buildPartial()</Message></Method><LocalVariable role='LOCAL_VARIABLE_NAMED' pc='15' name='from_bitField0_' register='2'><Message>Local variable named from_bitField0_</Message></LocalVariable><SourceLine endBytecode='14' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ReportBadBlocksRequestProto$Builder' start='22805' end='22805' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='14' primary='true'><Message>At ClientNamenodeProtocolProtos.java:[line 22805]</Message></SourceLine><Property name='edu.umd.cs.findbugs.detect.DeadLocalStoreProperty.BASE_VALUE' value='true'></Property><Property name='edu.umd.cs.findbugs.detect.DeadLocalStoreProperty.CACHING_VALUE' value='true'></Property><Property name='edu.umd.cs.findbugs.detect.DeadLocalStoreProperty.LOCAL_NAME' value='from_bitField0_'></Property><Property name='edu.umd.cs.findbugs.detect.DeadLocalStoreProperty.NO_LOADS' value='true'></Property></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='f80ef7e931a2c6ba71b99be640c7ecdd' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ReportBadBlocksResponseProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ReportBadBlocksResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ReportBadBlocksResponseProto' start='23150' end='23481' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 23150-23481]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ReportBadBlocksResponseProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ReportBadBlocksResponseProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ReportBadBlocksResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ReportBadBlocksResponseProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ReportBadBlocksResponseProto' start='23221' end='23221' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='7' primary='true'><Message>At ClientNamenodeProtocolProtos.java:[line 23221]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='45c8fa8223cd061c8a97df1db9e01865' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ReportBadBlocksResponseProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ReportBadBlocksResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ReportBadBlocksResponseProto' start='23150' end='23481' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 23150-23481]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ReportBadBlocksResponseProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ReportBadBlocksResponseProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ReportBadBlocksResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ReportBadBlocksResponseProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ReportBadBlocksResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='990a6aedfe9527a3df3c4412d0d98a3b' rank='17' abbrev='UCF' category='STYLE' priority='2' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ReportBadBlocksResponseProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ReportBadBlocksResponseProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ReportBadBlocksResponseProto$Builder' start='23373' end='23472' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 23373-23472]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ReportBadBlocksResponseProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ReportBadBlocksResponseProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine endBytecode='61' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ReportBadBlocksResponseProto$Builder' start='23399' end='23401' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ReportBadBlocksResponseProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ReportBadBlocksResponseProto$Builder' start='23399' end='23399' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='3' primary='true'><Message>At ClientNamenodeProtocolProtos.java:[line 23399]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='7cc9906540eb2951b74a82ac5848f4fb' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RestoreFailedStorageRequestProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RestoreFailedStorageRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RestoreFailedStorageRequestProto' start='48918' end='49409' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 48918-49409]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RestoreFailedStorageRequestProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RestoreFailedStorageRequestProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RestoreFailedStorageRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RestoreFailedStorageRequestProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RestoreFailedStorageRequestProto' start='48995' end='48995' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='7' primary='true'><Message>At ClientNamenodeProtocolProtos.java:[line 48995]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='3511e5b5ad482e542fde9234940792b0' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RestoreFailedStorageRequestProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RestoreFailedStorageRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RestoreFailedStorageRequestProto' start='48918' end='49409' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 48918-49409]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RestoreFailedStorageRequestProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RestoreFailedStorageRequestProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RestoreFailedStorageRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RestoreFailedStorageRequestProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RestoreFailedStorageRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='d45995bba048cedbe446dc29168d4cb' rank='17' abbrev='UCF' category='STYLE' priority='2' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RestoreFailedStorageRequestProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RestoreFailedStorageRequestProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RestoreFailedStorageRequestProto$Builder' start='49208' end='49400' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 49208-49400]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RestoreFailedStorageRequestProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RestoreFailedStorageRequestProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine endBytecode='61' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RestoreFailedStorageRequestProto$Builder' start='49234' end='49236' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RestoreFailedStorageRequestProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RestoreFailedStorageRequestProto$Builder' start='49234' end='49234' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='3' primary='true'><Message>At ClientNamenodeProtocolProtos.java:[line 49234]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='dfed585d7c5837e6ddc8c0576c12d424' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RestoreFailedStorageResponseProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RestoreFailedStorageResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RestoreFailedStorageResponseProto' start='49430' end='49851' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 49430-49851]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RestoreFailedStorageResponseProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RestoreFailedStorageResponseProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RestoreFailedStorageResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RestoreFailedStorageResponseProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RestoreFailedStorageResponseProto' start='49507' end='49507' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='7' primary='true'><Message>At ClientNamenodeProtocolProtos.java:[line 49507]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='362399560be5f2a64a81d2986fc33436' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RestoreFailedStorageResponseProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RestoreFailedStorageResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RestoreFailedStorageResponseProto' start='49430' end='49851' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 49430-49851]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RestoreFailedStorageResponseProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RestoreFailedStorageResponseProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RestoreFailedStorageResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RestoreFailedStorageResponseProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RestoreFailedStorageResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='f6c33c4a5c02af8f7306d43f7fc8758b' rank='17' abbrev='UCF' category='STYLE' priority='2' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RestoreFailedStorageResponseProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RestoreFailedStorageResponseProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RestoreFailedStorageResponseProto$Builder' start='49693' end='49842' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 49693-49842]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RestoreFailedStorageResponseProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RestoreFailedStorageResponseProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine endBytecode='61' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RestoreFailedStorageResponseProto$Builder' start='49719' end='49721' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RestoreFailedStorageResponseProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RestoreFailedStorageResponseProto$Builder' start='49719' end='49719' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='3' primary='true'><Message>At ClientNamenodeProtocolProtos.java:[line 49719]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='7c8f61847eda8fe394ba9af3bc357ab4' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RollEditsRequestProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RollEditsRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RollEditsRequestProto' start='48111' end='48442' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 48111-48442]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RollEditsRequestProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RollEditsRequestProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RollEditsRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RollEditsRequestProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RollEditsRequestProto' start='48182' end='48182' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='7' primary='true'><Message>At ClientNamenodeProtocolProtos.java:[line 48182]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='8e81131e13564a3052606f2e787a3f62' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RollEditsRequestProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RollEditsRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RollEditsRequestProto' start='48111' end='48442' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 48111-48442]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RollEditsRequestProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RollEditsRequestProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RollEditsRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RollEditsRequestProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RollEditsRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='32e769c9c62001ef364e15fc5e7965cc' rank='17' abbrev='UCF' category='STYLE' priority='2' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RollEditsRequestProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RollEditsRequestProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RollEditsRequestProto$Builder' start='48334' end='48433' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 48334-48433]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RollEditsRequestProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RollEditsRequestProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine endBytecode='61' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RollEditsRequestProto$Builder' start='48360' end='48362' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RollEditsRequestProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RollEditsRequestProto$Builder' start='48360' end='48360' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='3' primary='true'><Message>At ClientNamenodeProtocolProtos.java:[line 48360]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='95071c6eb88c522abe485e7ac53d86aa' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RollEditsResponseProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RollEditsResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RollEditsResponseProto' start='48467' end='48892' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 48467-48892]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RollEditsResponseProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RollEditsResponseProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RollEditsResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RollEditsResponseProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RollEditsResponseProto' start='48544' end='48544' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='7' primary='true'><Message>At ClientNamenodeProtocolProtos.java:[line 48544]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='1b41490d5694cd726ddcff60ef24b221' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RollEditsResponseProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RollEditsResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RollEditsResponseProto' start='48467' end='48892' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 48467-48892]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RollEditsResponseProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RollEditsResponseProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RollEditsResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RollEditsResponseProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RollEditsResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='32b9915c33c89e2e8a853732b8767a67' rank='17' abbrev='UCF' category='STYLE' priority='2' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RollEditsResponseProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RollEditsResponseProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RollEditsResponseProto$Builder' start='48734' end='48883' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 48734-48883]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RollEditsResponseProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RollEditsResponseProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine endBytecode='61' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RollEditsResponseProto$Builder' start='48760' end='48762' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RollEditsResponseProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RollEditsResponseProto$Builder' start='48760' end='48760' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='3' primary='true'><Message>At ClientNamenodeProtocolProtos.java:[line 48760]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='d72230b274f19ca5a92fea4d3a70cd11' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RollingUpgradeInfoProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RollingUpgradeInfoProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RollingUpgradeInfoProto' start='52529' end='53329' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 52529-53329]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RollingUpgradeInfoProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RollingUpgradeInfoProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RollingUpgradeInfoProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RollingUpgradeInfoProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RollingUpgradeInfoProto' start='52629' end='52629' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='7' primary='true'><Message>At ClientNamenodeProtocolProtos.java:[line 52629]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='14a1c9c3ca582fcc943737455f36ae1f' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RollingUpgradeInfoProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RollingUpgradeInfoProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RollingUpgradeInfoProto' start='52529' end='53329' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 52529-53329]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RollingUpgradeInfoProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RollingUpgradeInfoProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RollingUpgradeInfoProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RollingUpgradeInfoProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RollingUpgradeInfoProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='1adfbf333761089060b4fa1c367229db' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RollingUpgradeRequestProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RollingUpgradeRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RollingUpgradeRequestProto' start='52044' end='52474' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 52044-52474]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RollingUpgradeRequestProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RollingUpgradeRequestProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RollingUpgradeRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RollingUpgradeRequestProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RollingUpgradeRequestProto' start='52127' end='52127' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='7' primary='true'><Message>At ClientNamenodeProtocolProtos.java:[line 52127]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='31dd0d72215d946eb5bd445edb949ea' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RollingUpgradeRequestProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RollingUpgradeRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RollingUpgradeRequestProto' start='52044' end='52474' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 52044-52474]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RollingUpgradeRequestProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RollingUpgradeRequestProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RollingUpgradeRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RollingUpgradeRequestProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RollingUpgradeRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='60c5b7756c92960433c5392f1fadbe13' rank='17' abbrev='UCF' category='STYLE' priority='2' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RollingUpgradeRequestProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RollingUpgradeRequestProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RollingUpgradeRequestProto$Builder' start='52313' end='52465' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 52313-52465]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RollingUpgradeRequestProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RollingUpgradeRequestProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine endBytecode='61' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RollingUpgradeRequestProto$Builder' start='52339' end='52341' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RollingUpgradeRequestProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RollingUpgradeRequestProto$Builder' start='52339' end='52339' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='3' primary='true'><Message>At ClientNamenodeProtocolProtos.java:[line 52339]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='b464ae484e102d3ae97cd4ff4cebadb5' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RollingUpgradeResponseProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RollingUpgradeResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RollingUpgradeResponseProto' start='53354' end='53886' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 53354-53886]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RollingUpgradeResponseProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RollingUpgradeResponseProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RollingUpgradeResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RollingUpgradeResponseProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RollingUpgradeResponseProto' start='53439' end='53439' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='7' primary='true'><Message>At ClientNamenodeProtocolProtos.java:[line 53439]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='b36fd55502413bb54db611b0e48d04ba' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RollingUpgradeResponseProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RollingUpgradeResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RollingUpgradeResponseProto' start='53354' end='53886' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 53354-53886]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RollingUpgradeResponseProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RollingUpgradeResponseProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RollingUpgradeResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RollingUpgradeResponseProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RollingUpgradeResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='ca73fde34d48c65ea6c07f1584b57dd6' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SaveNamespaceRequestProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SaveNamespaceRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SaveNamespaceRequestProto' start='47161' end='47654' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 47161-47654]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SaveNamespaceRequestProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SaveNamespaceRequestProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SaveNamespaceRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SaveNamespaceRequestProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SaveNamespaceRequestProto' start='47243' end='47243' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='7' primary='true'><Message>At ClientNamenodeProtocolProtos.java:[line 47243]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='55be116e2757208dfb752dd42405a02d' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SaveNamespaceRequestProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SaveNamespaceRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SaveNamespaceRequestProto' start='47161' end='47654' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 47161-47654]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SaveNamespaceRequestProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SaveNamespaceRequestProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SaveNamespaceRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SaveNamespaceRequestProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SaveNamespaceRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='2fd520bbdbd670f8534d2a2c50a05976' rank='17' abbrev='UCF' category='STYLE' priority='2' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SaveNamespaceRequestProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SaveNamespaceRequestProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SaveNamespaceRequestProto$Builder' start='47458' end='47645' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 47458-47645]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SaveNamespaceRequestProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SaveNamespaceRequestProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine endBytecode='61' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SaveNamespaceRequestProto$Builder' start='47484' end='47486' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SaveNamespaceRequestProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SaveNamespaceRequestProto$Builder' start='47484' end='47484' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='3' primary='true'><Message>At ClientNamenodeProtocolProtos.java:[line 47484]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='82a710f3db9dfcc74376afc85e9b69a8' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SaveNamespaceResponseProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SaveNamespaceResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SaveNamespaceResponseProto' start='47679' end='48096' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 47679-48096]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SaveNamespaceResponseProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SaveNamespaceResponseProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SaveNamespaceResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SaveNamespaceResponseProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SaveNamespaceResponseProto' start='47756' end='47756' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='7' primary='true'><Message>At ClientNamenodeProtocolProtos.java:[line 47756]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='c2c4dde13f67b320e9cfa360902edb2f' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SaveNamespaceResponseProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SaveNamespaceResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SaveNamespaceResponseProto' start='47679' end='48096' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 47679-48096]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SaveNamespaceResponseProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SaveNamespaceResponseProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SaveNamespaceResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SaveNamespaceResponseProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SaveNamespaceResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='44ee98b18506101704c8f79f3f90cf21' rank='17' abbrev='UCF' category='STYLE' priority='2' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SaveNamespaceResponseProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SaveNamespaceResponseProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SaveNamespaceResponseProto$Builder' start='47942' end='48087' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 47942-48087]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SaveNamespaceResponseProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SaveNamespaceResponseProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine endBytecode='61' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SaveNamespaceResponseProto$Builder' start='47968' end='47970' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SaveNamespaceResponseProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SaveNamespaceResponseProto$Builder' start='47968' end='47968' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='3' primary='true'><Message>At ClientNamenodeProtocolProtos.java:[line 47968]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='3af2ea87e16163808004f152044773c4' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetBalancerBandwidthRequestProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetBalancerBandwidthRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetBalancerBandwidthRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetBalancerBandwidthRequestProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetBalancerBandwidthRequestProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetBalancerBandwidthRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetBalancerBandwidthRequestProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetBalancerBandwidthRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='7'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='158399dee568499764204b54dbbcc380' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetBalancerBandwidthRequestProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetBalancerBandwidthRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetBalancerBandwidthRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetBalancerBandwidthRequestProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetBalancerBandwidthRequestProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetBalancerBandwidthRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetBalancerBandwidthRequestProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetBalancerBandwidthRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='4a4bd17ed2add94e32cfd005e39c657e' rank='20' abbrev='UCF' category='STYLE' priority='3' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetBalancerBandwidthRequestProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetBalancerBandwidthRequestProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetBalancerBandwidthRequestProto$Builder' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetBalancerBandwidthRequestProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetBalancerBandwidthRequestProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetBalancerBandwidthRequestProto$Builder' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetBalancerBandwidthRequestProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetBalancerBandwidthRequestProto$Builder' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='3'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='479c2ea28679af32ce708d9436efec4b' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetBalancerBandwidthResponseProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetBalancerBandwidthResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetBalancerBandwidthResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetBalancerBandwidthResponseProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetBalancerBandwidthResponseProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetBalancerBandwidthResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetBalancerBandwidthResponseProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetBalancerBandwidthResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='7'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='db493daa5a5f83c3173e0af67167f6a4' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetBalancerBandwidthResponseProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetBalancerBandwidthResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetBalancerBandwidthResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetBalancerBandwidthResponseProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetBalancerBandwidthResponseProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetBalancerBandwidthResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetBalancerBandwidthResponseProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetBalancerBandwidthResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='3ebc44ce4971bd098c05cd9bd187c15c' rank='20' abbrev='UCF' category='STYLE' priority='3' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetBalancerBandwidthResponseProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetBalancerBandwidthResponseProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetBalancerBandwidthResponseProto$Builder' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetBalancerBandwidthResponseProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetBalancerBandwidthResponseProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetBalancerBandwidthResponseProto$Builder' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetBalancerBandwidthResponseProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetBalancerBandwidthResponseProto$Builder' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='3'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='31f2013bd3ed305292d244bf824baac0' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetOwnerRequestProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetOwnerRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetOwnerRequestProto' start='13339' end='14130' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 13339-14130]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetOwnerRequestProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetOwnerRequestProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetOwnerRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetOwnerRequestProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetOwnerRequestProto' start='13426' end='13426' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='7' primary='true'><Message>At ClientNamenodeProtocolProtos.java:[line 13426]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='2cbc8d7cd172d062d531678a1529df6d' rank='19' abbrev='Nm' category='BAD_PRACTICE' priority='3' type='NM_CONFUSING' instanceOccurrenceMax='0'><ShortMessage>Confusing method names</ShortMessage><LongMessage>Confusing to have methods org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetOwnerRequestProto.getUsername() and org.apache.hadoop.hdfs.web.KerberosUgiAuthenticator$1.getUserName()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetOwnerRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetOwnerRequestProto' start='13339' end='14130' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 13339-14130]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetOwnerRequestProto</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetOwnerRequestProto' signature='()Ljava/lang/String;' name='getUsername' primary='true'><SourceLine endBytecode='163' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetOwnerRequestProto' start='13498' end='13508' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetOwnerRequestProto.getUsername()</Message></Method><Class classname='org.apache.hadoop.hdfs.web.KerberosUgiAuthenticator$1'><SourceLine classname='org.apache.hadoop.hdfs.web.KerberosUgiAuthenticator$1' start='34' end='40' sourcepath='org/apache/hadoop/hdfs/web/KerberosUgiAuthenticator.java' sourcefile='KerberosUgiAuthenticator.java'><Message>At KerberosUgiAuthenticator.java:[lines 34-40]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.web.KerberosUgiAuthenticator$1</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.web.KerberosUgiAuthenticator$1' signature='()Ljava/lang/String;' name='getUserName'><SourceLine endBytecode='98' classname='org.apache.hadoop.hdfs.web.KerberosUgiAuthenticator$1' start='38' end='40' sourcepath='org/apache/hadoop/hdfs/web/KerberosUgiAuthenticator.java' sourcefile='KerberosUgiAuthenticator.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.web.KerberosUgiAuthenticator$1.getUserName()</Message></Method><SourceLine synthetic='true' endBytecode='163' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetOwnerRequestProto' start='13498' end='13508' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'><Message>At ClientNamenodeProtocolProtos.java:[lines 13498-13508]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='bb136d825084dd51f44b4e188b5793e7' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetOwnerRequestProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetOwnerRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetOwnerRequestProto' start='13339' end='14130' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 13339-14130]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetOwnerRequestProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetOwnerRequestProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetOwnerRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetOwnerRequestProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetOwnerRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='fa4f526bf555e234f8a5b1dee2d1761f' rank='17' abbrev='UCF' category='STYLE' priority='2' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetOwnerRequestProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetOwnerRequestProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetOwnerRequestProto$Builder' start='13759' end='14121' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 13759-14121]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetOwnerRequestProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetOwnerRequestProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine endBytecode='61' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetOwnerRequestProto$Builder' start='13785' end='13787' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetOwnerRequestProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetOwnerRequestProto$Builder' start='13785' end='13785' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='3' primary='true'><Message>At ClientNamenodeProtocolProtos.java:[line 13785]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='f2646c77f266a4a7a8e4a712f2d22d39' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetOwnerResponseProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetOwnerResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetOwnerResponseProto' start='14145' end='14476' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 14145-14476]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetOwnerResponseProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetOwnerResponseProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetOwnerResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetOwnerResponseProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetOwnerResponseProto' start='14216' end='14216' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='7' primary='true'><Message>At ClientNamenodeProtocolProtos.java:[line 14216]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='3c8519036b7f769c792009a7c2fc0fb4' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetOwnerResponseProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetOwnerResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetOwnerResponseProto' start='14145' end='14476' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 14145-14476]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetOwnerResponseProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetOwnerResponseProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetOwnerResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetOwnerResponseProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetOwnerResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='dc2bfa62b9631280a143c475aafa979f' rank='17' abbrev='UCF' category='STYLE' priority='2' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetOwnerResponseProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetOwnerResponseProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetOwnerResponseProto$Builder' start='14368' end='14467' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 14368-14467]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetOwnerResponseProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetOwnerResponseProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine endBytecode='61' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetOwnerResponseProto$Builder' start='14394' end='14396' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetOwnerResponseProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetOwnerResponseProto$Builder' start='14394' end='14394' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='3' primary='true'><Message>At ClientNamenodeProtocolProtos.java:[line 14394]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='350836e57958b1e2ac1bcaeafea05c23' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetPermissionRequestProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetPermissionRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetPermissionRequestProto' start='12243' end='12937' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 12243-12937]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetPermissionRequestProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetPermissionRequestProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetPermissionRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetPermissionRequestProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetPermissionRequestProto' start='12333' end='12333' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='7' primary='true'><Message>At ClientNamenodeProtocolProtos.java:[line 12333]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='d51cd4ad5b99365e01591ef3ea520c1f' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetPermissionRequestProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetPermissionRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetPermissionRequestProto' start='12243' end='12937' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 12243-12937]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetPermissionRequestProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetPermissionRequestProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetPermissionRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetPermissionRequestProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetPermissionRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='276c33e09cb7f287086ac5591a36ed06' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetPermissionResponseProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetPermissionResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetPermissionResponseProto' start='12952' end='13283' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 12952-13283]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetPermissionResponseProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetPermissionResponseProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetPermissionResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetPermissionResponseProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetPermissionResponseProto' start='13023' end='13023' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='7' primary='true'><Message>At ClientNamenodeProtocolProtos.java:[line 13023]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='9d3a82357f3532a2c9e2d9ce799125d0' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetPermissionResponseProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetPermissionResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetPermissionResponseProto' start='12952' end='13283' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 12952-13283]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetPermissionResponseProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetPermissionResponseProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetPermissionResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetPermissionResponseProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetPermissionResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='633c6af02b2bdf37d970f395879b42b2' rank='17' abbrev='UCF' category='STYLE' priority='2' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetPermissionResponseProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetPermissionResponseProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetPermissionResponseProto$Builder' start='13175' end='13274' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 13175-13274]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetPermissionResponseProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetPermissionResponseProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine endBytecode='61' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetPermissionResponseProto$Builder' start='13201' end='13203' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetPermissionResponseProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetPermissionResponseProto$Builder' start='13201' end='13201' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='3' primary='true'><Message>At ClientNamenodeProtocolProtos.java:[line 13201]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='751d638303281ecf840377f631293bdd' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetQuotaRequestProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetQuotaRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetQuotaRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetQuotaRequestProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetQuotaRequestProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetQuotaRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetQuotaRequestProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetQuotaRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='7'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='22dfa35f4cf81c354ccd013e6747bbf9' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetQuotaRequestProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetQuotaRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetQuotaRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetQuotaRequestProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetQuotaRequestProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetQuotaRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetQuotaRequestProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetQuotaRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='2ef12524263a526cdfdae3a67661eb95' rank='20' abbrev='UCF' category='STYLE' priority='3' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetQuotaRequestProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetQuotaRequestProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetQuotaRequestProto$Builder' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetQuotaRequestProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetQuotaRequestProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetQuotaRequestProto$Builder' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetQuotaRequestProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetQuotaRequestProto$Builder' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='3'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='1b4b58a7046473dfd1b019fcf4ca8d9d' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetQuotaResponseProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetQuotaResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetQuotaResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetQuotaResponseProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetQuotaResponseProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetQuotaResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetQuotaResponseProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetQuotaResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='7'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='2816e25ef8214f11df225b3766f79e1f' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetQuotaResponseProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetQuotaResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetQuotaResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetQuotaResponseProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetQuotaResponseProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetQuotaResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetQuotaResponseProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetQuotaResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='96fa417c114a768955729c03c66c7f5a' rank='20' abbrev='UCF' category='STYLE' priority='3' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetQuotaResponseProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetQuotaResponseProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetQuotaResponseProto$Builder' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetQuotaResponseProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetQuotaResponseProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetQuotaResponseProto$Builder' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetQuotaResponseProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetQuotaResponseProto$Builder' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='3'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='2166e9266dea6a36c10d3df16a6b9630' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetReplicationRequestProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetReplicationRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetReplicationRequestProto' start='7122' end='7725' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 7122-7725]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetReplicationRequestProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetReplicationRequestProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetReplicationRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetReplicationRequestProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetReplicationRequestProto' start='7204' end='7204' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='7' primary='true'><Message>At ClientNamenodeProtocolProtos.java:[line 7204]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='5caca5df7247e221dc47c92a99a85983' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetReplicationRequestProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetReplicationRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetReplicationRequestProto' start='7122' end='7725' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 7122-7725]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetReplicationRequestProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetReplicationRequestProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetReplicationRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetReplicationRequestProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetReplicationRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='c9ee7e1b5e6075f4423f8e4ff4ea55e8' rank='17' abbrev='UCF' category='STYLE' priority='2' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetReplicationRequestProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetReplicationRequestProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetReplicationRequestProto$Builder' start='7462' end='7716' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 7462-7716]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetReplicationRequestProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetReplicationRequestProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine endBytecode='61' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetReplicationRequestProto$Builder' start='7488' end='7490' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetReplicationRequestProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetReplicationRequestProto$Builder' start='7488' end='7488' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='3' primary='true'><Message>At ClientNamenodeProtocolProtos.java:[line 7488]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='c996d6ee32761a7046f8406d32c50c4d' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetReplicationResponseProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetReplicationResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetReplicationResponseProto' start='7746' end='8167' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 7746-8167]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetReplicationResponseProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetReplicationResponseProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetReplicationResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetReplicationResponseProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetReplicationResponseProto' start='7823' end='7823' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='7' primary='true'><Message>At ClientNamenodeProtocolProtos.java:[line 7823]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='beddb881cd06ecf21f2a2978811e677' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetReplicationResponseProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetReplicationResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetReplicationResponseProto' start='7746' end='8167' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 7746-8167]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetReplicationResponseProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetReplicationResponseProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetReplicationResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetReplicationResponseProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetReplicationResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='855066329ea2781d45168164c913e3c4' rank='17' abbrev='UCF' category='STYLE' priority='2' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetReplicationResponseProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetReplicationResponseProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetReplicationResponseProto$Builder' start='8009' end='8158' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 8009-8158]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetReplicationResponseProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetReplicationResponseProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine endBytecode='61' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetReplicationResponseProto$Builder' start='8035' end='8037' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetReplicationResponseProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetReplicationResponseProto$Builder' start='8035' end='8035' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='3' primary='true'><Message>At ClientNamenodeProtocolProtos.java:[line 8035]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='ad65b701a0107088761ce34de5d377bf' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetSafeModeRequestProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetSafeModeRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetSafeModeRequestProto' start='46178' end='46688' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 46178-46688]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetSafeModeRequestProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetSafeModeRequestProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetSafeModeRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetSafeModeRequestProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetSafeModeRequestProto' start='46266' end='46266' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='7' primary='true'><Message>At ClientNamenodeProtocolProtos.java:[line 46266]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='259d62245824d4e0a4db076835b6dd2a' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetSafeModeRequestProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetSafeModeRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetSafeModeRequestProto' start='46178' end='46688' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 46178-46688]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetSafeModeRequestProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetSafeModeRequestProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetSafeModeRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetSafeModeRequestProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetSafeModeRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='12f4295d9bb2f390652d7d7a415b9a26' rank='17' abbrev='UCF' category='STYLE' priority='2' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetSafeModeRequestProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetSafeModeRequestProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetSafeModeRequestProto$Builder' start='46485' end='46679' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 46485-46679]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetSafeModeRequestProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetSafeModeRequestProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine endBytecode='61' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetSafeModeRequestProto$Builder' start='46511' end='46513' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetSafeModeRequestProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetSafeModeRequestProto$Builder' start='46511' end='46511' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='3' primary='true'><Message>At ClientNamenodeProtocolProtos.java:[line 46511]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='4605b0671e92d3fd1f5ec4b9bcf73bad' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetSafeModeResponseProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetSafeModeResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetSafeModeResponseProto' start='46709' end='47130' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 46709-47130]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetSafeModeResponseProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetSafeModeResponseProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetSafeModeResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetSafeModeResponseProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetSafeModeResponseProto' start='46786' end='46786' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='7' primary='true'><Message>At ClientNamenodeProtocolProtos.java:[line 46786]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='481cf99ca9005ba16a5a475fd6606ec8' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetSafeModeResponseProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetSafeModeResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetSafeModeResponseProto' start='46709' end='47130' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 46709-47130]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetSafeModeResponseProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetSafeModeResponseProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetSafeModeResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetSafeModeResponseProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetSafeModeResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='696b2f548d4f094133e848cd67b19f9d' rank='17' abbrev='UCF' category='STYLE' priority='2' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetSafeModeResponseProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetSafeModeResponseProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetSafeModeResponseProto$Builder' start='46972' end='47121' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 46972-47121]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetSafeModeResponseProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetSafeModeResponseProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine endBytecode='61' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetSafeModeResponseProto$Builder' start='46998' end='47000' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetSafeModeResponseProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetSafeModeResponseProto$Builder' start='46998' end='46998' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='3' primary='true'><Message>At ClientNamenodeProtocolProtos.java:[line 46998]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='798c11b9aed41ce8ba64b707cedf009b' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetStoragePolicyRequestProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetStoragePolicyRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetStoragePolicyRequestProto' start='8208' end='8857' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 8208-8857]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetStoragePolicyRequestProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetStoragePolicyRequestProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetStoragePolicyRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetStoragePolicyRequestProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetStoragePolicyRequestProto' start='8290' end='8290' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='7' primary='true'><Message>At ClientNamenodeProtocolProtos.java:[line 8290]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='cad78069a441e8e645055ed604421b39' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetStoragePolicyRequestProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetStoragePolicyRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetStoragePolicyRequestProto' start='8208' end='8857' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 8208-8857]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetStoragePolicyRequestProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetStoragePolicyRequestProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetStoragePolicyRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetStoragePolicyRequestProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetStoragePolicyRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='9565fff0c23f8c7be17fc707c0ebff12' rank='17' abbrev='UCF' category='STYLE' priority='2' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetStoragePolicyRequestProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetStoragePolicyRequestProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetStoragePolicyRequestProto$Builder' start='8567' end='8848' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 8567-8848]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetStoragePolicyRequestProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetStoragePolicyRequestProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine endBytecode='61' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetStoragePolicyRequestProto$Builder' start='8593' end='8595' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetStoragePolicyRequestProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetStoragePolicyRequestProto$Builder' start='8593' end='8593' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='3' primary='true'><Message>At ClientNamenodeProtocolProtos.java:[line 8593]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='ee9b619bd311230570d9afcc91339c2' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetStoragePolicyResponseProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetStoragePolicyResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetStoragePolicyResponseProto' start='8872' end='9203' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 8872-9203]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetStoragePolicyResponseProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetStoragePolicyResponseProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetStoragePolicyResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetStoragePolicyResponseProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetStoragePolicyResponseProto' start='8943' end='8943' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='7' primary='true'><Message>At ClientNamenodeProtocolProtos.java:[line 8943]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='1c54995e8f494272a1f1e359058ee4d9' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetStoragePolicyResponseProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetStoragePolicyResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetStoragePolicyResponseProto' start='8872' end='9203' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 8872-9203]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetStoragePolicyResponseProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetStoragePolicyResponseProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetStoragePolicyResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetStoragePolicyResponseProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetStoragePolicyResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='33c23400f83c06dda038bf6ada6c83fa' rank='17' abbrev='UCF' category='STYLE' priority='2' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetStoragePolicyResponseProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetStoragePolicyResponseProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetStoragePolicyResponseProto$Builder' start='9095' end='9194' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 9095-9194]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetStoragePolicyResponseProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetStoragePolicyResponseProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine endBytecode='61' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetStoragePolicyResponseProto$Builder' start='9121' end='9123' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetStoragePolicyResponseProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetStoragePolicyResponseProto$Builder' start='9121' end='9121' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='3' primary='true'><Message>At ClientNamenodeProtocolProtos.java:[line 9121]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='f77c14f097e9ec139a292b7065fc0a48' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetTimesRequestProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetTimesRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetTimesRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetTimesRequestProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetTimesRequestProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetTimesRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetTimesRequestProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetTimesRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='7'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='eed5eb4316809c02a4a6c3b6c4bbb51e' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetTimesRequestProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetTimesRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetTimesRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetTimesRequestProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetTimesRequestProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetTimesRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetTimesRequestProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetTimesRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='37e62479efdb02e25d9525aa57817602' rank='20' abbrev='UCF' category='STYLE' priority='3' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetTimesRequestProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetTimesRequestProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetTimesRequestProto$Builder' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetTimesRequestProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetTimesRequestProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetTimesRequestProto$Builder' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetTimesRequestProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetTimesRequestProto$Builder' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='3'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='af17f827ddca463526489d6fbb51ea7d' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetTimesResponseProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetTimesResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetTimesResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetTimesResponseProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetTimesResponseProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetTimesResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetTimesResponseProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetTimesResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='7'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='46d4819bf244c6bfb42bf3c1e7a60c76' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetTimesResponseProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetTimesResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetTimesResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetTimesResponseProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetTimesResponseProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetTimesResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetTimesResponseProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetTimesResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='fdd39d9c3a6486df8cc80a93f89c02c5' rank='20' abbrev='UCF' category='STYLE' priority='3' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetTimesResponseProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetTimesResponseProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetTimesResponseProto$Builder' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetTimesResponseProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetTimesResponseProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetTimesResponseProto$Builder' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetTimesResponseProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetTimesResponseProto$Builder' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='3'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='cc1ac3767b7404fdd9ee015c3662752f' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$TruncateRequestProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$TruncateRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$TruncateRequestProto' start='24586' end='25323' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 24586-25323]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$TruncateRequestProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$TruncateRequestProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$TruncateRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$TruncateRequestProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$TruncateRequestProto' start='24673' end='24673' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='7' primary='true'><Message>At ClientNamenodeProtocolProtos.java:[line 24673]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='5fdfb92e53246d2a9263d7b34e9468e3' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$TruncateRequestProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$TruncateRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$TruncateRequestProto' start='24586' end='25323' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 24586-25323]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$TruncateRequestProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$TruncateRequestProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$TruncateRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$TruncateRequestProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$TruncateRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='7ef981a869cf5856d3e34f391797e708' rank='17' abbrev='UCF' category='STYLE' priority='2' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$TruncateRequestProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$TruncateRequestProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$TruncateRequestProto$Builder' start='24987' end='25314' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 24987-25314]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$TruncateRequestProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$TruncateRequestProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine endBytecode='61' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$TruncateRequestProto$Builder' start='25013' end='25015' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$TruncateRequestProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$TruncateRequestProto$Builder' start='25013' end='25013' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='3' primary='true'><Message>At ClientNamenodeProtocolProtos.java:[line 25013]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='4821aae39d37096e35a033467a3a6b29' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$TruncateResponseProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$TruncateResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$TruncateResponseProto' start='25344' end='25765' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 25344-25765]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$TruncateResponseProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$TruncateResponseProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$TruncateResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$TruncateResponseProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$TruncateResponseProto' start='25421' end='25421' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='7' primary='true'><Message>At ClientNamenodeProtocolProtos.java:[line 25421]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='9dd1fb301d1f6f40f89e365a801237e4' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$TruncateResponseProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$TruncateResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$TruncateResponseProto' start='25344' end='25765' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 25344-25765]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$TruncateResponseProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$TruncateResponseProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$TruncateResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$TruncateResponseProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$TruncateResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='d0fbc6f79d3dbf70d57ba5aa12a87324' rank='17' abbrev='UCF' category='STYLE' priority='2' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$TruncateResponseProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$TruncateResponseProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$TruncateResponseProto$Builder' start='25607' end='25756' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 25607-25756]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$TruncateResponseProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$TruncateResponseProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine endBytecode='61' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$TruncateResponseProto$Builder' start='25633' end='25635' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$TruncateResponseProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$TruncateResponseProto$Builder' start='25633' end='25633' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='3' primary='true'><Message>At ClientNamenodeProtocolProtos.java:[line 25633]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='91a066b619eb8155c71eff4f26e6139a' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UnsetStoragePolicyRequestProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UnsetStoragePolicyRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UnsetStoragePolicyRequestProto' start='9229' end='9720' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 9229-9720]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UnsetStoragePolicyRequestProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UnsetStoragePolicyRequestProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UnsetStoragePolicyRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UnsetStoragePolicyRequestProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UnsetStoragePolicyRequestProto' start='9306' end='9306' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='7' primary='true'><Message>At ClientNamenodeProtocolProtos.java:[line 9306]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='5e08443e638dd15b50434a5db435c463' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UnsetStoragePolicyRequestProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UnsetStoragePolicyRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UnsetStoragePolicyRequestProto' start='9229' end='9720' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 9229-9720]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UnsetStoragePolicyRequestProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UnsetStoragePolicyRequestProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UnsetStoragePolicyRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UnsetStoragePolicyRequestProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UnsetStoragePolicyRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='c6e9b462e7983d00b0ee0f5209a0ff8f' rank='17' abbrev='UCF' category='STYLE' priority='2' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UnsetStoragePolicyRequestProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UnsetStoragePolicyRequestProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UnsetStoragePolicyRequestProto$Builder' start='9519' end='9711' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 9519-9711]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UnsetStoragePolicyRequestProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UnsetStoragePolicyRequestProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine endBytecode='61' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UnsetStoragePolicyRequestProto$Builder' start='9545' end='9547' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UnsetStoragePolicyRequestProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UnsetStoragePolicyRequestProto$Builder' start='9545' end='9545' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='3' primary='true'><Message>At ClientNamenodeProtocolProtos.java:[line 9545]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='ac1a123d4c1ec66e57047c8dec5b5db1' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UnsetStoragePolicyResponseProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UnsetStoragePolicyResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UnsetStoragePolicyResponseProto' start='9731' end='10058' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 9731-10058]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UnsetStoragePolicyResponseProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UnsetStoragePolicyResponseProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UnsetStoragePolicyResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UnsetStoragePolicyResponseProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UnsetStoragePolicyResponseProto' start='9802' end='9802' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='7' primary='true'><Message>At ClientNamenodeProtocolProtos.java:[line 9802]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='3682b41ba1fbc41fd95fd867319d3e64' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UnsetStoragePolicyResponseProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UnsetStoragePolicyResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UnsetStoragePolicyResponseProto' start='9731' end='10058' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 9731-10058]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UnsetStoragePolicyResponseProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UnsetStoragePolicyResponseProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UnsetStoragePolicyResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UnsetStoragePolicyResponseProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UnsetStoragePolicyResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='e5005454762387a0b79788e513bc5427' rank='17' abbrev='UCF' category='STYLE' priority='2' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UnsetStoragePolicyResponseProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UnsetStoragePolicyResponseProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UnsetStoragePolicyResponseProto$Builder' start='9950' end='10049' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 9950-10049]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UnsetStoragePolicyResponseProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UnsetStoragePolicyResponseProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine endBytecode='61' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UnsetStoragePolicyResponseProto$Builder' start='9976' end='9978' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UnsetStoragePolicyResponseProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UnsetStoragePolicyResponseProto$Builder' start='9976' end='9976' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='3' primary='true'><Message>At ClientNamenodeProtocolProtos.java:[line 9976]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='528c9974cf48c390982ebe6baf8614d7' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpdateBlockForPipelineRequestProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpdateBlockForPipelineRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpdateBlockForPipelineRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpdateBlockForPipelineRequestProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpdateBlockForPipelineRequestProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpdateBlockForPipelineRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpdateBlockForPipelineRequestProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpdateBlockForPipelineRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='7'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='de4758ab7ed6d11103c867b00b89c671' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpdateBlockForPipelineRequestProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpdateBlockForPipelineRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpdateBlockForPipelineRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpdateBlockForPipelineRequestProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpdateBlockForPipelineRequestProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpdateBlockForPipelineRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpdateBlockForPipelineRequestProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpdateBlockForPipelineRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='1bd83cf1057847be907baba95948eb1e' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpdateBlockForPipelineResponseProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpdateBlockForPipelineResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpdateBlockForPipelineResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpdateBlockForPipelineResponseProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpdateBlockForPipelineResponseProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpdateBlockForPipelineResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpdateBlockForPipelineResponseProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpdateBlockForPipelineResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='7'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='b1c664db552084544af5994942d1bc58' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpdateBlockForPipelineResponseProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpdateBlockForPipelineResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpdateBlockForPipelineResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpdateBlockForPipelineResponseProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpdateBlockForPipelineResponseProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpdateBlockForPipelineResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpdateBlockForPipelineResponseProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpdateBlockForPipelineResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='5b3a4ccaa3b8907a94f4a295580ce636' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpdatePipelineRequestProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpdatePipelineRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpdatePipelineRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpdatePipelineRequestProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpdatePipelineRequestProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpdatePipelineRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpdatePipelineRequestProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpdatePipelineRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='7'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='eec9603c6bb6cefae8e6b5e77acfb920' rank='19' abbrev='Nm' category='BAD_PRACTICE' priority='3' type='NM_CONFUSING' instanceOccurrenceMax='0'><ShortMessage>Confusing method names</ShortMessage><LongMessage>Confusing to have methods org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpdatePipelineRequestProto.getStorageIDs(int) and org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$BlockTokenSecretProto.getStorageIds(int)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpdatePipelineRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpdatePipelineRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpdatePipelineRequestProto</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpdatePipelineRequestProto' signature='(I)Ljava/lang/String;' name='getStorageIDs' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpdatePipelineRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpdatePipelineRequestProto.getStorageIDs(int)</Message></Method><Class classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$BlockTokenSecretProto'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$BlockTokenSecretProto' start='49022' end='50414' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>At HdfsProtos.java:[lines 49022-50414]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$BlockTokenSecretProto</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$BlockTokenSecretProto' signature='(I)Ljava/lang/String;' name='getStorageIds'><SourceLine endBytecode='65' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$BlockTokenSecretProto' start='49416' end='49416' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$BlockTokenSecretProto.getStorageIds(int)</Message></Method><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpdatePipelineRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='8b7ac808b761c1e74e97cbeccfecf71d' rank='19' abbrev='Nm' category='BAD_PRACTICE' priority='3' type='NM_CONFUSING' instanceOccurrenceMax='0'><ShortMessage>Confusing method names</ShortMessage><LongMessage>Confusing to have methods org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpdatePipelineRequestProto.getStorageIDsBytes(int) and org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$BlockTokenSecretProto.getStorageIdsBytes(int)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpdatePipelineRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpdatePipelineRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpdatePipelineRequestProto</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpdatePipelineRequestProto' signature='(I)Lcom/google/protobuf/ByteString;' name='getStorageIDsBytes' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpdatePipelineRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpdatePipelineRequestProto.getStorageIDsBytes(int)</Message></Method><Class classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$BlockTokenSecretProto'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$BlockTokenSecretProto' start='49022' end='50414' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>At HdfsProtos.java:[lines 49022-50414]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$BlockTokenSecretProto</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$BlockTokenSecretProto' signature='(I)Lcom/google/protobuf/ByteString;' name='getStorageIdsBytes'><SourceLine endBytecode='62' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$BlockTokenSecretProto' start='49423' end='49423' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$BlockTokenSecretProto.getStorageIdsBytes(int)</Message></Method><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpdatePipelineRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='4b7cf821c81e6e21d9dcdbb36ba2f914' rank='19' abbrev='Nm' category='BAD_PRACTICE' priority='3' type='NM_CONFUSING' instanceOccurrenceMax='0'><ShortMessage>Confusing method names</ShortMessage><LongMessage>Confusing to have methods org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpdatePipelineRequestProto.getStorageIDsCount() and org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$BlockTokenSecretProto.getStorageIdsCount()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpdatePipelineRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpdatePipelineRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpdatePipelineRequestProto</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpdatePipelineRequestProto' signature='()I' name='getStorageIDsCount' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpdatePipelineRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpdatePipelineRequestProto.getStorageIDsCount()</Message></Method><Class classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$BlockTokenSecretProto'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$BlockTokenSecretProto' start='49022' end='50414' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>At HdfsProtos.java:[lines 49022-50414]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$BlockTokenSecretProto</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$BlockTokenSecretProto' signature='()I' name='getStorageIdsCount'><SourceLine endBytecode='51' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$BlockTokenSecretProto' start='49410' end='49410' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$BlockTokenSecretProto.getStorageIdsCount()</Message></Method><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpdatePipelineRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='5111e73371521b3d039ceae0ecb02251' rank='19' abbrev='Nm' category='BAD_PRACTICE' priority='3' type='NM_CONFUSING' instanceOccurrenceMax='0'><ShortMessage>Confusing method names</ShortMessage><LongMessage>Confusing to have methods org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpdatePipelineRequestProto.getStorageIDsList() and org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$BlockTokenSecretProto.getStorageIdsList()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpdatePipelineRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpdatePipelineRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpdatePipelineRequestProto</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpdatePipelineRequestProto' signature='()Ljava/util/List;' name='getStorageIDsList' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpdatePipelineRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpdatePipelineRequestProto.getStorageIDsList()</Message></Method><Class classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$BlockTokenSecretProto'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$BlockTokenSecretProto' start='49022' end='50414' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>At HdfsProtos.java:[lines 49022-50414]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$BlockTokenSecretProto</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$BlockTokenSecretProto' signature='()Ljava/util/List;' name='getStorageIdsList'><SourceLine endBytecode='46' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$BlockTokenSecretProto' start='49404' end='49404' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$BlockTokenSecretProto.getStorageIdsList()</Message></Method><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpdatePipelineRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='53c578b6b967d4e710e4a8817d327450' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpdatePipelineRequestProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpdatePipelineRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpdatePipelineRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpdatePipelineRequestProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpdatePipelineRequestProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpdatePipelineRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpdatePipelineRequestProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpdatePipelineRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='c8657eb476a5cdaf362565454a22770c' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpdatePipelineResponseProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpdatePipelineResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpdatePipelineResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpdatePipelineResponseProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpdatePipelineResponseProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpdatePipelineResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpdatePipelineResponseProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpdatePipelineResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='7'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='f308d900644db2d7a6d3229bc51e7b41' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpdatePipelineResponseProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpdatePipelineResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpdatePipelineResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpdatePipelineResponseProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpdatePipelineResponseProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpdatePipelineResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpdatePipelineResponseProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpdatePipelineResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='e4395ac956519b594217f71809ba0b69' rank='20' abbrev='UCF' category='STYLE' priority='3' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpdatePipelineResponseProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpdatePipelineResponseProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpdatePipelineResponseProto$Builder' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpdatePipelineResponseProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpdatePipelineResponseProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpdatePipelineResponseProto$Builder' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpdatePipelineResponseProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpdatePipelineResponseProto$Builder' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='3'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='1f4d52805fd74a04838dc4fdec44e5cd' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpgradeStatusRequestProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpgradeStatusRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpgradeStatusRequestProto' start='51250' end='51581' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 51250-51581]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpgradeStatusRequestProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpgradeStatusRequestProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpgradeStatusRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpgradeStatusRequestProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpgradeStatusRequestProto' start='51321' end='51321' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='7' primary='true'><Message>At ClientNamenodeProtocolProtos.java:[line 51321]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='2f306b167ea11b1d0b84ad8f84527bd1' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpgradeStatusRequestProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpgradeStatusRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpgradeStatusRequestProto' start='51250' end='51581' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 51250-51581]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpgradeStatusRequestProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpgradeStatusRequestProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpgradeStatusRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpgradeStatusRequestProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpgradeStatusRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='745e0e943d8881ce0bd6ec4d2a2a3da3' rank='17' abbrev='UCF' category='STYLE' priority='2' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpgradeStatusRequestProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpgradeStatusRequestProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpgradeStatusRequestProto$Builder' start='51473' end='51572' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 51473-51572]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpgradeStatusRequestProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpgradeStatusRequestProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine endBytecode='61' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpgradeStatusRequestProto$Builder' start='51499' end='51501' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpgradeStatusRequestProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpgradeStatusRequestProto$Builder' start='51499' end='51499' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='3' primary='true'><Message>At ClientNamenodeProtocolProtos.java:[line 51499]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='d526e11161148bcc3d607f806806cfb0' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpgradeStatusResponseProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpgradeStatusResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpgradeStatusResponseProto' start='51602' end='52023' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 51602-52023]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpgradeStatusResponseProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpgradeStatusResponseProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpgradeStatusResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpgradeStatusResponseProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpgradeStatusResponseProto' start='51679' end='51679' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='7' primary='true'><Message>At ClientNamenodeProtocolProtos.java:[line 51679]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='6e4ff535ff118f36d881d84f61fe3d1c' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpgradeStatusResponseProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpgradeStatusResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpgradeStatusResponseProto' start='51602' end='52023' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 51602-52023]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpgradeStatusResponseProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpgradeStatusResponseProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpgradeStatusResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpgradeStatusResponseProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpgradeStatusResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>In ClientNamenodeProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='9a70114ffce5d5a7d09094d35fb57cef' rank='17' abbrev='UCF' category='STYLE' priority='2' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpgradeStatusResponseProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpgradeStatusResponseProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpgradeStatusResponseProto$Builder' start='51865' end='52014' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java'><Message>At ClientNamenodeProtocolProtos.java:[lines 51865-52014]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpgradeStatusResponseProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpgradeStatusResponseProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine endBytecode='61' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpgradeStatusResponseProto$Builder' start='51891' end='51893' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpgradeStatusResponseProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpgradeStatusResponseProto$Builder' start='51891' end='51891' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' sourcefile='ClientNamenodeProtocolProtos.java' startBytecode='3' primary='true'><Message>At ClientNamenodeProtocolProtos.java:[line 51891]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='89a31573fa132fb5fa7321c2e1e57b50' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$BaseHeaderProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$BaseHeaderProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$BaseHeaderProto' start='1547' end='2481' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java'><Message>At DataTransferProtos.java:[lines 1547-2481]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$BaseHeaderProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$BaseHeaderProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$BaseHeaderProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java'><Message>In DataTransferProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$BaseHeaderProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$BaseHeaderProto' start='1658' end='1658' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java' startBytecode='7' primary='true'><Message>At DataTransferProtos.java:[line 1658]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='164f9b9538f752e201428b113479430c' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$BaseHeaderProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$BaseHeaderProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$BaseHeaderProto' start='1547' end='2481' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java'><Message>At DataTransferProtos.java:[lines 1547-2481]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$BaseHeaderProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$BaseHeaderProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$BaseHeaderProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java'><Message>In DataTransferProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$BaseHeaderProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$BaseHeaderProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java'><Message>In DataTransferProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='4133bd250885f27ef27465af76c1bfa3' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$BlockOpResponseProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$BlockOpResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$BlockOpResponseProto' start='23053' end='24357' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java'><Message>At DataTransferProtos.java:[lines 23053-24357]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$BlockOpResponseProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$BlockOpResponseProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$BlockOpResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java'><Message>In DataTransferProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$BlockOpResponseProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$BlockOpResponseProto' start='23177' end='23177' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java' startBytecode='7' primary='true'><Message>At DataTransferProtos.java:[line 23177]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='fddee36d95107e581ba0ea02086b6f36' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$BlockOpResponseProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$BlockOpResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$BlockOpResponseProto' start='23053' end='24357' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java'><Message>At DataTransferProtos.java:[lines 23053-24357]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$BlockOpResponseProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$BlockOpResponseProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$BlockOpResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java'><Message>In DataTransferProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$BlockOpResponseProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$BlockOpResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java'><Message>In DataTransferProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='ac828d4ad8c942934dc46db4e9df597a' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$CachingStrategyProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$CachingStrategyProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$CachingStrategyProto' start='3786' end='4279' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java'><Message>At DataTransferProtos.java:[lines 3786-4279]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$CachingStrategyProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$CachingStrategyProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$CachingStrategyProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java'><Message>In DataTransferProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$CachingStrategyProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$CachingStrategyProto' start='3868' end='3868' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java' startBytecode='7' primary='true'><Message>At DataTransferProtos.java:[line 3868]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='56d42e767958a8fadb471f1dd4f7a59d' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$CachingStrategyProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$CachingStrategyProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$CachingStrategyProto' start='3786' end='4279' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java'><Message>At DataTransferProtos.java:[lines 3786-4279]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$CachingStrategyProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$CachingStrategyProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$CachingStrategyProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java'><Message>In DataTransferProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$CachingStrategyProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$CachingStrategyProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java'><Message>In DataTransferProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='e18103b6c5ba4c1066ba2df59aaecb8' rank='17' abbrev='UCF' category='STYLE' priority='2' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$CachingStrategyProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$CachingStrategyProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$CachingStrategyProto$Builder' start='4083' end='4270' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java'><Message>At DataTransferProtos.java:[lines 4083-4270]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$CachingStrategyProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$CachingStrategyProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine endBytecode='61' classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$CachingStrategyProto$Builder' start='4109' end='4111' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$CachingStrategyProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$CachingStrategyProto$Builder' start='4109' end='4109' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java' startBytecode='3' primary='true'><Message>At DataTransferProtos.java:[line 4109]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='cffcc04b0103581c3656286ba637dc83' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ChecksumProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ChecksumProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ChecksumProto' start='5358' end='5876' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java'><Message>At DataTransferProtos.java:[lines 5358-5876]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ChecksumProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ChecksumProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ChecksumProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java'><Message>In DataTransferProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ChecksumProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ChecksumProto' start='5446' end='5446' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java' startBytecode='7' primary='true'><Message>At DataTransferProtos.java:[line 5446]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='b42256062259b7e76b43ada45c03c467' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ChecksumProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ChecksumProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ChecksumProto' start='5358' end='5876' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java'><Message>At DataTransferProtos.java:[lines 5358-5876]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ChecksumProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ChecksumProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ChecksumProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java'><Message>In DataTransferProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ChecksumProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ChecksumProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java'><Message>In DataTransferProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='ff1841a39dceb604696a5bfc37bab5d3' rank='17' abbrev='UCF' category='STYLE' priority='2' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ChecksumProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ChecksumProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ChecksumProto$Builder' start='5669' end='5867' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java'><Message>At DataTransferProtos.java:[lines 5669-5867]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ChecksumProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ChecksumProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine endBytecode='61' classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ChecksumProto$Builder' start='5695' end='5697' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ChecksumProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ChecksumProto$Builder' start='5695' end='5695' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java' startBytecode='3' primary='true'><Message>At DataTransferProtos.java:[line 5695]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='981eca2bc7f67f4792ae9abc1eb791c3' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ClientOperationHeaderProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ClientOperationHeaderProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ClientOperationHeaderProto' start='3061' end='3755' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java'><Message>At DataTransferProtos.java:[lines 3061-3755]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ClientOperationHeaderProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ClientOperationHeaderProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ClientOperationHeaderProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java'><Message>In DataTransferProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ClientOperationHeaderProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ClientOperationHeaderProto' start='3151' end='3151' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java' startBytecode='7' primary='true'><Message>At DataTransferProtos.java:[line 3151]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='32cb7becee1d4b922e000e6165a5733c' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ClientOperationHeaderProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ClientOperationHeaderProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ClientOperationHeaderProto' start='3061' end='3755' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java'><Message>At DataTransferProtos.java:[lines 3061-3755]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ClientOperationHeaderProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ClientOperationHeaderProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ClientOperationHeaderProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java'><Message>In DataTransferProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ClientOperationHeaderProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ClientOperationHeaderProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java'><Message>In DataTransferProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='ab3fd8b5feeb126683f399c6f9db7848' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ClientReadStatusProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ClientReadStatusProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ClientReadStatusProto' start='24384' end='24820' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java'><Message>At DataTransferProtos.java:[lines 24384-24820]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ClientReadStatusProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ClientReadStatusProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ClientReadStatusProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java'><Message>In DataTransferProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ClientReadStatusProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ClientReadStatusProto' start='24467' end='24467' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java' startBytecode='7' primary='true'><Message>At DataTransferProtos.java:[line 24467]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='17b93c0dd8d7af839be6a9945608a71c' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ClientReadStatusProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ClientReadStatusProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ClientReadStatusProto' start='24384' end='24820' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java'><Message>At DataTransferProtos.java:[lines 24384-24820]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ClientReadStatusProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ClientReadStatusProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ClientReadStatusProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java'><Message>In DataTransferProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ClientReadStatusProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ClientReadStatusProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java'><Message>In DataTransferProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='f3689cae1cf3e0c66eed7f66f907d226' rank='17' abbrev='UCF' category='STYLE' priority='2' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ClientReadStatusProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ClientReadStatusProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ClientReadStatusProto$Builder' start='24659' end='24811' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java'><Message>At DataTransferProtos.java:[lines 24659-24811]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ClientReadStatusProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ClientReadStatusProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine endBytecode='61' classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ClientReadStatusProto$Builder' start='24685' end='24687' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ClientReadStatusProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ClientReadStatusProto$Builder' start='24685' end='24685' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java' startBytecode='3' primary='true'><Message>At DataTransferProtos.java:[line 24685]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='1bf6422110d439ad423b5438ac4746b1' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$DNTransferAckProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$DNTransferAckProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$DNTransferAckProto' start='24841' end='25271' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java'><Message>At DataTransferProtos.java:[lines 24841-25271]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$DNTransferAckProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$DNTransferAckProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$DNTransferAckProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java'><Message>In DataTransferProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$DNTransferAckProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$DNTransferAckProto' start='24924' end='24924' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java' startBytecode='7' primary='true'><Message>At DataTransferProtos.java:[line 24924]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='dd411481e12bc16b87774ca331e5d2c2' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$DNTransferAckProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$DNTransferAckProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$DNTransferAckProto' start='24841' end='25271' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java'><Message>At DataTransferProtos.java:[lines 24841-25271]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$DNTransferAckProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$DNTransferAckProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$DNTransferAckProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java'><Message>In DataTransferProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$DNTransferAckProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$DNTransferAckProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java'><Message>In DataTransferProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='5f923eb198ca97f1453f4e2bd639836e' rank='17' abbrev='UCF' category='STYLE' priority='2' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$DNTransferAckProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$DNTransferAckProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$DNTransferAckProto$Builder' start='25110' end='25262' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java'><Message>At DataTransferProtos.java:[lines 25110-25262]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$DNTransferAckProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$DNTransferAckProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine endBytecode='61' classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$DNTransferAckProto$Builder' start='25136' end='25138' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$DNTransferAckProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$DNTransferAckProto$Builder' start='25136' end='25136' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java' startBytecode='3' primary='true'><Message>At DataTransferProtos.java:[line 25136]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='64ff4efadf3924db04144060ce02bf53' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$DataTransferEncryptorMessageProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$DataTransferEncryptorMessageProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$DataTransferEncryptorMessageProto' start='385' end='1494' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java'><Message>At DataTransferProtos.java:[lines 385-1494]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$DataTransferEncryptorMessageProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$DataTransferEncryptorMessageProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$DataTransferEncryptorMessageProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java'><Message>In DataTransferProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$DataTransferEncryptorMessageProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$DataTransferEncryptorMessageProto' start='489' end='489' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java' startBytecode='7' primary='true'><Message>At DataTransferProtos.java:[line 489]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='bb6313838e0de5fb1ceb7056c4fac441' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$DataTransferEncryptorMessageProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$DataTransferEncryptorMessageProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$DataTransferEncryptorMessageProto' start='385' end='1494' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java'><Message>At DataTransferProtos.java:[lines 385-1494]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$DataTransferEncryptorMessageProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$DataTransferEncryptorMessageProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$DataTransferEncryptorMessageProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java'><Message>In DataTransferProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$DataTransferEncryptorMessageProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$DataTransferEncryptorMessageProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java'><Message>In DataTransferProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='4a18ce17274433a6e5472a3103fbdb64' rank='19' abbrev='Se' category='BAD_PRACTICE' priority='3' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$DataTransferEncryptorMessageProto defines non-transient non-serializable instance field payload_</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$DataTransferEncryptorMessageProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$DataTransferEncryptorMessageProto' start='385' end='1494' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java'><Message>At DataTransferProtos.java:[lines 385-1494]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$DataTransferEncryptorMessageProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$DataTransferEncryptorMessageProto' signature='Lcom/google/protobuf/ByteString;' name='payload_' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$DataTransferEncryptorMessageProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java'><Message>In DataTransferProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$DataTransferEncryptorMessageProto.payload_</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/ByteString;'><SourceLine classname='com.google.protobuf.ByteString' start='60' end='967' sourcepath='com/google/protobuf/ByteString.java' sourcefile='ByteString.java'><Message>At ByteString.java:[lines 60-967]</Message></SourceLine><Message>Actual type com.google.protobuf.ByteString</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$DataTransferEncryptorMessageProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java'><Message>In DataTransferProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='ceeb3db9a2f48cf0306b7449dcc51ba7' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$DataTransferTraceInfoProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$DataTransferTraceInfoProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$DataTransferTraceInfoProto' start='2512' end='3021' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java'><Message>At DataTransferProtos.java:[lines 2512-3021]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$DataTransferTraceInfoProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$DataTransferTraceInfoProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$DataTransferTraceInfoProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java'><Message>In DataTransferProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$DataTransferTraceInfoProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$DataTransferTraceInfoProto' start='2594' end='2594' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java' startBytecode='7' primary='true'><Message>At DataTransferProtos.java:[line 2594]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='3a2615dab6bae2962c72d13ef4ff0638' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$DataTransferTraceInfoProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$DataTransferTraceInfoProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$DataTransferTraceInfoProto' start='2512' end='3021' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java'><Message>At DataTransferProtos.java:[lines 2512-3021]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$DataTransferTraceInfoProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$DataTransferTraceInfoProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$DataTransferTraceInfoProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java'><Message>In DataTransferProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$DataTransferTraceInfoProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$DataTransferTraceInfoProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java'><Message>In DataTransferProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='4b256056be0458e576231c5da57e22f1' rank='17' abbrev='UCF' category='STYLE' priority='2' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$DataTransferTraceInfoProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$DataTransferTraceInfoProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$DataTransferTraceInfoProto$Builder' start='2817' end='3012' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java'><Message>At DataTransferProtos.java:[lines 2817-3012]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$DataTransferTraceInfoProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$DataTransferTraceInfoProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine endBytecode='61' classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$DataTransferTraceInfoProto$Builder' start='2843' end='2845' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$DataTransferTraceInfoProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$DataTransferTraceInfoProto$Builder' start='2843' end='2843' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java' startBytecode='3' primary='true'><Message>At DataTransferProtos.java:[line 2843]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='bb03b14d632328c1140cc006c8353001' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpBlockChecksumProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpBlockChecksumProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpBlockChecksumProto' start='12421' end='13144' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java'><Message>At DataTransferProtos.java:[lines 12421-13144]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpBlockChecksumProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpBlockChecksumProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpBlockChecksumProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java'><Message>In DataTransferProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpBlockChecksumProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpBlockChecksumProto' start='12519' end='12519' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java' startBytecode='7' primary='true'><Message>At DataTransferProtos.java:[line 12519]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='d2047c5e71584c9a25c1d991655b358c' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpBlockChecksumProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpBlockChecksumProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpBlockChecksumProto' start='12421' end='13144' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java'><Message>At DataTransferProtos.java:[lines 12421-13144]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpBlockChecksumProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpBlockChecksumProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpBlockChecksumProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java'><Message>In DataTransferProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpBlockChecksumProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpBlockChecksumProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java'><Message>In DataTransferProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='233bc26318f2462709968486f6d9a969' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpBlockChecksumResponseProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpBlockChecksumResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpBlockChecksumResponseProto' start='25336' end='26212' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java'><Message>At DataTransferProtos.java:[lines 25336-26212]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpBlockChecksumResponseProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpBlockChecksumResponseProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpBlockChecksumResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java'><Message>In DataTransferProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpBlockChecksumResponseProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpBlockChecksumResponseProto' start='25447' end='25447' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java' startBytecode='7' primary='true'><Message>At DataTransferProtos.java:[line 25447]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='f6525fd0652d43e1f536c028179bf210' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpBlockChecksumResponseProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpBlockChecksumResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpBlockChecksumResponseProto' start='25336' end='26212' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java'><Message>At DataTransferProtos.java:[lines 25336-26212]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpBlockChecksumResponseProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpBlockChecksumResponseProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpBlockChecksumResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java'><Message>In DataTransferProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpBlockChecksumResponseProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpBlockChecksumResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java'><Message>In DataTransferProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='aaa8e22e45042d220eb084f3a4140f98' rank='19' abbrev='Se' category='BAD_PRACTICE' priority='3' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpBlockChecksumResponseProto defines non-transient non-serializable instance field blockChecksum_</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpBlockChecksumResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpBlockChecksumResponseProto' start='25336' end='26212' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java'><Message>At DataTransferProtos.java:[lines 25336-26212]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpBlockChecksumResponseProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpBlockChecksumResponseProto' signature='Lcom/google/protobuf/ByteString;' name='blockChecksum_' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpBlockChecksumResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java'><Message>In DataTransferProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpBlockChecksumResponseProto.blockChecksum_</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/ByteString;'><SourceLine classname='com.google.protobuf.ByteString' start='60' end='967' sourcepath='com/google/protobuf/ByteString.java' sourcefile='ByteString.java'><Message>At ByteString.java:[lines 60-967]</Message></SourceLine><Message>Actual type com.google.protobuf.ByteString</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpBlockChecksumResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java'><Message>In DataTransferProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='eb9f12fbb98acecb5848149dd02394a8' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpBlockGroupChecksumProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpBlockGroupChecksumProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpBlockGroupChecksumProto' start='13280' end='15093' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java'><Message>At DataTransferProtos.java:[lines 13280-15093]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpBlockGroupChecksumProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpBlockGroupChecksumProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpBlockGroupChecksumProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java'><Message>In DataTransferProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpBlockGroupChecksumProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpBlockGroupChecksumProto' start='13444' end='13444' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java' startBytecode='7' primary='true'><Message>At DataTransferProtos.java:[line 13444]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='224869c31193de41a3474128d974af9e' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpBlockGroupChecksumProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpBlockGroupChecksumProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpBlockGroupChecksumProto' start='13280' end='15093' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java'><Message>At DataTransferProtos.java:[lines 13280-15093]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpBlockGroupChecksumProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpBlockGroupChecksumProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpBlockGroupChecksumProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java'><Message>In DataTransferProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpBlockGroupChecksumProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpBlockGroupChecksumProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java'><Message>In DataTransferProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='da5e0d2c065eae02533624a6d21d868b' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpCopyBlockProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpCopyBlockProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpCopyBlockProto' start='11846' end='12382' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java'><Message>At DataTransferProtos.java:[lines 11846-12382]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpCopyBlockProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpCopyBlockProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpCopyBlockProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java'><Message>In DataTransferProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpCopyBlockProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpCopyBlockProto' start='11931' end='11931' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java' startBytecode='7' primary='true'><Message>At DataTransferProtos.java:[line 11931]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='f35a1072fd1f0f6039a7023d064794bc' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpCopyBlockProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpCopyBlockProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpCopyBlockProto' start='11846' end='12382' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java'><Message>At DataTransferProtos.java:[lines 11846-12382]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpCopyBlockProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpCopyBlockProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpCopyBlockProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java'><Message>In DataTransferProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpCopyBlockProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpCopyBlockProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java'><Message>In DataTransferProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='8c4efbc6cde0937fb234e447166fcfa7' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpCustomProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpCustomProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpCustomProto' start='26238' end='26729' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java'><Message>At DataTransferProtos.java:[lines 26238-26729]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpCustomProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpCustomProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpCustomProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java'><Message>In DataTransferProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpCustomProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpCustomProto' start='26315' end='26315' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java' startBytecode='7' primary='true'><Message>At DataTransferProtos.java:[line 26315]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='97f1232f0be4868520e5227df6f203d3' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpCustomProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpCustomProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpCustomProto' start='26238' end='26729' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java'><Message>At DataTransferProtos.java:[lines 26238-26729]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpCustomProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpCustomProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpCustomProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java'><Message>In DataTransferProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpCustomProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpCustomProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java'><Message>In DataTransferProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='b09f7843129f51d3d9ed43d0469ba7b6' rank='17' abbrev='UCF' category='STYLE' priority='2' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpCustomProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpCustomProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpCustomProto$Builder' start='26528' end='26720' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java'><Message>At DataTransferProtos.java:[lines 26528-26720]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpCustomProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpCustomProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine endBytecode='61' classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpCustomProto$Builder' start='26554' end='26556' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpCustomProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpCustomProto$Builder' start='26554' end='26554' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java' startBytecode='3' primary='true'><Message>At DataTransferProtos.java:[line 26554]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='e38a867b3f65192330a69a5d2e134b75' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpReadBlockProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpReadBlockProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpReadBlockProto' start='4348' end='5327' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java'><Message>At DataTransferProtos.java:[lines 4348-5327]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpReadBlockProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpReadBlockProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpReadBlockProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java'><Message>In DataTransferProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpReadBlockProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpReadBlockProto' start='4461' end='4461' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java' startBytecode='7' primary='true'><Message>At DataTransferProtos.java:[line 4461]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='538df20e4f8248355dcf313ed33839b0' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpReadBlockProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpReadBlockProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpReadBlockProto' start='4348' end='5327' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java'><Message>At DataTransferProtos.java:[lines 4348-5327]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpReadBlockProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpReadBlockProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpReadBlockProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java'><Message>In DataTransferProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpReadBlockProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpReadBlockProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java'><Message>In DataTransferProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='23c7becc1ec3ac6caf591fc6e197b18e' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpReplaceBlockProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpReplaceBlockProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpReplaceBlockProto' start='10685' end='11821' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java'><Message>At DataTransferProtos.java:[lines 10685-11821]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpReplaceBlockProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpReplaceBlockProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpReplaceBlockProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java'><Message>In DataTransferProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpReplaceBlockProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpReplaceBlockProto' start='10804' end='10804' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java' startBytecode='7' primary='true'><Message>At DataTransferProtos.java:[line 10804]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='6494c83ee36053b13c86dff9e9d010da' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpReplaceBlockProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpReplaceBlockProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpReplaceBlockProto' start='10685' end='11821' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java'><Message>At DataTransferProtos.java:[lines 10685-11821]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpReplaceBlockProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpReplaceBlockProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpReplaceBlockProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java'><Message>In DataTransferProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpReplaceBlockProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpReplaceBlockProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java'><Message>In DataTransferProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='556b07cc23d83c87850faaeb6535b289' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpRequestShortCircuitAccessProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpRequestShortCircuitAccessProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpRequestShortCircuitAccessProto' start='16412' end='17453' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java'><Message>At DataTransferProtos.java:[lines 16412-17453]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpRequestShortCircuitAccessProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpRequestShortCircuitAccessProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpRequestShortCircuitAccessProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java'><Message>In DataTransferProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpRequestShortCircuitAccessProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpRequestShortCircuitAccessProto' start='16520' end='16520' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java' startBytecode='7' primary='true'><Message>At DataTransferProtos.java:[line 16520]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='36360f11508e79caccdffa93e453fd17' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpRequestShortCircuitAccessProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpRequestShortCircuitAccessProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpRequestShortCircuitAccessProto' start='16412' end='17453' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java'><Message>At DataTransferProtos.java:[lines 16412-17453]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpRequestShortCircuitAccessProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpRequestShortCircuitAccessProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpRequestShortCircuitAccessProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java'><Message>In DataTransferProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpRequestShortCircuitAccessProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpRequestShortCircuitAccessProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java'><Message>In DataTransferProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='663a1f59f349c928e6f8bac687b8736e' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpTransferBlockProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpTransferBlockProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpTransferBlockProto' start='9378' end='10606' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java'><Message>At DataTransferProtos.java:[lines 9378-10606]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpTransferBlockProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpTransferBlockProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpTransferBlockProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java'><Message>In DataTransferProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpTransferBlockProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpTransferBlockProto' start='9521' end='9521' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java' startBytecode='7' primary='true'><Message>At DataTransferProtos.java:[line 9521]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='504566dae5c52054675ae3cbaf51b061' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpTransferBlockProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpTransferBlockProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpTransferBlockProto' start='9378' end='10606' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java'><Message>At DataTransferProtos.java:[lines 9378-10606]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpTransferBlockProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpTransferBlockProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpTransferBlockProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java'><Message>In DataTransferProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpTransferBlockProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpTransferBlockProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java'><Message>In DataTransferProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='285931de2673e4aab7f2bd5c91fd2487' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpWriteBlockProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpWriteBlockProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpWriteBlockProto' start='6148' end='9294' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java'><Message>At DataTransferProtos.java:[lines 6148-9294]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpWriteBlockProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpWriteBlockProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpWriteBlockProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java'><Message>In DataTransferProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpWriteBlockProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpWriteBlockProto' start='6411' end='6411' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java' startBytecode='7' primary='true'><Message>At DataTransferProtos.java:[line 6411]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='29a04ff2e7311ea8fa53a4237f8a3fa4' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpWriteBlockProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpWriteBlockProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpWriteBlockProto' start='6148' end='9294' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java'><Message>At DataTransferProtos.java:[lines 6148-9294]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpWriteBlockProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpWriteBlockProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpWriteBlockProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java'><Message>In DataTransferProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpWriteBlockProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpWriteBlockProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java'><Message>In DataTransferProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='aaefae53d3b701610d764da107231546' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$PacketHeaderProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$PacketHeaderProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$PacketHeaderProto' start='20531' end='21320' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java'><Message>At DataTransferProtos.java:[lines 20531-21320]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$PacketHeaderProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$PacketHeaderProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$PacketHeaderProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java'><Message>In DataTransferProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$PacketHeaderProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$PacketHeaderProto' start='20628' end='20628' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java' startBytecode='7' primary='true'><Message>At DataTransferProtos.java:[line 20628]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='eae73fbcdd31ac8bf918df3fe07155ee' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$PacketHeaderProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$PacketHeaderProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$PacketHeaderProto' start='20531' end='21320' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java'><Message>At DataTransferProtos.java:[lines 20531-21320]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$PacketHeaderProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$PacketHeaderProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$PacketHeaderProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java'><Message>In DataTransferProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$PacketHeaderProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$PacketHeaderProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java'><Message>In DataTransferProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='8ad9a03216fffd78f42f94ec2de109e' rank='17' abbrev='UCF' category='STYLE' priority='2' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$PacketHeaderProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$PacketHeaderProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$PacketHeaderProto$Builder' start='20966' end='21311' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java'><Message>At DataTransferProtos.java:[lines 20966-21311]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$PacketHeaderProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$PacketHeaderProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine endBytecode='61' classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$PacketHeaderProto$Builder' start='20992' end='20994' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$PacketHeaderProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$PacketHeaderProto$Builder' start='20992' end='20992' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java' startBytecode='3' primary='true'><Message>At DataTransferProtos.java:[line 20992]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='2f34aedc744cce0b0641e656a3f9e469' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$PipelineAckProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$PipelineAckProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$PipelineAckProto' start='21379' end='22205' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java'><Message>At DataTransferProtos.java:[lines 21379-22205]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$PipelineAckProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$PipelineAckProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$PipelineAckProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java'><Message>In DataTransferProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$PipelineAckProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$PipelineAckProto' start='21521' end='21521' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java' startBytecode='7' primary='true'><Message>At DataTransferProtos.java:[line 21521]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='8fffa5ad0b2c6af8d70b508ec7118266' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$PipelineAckProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$PipelineAckProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$PipelineAckProto' start='21379' end='22205' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java'><Message>At DataTransferProtos.java:[lines 21379-22205]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$PipelineAckProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$PipelineAckProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$PipelineAckProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java'><Message>In DataTransferProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$PipelineAckProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$PipelineAckProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java'><Message>In DataTransferProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='9901bce4468a9498ed2cf687c28c0902' rank='17' abbrev='UCF' category='STYLE' priority='2' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$PipelineAckProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$PipelineAckProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$PipelineAckProto$Builder' start='21833' end='22196' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java'><Message>At DataTransferProtos.java:[lines 21833-22196]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$PipelineAckProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$PipelineAckProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine endBytecode='61' classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$PipelineAckProto$Builder' start='21859' end='21861' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$PipelineAckProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$PipelineAckProto$Builder' start='21859' end='21859' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java' startBytecode='3' primary='true'><Message>At DataTransferProtos.java:[line 21859]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='f7e3e156d47085db599983a8a67db612' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ReadOpChecksumInfoProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ReadOpChecksumInfoProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ReadOpChecksumInfoProto' start='22260' end='22932' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java'><Message>At DataTransferProtos.java:[lines 22260-22932]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ReadOpChecksumInfoProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ReadOpChecksumInfoProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ReadOpChecksumInfoProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java'><Message>In DataTransferProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ReadOpChecksumInfoProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ReadOpChecksumInfoProto' start='22350' end='22350' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java' startBytecode='7' primary='true'><Message>At DataTransferProtos.java:[line 22350]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='7a6bcd74d33d0deddaa9fc09f725978f' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ReadOpChecksumInfoProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ReadOpChecksumInfoProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ReadOpChecksumInfoProto' start='22260' end='22932' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java'><Message>At DataTransferProtos.java:[lines 22260-22932]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ReadOpChecksumInfoProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ReadOpChecksumInfoProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ReadOpChecksumInfoProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java'><Message>In DataTransferProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ReadOpChecksumInfoProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ReadOpChecksumInfoProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java'><Message>In DataTransferProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='28aaf5ba7281b46195792c45bf4c5fea' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ReleaseShortCircuitAccessRequestProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ReleaseShortCircuitAccessRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ReleaseShortCircuitAccessRequestProto' start='17492' end='18227' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java'><Message>At DataTransferProtos.java:[lines 17492-18227]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ReleaseShortCircuitAccessRequestProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ReleaseShortCircuitAccessRequestProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ReleaseShortCircuitAccessRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java'><Message>In DataTransferProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ReleaseShortCircuitAccessRequestProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ReleaseShortCircuitAccessRequestProto' start='17590' end='17590' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java' startBytecode='7' primary='true'><Message>At DataTransferProtos.java:[line 17590]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='fd324a4629fa1c79aab5743815eb4a9a' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ReleaseShortCircuitAccessRequestProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ReleaseShortCircuitAccessRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ReleaseShortCircuitAccessRequestProto' start='17492' end='18227' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java'><Message>At DataTransferProtos.java:[lines 17492-18227]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ReleaseShortCircuitAccessRequestProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ReleaseShortCircuitAccessRequestProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ReleaseShortCircuitAccessRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java'><Message>In DataTransferProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ReleaseShortCircuitAccessRequestProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ReleaseShortCircuitAccessRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java'><Message>In DataTransferProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='506622b595353ee2b79cd52fdeca251d' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ReleaseShortCircuitAccessResponseProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ReleaseShortCircuitAccessResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ReleaseShortCircuitAccessResponseProto' start='18263' end='18843' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java'><Message>At DataTransferProtos.java:[lines 18263-18843]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ReleaseShortCircuitAccessResponseProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ReleaseShortCircuitAccessResponseProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ReleaseShortCircuitAccessResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java'><Message>In DataTransferProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ReleaseShortCircuitAccessResponseProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ReleaseShortCircuitAccessResponseProto' start='18351' end='18351' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java' startBytecode='7' primary='true'><Message>At DataTransferProtos.java:[line 18351]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='2b0fba7fddbd80085641bafb0c8a3498' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ReleaseShortCircuitAccessResponseProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ReleaseShortCircuitAccessResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ReleaseShortCircuitAccessResponseProto' start='18263' end='18843' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java'><Message>At DataTransferProtos.java:[lines 18263-18843]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ReleaseShortCircuitAccessResponseProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ReleaseShortCircuitAccessResponseProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ReleaseShortCircuitAccessResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java'><Message>In DataTransferProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ReleaseShortCircuitAccessResponseProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ReleaseShortCircuitAccessResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java'><Message>In DataTransferProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='8fbf349efa9fae7e8c48a6b2f515cdaa' rank='17' abbrev='UCF' category='STYLE' priority='2' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ReleaseShortCircuitAccessResponseProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ReleaseShortCircuitAccessResponseProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ReleaseShortCircuitAccessResponseProto$Builder' start='18597' end='18834' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java'><Message>At DataTransferProtos.java:[lines 18597-18834]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ReleaseShortCircuitAccessResponseProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ReleaseShortCircuitAccessResponseProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine endBytecode='61' classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ReleaseShortCircuitAccessResponseProto$Builder' start='18623' end='18625' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ReleaseShortCircuitAccessResponseProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ReleaseShortCircuitAccessResponseProto$Builder' start='18623' end='18623' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java' startBytecode='3' primary='true'><Message>At DataTransferProtos.java:[line 18623]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='e08b12e3de8abc67a24aae4251b891af' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ShortCircuitShmIdProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ShortCircuitShmIdProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ShortCircuitShmIdProto' start='15129' end='15643' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java'><Message>At DataTransferProtos.java:[lines 15129-15643]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ShortCircuitShmIdProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ShortCircuitShmIdProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ShortCircuitShmIdProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java'><Message>In DataTransferProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ShortCircuitShmIdProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ShortCircuitShmIdProto' start='15211' end='15211' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java' startBytecode='7' primary='true'><Message>At DataTransferProtos.java:[line 15211]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='6cb08ae473d33b19c8e353b833ddc626' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ShortCircuitShmIdProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ShortCircuitShmIdProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ShortCircuitShmIdProto' start='15129' end='15643' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java'><Message>At DataTransferProtos.java:[lines 15129-15643]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ShortCircuitShmIdProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ShortCircuitShmIdProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ShortCircuitShmIdProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java'><Message>In DataTransferProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ShortCircuitShmIdProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ShortCircuitShmIdProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java'><Message>In DataTransferProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='85ba7ce31bb9234e57dfa2d15d1faea4' rank='17' abbrev='UCF' category='STYLE' priority='2' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ShortCircuitShmIdProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ShortCircuitShmIdProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ShortCircuitShmIdProto$Builder' start='15439' end='15634' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java'><Message>At DataTransferProtos.java:[lines 15439-15634]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ShortCircuitShmIdProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ShortCircuitShmIdProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine endBytecode='61' classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ShortCircuitShmIdProto$Builder' start='15465' end='15467' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ShortCircuitShmIdProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ShortCircuitShmIdProto$Builder' start='15465' end='15465' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java' startBytecode='3' primary='true'><Message>At DataTransferProtos.java:[line 15465]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='c6356b1824cb0cea4f5a1916f63bdd09' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ShortCircuitShmRequestProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ShortCircuitShmRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ShortCircuitShmRequestProto' start='18898' end='19633' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java'><Message>At DataTransferProtos.java:[lines 18898-19633]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ShortCircuitShmRequestProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ShortCircuitShmRequestProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ShortCircuitShmRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java'><Message>In DataTransferProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ShortCircuitShmRequestProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ShortCircuitShmRequestProto' start='18988' end='18988' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java' startBytecode='7' primary='true'><Message>At DataTransferProtos.java:[line 18988]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='1bffd3c90a98fd7efb59966986717f7' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ShortCircuitShmRequestProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ShortCircuitShmRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ShortCircuitShmRequestProto' start='18898' end='19633' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java'><Message>At DataTransferProtos.java:[lines 18898-19633]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ShortCircuitShmRequestProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ShortCircuitShmRequestProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ShortCircuitShmRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java'><Message>In DataTransferProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ShortCircuitShmRequestProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ShortCircuitShmRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java'><Message>In DataTransferProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='50adc6e9ac3e1ab2aaa8b88e02983a14' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ShortCircuitShmResponseProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ShortCircuitShmResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ShortCircuitShmResponseProto' start='19683' end='20462' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java'><Message>At DataTransferProtos.java:[lines 19683-20462]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ShortCircuitShmResponseProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ShortCircuitShmResponseProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ShortCircuitShmResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java'><Message>In DataTransferProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ShortCircuitShmResponseProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ShortCircuitShmResponseProto' start='19784' end='19784' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java' startBytecode='7' primary='true'><Message>At DataTransferProtos.java:[line 19784]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='d0818753a205ddaf2c4498976737f24c' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ShortCircuitShmResponseProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ShortCircuitShmResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ShortCircuitShmResponseProto' start='19683' end='20462' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java'><Message>At DataTransferProtos.java:[lines 19683-20462]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ShortCircuitShmResponseProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ShortCircuitShmResponseProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ShortCircuitShmResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java'><Message>In DataTransferProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ShortCircuitShmResponseProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ShortCircuitShmResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java'><Message>In DataTransferProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='71b08b6f290b82b4c37f196889b6d8af' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ShortCircuitShmSlotProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ShortCircuitShmSlotProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ShortCircuitShmSlotProto' start='15683' end='16312' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java'><Message>At DataTransferProtos.java:[lines 15683-16312]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ShortCircuitShmSlotProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ShortCircuitShmSlotProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ShortCircuitShmSlotProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java'><Message>In DataTransferProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ShortCircuitShmSlotProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ShortCircuitShmSlotProto' start='15773' end='15773' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java' startBytecode='7' primary='true'><Message>At DataTransferProtos.java:[line 15773]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='320090b6d0bc4604b59918c3b00cd83a' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ShortCircuitShmSlotProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ShortCircuitShmSlotProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ShortCircuitShmSlotProto' start='15683' end='16312' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java'><Message>At DataTransferProtos.java:[lines 15683-16312]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ShortCircuitShmSlotProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ShortCircuitShmSlotProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ShortCircuitShmSlotProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java'><Message>In DataTransferProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ShortCircuitShmSlotProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ShortCircuitShmSlotProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' sourcefile='DataTransferProtos.java'><Message>In DataTransferProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='ae915c366fbdea8d4cb45842041c9398' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$CreateEncryptionZoneRequestProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$CreateEncryptionZoneRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$CreateEncryptionZoneRequestProto' start='220' end='861' sourcepath='org/apache/hadoop/hdfs/protocol/proto/EncryptionZonesProtos.java' sourcefile='EncryptionZonesProtos.java'><Message>At EncryptionZonesProtos.java:[lines 220-861]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$CreateEncryptionZoneRequestProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$CreateEncryptionZoneRequestProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$CreateEncryptionZoneRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/EncryptionZonesProtos.java' sourcefile='EncryptionZonesProtos.java'><Message>In EncryptionZonesProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$CreateEncryptionZoneRequestProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$CreateEncryptionZoneRequestProto' start='302' end='302' sourcepath='org/apache/hadoop/hdfs/protocol/proto/EncryptionZonesProtos.java' sourcefile='EncryptionZonesProtos.java' startBytecode='7' primary='true'><Message>At EncryptionZonesProtos.java:[line 302]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='d29be18405b59780642bf84eebbfb53c' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$CreateEncryptionZoneRequestProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$CreateEncryptionZoneRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$CreateEncryptionZoneRequestProto' start='220' end='861' sourcepath='org/apache/hadoop/hdfs/protocol/proto/EncryptionZonesProtos.java' sourcefile='EncryptionZonesProtos.java'><Message>At EncryptionZonesProtos.java:[lines 220-861]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$CreateEncryptionZoneRequestProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$CreateEncryptionZoneRequestProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$CreateEncryptionZoneRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/EncryptionZonesProtos.java' sourcefile='EncryptionZonesProtos.java'><Message>In EncryptionZonesProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$CreateEncryptionZoneRequestProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$CreateEncryptionZoneRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/EncryptionZonesProtos.java' sourcefile='EncryptionZonesProtos.java'><Message>In EncryptionZonesProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='148aec7fe06f540d28cfc3332b1feb73' rank='17' abbrev='UCF' category='STYLE' priority='2' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$CreateEncryptionZoneRequestProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$CreateEncryptionZoneRequestProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$CreateEncryptionZoneRequestProto$Builder' start='575' end='852' sourcepath='org/apache/hadoop/hdfs/protocol/proto/EncryptionZonesProtos.java' sourcefile='EncryptionZonesProtos.java'><Message>At EncryptionZonesProtos.java:[lines 575-852]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$CreateEncryptionZoneRequestProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$CreateEncryptionZoneRequestProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine endBytecode='61' classname='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$CreateEncryptionZoneRequestProto$Builder' start='601' end='603' sourcepath='org/apache/hadoop/hdfs/protocol/proto/EncryptionZonesProtos.java' sourcefile='EncryptionZonesProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$CreateEncryptionZoneRequestProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$CreateEncryptionZoneRequestProto$Builder' start='601' end='601' sourcepath='org/apache/hadoop/hdfs/protocol/proto/EncryptionZonesProtos.java' sourcefile='EncryptionZonesProtos.java' startBytecode='3' primary='true'><Message>At EncryptionZonesProtos.java:[line 601]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='ed4b9331451e8494620b71c4ced3ec4b' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$CreateEncryptionZoneResponseProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$CreateEncryptionZoneResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$CreateEncryptionZoneResponseProto' start='872' end='1199' sourcepath='org/apache/hadoop/hdfs/protocol/proto/EncryptionZonesProtos.java' sourcefile='EncryptionZonesProtos.java'><Message>At EncryptionZonesProtos.java:[lines 872-1199]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$CreateEncryptionZoneResponseProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$CreateEncryptionZoneResponseProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$CreateEncryptionZoneResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/EncryptionZonesProtos.java' sourcefile='EncryptionZonesProtos.java'><Message>In EncryptionZonesProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$CreateEncryptionZoneResponseProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$CreateEncryptionZoneResponseProto' start='943' end='943' sourcepath='org/apache/hadoop/hdfs/protocol/proto/EncryptionZonesProtos.java' sourcefile='EncryptionZonesProtos.java' startBytecode='7' primary='true'><Message>At EncryptionZonesProtos.java:[line 943]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='8cf22afdeeb63c3e25d3af6f81936d16' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$CreateEncryptionZoneResponseProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$CreateEncryptionZoneResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$CreateEncryptionZoneResponseProto' start='872' end='1199' sourcepath='org/apache/hadoop/hdfs/protocol/proto/EncryptionZonesProtos.java' sourcefile='EncryptionZonesProtos.java'><Message>At EncryptionZonesProtos.java:[lines 872-1199]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$CreateEncryptionZoneResponseProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$CreateEncryptionZoneResponseProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$CreateEncryptionZoneResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/EncryptionZonesProtos.java' sourcefile='EncryptionZonesProtos.java'><Message>In EncryptionZonesProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$CreateEncryptionZoneResponseProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$CreateEncryptionZoneResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/EncryptionZonesProtos.java' sourcefile='EncryptionZonesProtos.java'><Message>In EncryptionZonesProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='2dca74e606bd6c401afc2d8fcf4f6f0c' rank='17' abbrev='UCF' category='STYLE' priority='2' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$CreateEncryptionZoneResponseProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$CreateEncryptionZoneResponseProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$CreateEncryptionZoneResponseProto$Builder' start='1091' end='1190' sourcepath='org/apache/hadoop/hdfs/protocol/proto/EncryptionZonesProtos.java' sourcefile='EncryptionZonesProtos.java'><Message>At EncryptionZonesProtos.java:[lines 1091-1190]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$CreateEncryptionZoneResponseProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$CreateEncryptionZoneResponseProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine endBytecode='61' classname='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$CreateEncryptionZoneResponseProto$Builder' start='1117' end='1119' sourcepath='org/apache/hadoop/hdfs/protocol/proto/EncryptionZonesProtos.java' sourcefile='EncryptionZonesProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$CreateEncryptionZoneResponseProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$CreateEncryptionZoneResponseProto$Builder' start='1117' end='1117' sourcepath='org/apache/hadoop/hdfs/protocol/proto/EncryptionZonesProtos.java' sourcefile='EncryptionZonesProtos.java' startBytecode='3' primary='true'><Message>At EncryptionZonesProtos.java:[line 1117]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='ac1ced983ae98743bd0ead9be8ad55ae' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$EncryptionZoneProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$EncryptionZoneProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$EncryptionZoneProto' start='1712' end='2643' sourcepath='org/apache/hadoop/hdfs/protocol/proto/EncryptionZonesProtos.java' sourcefile='EncryptionZonesProtos.java'><Message>At EncryptionZonesProtos.java:[lines 1712-2643]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$EncryptionZoneProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$EncryptionZoneProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$EncryptionZoneProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/EncryptionZonesProtos.java' sourcefile='EncryptionZonesProtos.java'><Message>In EncryptionZonesProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$EncryptionZoneProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$EncryptionZoneProto' start='1821' end='1821' sourcepath='org/apache/hadoop/hdfs/protocol/proto/EncryptionZonesProtos.java' sourcefile='EncryptionZonesProtos.java' startBytecode='7' primary='true'><Message>At EncryptionZonesProtos.java:[line 1821]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='f8efa32f17abe6110d4e7b972a235a07' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$EncryptionZoneProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$EncryptionZoneProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$EncryptionZoneProto' start='1712' end='2643' sourcepath='org/apache/hadoop/hdfs/protocol/proto/EncryptionZonesProtos.java' sourcefile='EncryptionZonesProtos.java'><Message>At EncryptionZonesProtos.java:[lines 1712-2643]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$EncryptionZoneProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$EncryptionZoneProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$EncryptionZoneProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/EncryptionZonesProtos.java' sourcefile='EncryptionZonesProtos.java'><Message>In EncryptionZonesProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$EncryptionZoneProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$EncryptionZoneProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/EncryptionZonesProtos.java' sourcefile='EncryptionZonesProtos.java'><Message>In EncryptionZonesProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='95d60778eadc04fe277c62235ec9479b' rank='17' abbrev='UCF' category='STYLE' priority='2' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$EncryptionZoneProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$EncryptionZoneProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$EncryptionZoneProto$Builder' start='2209' end='2634' sourcepath='org/apache/hadoop/hdfs/protocol/proto/EncryptionZonesProtos.java' sourcefile='EncryptionZonesProtos.java'><Message>At EncryptionZonesProtos.java:[lines 2209-2634]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$EncryptionZoneProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$EncryptionZoneProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine endBytecode='61' classname='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$EncryptionZoneProto$Builder' start='2235' end='2237' sourcepath='org/apache/hadoop/hdfs/protocol/proto/EncryptionZonesProtos.java' sourcefile='EncryptionZonesProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$EncryptionZoneProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$EncryptionZoneProto$Builder' start='2235' end='2235' sourcepath='org/apache/hadoop/hdfs/protocol/proto/EncryptionZonesProtos.java' sourcefile='EncryptionZonesProtos.java' startBytecode='3' primary='true'><Message>At EncryptionZonesProtos.java:[line 2235]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='443c55ff5916943d8d4c637ed25d8dec' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$GetEZForPathRequestProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$GetEZForPathRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$GetEZForPathRequestProto' start='7259' end='7750' sourcepath='org/apache/hadoop/hdfs/protocol/proto/EncryptionZonesProtos.java' sourcefile='EncryptionZonesProtos.java'><Message>At EncryptionZonesProtos.java:[lines 7259-7750]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$GetEZForPathRequestProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$GetEZForPathRequestProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$GetEZForPathRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/EncryptionZonesProtos.java' sourcefile='EncryptionZonesProtos.java'><Message>In EncryptionZonesProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$GetEZForPathRequestProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$GetEZForPathRequestProto' start='7336' end='7336' sourcepath='org/apache/hadoop/hdfs/protocol/proto/EncryptionZonesProtos.java' sourcefile='EncryptionZonesProtos.java' startBytecode='7' primary='true'><Message>At EncryptionZonesProtos.java:[line 7336]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='2b9e2e14341e6bba6df0c652bc51ec6c' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$GetEZForPathRequestProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$GetEZForPathRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$GetEZForPathRequestProto' start='7259' end='7750' sourcepath='org/apache/hadoop/hdfs/protocol/proto/EncryptionZonesProtos.java' sourcefile='EncryptionZonesProtos.java'><Message>At EncryptionZonesProtos.java:[lines 7259-7750]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$GetEZForPathRequestProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$GetEZForPathRequestProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$GetEZForPathRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/EncryptionZonesProtos.java' sourcefile='EncryptionZonesProtos.java'><Message>In EncryptionZonesProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$GetEZForPathRequestProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$GetEZForPathRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/EncryptionZonesProtos.java' sourcefile='EncryptionZonesProtos.java'><Message>In EncryptionZonesProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='68a2c5c2ff8743fc15629ec5680e38bc' rank='17' abbrev='UCF' category='STYLE' priority='2' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$GetEZForPathRequestProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$GetEZForPathRequestProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$GetEZForPathRequestProto$Builder' start='7549' end='7741' sourcepath='org/apache/hadoop/hdfs/protocol/proto/EncryptionZonesProtos.java' sourcefile='EncryptionZonesProtos.java'><Message>At EncryptionZonesProtos.java:[lines 7549-7741]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$GetEZForPathRequestProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$GetEZForPathRequestProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine endBytecode='61' classname='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$GetEZForPathRequestProto$Builder' start='7575' end='7577' sourcepath='org/apache/hadoop/hdfs/protocol/proto/EncryptionZonesProtos.java' sourcefile='EncryptionZonesProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$GetEZForPathRequestProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$GetEZForPathRequestProto$Builder' start='7575' end='7575' sourcepath='org/apache/hadoop/hdfs/protocol/proto/EncryptionZonesProtos.java' sourcefile='EncryptionZonesProtos.java' startBytecode='3' primary='true'><Message>At EncryptionZonesProtos.java:[line 7575]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='cff5a93532a96ae7b9992ed68fedb29e' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$GetEZForPathResponseProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$GetEZForPathResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$GetEZForPathResponseProto' start='7775' end='8307' sourcepath='org/apache/hadoop/hdfs/protocol/proto/EncryptionZonesProtos.java' sourcefile='EncryptionZonesProtos.java'><Message>At EncryptionZonesProtos.java:[lines 7775-8307]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$GetEZForPathResponseProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$GetEZForPathResponseProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$GetEZForPathResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/EncryptionZonesProtos.java' sourcefile='EncryptionZonesProtos.java'><Message>In EncryptionZonesProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$GetEZForPathResponseProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$GetEZForPathResponseProto' start='7860' end='7860' sourcepath='org/apache/hadoop/hdfs/protocol/proto/EncryptionZonesProtos.java' sourcefile='EncryptionZonesProtos.java' startBytecode='7' primary='true'><Message>At EncryptionZonesProtos.java:[line 7860]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='e9f6fd40660dd818b8e8affe19a52c63' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$GetEZForPathResponseProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$GetEZForPathResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$GetEZForPathResponseProto' start='7775' end='8307' sourcepath='org/apache/hadoop/hdfs/protocol/proto/EncryptionZonesProtos.java' sourcefile='EncryptionZonesProtos.java'><Message>At EncryptionZonesProtos.java:[lines 7775-8307]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$GetEZForPathResponseProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$GetEZForPathResponseProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$GetEZForPathResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/EncryptionZonesProtos.java' sourcefile='EncryptionZonesProtos.java'><Message>In EncryptionZonesProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$GetEZForPathResponseProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$GetEZForPathResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/EncryptionZonesProtos.java' sourcefile='EncryptionZonesProtos.java'><Message>In EncryptionZonesProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='85b8e113c6a9f53fb0ae33f963e4d90c' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ListEncryptionZonesRequestProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ListEncryptionZonesRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ListEncryptionZonesRequestProto' start='1220' end='1641' sourcepath='org/apache/hadoop/hdfs/protocol/proto/EncryptionZonesProtos.java' sourcefile='EncryptionZonesProtos.java'><Message>At EncryptionZonesProtos.java:[lines 1220-1641]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ListEncryptionZonesRequestProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ListEncryptionZonesRequestProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ListEncryptionZonesRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/EncryptionZonesProtos.java' sourcefile='EncryptionZonesProtos.java'><Message>In EncryptionZonesProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ListEncryptionZonesRequestProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ListEncryptionZonesRequestProto' start='1297' end='1297' sourcepath='org/apache/hadoop/hdfs/protocol/proto/EncryptionZonesProtos.java' sourcefile='EncryptionZonesProtos.java' startBytecode='7' primary='true'><Message>At EncryptionZonesProtos.java:[line 1297]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='a96aedd7b3991f5f25c692472362ac11' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ListEncryptionZonesRequestProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ListEncryptionZonesRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ListEncryptionZonesRequestProto' start='1220' end='1641' sourcepath='org/apache/hadoop/hdfs/protocol/proto/EncryptionZonesProtos.java' sourcefile='EncryptionZonesProtos.java'><Message>At EncryptionZonesProtos.java:[lines 1220-1641]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ListEncryptionZonesRequestProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ListEncryptionZonesRequestProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ListEncryptionZonesRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/EncryptionZonesProtos.java' sourcefile='EncryptionZonesProtos.java'><Message>In EncryptionZonesProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ListEncryptionZonesRequestProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ListEncryptionZonesRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/EncryptionZonesProtos.java' sourcefile='EncryptionZonesProtos.java'><Message>In EncryptionZonesProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='2fee98ee8dbb744ad700a49bfa771c8a' rank='17' abbrev='UCF' category='STYLE' priority='2' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ListEncryptionZonesRequestProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ListEncryptionZonesRequestProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ListEncryptionZonesRequestProto$Builder' start='1483' end='1632' sourcepath='org/apache/hadoop/hdfs/protocol/proto/EncryptionZonesProtos.java' sourcefile='EncryptionZonesProtos.java'><Message>At EncryptionZonesProtos.java:[lines 1483-1632]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ListEncryptionZonesRequestProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ListEncryptionZonesRequestProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine endBytecode='61' classname='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ListEncryptionZonesRequestProto$Builder' start='1509' end='1511' sourcepath='org/apache/hadoop/hdfs/protocol/proto/EncryptionZonesProtos.java' sourcefile='EncryptionZonesProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ListEncryptionZonesRequestProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ListEncryptionZonesRequestProto$Builder' start='1509' end='1509' sourcepath='org/apache/hadoop/hdfs/protocol/proto/EncryptionZonesProtos.java' sourcefile='EncryptionZonesProtos.java' startBytecode='3' primary='true'><Message>At EncryptionZonesProtos.java:[line 1509]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='2a02d70a457d16afd7c15ee4eb9a67aa' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ListEncryptionZonesResponseProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ListEncryptionZonesResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ListEncryptionZonesResponseProto' start='2689' end='3465' sourcepath='org/apache/hadoop/hdfs/protocol/proto/EncryptionZonesProtos.java' sourcefile='EncryptionZonesProtos.java'><Message>At EncryptionZonesProtos.java:[lines 2689-3465]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ListEncryptionZonesResponseProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ListEncryptionZonesResponseProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ListEncryptionZonesResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/EncryptionZonesProtos.java' sourcefile='EncryptionZonesProtos.java'><Message>In EncryptionZonesProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ListEncryptionZonesResponseProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ListEncryptionZonesResponseProto' start='2777' end='2777' sourcepath='org/apache/hadoop/hdfs/protocol/proto/EncryptionZonesProtos.java' sourcefile='EncryptionZonesProtos.java' startBytecode='7' primary='true'><Message>At EncryptionZonesProtos.java:[line 2777]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='92bd0fb2c823801a11e88f82c10861ff' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ListEncryptionZonesResponseProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ListEncryptionZonesResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ListEncryptionZonesResponseProto' start='2689' end='3465' sourcepath='org/apache/hadoop/hdfs/protocol/proto/EncryptionZonesProtos.java' sourcefile='EncryptionZonesProtos.java'><Message>At EncryptionZonesProtos.java:[lines 2689-3465]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ListEncryptionZonesResponseProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ListEncryptionZonesResponseProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ListEncryptionZonesResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/EncryptionZonesProtos.java' sourcefile='EncryptionZonesProtos.java'><Message>In EncryptionZonesProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ListEncryptionZonesResponseProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ListEncryptionZonesResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/EncryptionZonesProtos.java' sourcefile='EncryptionZonesProtos.java'><Message>In EncryptionZonesProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='eeb9f53993f06b3e9cf9dd0107788f93' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ListReencryptionStatusRequestProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ListReencryptionStatusRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ListReencryptionStatusRequestProto' start='4448' end='4869' sourcepath='org/apache/hadoop/hdfs/protocol/proto/EncryptionZonesProtos.java' sourcefile='EncryptionZonesProtos.java'><Message>At EncryptionZonesProtos.java:[lines 4448-4869]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ListReencryptionStatusRequestProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ListReencryptionStatusRequestProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ListReencryptionStatusRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/EncryptionZonesProtos.java' sourcefile='EncryptionZonesProtos.java'><Message>In EncryptionZonesProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ListReencryptionStatusRequestProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ListReencryptionStatusRequestProto' start='4525' end='4525' sourcepath='org/apache/hadoop/hdfs/protocol/proto/EncryptionZonesProtos.java' sourcefile='EncryptionZonesProtos.java' startBytecode='7' primary='true'><Message>At EncryptionZonesProtos.java:[line 4525]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='c45f249afbfb668d48d3b0fb2b7e349a' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ListReencryptionStatusRequestProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ListReencryptionStatusRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ListReencryptionStatusRequestProto' start='4448' end='4869' sourcepath='org/apache/hadoop/hdfs/protocol/proto/EncryptionZonesProtos.java' sourcefile='EncryptionZonesProtos.java'><Message>At EncryptionZonesProtos.java:[lines 4448-4869]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ListReencryptionStatusRequestProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ListReencryptionStatusRequestProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ListReencryptionStatusRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/EncryptionZonesProtos.java' sourcefile='EncryptionZonesProtos.java'><Message>In EncryptionZonesProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ListReencryptionStatusRequestProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ListReencryptionStatusRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/EncryptionZonesProtos.java' sourcefile='EncryptionZonesProtos.java'><Message>In EncryptionZonesProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='2b2b776104c4dccc4b6fdadc28d8939b' rank='17' abbrev='UCF' category='STYLE' priority='2' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ListReencryptionStatusRequestProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ListReencryptionStatusRequestProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ListReencryptionStatusRequestProto$Builder' start='4711' end='4860' sourcepath='org/apache/hadoop/hdfs/protocol/proto/EncryptionZonesProtos.java' sourcefile='EncryptionZonesProtos.java'><Message>At EncryptionZonesProtos.java:[lines 4711-4860]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ListReencryptionStatusRequestProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ListReencryptionStatusRequestProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine endBytecode='61' classname='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ListReencryptionStatusRequestProto$Builder' start='4737' end='4739' sourcepath='org/apache/hadoop/hdfs/protocol/proto/EncryptionZonesProtos.java' sourcefile='EncryptionZonesProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ListReencryptionStatusRequestProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ListReencryptionStatusRequestProto$Builder' start='4737' end='4737' sourcepath='org/apache/hadoop/hdfs/protocol/proto/EncryptionZonesProtos.java' sourcefile='EncryptionZonesProtos.java' startBytecode='3' primary='true'><Message>At EncryptionZonesProtos.java:[line 4737]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='9c9b9374db01288c6e009cb5a702ea8b' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ListReencryptionStatusResponseProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ListReencryptionStatusResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ListReencryptionStatusResponseProto' start='6457' end='7233' sourcepath='org/apache/hadoop/hdfs/protocol/proto/EncryptionZonesProtos.java' sourcefile='EncryptionZonesProtos.java'><Message>At EncryptionZonesProtos.java:[lines 6457-7233]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ListReencryptionStatusResponseProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ListReencryptionStatusResponseProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ListReencryptionStatusResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/EncryptionZonesProtos.java' sourcefile='EncryptionZonesProtos.java'><Message>In EncryptionZonesProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ListReencryptionStatusResponseProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ListReencryptionStatusResponseProto' start='6545' end='6545' sourcepath='org/apache/hadoop/hdfs/protocol/proto/EncryptionZonesProtos.java' sourcefile='EncryptionZonesProtos.java' startBytecode='7' primary='true'><Message>At EncryptionZonesProtos.java:[line 6545]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='234aa26405e2f8dc4b3338572218e8ed' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ListReencryptionStatusResponseProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ListReencryptionStatusResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ListReencryptionStatusResponseProto' start='6457' end='7233' sourcepath='org/apache/hadoop/hdfs/protocol/proto/EncryptionZonesProtos.java' sourcefile='EncryptionZonesProtos.java'><Message>At EncryptionZonesProtos.java:[lines 6457-7233]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ListReencryptionStatusResponseProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ListReencryptionStatusResponseProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ListReencryptionStatusResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/EncryptionZonesProtos.java' sourcefile='EncryptionZonesProtos.java'><Message>In EncryptionZonesProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ListReencryptionStatusResponseProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ListReencryptionStatusResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/EncryptionZonesProtos.java' sourcefile='EncryptionZonesProtos.java'><Message>In EncryptionZonesProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='ec1536d8c0b997beee1c744e2f4e9fbb' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ReencryptEncryptionZoneRequestProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ReencryptEncryptionZoneRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ReencryptEncryptionZoneRequestProto' start='3501' end='4089' sourcepath='org/apache/hadoop/hdfs/protocol/proto/EncryptionZonesProtos.java' sourcefile='EncryptionZonesProtos.java'><Message>At EncryptionZonesProtos.java:[lines 3501-4089]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ReencryptEncryptionZoneRequestProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ReencryptEncryptionZoneRequestProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ReencryptEncryptionZoneRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/EncryptionZonesProtos.java' sourcefile='EncryptionZonesProtos.java'><Message>In EncryptionZonesProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ReencryptEncryptionZoneRequestProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ReencryptEncryptionZoneRequestProto' start='3589' end='3589' sourcepath='org/apache/hadoop/hdfs/protocol/proto/EncryptionZonesProtos.java' sourcefile='EncryptionZonesProtos.java' startBytecode='7' primary='true'><Message>At EncryptionZonesProtos.java:[line 3589]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='980ca1db972e155308b65e93934d1344' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ReencryptEncryptionZoneRequestProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ReencryptEncryptionZoneRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ReencryptEncryptionZoneRequestProto' start='3501' end='4089' sourcepath='org/apache/hadoop/hdfs/protocol/proto/EncryptionZonesProtos.java' sourcefile='EncryptionZonesProtos.java'><Message>At EncryptionZonesProtos.java:[lines 3501-4089]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ReencryptEncryptionZoneRequestProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ReencryptEncryptionZoneRequestProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ReencryptEncryptionZoneRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/EncryptionZonesProtos.java' sourcefile='EncryptionZonesProtos.java'><Message>In EncryptionZonesProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ReencryptEncryptionZoneRequestProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ReencryptEncryptionZoneRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/EncryptionZonesProtos.java' sourcefile='EncryptionZonesProtos.java'><Message>In EncryptionZonesProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='beef130fef2d5e07708b36e1a440387c' rank='17' abbrev='UCF' category='STYLE' priority='2' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ReencryptEncryptionZoneRequestProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ReencryptEncryptionZoneRequestProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ReencryptEncryptionZoneRequestProto$Builder' start='3839' end='4080' sourcepath='org/apache/hadoop/hdfs/protocol/proto/EncryptionZonesProtos.java' sourcefile='EncryptionZonesProtos.java'><Message>At EncryptionZonesProtos.java:[lines 3839-4080]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ReencryptEncryptionZoneRequestProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ReencryptEncryptionZoneRequestProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine endBytecode='61' classname='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ReencryptEncryptionZoneRequestProto$Builder' start='3865' end='3867' sourcepath='org/apache/hadoop/hdfs/protocol/proto/EncryptionZonesProtos.java' sourcefile='EncryptionZonesProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ReencryptEncryptionZoneRequestProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ReencryptEncryptionZoneRequestProto$Builder' start='3865' end='3865' sourcepath='org/apache/hadoop/hdfs/protocol/proto/EncryptionZonesProtos.java' sourcefile='EncryptionZonesProtos.java' startBytecode='3' primary='true'><Message>At EncryptionZonesProtos.java:[line 3865]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='b7c999624388afee80af6fc985c2794f' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ReencryptEncryptionZoneResponseProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ReencryptEncryptionZoneResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ReencryptEncryptionZoneResponseProto' start='4100' end='4427' sourcepath='org/apache/hadoop/hdfs/protocol/proto/EncryptionZonesProtos.java' sourcefile='EncryptionZonesProtos.java'><Message>At EncryptionZonesProtos.java:[lines 4100-4427]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ReencryptEncryptionZoneResponseProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ReencryptEncryptionZoneResponseProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ReencryptEncryptionZoneResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/EncryptionZonesProtos.java' sourcefile='EncryptionZonesProtos.java'><Message>In EncryptionZonesProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ReencryptEncryptionZoneResponseProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ReencryptEncryptionZoneResponseProto' start='4171' end='4171' sourcepath='org/apache/hadoop/hdfs/protocol/proto/EncryptionZonesProtos.java' sourcefile='EncryptionZonesProtos.java' startBytecode='7' primary='true'><Message>At EncryptionZonesProtos.java:[line 4171]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='492bc3f0defe4aeb341ab3cae2ea53c6' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ReencryptEncryptionZoneResponseProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ReencryptEncryptionZoneResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ReencryptEncryptionZoneResponseProto' start='4100' end='4427' sourcepath='org/apache/hadoop/hdfs/protocol/proto/EncryptionZonesProtos.java' sourcefile='EncryptionZonesProtos.java'><Message>At EncryptionZonesProtos.java:[lines 4100-4427]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ReencryptEncryptionZoneResponseProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ReencryptEncryptionZoneResponseProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ReencryptEncryptionZoneResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/EncryptionZonesProtos.java' sourcefile='EncryptionZonesProtos.java'><Message>In EncryptionZonesProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ReencryptEncryptionZoneResponseProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ReencryptEncryptionZoneResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/EncryptionZonesProtos.java' sourcefile='EncryptionZonesProtos.java'><Message>In EncryptionZonesProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='f5004124c8040c058923006b8ee7dbea' rank='17' abbrev='UCF' category='STYLE' priority='2' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ReencryptEncryptionZoneResponseProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ReencryptEncryptionZoneResponseProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ReencryptEncryptionZoneResponseProto$Builder' start='4319' end='4418' sourcepath='org/apache/hadoop/hdfs/protocol/proto/EncryptionZonesProtos.java' sourcefile='EncryptionZonesProtos.java'><Message>At EncryptionZonesProtos.java:[lines 4319-4418]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ReencryptEncryptionZoneResponseProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ReencryptEncryptionZoneResponseProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine endBytecode='61' classname='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ReencryptEncryptionZoneResponseProto$Builder' start='4345' end='4347' sourcepath='org/apache/hadoop/hdfs/protocol/proto/EncryptionZonesProtos.java' sourcefile='EncryptionZonesProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ReencryptEncryptionZoneResponseProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ReencryptEncryptionZoneResponseProto$Builder' start='4345' end='4345' sourcepath='org/apache/hadoop/hdfs/protocol/proto/EncryptionZonesProtos.java' sourcefile='EncryptionZonesProtos.java' startBytecode='3' primary='true'><Message>At EncryptionZonesProtos.java:[line 4345]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='1dfdbf2e060b30d20ba7de58709a9179' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ZoneReencryptionStatusProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ZoneReencryptionStatusProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ZoneReencryptionStatusProto' start='4995' end='6411' sourcepath='org/apache/hadoop/hdfs/protocol/proto/EncryptionZonesProtos.java' sourcefile='EncryptionZonesProtos.java'><Message>At EncryptionZonesProtos.java:[lines 4995-6411]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ZoneReencryptionStatusProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ZoneReencryptionStatusProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ZoneReencryptionStatusProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/EncryptionZonesProtos.java' sourcefile='EncryptionZonesProtos.java'><Message>In EncryptionZonesProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ZoneReencryptionStatusProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ZoneReencryptionStatusProto' start='5123' end='5123' sourcepath='org/apache/hadoop/hdfs/protocol/proto/EncryptionZonesProtos.java' sourcefile='EncryptionZonesProtos.java' startBytecode='7' primary='true'><Message>At EncryptionZonesProtos.java:[line 5123]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='b0f81bc1cd8caffd9190a92c63ddad2' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ZoneReencryptionStatusProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ZoneReencryptionStatusProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ZoneReencryptionStatusProto' start='4995' end='6411' sourcepath='org/apache/hadoop/hdfs/protocol/proto/EncryptionZonesProtos.java' sourcefile='EncryptionZonesProtos.java'><Message>At EncryptionZonesProtos.java:[lines 4995-6411]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ZoneReencryptionStatusProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ZoneReencryptionStatusProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ZoneReencryptionStatusProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/EncryptionZonesProtos.java' sourcefile='EncryptionZonesProtos.java'><Message>In EncryptionZonesProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ZoneReencryptionStatusProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ZoneReencryptionStatusProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/EncryptionZonesProtos.java' sourcefile='EncryptionZonesProtos.java'><Message>In EncryptionZonesProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='e121566e92f733ac30fd21cf802ce4a4' rank='17' abbrev='UCF' category='STYLE' priority='2' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ZoneReencryptionStatusProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ZoneReencryptionStatusProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ZoneReencryptionStatusProto$Builder' start='5715' end='6402' sourcepath='org/apache/hadoop/hdfs/protocol/proto/EncryptionZonesProtos.java' sourcefile='EncryptionZonesProtos.java'><Message>At EncryptionZonesProtos.java:[lines 5715-6402]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ZoneReencryptionStatusProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ZoneReencryptionStatusProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine endBytecode='61' classname='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ZoneReencryptionStatusProto$Builder' start='5741' end='5743' sourcepath='org/apache/hadoop/hdfs/protocol/proto/EncryptionZonesProtos.java' sourcefile='EncryptionZonesProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ZoneReencryptionStatusProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ZoneReencryptionStatusProto$Builder' start='5741' end='5741' sourcepath='org/apache/hadoop/hdfs/protocol/proto/EncryptionZonesProtos.java' sourcefile='EncryptionZonesProtos.java' startBytecode='3' primary='true'><Message>At EncryptionZonesProtos.java:[line 5741]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='1a54fb0827f5c6473f62625897cd6259' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$AddErasureCodingPoliciesRequestProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$AddErasureCodingPoliciesRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$AddErasureCodingPoliciesRequestProto' start='4318' end='5003' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' sourcefile='ErasureCodingProtos.java'><Message>At ErasureCodingProtos.java:[lines 4318-5003]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$AddErasureCodingPoliciesRequestProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$AddErasureCodingPoliciesRequestProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$AddErasureCodingPoliciesRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' sourcefile='ErasureCodingProtos.java'><Message>In ErasureCodingProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$AddErasureCodingPoliciesRequestProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$AddErasureCodingPoliciesRequestProto' start='4401' end='4401' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' sourcefile='ErasureCodingProtos.java' startBytecode='7' primary='true'><Message>At ErasureCodingProtos.java:[line 4401]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='5112eabab00850e2082dbadcb746a15f' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$AddErasureCodingPoliciesRequestProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$AddErasureCodingPoliciesRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$AddErasureCodingPoliciesRequestProto' start='4318' end='5003' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' sourcefile='ErasureCodingProtos.java'><Message>At ErasureCodingProtos.java:[lines 4318-5003]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$AddErasureCodingPoliciesRequestProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$AddErasureCodingPoliciesRequestProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$AddErasureCodingPoliciesRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' sourcefile='ErasureCodingProtos.java'><Message>In ErasureCodingProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$AddErasureCodingPoliciesRequestProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$AddErasureCodingPoliciesRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' sourcefile='ErasureCodingProtos.java'><Message>In ErasureCodingProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='7b86c862d08d70a7c329e2f0516ff0b9' cweid='563' rank='20' abbrev='DLS' category='STYLE' priority='3' type='DLS_DEAD_LOCAL_STORE' instanceOccurrenceMax='0'><ShortMessage>Dead store to local variable</ShortMessage><LongMessage>Dead store to from_bitField0_ in org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$AddErasureCodingPoliciesRequestProto$Builder.buildPartial()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$AddErasureCodingPoliciesRequestProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$AddErasureCodingPoliciesRequestProto$Builder' start='4605' end='4994' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' sourcefile='ErasureCodingProtos.java'><Message>At ErasureCodingProtos.java:[lines 4605-4994]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$AddErasureCodingPoliciesRequestProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$AddErasureCodingPoliciesRequestProto$Builder' signature='()Lorg/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos$AddErasureCodingPoliciesRequestProto;' name='buildPartial' primary='true'><SourceLine endBytecode='44' classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$AddErasureCodingPoliciesRequestProto$Builder' start='4672' end='4684' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' sourcefile='ErasureCodingProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$AddErasureCodingPoliciesRequestProto$Builder.buildPartial()</Message></Method><LocalVariable role='LOCAL_VARIABLE_NAMED' pc='15' name='from_bitField0_' register='2'><Message>Local variable named from_bitField0_</Message></LocalVariable><SourceLine endBytecode='14' classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$AddErasureCodingPoliciesRequestProto$Builder' start='4673' end='4673' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' sourcefile='ErasureCodingProtos.java' startBytecode='14' primary='true'><Message>At ErasureCodingProtos.java:[line 4673]</Message></SourceLine><Property name='edu.umd.cs.findbugs.detect.DeadLocalStoreProperty.BASE_VALUE' value='true'></Property><Property name='edu.umd.cs.findbugs.detect.DeadLocalStoreProperty.CACHING_VALUE' value='true'></Property><Property name='edu.umd.cs.findbugs.detect.DeadLocalStoreProperty.LOCAL_NAME' value='from_bitField0_'></Property><Property name='edu.umd.cs.findbugs.detect.DeadLocalStoreProperty.NO_LOADS' value='true'></Property></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='c5ee6f07ac64c5fc64c6027345859130' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$AddErasureCodingPoliciesResponseProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$AddErasureCodingPoliciesResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$AddErasureCodingPoliciesResponseProto' start='5039' end='5724' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' sourcefile='ErasureCodingProtos.java'><Message>At ErasureCodingProtos.java:[lines 5039-5724]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$AddErasureCodingPoliciesResponseProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$AddErasureCodingPoliciesResponseProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$AddErasureCodingPoliciesResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' sourcefile='ErasureCodingProtos.java'><Message>In ErasureCodingProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$AddErasureCodingPoliciesResponseProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$AddErasureCodingPoliciesResponseProto' start='5122' end='5122' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' sourcefile='ErasureCodingProtos.java' startBytecode='7' primary='true'><Message>At ErasureCodingProtos.java:[line 5122]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='edda5c0502b83303b9ce7710357fb381' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$AddErasureCodingPoliciesResponseProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$AddErasureCodingPoliciesResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$AddErasureCodingPoliciesResponseProto' start='5039' end='5724' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' sourcefile='ErasureCodingProtos.java'><Message>At ErasureCodingProtos.java:[lines 5039-5724]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$AddErasureCodingPoliciesResponseProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$AddErasureCodingPoliciesResponseProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$AddErasureCodingPoliciesResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' sourcefile='ErasureCodingProtos.java'><Message>In ErasureCodingProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$AddErasureCodingPoliciesResponseProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$AddErasureCodingPoliciesResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' sourcefile='ErasureCodingProtos.java'><Message>In ErasureCodingProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='4fb3b0860e77552b2063bf0f59b49950' cweid='563' rank='20' abbrev='DLS' category='STYLE' priority='3' type='DLS_DEAD_LOCAL_STORE' instanceOccurrenceMax='0'><ShortMessage>Dead store to local variable</ShortMessage><LongMessage>Dead store to from_bitField0_ in org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$AddErasureCodingPoliciesResponseProto$Builder.buildPartial()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$AddErasureCodingPoliciesResponseProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$AddErasureCodingPoliciesResponseProto$Builder' start='5326' end='5715' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' sourcefile='ErasureCodingProtos.java'><Message>At ErasureCodingProtos.java:[lines 5326-5715]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$AddErasureCodingPoliciesResponseProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$AddErasureCodingPoliciesResponseProto$Builder' signature='()Lorg/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos$AddErasureCodingPoliciesResponseProto;' name='buildPartial' primary='true'><SourceLine endBytecode='44' classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$AddErasureCodingPoliciesResponseProto$Builder' start='5393' end='5405' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' sourcefile='ErasureCodingProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$AddErasureCodingPoliciesResponseProto$Builder.buildPartial()</Message></Method><LocalVariable role='LOCAL_VARIABLE_NAMED' pc='15' name='from_bitField0_' register='2'><Message>Local variable named from_bitField0_</Message></LocalVariable><SourceLine endBytecode='14' classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$AddErasureCodingPoliciesResponseProto$Builder' start='5394' end='5394' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' sourcefile='ErasureCodingProtos.java' startBytecode='14' primary='true'><Message>At ErasureCodingProtos.java:[line 5394]</Message></SourceLine><Property name='edu.umd.cs.findbugs.detect.DeadLocalStoreProperty.BASE_VALUE' value='true'></Property><Property name='edu.umd.cs.findbugs.detect.DeadLocalStoreProperty.CACHING_VALUE' value='true'></Property><Property name='edu.umd.cs.findbugs.detect.DeadLocalStoreProperty.LOCAL_NAME' value='from_bitField0_'></Property><Property name='edu.umd.cs.findbugs.detect.DeadLocalStoreProperty.NO_LOADS' value='true'></Property></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='72708c7375bb70f304f75a62530200f1' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$BlockECReconstructionInfoProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$BlockECReconstructionInfoProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$BlockECReconstructionInfoProto' start='9254' end='10885' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' sourcefile='ErasureCodingProtos.java'><Message>At ErasureCodingProtos.java:[lines 9254-10885]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$BlockECReconstructionInfoProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$BlockECReconstructionInfoProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$BlockECReconstructionInfoProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' sourcefile='ErasureCodingProtos.java'><Message>In ErasureCodingProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$BlockECReconstructionInfoProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$BlockECReconstructionInfoProto' start='9409' end='9409' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' sourcefile='ErasureCodingProtos.java' startBytecode='7' primary='true'><Message>At ErasureCodingProtos.java:[line 9409]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='9ddd8453ff88540ef01d797012b56417' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$BlockECReconstructionInfoProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$BlockECReconstructionInfoProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$BlockECReconstructionInfoProto' start='9254' end='10885' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' sourcefile='ErasureCodingProtos.java'><Message>At ErasureCodingProtos.java:[lines 9254-10885]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$BlockECReconstructionInfoProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$BlockECReconstructionInfoProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$BlockECReconstructionInfoProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' sourcefile='ErasureCodingProtos.java'><Message>In ErasureCodingProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$BlockECReconstructionInfoProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$BlockECReconstructionInfoProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' sourcefile='ErasureCodingProtos.java'><Message>In ErasureCodingProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='d0246e8a20971f395dc2c885ff4f1e74' rank='19' abbrev='Se' category='BAD_PRACTICE' priority='3' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$BlockECReconstructionInfoProto defines non-transient non-serializable instance field liveBlockIndices_</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$BlockECReconstructionInfoProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$BlockECReconstructionInfoProto' start='9254' end='10885' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' sourcefile='ErasureCodingProtos.java'><Message>At ErasureCodingProtos.java:[lines 9254-10885]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$BlockECReconstructionInfoProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$BlockECReconstructionInfoProto' signature='Lcom/google/protobuf/ByteString;' name='liveBlockIndices_' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$BlockECReconstructionInfoProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' sourcefile='ErasureCodingProtos.java'><Message>In ErasureCodingProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$BlockECReconstructionInfoProto.liveBlockIndices_</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/ByteString;'><SourceLine classname='com.google.protobuf.ByteString' start='60' end='967' sourcepath='com/google/protobuf/ByteString.java' sourcefile='ByteString.java'><Message>At ByteString.java:[lines 60-967]</Message></SourceLine><Message>Actual type com.google.protobuf.ByteString</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$BlockECReconstructionInfoProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' sourcefile='ErasureCodingProtos.java'><Message>In ErasureCodingProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='1c81c9b510ee2af2b16097954b79af73' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$CodecProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$CodecProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$CodecProto' start='10931' end='11585' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' sourcefile='ErasureCodingProtos.java'><Message>At ErasureCodingProtos.java:[lines 10931-11585]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$CodecProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$CodecProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$CodecProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' sourcefile='ErasureCodingProtos.java'><Message>In ErasureCodingProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$CodecProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$CodecProto' start='11013' end='11013' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' sourcefile='ErasureCodingProtos.java' startBytecode='7' primary='true'><Message>At ErasureCodingProtos.java:[line 11013]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='cdffe6649b7127d6ad52644ddac16245' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$CodecProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$CodecProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$CodecProto' start='10931' end='11585' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' sourcefile='ErasureCodingProtos.java'><Message>At ErasureCodingProtos.java:[lines 10931-11585]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$CodecProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$CodecProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$CodecProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' sourcefile='ErasureCodingProtos.java'><Message>In ErasureCodingProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$CodecProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$CodecProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' sourcefile='ErasureCodingProtos.java'><Message>In ErasureCodingProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='e916385258bda862d074b6d1143991ce' rank='17' abbrev='UCF' category='STYLE' priority='2' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$CodecProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$CodecProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$CodecProto$Builder' start='11295' end='11576' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' sourcefile='ErasureCodingProtos.java'><Message>At ErasureCodingProtos.java:[lines 11295-11576]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$CodecProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$CodecProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine endBytecode='61' classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$CodecProto$Builder' start='11321' end='11323' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' sourcefile='ErasureCodingProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$CodecProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$CodecProto$Builder' start='11321' end='11321' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' sourcefile='ErasureCodingProtos.java' startBytecode='3' primary='true'><Message>At ErasureCodingProtos.java:[line 11321]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='52391f6b0d5b0007e3dbfadc44f7b746' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$DisableErasureCodingPolicyRequestProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$DisableErasureCodingPolicyRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$DisableErasureCodingPolicyRequestProto' start='7460' end='7951' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' sourcefile='ErasureCodingProtos.java'><Message>At ErasureCodingProtos.java:[lines 7460-7951]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$DisableErasureCodingPolicyRequestProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$DisableErasureCodingPolicyRequestProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$DisableErasureCodingPolicyRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' sourcefile='ErasureCodingProtos.java'><Message>In ErasureCodingProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$DisableErasureCodingPolicyRequestProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$DisableErasureCodingPolicyRequestProto' start='7537' end='7537' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' sourcefile='ErasureCodingProtos.java' startBytecode='7' primary='true'><Message>At ErasureCodingProtos.java:[line 7537]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='f5c9029deba9a35637abd7f54eeb91c5' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$DisableErasureCodingPolicyRequestProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$DisableErasureCodingPolicyRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$DisableErasureCodingPolicyRequestProto' start='7460' end='7951' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' sourcefile='ErasureCodingProtos.java'><Message>At ErasureCodingProtos.java:[lines 7460-7951]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$DisableErasureCodingPolicyRequestProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$DisableErasureCodingPolicyRequestProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$DisableErasureCodingPolicyRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' sourcefile='ErasureCodingProtos.java'><Message>In ErasureCodingProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$DisableErasureCodingPolicyRequestProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$DisableErasureCodingPolicyRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' sourcefile='ErasureCodingProtos.java'><Message>In ErasureCodingProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='6684d9233f2a8aa68fbc8c14f23c078' rank='17' abbrev='UCF' category='STYLE' priority='2' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$DisableErasureCodingPolicyRequestProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$DisableErasureCodingPolicyRequestProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$DisableErasureCodingPolicyRequestProto$Builder' start='7750' end='7942' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' sourcefile='ErasureCodingProtos.java'><Message>At ErasureCodingProtos.java:[lines 7750-7942]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$DisableErasureCodingPolicyRequestProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$DisableErasureCodingPolicyRequestProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine endBytecode='61' classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$DisableErasureCodingPolicyRequestProto$Builder' start='7776' end='7778' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' sourcefile='ErasureCodingProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$DisableErasureCodingPolicyRequestProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$DisableErasureCodingPolicyRequestProto$Builder' start='7776' end='7776' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' sourcefile='ErasureCodingProtos.java' startBytecode='3' primary='true'><Message>At ErasureCodingProtos.java:[line 7776]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='7a666b301bde813443237b61faf04bec' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$DisableErasureCodingPolicyResponseProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$DisableErasureCodingPolicyResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$DisableErasureCodingPolicyResponseProto' start='7962' end='8289' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' sourcefile='ErasureCodingProtos.java'><Message>At ErasureCodingProtos.java:[lines 7962-8289]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$DisableErasureCodingPolicyResponseProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$DisableErasureCodingPolicyResponseProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$DisableErasureCodingPolicyResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' sourcefile='ErasureCodingProtos.java'><Message>In ErasureCodingProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$DisableErasureCodingPolicyResponseProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$DisableErasureCodingPolicyResponseProto' start='8033' end='8033' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' sourcefile='ErasureCodingProtos.java' startBytecode='7' primary='true'><Message>At ErasureCodingProtos.java:[line 8033]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='6602ea508b9efbe40a21665b50e0a5dc' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$DisableErasureCodingPolicyResponseProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$DisableErasureCodingPolicyResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$DisableErasureCodingPolicyResponseProto' start='7962' end='8289' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' sourcefile='ErasureCodingProtos.java'><Message>At ErasureCodingProtos.java:[lines 7962-8289]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$DisableErasureCodingPolicyResponseProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$DisableErasureCodingPolicyResponseProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$DisableErasureCodingPolicyResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' sourcefile='ErasureCodingProtos.java'><Message>In ErasureCodingProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$DisableErasureCodingPolicyResponseProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$DisableErasureCodingPolicyResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' sourcefile='ErasureCodingProtos.java'><Message>In ErasureCodingProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='64563ba71f7d1867bbe251e846258155' rank='17' abbrev='UCF' category='STYLE' priority='2' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$DisableErasureCodingPolicyResponseProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$DisableErasureCodingPolicyResponseProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$DisableErasureCodingPolicyResponseProto$Builder' start='8181' end='8280' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' sourcefile='ErasureCodingProtos.java'><Message>At ErasureCodingProtos.java:[lines 8181-8280]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$DisableErasureCodingPolicyResponseProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$DisableErasureCodingPolicyResponseProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine endBytecode='61' classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$DisableErasureCodingPolicyResponseProto$Builder' start='8207' end='8209' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' sourcefile='ErasureCodingProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$DisableErasureCodingPolicyResponseProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$DisableErasureCodingPolicyResponseProto$Builder' start='8207' end='8207' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' sourcefile='ErasureCodingProtos.java' startBytecode='3' primary='true'><Message>At ErasureCodingProtos.java:[line 8207]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='d1628a85a2b9d0ee6af1c83a4d83996a' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$EnableErasureCodingPolicyRequestProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$EnableErasureCodingPolicyRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$EnableErasureCodingPolicyRequestProto' start='6605' end='7096' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' sourcefile='ErasureCodingProtos.java'><Message>At ErasureCodingProtos.java:[lines 6605-7096]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$EnableErasureCodingPolicyRequestProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$EnableErasureCodingPolicyRequestProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$EnableErasureCodingPolicyRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' sourcefile='ErasureCodingProtos.java'><Message>In ErasureCodingProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$EnableErasureCodingPolicyRequestProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$EnableErasureCodingPolicyRequestProto' start='6682' end='6682' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' sourcefile='ErasureCodingProtos.java' startBytecode='7' primary='true'><Message>At ErasureCodingProtos.java:[line 6682]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='46398af98d5a9485ce0664d7007e51' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$EnableErasureCodingPolicyRequestProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$EnableErasureCodingPolicyRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$EnableErasureCodingPolicyRequestProto' start='6605' end='7096' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' sourcefile='ErasureCodingProtos.java'><Message>At ErasureCodingProtos.java:[lines 6605-7096]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$EnableErasureCodingPolicyRequestProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$EnableErasureCodingPolicyRequestProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$EnableErasureCodingPolicyRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' sourcefile='ErasureCodingProtos.java'><Message>In ErasureCodingProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$EnableErasureCodingPolicyRequestProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$EnableErasureCodingPolicyRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' sourcefile='ErasureCodingProtos.java'><Message>In ErasureCodingProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='fefa52704aa9bc6e7607e1ef918c244a' rank='17' abbrev='UCF' category='STYLE' priority='2' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$EnableErasureCodingPolicyRequestProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$EnableErasureCodingPolicyRequestProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$EnableErasureCodingPolicyRequestProto$Builder' start='6895' end='7087' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' sourcefile='ErasureCodingProtos.java'><Message>At ErasureCodingProtos.java:[lines 6895-7087]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$EnableErasureCodingPolicyRequestProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$EnableErasureCodingPolicyRequestProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine endBytecode='61' classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$EnableErasureCodingPolicyRequestProto$Builder' start='6921' end='6923' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' sourcefile='ErasureCodingProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$EnableErasureCodingPolicyRequestProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$EnableErasureCodingPolicyRequestProto$Builder' start='6921' end='6921' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' sourcefile='ErasureCodingProtos.java' startBytecode='3' primary='true'><Message>At ErasureCodingProtos.java:[line 6921]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='efbff8e16fe1f704fcc362bf0ba66908' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$EnableErasureCodingPolicyResponseProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$EnableErasureCodingPolicyResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$EnableErasureCodingPolicyResponseProto' start='7107' end='7434' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' sourcefile='ErasureCodingProtos.java'><Message>At ErasureCodingProtos.java:[lines 7107-7434]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$EnableErasureCodingPolicyResponseProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$EnableErasureCodingPolicyResponseProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$EnableErasureCodingPolicyResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' sourcefile='ErasureCodingProtos.java'><Message>In ErasureCodingProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$EnableErasureCodingPolicyResponseProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$EnableErasureCodingPolicyResponseProto' start='7178' end='7178' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' sourcefile='ErasureCodingProtos.java' startBytecode='7' primary='true'><Message>At ErasureCodingProtos.java:[line 7178]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='7e5571f37316d31d2b11f76ed9177961' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$EnableErasureCodingPolicyResponseProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$EnableErasureCodingPolicyResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$EnableErasureCodingPolicyResponseProto' start='7107' end='7434' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' sourcefile='ErasureCodingProtos.java'><Message>At ErasureCodingProtos.java:[lines 7107-7434]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$EnableErasureCodingPolicyResponseProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$EnableErasureCodingPolicyResponseProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$EnableErasureCodingPolicyResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' sourcefile='ErasureCodingProtos.java'><Message>In ErasureCodingProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$EnableErasureCodingPolicyResponseProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$EnableErasureCodingPolicyResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' sourcefile='ErasureCodingProtos.java'><Message>In ErasureCodingProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='db5d97ce0b797efebd15206aaca092df' rank='17' abbrev='UCF' category='STYLE' priority='2' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$EnableErasureCodingPolicyResponseProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$EnableErasureCodingPolicyResponseProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$EnableErasureCodingPolicyResponseProto$Builder' start='7326' end='7425' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' sourcefile='ErasureCodingProtos.java'><Message>At ErasureCodingProtos.java:[lines 7326-7425]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$EnableErasureCodingPolicyResponseProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$EnableErasureCodingPolicyResponseProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine endBytecode='61' classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$EnableErasureCodingPolicyResponseProto$Builder' start='7352' end='7354' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' sourcefile='ErasureCodingProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$EnableErasureCodingPolicyResponseProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$EnableErasureCodingPolicyResponseProto$Builder' start='7352' end='7352' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' sourcefile='ErasureCodingProtos.java' startBytecode='3' primary='true'><Message>At ErasureCodingProtos.java:[line 7352]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='5fd10756407fb044b3669aa9e01cbab1' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingCodecsRequestProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingCodecsRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingCodecsRequestProto' start='2108' end='2439' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' sourcefile='ErasureCodingProtos.java'><Message>At ErasureCodingProtos.java:[lines 2108-2439]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingCodecsRequestProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingCodecsRequestProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingCodecsRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' sourcefile='ErasureCodingProtos.java'><Message>In ErasureCodingProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingCodecsRequestProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingCodecsRequestProto' start='2179' end='2179' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' sourcefile='ErasureCodingProtos.java' startBytecode='7' primary='true'><Message>At ErasureCodingProtos.java:[line 2179]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='eb872810d2d6598871b3af12edc0aec8' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingCodecsRequestProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingCodecsRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingCodecsRequestProto' start='2108' end='2439' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' sourcefile='ErasureCodingProtos.java'><Message>At ErasureCodingProtos.java:[lines 2108-2439]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingCodecsRequestProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingCodecsRequestProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingCodecsRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' sourcefile='ErasureCodingProtos.java'><Message>In ErasureCodingProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingCodecsRequestProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingCodecsRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' sourcefile='ErasureCodingProtos.java'><Message>In ErasureCodingProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='2fba4d591b66e0212d4e94c9b1b36eeb' rank='17' abbrev='UCF' category='STYLE' priority='2' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingCodecsRequestProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingCodecsRequestProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingCodecsRequestProto$Builder' start='2331' end='2430' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' sourcefile='ErasureCodingProtos.java'><Message>At ErasureCodingProtos.java:[lines 2331-2430]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingCodecsRequestProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingCodecsRequestProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine endBytecode='61' classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingCodecsRequestProto$Builder' start='2357' end='2359' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' sourcefile='ErasureCodingProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingCodecsRequestProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingCodecsRequestProto$Builder' start='2357' end='2357' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' sourcefile='ErasureCodingProtos.java' startBytecode='3' primary='true'><Message>At ErasureCodingProtos.java:[line 2357]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='8854f947c6e878d290f922e226cd7422' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingCodecsResponseProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingCodecsResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingCodecsResponseProto' start='2475' end='3160' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' sourcefile='ErasureCodingProtos.java'><Message>At ErasureCodingProtos.java:[lines 2475-3160]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingCodecsResponseProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingCodecsResponseProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingCodecsResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' sourcefile='ErasureCodingProtos.java'><Message>In ErasureCodingProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingCodecsResponseProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingCodecsResponseProto' start='2558' end='2558' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' sourcefile='ErasureCodingProtos.java' startBytecode='7' primary='true'><Message>At ErasureCodingProtos.java:[line 2558]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='46c9a6dfa66da304d861a232e642d05' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingCodecsResponseProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingCodecsResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingCodecsResponseProto' start='2475' end='3160' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' sourcefile='ErasureCodingProtos.java'><Message>At ErasureCodingProtos.java:[lines 2475-3160]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingCodecsResponseProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingCodecsResponseProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingCodecsResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' sourcefile='ErasureCodingProtos.java'><Message>In ErasureCodingProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingCodecsResponseProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingCodecsResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' sourcefile='ErasureCodingProtos.java'><Message>In ErasureCodingProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='22882641eb48b5c4c4e8f84c58447640' cweid='563' rank='20' abbrev='DLS' category='STYLE' priority='3' type='DLS_DEAD_LOCAL_STORE' instanceOccurrenceMax='0'><ShortMessage>Dead store to local variable</ShortMessage><LongMessage>Dead store to from_bitField0_ in org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingCodecsResponseProto$Builder.buildPartial()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingCodecsResponseProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingCodecsResponseProto$Builder' start='2762' end='3151' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' sourcefile='ErasureCodingProtos.java'><Message>At ErasureCodingProtos.java:[lines 2762-3151]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingCodecsResponseProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingCodecsResponseProto$Builder' signature='()Lorg/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos$GetErasureCodingCodecsResponseProto;' name='buildPartial' primary='true'><SourceLine endBytecode='44' classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingCodecsResponseProto$Builder' start='2829' end='2841' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' sourcefile='ErasureCodingProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingCodecsResponseProto$Builder.buildPartial()</Message></Method><LocalVariable role='LOCAL_VARIABLE_NAMED' pc='15' name='from_bitField0_' register='2'><Message>Local variable named from_bitField0_</Message></LocalVariable><SourceLine endBytecode='14' classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingCodecsResponseProto$Builder' start='2830' end='2830' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' sourcefile='ErasureCodingProtos.java' startBytecode='14' primary='true'><Message>At ErasureCodingProtos.java:[line 2830]</Message></SourceLine><Property name='edu.umd.cs.findbugs.detect.DeadLocalStoreProperty.BASE_VALUE' value='true'></Property><Property name='edu.umd.cs.findbugs.detect.DeadLocalStoreProperty.CACHING_VALUE' value='true'></Property><Property name='edu.umd.cs.findbugs.detect.DeadLocalStoreProperty.LOCAL_NAME' value='from_bitField0_'></Property><Property name='edu.umd.cs.findbugs.detect.DeadLocalStoreProperty.NO_LOADS' value='true'></Property></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='5283a488dacc17709ec59c2fd1fbb217' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingPoliciesRequestProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingPoliciesRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingPoliciesRequestProto' start='1041' end='1372' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' sourcefile='ErasureCodingProtos.java'><Message>At ErasureCodingProtos.java:[lines 1041-1372]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingPoliciesRequestProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingPoliciesRequestProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingPoliciesRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' sourcefile='ErasureCodingProtos.java'><Message>In ErasureCodingProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingPoliciesRequestProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingPoliciesRequestProto' start='1112' end='1112' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' sourcefile='ErasureCodingProtos.java' startBytecode='7' primary='true'><Message>At ErasureCodingProtos.java:[line 1112]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='307a772ee335deb190043fa12a623cba' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingPoliciesRequestProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingPoliciesRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingPoliciesRequestProto' start='1041' end='1372' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' sourcefile='ErasureCodingProtos.java'><Message>At ErasureCodingProtos.java:[lines 1041-1372]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingPoliciesRequestProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingPoliciesRequestProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingPoliciesRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' sourcefile='ErasureCodingProtos.java'><Message>In ErasureCodingProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingPoliciesRequestProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingPoliciesRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' sourcefile='ErasureCodingProtos.java'><Message>In ErasureCodingProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='3de595d227a3966ebc3ba5710e8f9626' rank='17' abbrev='UCF' category='STYLE' priority='2' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingPoliciesRequestProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingPoliciesRequestProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingPoliciesRequestProto$Builder' start='1264' end='1363' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' sourcefile='ErasureCodingProtos.java'><Message>At ErasureCodingProtos.java:[lines 1264-1363]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingPoliciesRequestProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingPoliciesRequestProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine endBytecode='61' classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingPoliciesRequestProto$Builder' start='1290' end='1292' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' sourcefile='ErasureCodingProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingPoliciesRequestProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingPoliciesRequestProto$Builder' start='1290' end='1290' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' sourcefile='ErasureCodingProtos.java' startBytecode='3' primary='true'><Message>At ErasureCodingProtos.java:[line 1290]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='34b7f1fc0bdb171575a799b9d4233d8b' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingPoliciesResponseProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingPoliciesResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingPoliciesResponseProto' start='1408' end='2093' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' sourcefile='ErasureCodingProtos.java'><Message>At ErasureCodingProtos.java:[lines 1408-2093]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingPoliciesResponseProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingPoliciesResponseProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingPoliciesResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' sourcefile='ErasureCodingProtos.java'><Message>In ErasureCodingProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingPoliciesResponseProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingPoliciesResponseProto' start='1491' end='1491' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' sourcefile='ErasureCodingProtos.java' startBytecode='7' primary='true'><Message>At ErasureCodingProtos.java:[line 1491]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='552271190092c7adcb6325264df7e7a9' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingPoliciesResponseProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingPoliciesResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingPoliciesResponseProto' start='1408' end='2093' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' sourcefile='ErasureCodingProtos.java'><Message>At ErasureCodingProtos.java:[lines 1408-2093]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingPoliciesResponseProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingPoliciesResponseProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingPoliciesResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' sourcefile='ErasureCodingProtos.java'><Message>In ErasureCodingProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingPoliciesResponseProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingPoliciesResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' sourcefile='ErasureCodingProtos.java'><Message>In ErasureCodingProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='c66ea0bf4c596d159b0be21298d75cb4' cweid='563' rank='20' abbrev='DLS' category='STYLE' priority='3' type='DLS_DEAD_LOCAL_STORE' instanceOccurrenceMax='0'><ShortMessage>Dead store to local variable</ShortMessage><LongMessage>Dead store to from_bitField0_ in org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingPoliciesResponseProto$Builder.buildPartial()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingPoliciesResponseProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingPoliciesResponseProto$Builder' start='1695' end='2084' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' sourcefile='ErasureCodingProtos.java'><Message>At ErasureCodingProtos.java:[lines 1695-2084]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingPoliciesResponseProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingPoliciesResponseProto$Builder' signature='()Lorg/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos$GetErasureCodingPoliciesResponseProto;' name='buildPartial' primary='true'><SourceLine endBytecode='44' classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingPoliciesResponseProto$Builder' start='1762' end='1774' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' sourcefile='ErasureCodingProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingPoliciesResponseProto$Builder.buildPartial()</Message></Method><LocalVariable role='LOCAL_VARIABLE_NAMED' pc='15' name='from_bitField0_' register='2'><Message>Local variable named from_bitField0_</Message></LocalVariable><SourceLine endBytecode='14' classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingPoliciesResponseProto$Builder' start='1763' end='1763' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' sourcefile='ErasureCodingProtos.java' startBytecode='14' primary='true'><Message>At ErasureCodingProtos.java:[line 1763]</Message></SourceLine><Property name='edu.umd.cs.findbugs.detect.DeadLocalStoreProperty.BASE_VALUE' value='true'></Property><Property name='edu.umd.cs.findbugs.detect.DeadLocalStoreProperty.CACHING_VALUE' value='true'></Property><Property name='edu.umd.cs.findbugs.detect.DeadLocalStoreProperty.LOCAL_NAME' value='from_bitField0_'></Property><Property name='edu.umd.cs.findbugs.detect.DeadLocalStoreProperty.NO_LOADS' value='true'></Property></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='4320f86743f5fa1c6171d77a5090d26a' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingPolicyRequestProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingPolicyRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingPolicyRequestProto' start='3198' end='3725' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' sourcefile='ErasureCodingProtos.java'><Message>At ErasureCodingProtos.java:[lines 3198-3725]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingPolicyRequestProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingPolicyRequestProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingPolicyRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' sourcefile='ErasureCodingProtos.java'><Message>In ErasureCodingProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingPolicyRequestProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingPolicyRequestProto' start='3275' end='3275' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' sourcefile='ErasureCodingProtos.java' startBytecode='7' primary='true'><Message>At ErasureCodingProtos.java:[line 3275]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='6e7a571ff41b9a27a278afd30a8f4a86' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingPolicyRequestProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingPolicyRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingPolicyRequestProto' start='3198' end='3725' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' sourcefile='ErasureCodingProtos.java'><Message>At ErasureCodingProtos.java:[lines 3198-3725]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingPolicyRequestProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingPolicyRequestProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingPolicyRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' sourcefile='ErasureCodingProtos.java'><Message>In ErasureCodingProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingPolicyRequestProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingPolicyRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' sourcefile='ErasureCodingProtos.java'><Message>In ErasureCodingProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='aa662c8bb2e1708933242e0ec02bf423' rank='17' abbrev='UCF' category='STYLE' priority='2' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingPolicyRequestProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingPolicyRequestProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingPolicyRequestProto$Builder' start='3500' end='3716' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' sourcefile='ErasureCodingProtos.java'><Message>At ErasureCodingProtos.java:[lines 3500-3716]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingPolicyRequestProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingPolicyRequestProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine endBytecode='61' classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingPolicyRequestProto$Builder' start='3526' end='3528' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' sourcefile='ErasureCodingProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingPolicyRequestProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingPolicyRequestProto$Builder' start='3526' end='3526' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' sourcefile='ErasureCodingProtos.java' startBytecode='3' primary='true'><Message>At ErasureCodingProtos.java:[line 3526]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='47170b1a1126c1ac66fa54f586b3afef' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingPolicyResponseProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingPolicyResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingPolicyResponseProto' start='3750' end='4282' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' sourcefile='ErasureCodingProtos.java'><Message>At ErasureCodingProtos.java:[lines 3750-4282]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingPolicyResponseProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingPolicyResponseProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingPolicyResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' sourcefile='ErasureCodingProtos.java'><Message>In ErasureCodingProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingPolicyResponseProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingPolicyResponseProto' start='3835' end='3835' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' sourcefile='ErasureCodingProtos.java' startBytecode='7' primary='true'><Message>At ErasureCodingProtos.java:[line 3835]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='24935737197409cc2e627c8b8e33a0de' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingPolicyResponseProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingPolicyResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingPolicyResponseProto' start='3750' end='4282' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' sourcefile='ErasureCodingProtos.java'><Message>At ErasureCodingProtos.java:[lines 3750-4282]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingPolicyResponseProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingPolicyResponseProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingPolicyResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' sourcefile='ErasureCodingProtos.java'><Message>In ErasureCodingProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingPolicyResponseProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingPolicyResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' sourcefile='ErasureCodingProtos.java'><Message>In ErasureCodingProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='172eeb55c6acf7769d4ccc4062f142dd' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$RemoveErasureCodingPolicyRequestProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$RemoveErasureCodingPolicyRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$RemoveErasureCodingPolicyRequestProto' start='5750' end='6241' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' sourcefile='ErasureCodingProtos.java'><Message>At ErasureCodingProtos.java:[lines 5750-6241]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$RemoveErasureCodingPolicyRequestProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$RemoveErasureCodingPolicyRequestProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$RemoveErasureCodingPolicyRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' sourcefile='ErasureCodingProtos.java'><Message>In ErasureCodingProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$RemoveErasureCodingPolicyRequestProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$RemoveErasureCodingPolicyRequestProto' start='5827' end='5827' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' sourcefile='ErasureCodingProtos.java' startBytecode='7' primary='true'><Message>At ErasureCodingProtos.java:[line 5827]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='9cec9139a4d00d519aa2493a4fe80e54' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$RemoveErasureCodingPolicyRequestProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$RemoveErasureCodingPolicyRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$RemoveErasureCodingPolicyRequestProto' start='5750' end='6241' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' sourcefile='ErasureCodingProtos.java'><Message>At ErasureCodingProtos.java:[lines 5750-6241]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$RemoveErasureCodingPolicyRequestProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$RemoveErasureCodingPolicyRequestProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$RemoveErasureCodingPolicyRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' sourcefile='ErasureCodingProtos.java'><Message>In ErasureCodingProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$RemoveErasureCodingPolicyRequestProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$RemoveErasureCodingPolicyRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' sourcefile='ErasureCodingProtos.java'><Message>In ErasureCodingProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='4fc0c6901d91e3ae5e2894d6370fbd07' rank='17' abbrev='UCF' category='STYLE' priority='2' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$RemoveErasureCodingPolicyRequestProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$RemoveErasureCodingPolicyRequestProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$RemoveErasureCodingPolicyRequestProto$Builder' start='6040' end='6232' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' sourcefile='ErasureCodingProtos.java'><Message>At ErasureCodingProtos.java:[lines 6040-6232]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$RemoveErasureCodingPolicyRequestProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$RemoveErasureCodingPolicyRequestProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine endBytecode='61' classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$RemoveErasureCodingPolicyRequestProto$Builder' start='6066' end='6068' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' sourcefile='ErasureCodingProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$RemoveErasureCodingPolicyRequestProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$RemoveErasureCodingPolicyRequestProto$Builder' start='6066' end='6066' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' sourcefile='ErasureCodingProtos.java' startBytecode='3' primary='true'><Message>At ErasureCodingProtos.java:[line 6066]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='36b93b9a389985799bf116c0d1941dd9' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$RemoveErasureCodingPolicyResponseProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$RemoveErasureCodingPolicyResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$RemoveErasureCodingPolicyResponseProto' start='6252' end='6579' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' sourcefile='ErasureCodingProtos.java'><Message>At ErasureCodingProtos.java:[lines 6252-6579]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$RemoveErasureCodingPolicyResponseProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$RemoveErasureCodingPolicyResponseProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$RemoveErasureCodingPolicyResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' sourcefile='ErasureCodingProtos.java'><Message>In ErasureCodingProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$RemoveErasureCodingPolicyResponseProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$RemoveErasureCodingPolicyResponseProto' start='6323' end='6323' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' sourcefile='ErasureCodingProtos.java' startBytecode='7' primary='true'><Message>At ErasureCodingProtos.java:[line 6323]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='785a25eb0bc7c488688c88e0af806438' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$RemoveErasureCodingPolicyResponseProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$RemoveErasureCodingPolicyResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$RemoveErasureCodingPolicyResponseProto' start='6252' end='6579' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' sourcefile='ErasureCodingProtos.java'><Message>At ErasureCodingProtos.java:[lines 6252-6579]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$RemoveErasureCodingPolicyResponseProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$RemoveErasureCodingPolicyResponseProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$RemoveErasureCodingPolicyResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' sourcefile='ErasureCodingProtos.java'><Message>In ErasureCodingProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$RemoveErasureCodingPolicyResponseProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$RemoveErasureCodingPolicyResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' sourcefile='ErasureCodingProtos.java'><Message>In ErasureCodingProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='6ed02bcf7dce2f03b3513c5f68b9a381' rank='17' abbrev='UCF' category='STYLE' priority='2' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$RemoveErasureCodingPolicyResponseProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$RemoveErasureCodingPolicyResponseProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$RemoveErasureCodingPolicyResponseProto$Builder' start='6471' end='6570' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' sourcefile='ErasureCodingProtos.java'><Message>At ErasureCodingProtos.java:[lines 6471-6570]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$RemoveErasureCodingPolicyResponseProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$RemoveErasureCodingPolicyResponseProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine endBytecode='61' classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$RemoveErasureCodingPolicyResponseProto$Builder' start='6497' end='6499' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' sourcefile='ErasureCodingProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$RemoveErasureCodingPolicyResponseProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$RemoveErasureCodingPolicyResponseProto$Builder' start='6497' end='6497' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' sourcefile='ErasureCodingProtos.java' startBytecode='3' primary='true'><Message>At ErasureCodingProtos.java:[line 6497]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='6e1cb97233c721295aa48bc363ae2927' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$SetErasureCodingPolicyRequestProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$SetErasureCodingPolicyRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$SetErasureCodingPolicyRequestProto' start='47' end='688' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' sourcefile='ErasureCodingProtos.java'><Message>At ErasureCodingProtos.java:[lines 47-688]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$SetErasureCodingPolicyRequestProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$SetErasureCodingPolicyRequestProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$SetErasureCodingPolicyRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' sourcefile='ErasureCodingProtos.java'><Message>In ErasureCodingProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$SetErasureCodingPolicyRequestProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$SetErasureCodingPolicyRequestProto' start='129' end='129' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' sourcefile='ErasureCodingProtos.java' startBytecode='7' primary='true'><Message>At ErasureCodingProtos.java:[line 129]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='df8cdbe2d7e747ae5bb1d4ca3418c39c' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$SetErasureCodingPolicyRequestProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$SetErasureCodingPolicyRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$SetErasureCodingPolicyRequestProto' start='47' end='688' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' sourcefile='ErasureCodingProtos.java'><Message>At ErasureCodingProtos.java:[lines 47-688]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$SetErasureCodingPolicyRequestProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$SetErasureCodingPolicyRequestProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$SetErasureCodingPolicyRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' sourcefile='ErasureCodingProtos.java'><Message>In ErasureCodingProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$SetErasureCodingPolicyRequestProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$SetErasureCodingPolicyRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' sourcefile='ErasureCodingProtos.java'><Message>In ErasureCodingProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='66213eba61bf83636e90ab13d521db49' rank='17' abbrev='UCF' category='STYLE' priority='2' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$SetErasureCodingPolicyRequestProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$SetErasureCodingPolicyRequestProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$SetErasureCodingPolicyRequestProto$Builder' start='402' end='679' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' sourcefile='ErasureCodingProtos.java'><Message>At ErasureCodingProtos.java:[lines 402-679]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$SetErasureCodingPolicyRequestProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$SetErasureCodingPolicyRequestProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine endBytecode='61' classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$SetErasureCodingPolicyRequestProto$Builder' start='428' end='430' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' sourcefile='ErasureCodingProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$SetErasureCodingPolicyRequestProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$SetErasureCodingPolicyRequestProto$Builder' start='428' end='428' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' sourcefile='ErasureCodingProtos.java' startBytecode='3' primary='true'><Message>At ErasureCodingProtos.java:[line 428]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='87e99dfe137e8d6e7f72580d49ed4290' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$SetErasureCodingPolicyResponseProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$SetErasureCodingPolicyResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$SetErasureCodingPolicyResponseProto' start='699' end='1026' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' sourcefile='ErasureCodingProtos.java'><Message>At ErasureCodingProtos.java:[lines 699-1026]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$SetErasureCodingPolicyResponseProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$SetErasureCodingPolicyResponseProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$SetErasureCodingPolicyResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' sourcefile='ErasureCodingProtos.java'><Message>In ErasureCodingProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$SetErasureCodingPolicyResponseProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$SetErasureCodingPolicyResponseProto' start='770' end='770' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' sourcefile='ErasureCodingProtos.java' startBytecode='7' primary='true'><Message>At ErasureCodingProtos.java:[line 770]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='86234f995edab3838f7562f5d1032adf' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$SetErasureCodingPolicyResponseProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$SetErasureCodingPolicyResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$SetErasureCodingPolicyResponseProto' start='699' end='1026' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' sourcefile='ErasureCodingProtos.java'><Message>At ErasureCodingProtos.java:[lines 699-1026]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$SetErasureCodingPolicyResponseProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$SetErasureCodingPolicyResponseProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$SetErasureCodingPolicyResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' sourcefile='ErasureCodingProtos.java'><Message>In ErasureCodingProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$SetErasureCodingPolicyResponseProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$SetErasureCodingPolicyResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' sourcefile='ErasureCodingProtos.java'><Message>In ErasureCodingProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='cb31978a937a70d626316dfa4876c0bb' rank='17' abbrev='UCF' category='STYLE' priority='2' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$SetErasureCodingPolicyResponseProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$SetErasureCodingPolicyResponseProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$SetErasureCodingPolicyResponseProto$Builder' start='918' end='1017' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' sourcefile='ErasureCodingProtos.java'><Message>At ErasureCodingProtos.java:[lines 918-1017]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$SetErasureCodingPolicyResponseProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$SetErasureCodingPolicyResponseProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine endBytecode='61' classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$SetErasureCodingPolicyResponseProto$Builder' start='944' end='946' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' sourcefile='ErasureCodingProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$SetErasureCodingPolicyResponseProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$SetErasureCodingPolicyResponseProto$Builder' start='944' end='944' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' sourcefile='ErasureCodingProtos.java' startBytecode='3' primary='true'><Message>At ErasureCodingProtos.java:[line 944]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='87a6e8b88ab284d320569803f3ce5b5b' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$UnsetErasureCodingPolicyRequestProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$UnsetErasureCodingPolicyRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$UnsetErasureCodingPolicyRequestProto' start='8315' end='8806' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' sourcefile='ErasureCodingProtos.java'><Message>At ErasureCodingProtos.java:[lines 8315-8806]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$UnsetErasureCodingPolicyRequestProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$UnsetErasureCodingPolicyRequestProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$UnsetErasureCodingPolicyRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' sourcefile='ErasureCodingProtos.java'><Message>In ErasureCodingProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$UnsetErasureCodingPolicyRequestProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$UnsetErasureCodingPolicyRequestProto' start='8392' end='8392' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' sourcefile='ErasureCodingProtos.java' startBytecode='7' primary='true'><Message>At ErasureCodingProtos.java:[line 8392]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='3ded41225eaa0d4fe03a61ff459cd096' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$UnsetErasureCodingPolicyRequestProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$UnsetErasureCodingPolicyRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$UnsetErasureCodingPolicyRequestProto' start='8315' end='8806' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' sourcefile='ErasureCodingProtos.java'><Message>At ErasureCodingProtos.java:[lines 8315-8806]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$UnsetErasureCodingPolicyRequestProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$UnsetErasureCodingPolicyRequestProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$UnsetErasureCodingPolicyRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' sourcefile='ErasureCodingProtos.java'><Message>In ErasureCodingProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$UnsetErasureCodingPolicyRequestProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$UnsetErasureCodingPolicyRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' sourcefile='ErasureCodingProtos.java'><Message>In ErasureCodingProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='3dec451d35b635f64080289418024f4f' rank='17' abbrev='UCF' category='STYLE' priority='2' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$UnsetErasureCodingPolicyRequestProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$UnsetErasureCodingPolicyRequestProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$UnsetErasureCodingPolicyRequestProto$Builder' start='8605' end='8797' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' sourcefile='ErasureCodingProtos.java'><Message>At ErasureCodingProtos.java:[lines 8605-8797]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$UnsetErasureCodingPolicyRequestProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$UnsetErasureCodingPolicyRequestProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine endBytecode='61' classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$UnsetErasureCodingPolicyRequestProto$Builder' start='8631' end='8633' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' sourcefile='ErasureCodingProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$UnsetErasureCodingPolicyRequestProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$UnsetErasureCodingPolicyRequestProto$Builder' start='8631' end='8631' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' sourcefile='ErasureCodingProtos.java' startBytecode='3' primary='true'><Message>At ErasureCodingProtos.java:[line 8631]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='fdd3c6825e1e0e17b0cd8cc95ef3b6bf' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$UnsetErasureCodingPolicyResponseProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$UnsetErasureCodingPolicyResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$UnsetErasureCodingPolicyResponseProto' start='8817' end='9144' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' sourcefile='ErasureCodingProtos.java'><Message>At ErasureCodingProtos.java:[lines 8817-9144]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$UnsetErasureCodingPolicyResponseProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$UnsetErasureCodingPolicyResponseProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$UnsetErasureCodingPolicyResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' sourcefile='ErasureCodingProtos.java'><Message>In ErasureCodingProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$UnsetErasureCodingPolicyResponseProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$UnsetErasureCodingPolicyResponseProto' start='8888' end='8888' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' sourcefile='ErasureCodingProtos.java' startBytecode='7' primary='true'><Message>At ErasureCodingProtos.java:[line 8888]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='b4efc5113549aade459c34b8b5758b79' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$UnsetErasureCodingPolicyResponseProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$UnsetErasureCodingPolicyResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$UnsetErasureCodingPolicyResponseProto' start='8817' end='9144' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' sourcefile='ErasureCodingProtos.java'><Message>At ErasureCodingProtos.java:[lines 8817-9144]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$UnsetErasureCodingPolicyResponseProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$UnsetErasureCodingPolicyResponseProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$UnsetErasureCodingPolicyResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' sourcefile='ErasureCodingProtos.java'><Message>In ErasureCodingProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$UnsetErasureCodingPolicyResponseProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$UnsetErasureCodingPolicyResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' sourcefile='ErasureCodingProtos.java'><Message>In ErasureCodingProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='d6d0ebab3acd0e46e085a493186ffee4' rank='17' abbrev='UCF' category='STYLE' priority='2' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$UnsetErasureCodingPolicyResponseProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$UnsetErasureCodingPolicyResponseProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$UnsetErasureCodingPolicyResponseProto$Builder' start='9036' end='9135' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' sourcefile='ErasureCodingProtos.java'><Message>At ErasureCodingProtos.java:[lines 9036-9135]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$UnsetErasureCodingPolicyResponseProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$UnsetErasureCodingPolicyResponseProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine endBytecode='61' classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$UnsetErasureCodingPolicyResponseProto$Builder' start='9062' end='9064' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' sourcefile='ErasureCodingProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$UnsetErasureCodingPolicyResponseProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$UnsetErasureCodingPolicyResponseProto$Builder' start='9062' end='9062' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' sourcefile='ErasureCodingProtos.java' startBytecode='3' primary='true'><Message>At ErasureCodingProtos.java:[line 9062]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='edeaa078ceca641d31bd3df773391163' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$AddErasureCodingPolicyResponseProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$AddErasureCodingPolicyResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$AddErasureCodingPolicyResponseProto' start='31031' end='31805' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>At HdfsProtos.java:[lines 31031-31805]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$AddErasureCodingPolicyResponseProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$AddErasureCodingPolicyResponseProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$AddErasureCodingPolicyResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>In HdfsProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$AddErasureCodingPolicyResponseProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$AddErasureCodingPolicyResponseProto' start='31126' end='31126' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java' startBytecode='7' primary='true'><Message>At HdfsProtos.java:[line 31126]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='1016fbd726a63dfc45c4e0f0527f94d9' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$AddErasureCodingPolicyResponseProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$AddErasureCodingPolicyResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$AddErasureCodingPolicyResponseProto' start='31031' end='31805' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>At HdfsProtos.java:[lines 31031-31805]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$AddErasureCodingPolicyResponseProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$AddErasureCodingPolicyResponseProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$AddErasureCodingPolicyResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>In HdfsProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$AddErasureCodingPolicyResponseProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$AddErasureCodingPolicyResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>In HdfsProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='69e19005a58f9bd9ca6eea3d46cf52a8' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$BlockChecksumOptionsProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$BlockChecksumOptionsProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$BlockChecksumOptionsProto' start='35845' end='36397' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>At HdfsProtos.java:[lines 35845-36397]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$BlockChecksumOptionsProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$BlockChecksumOptionsProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$BlockChecksumOptionsProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>In HdfsProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$BlockChecksumOptionsProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$BlockChecksumOptionsProto' start='35933' end='35933' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java' startBytecode='7' primary='true'><Message>At HdfsProtos.java:[line 35933]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='482cfdeb84696133d0d3be3252230d79' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$BlockChecksumOptionsProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$BlockChecksumOptionsProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$BlockChecksumOptionsProto' start='35845' end='36397' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>At HdfsProtos.java:[lines 35845-36397]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$BlockChecksumOptionsProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$BlockChecksumOptionsProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$BlockChecksumOptionsProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>In HdfsProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$BlockChecksumOptionsProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$BlockChecksumOptionsProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>In HdfsProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='f85f79fd58e7dae0a873c9ded2d078d7' rank='17' abbrev='UCF' category='STYLE' priority='2' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$BlockChecksumOptionsProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$BlockChecksumOptionsProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$BlockChecksumOptionsProto$Builder' start='36170' end='36388' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>At HdfsProtos.java:[lines 36170-36388]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$BlockChecksumOptionsProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$BlockChecksumOptionsProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine endBytecode='61' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$BlockChecksumOptionsProto$Builder' start='36196' end='36198' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$BlockChecksumOptionsProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$BlockChecksumOptionsProto$Builder' start='36196' end='36196' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java' startBytecode='3' primary='true'><Message>At HdfsProtos.java:[line 36196]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='468445460cc0ff848a839cd6b98d8537' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$BlockProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$BlockProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$BlockProto' start='45642' end='46242' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>At HdfsProtos.java:[lines 45642-46242]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$BlockProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$BlockProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$BlockProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>In HdfsProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$BlockProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$BlockProto' start='45729' end='45729' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java' startBytecode='7' primary='true'><Message>At HdfsProtos.java:[line 45729]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='8cb541c2e555c91547af405d37d6bd75' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$BlockProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$BlockProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$BlockProto' start='45642' end='46242' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>At HdfsProtos.java:[lines 45642-46242]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$BlockProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$BlockProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$BlockProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>In HdfsProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$BlockProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$BlockProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>In HdfsProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='dbd3aa368c1072e16134d4b435be91f' rank='17' abbrev='UCF' category='STYLE' priority='2' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$BlockProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$BlockProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$BlockProto$Builder' start='45996' end='46233' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>At HdfsProtos.java:[lines 45996-46233]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$BlockProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$BlockProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine endBytecode='61' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$BlockProto$Builder' start='46022' end='46024' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$BlockProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$BlockProto$Builder' start='46022' end='46022' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java' startBytecode='3' primary='true'><Message>At HdfsProtos.java:[line 46022]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='b7049219cf6fc7682dce4f970dbe029d' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$BlockStoragePolicyProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$BlockStoragePolicyProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$BlockStoragePolicyProto' start='16509' end='17770' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>At HdfsProtos.java:[lines 16509-17770]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$BlockStoragePolicyProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$BlockStoragePolicyProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$BlockStoragePolicyProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>In HdfsProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$BlockStoragePolicyProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$BlockStoragePolicyProto' start='16630' end='16630' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java' startBytecode='7' primary='true'><Message>At HdfsProtos.java:[line 16630]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='914eb18f26a398bec4c60f666ef6d18a' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$BlockStoragePolicyProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$BlockStoragePolicyProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$BlockStoragePolicyProto' start='16509' end='17770' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>At HdfsProtos.java:[lines 16509-17770]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$BlockStoragePolicyProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$BlockStoragePolicyProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$BlockStoragePolicyProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>In HdfsProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$BlockStoragePolicyProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$BlockStoragePolicyProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>In HdfsProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='c04958461c7cfede9c5797d371df4bb0' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$BlockTokenSecretProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$BlockTokenSecretProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$BlockTokenSecretProto' start='49022' end='50414' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>At HdfsProtos.java:[lines 49022-50414]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$BlockTokenSecretProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$BlockTokenSecretProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$BlockTokenSecretProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>In HdfsProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$BlockTokenSecretProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$BlockTokenSecretProto' start='49202' end='49202' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java' startBytecode='7' primary='true'><Message>At HdfsProtos.java:[line 49202]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='da666ecf5d9fe34e03c1b46df4b98e64' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$BlockTokenSecretProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$BlockTokenSecretProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$BlockTokenSecretProto' start='49022' end='50414' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>At HdfsProtos.java:[lines 49022-50414]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$BlockTokenSecretProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$BlockTokenSecretProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$BlockTokenSecretProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>In HdfsProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$BlockTokenSecretProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$BlockTokenSecretProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>In HdfsProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='8f89884ba7a9f0af9528fd321dd45f3c' rank='17' abbrev='UCF' category='STYLE' priority='2' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$BlockTokenSecretProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$BlockTokenSecretProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$BlockTokenSecretProto$Builder' start='49717' end='50405' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>At HdfsProtos.java:[lines 49717-50405]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$BlockTokenSecretProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$BlockTokenSecretProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine endBytecode='61' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$BlockTokenSecretProto$Builder' start='49743' end='49745' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$BlockTokenSecretProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$BlockTokenSecretProto$Builder' start='49743' end='49743' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java' startBytecode='3' primary='true'><Message>At HdfsProtos.java:[line 49743]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='6e4c44adf0234d88a648534cceea841f' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$CipherOptionProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$CipherOptionProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$CipherOptionProto' start='25643' end='26410' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>At HdfsProtos.java:[lines 25643-26410]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$CipherOptionProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$CipherOptionProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$CipherOptionProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>In HdfsProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$CipherOptionProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$CipherOptionProto' start='25746' end='25746' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java' startBytecode='7' primary='true'><Message>At HdfsProtos.java:[line 25746]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='9c4f6853b48638c54038d198532b6fd0' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$CipherOptionProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$CipherOptionProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$CipherOptionProto' start='25643' end='26410' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>At HdfsProtos.java:[lines 25643-26410]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$CipherOptionProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$CipherOptionProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$CipherOptionProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>In HdfsProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$CipherOptionProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$CipherOptionProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>In HdfsProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='f2fe9d79fcadd015744697a0fcb37814' rank='19' abbrev='Se' category='BAD_PRACTICE' priority='3' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$CipherOptionProto defines non-transient non-serializable instance field inIv_</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$CipherOptionProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$CipherOptionProto' start='25643' end='26410' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>At HdfsProtos.java:[lines 25643-26410]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$CipherOptionProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$CipherOptionProto' signature='Lcom/google/protobuf/ByteString;' name='inIv_' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$CipherOptionProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>In HdfsProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$CipherOptionProto.inIv_</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/ByteString;'><SourceLine classname='com.google.protobuf.ByteString' start='60' end='967' sourcepath='com/google/protobuf/ByteString.java' sourcefile='ByteString.java'><Message>At ByteString.java:[lines 60-967]</Message></SourceLine><Message>Actual type com.google.protobuf.ByteString</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$CipherOptionProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>In HdfsProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='92090013cadf06fd90f857e5b4f3040b' rank='19' abbrev='Se' category='BAD_PRACTICE' priority='3' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$CipherOptionProto defines non-transient non-serializable instance field inKey_</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$CipherOptionProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$CipherOptionProto' start='25643' end='26410' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>At HdfsProtos.java:[lines 25643-26410]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$CipherOptionProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$CipherOptionProto' signature='Lcom/google/protobuf/ByteString;' name='inKey_' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$CipherOptionProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>In HdfsProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$CipherOptionProto.inKey_</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/ByteString;'><SourceLine classname='com.google.protobuf.ByteString' start='60' end='967' sourcepath='com/google/protobuf/ByteString.java' sourcefile='ByteString.java'><Message>At ByteString.java:[lines 60-967]</Message></SourceLine><Message>Actual type com.google.protobuf.ByteString</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$CipherOptionProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>In HdfsProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='b3337195ba6dc1fad2633632967396f8' rank='19' abbrev='Se' category='BAD_PRACTICE' priority='3' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$CipherOptionProto defines non-transient non-serializable instance field outIv_</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$CipherOptionProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$CipherOptionProto' start='25643' end='26410' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>At HdfsProtos.java:[lines 25643-26410]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$CipherOptionProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$CipherOptionProto' signature='Lcom/google/protobuf/ByteString;' name='outIv_' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$CipherOptionProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>In HdfsProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$CipherOptionProto.outIv_</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/ByteString;'><SourceLine classname='com.google.protobuf.ByteString' start='60' end='967' sourcepath='com/google/protobuf/ByteString.java' sourcefile='ByteString.java'><Message>At ByteString.java:[lines 60-967]</Message></SourceLine><Message>Actual type com.google.protobuf.ByteString</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$CipherOptionProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>In HdfsProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='bdd5578083006fd8e98fcc3ad92de53d' rank='19' abbrev='Se' category='BAD_PRACTICE' priority='3' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$CipherOptionProto defines non-transient non-serializable instance field outKey_</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$CipherOptionProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$CipherOptionProto' start='25643' end='26410' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>At HdfsProtos.java:[lines 25643-26410]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$CipherOptionProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$CipherOptionProto' signature='Lcom/google/protobuf/ByteString;' name='outKey_' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$CipherOptionProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>In HdfsProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$CipherOptionProto.outKey_</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/ByteString;'><SourceLine classname='com.google.protobuf.ByteString' start='60' end='967' sourcepath='com/google/protobuf/ByteString.java' sourcefile='ByteString.java'><Message>At ByteString.java:[lines 60-967]</Message></SourceLine><Message>Actual type com.google.protobuf.ByteString</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$CipherOptionProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>In HdfsProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='5e3b8b13c484609804a0506bcca627ba' rank='17' abbrev='UCF' category='STYLE' priority='2' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$CipherOptionProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$CipherOptionProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$CipherOptionProto$Builder' start='26069' end='26401' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>At HdfsProtos.java:[lines 26069-26401]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$CipherOptionProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$CipherOptionProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine endBytecode='61' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$CipherOptionProto$Builder' start='26095' end='26097' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$CipherOptionProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$CipherOptionProto$Builder' start='26095' end='26095' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java' startBytecode='3' primary='true'><Message>At HdfsProtos.java:[line 26095]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='2785b2b1aec945c0fd140e4e3647ef69' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ContentSummaryProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ContentSummaryProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ContentSummaryProto' start='11276' end='12811' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>At HdfsProtos.java:[lines 11276-12811]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ContentSummaryProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ContentSummaryProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ContentSummaryProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>In HdfsProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ContentSummaryProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ContentSummaryProto' start='11416' end='11416' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java' startBytecode='7' primary='true'><Message>At HdfsProtos.java:[line 11416]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='8c076928120073bc9b4f842e4e28c52e' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ContentSummaryProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ContentSummaryProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ContentSummaryProto' start='11276' end='12811' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>At HdfsProtos.java:[lines 11276-12811]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ContentSummaryProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ContentSummaryProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ContentSummaryProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>In HdfsProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ContentSummaryProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ContentSummaryProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>In HdfsProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='ad77c8a1b384946a78a564c8c67d7d1b' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$CorruptFileBlocksProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$CorruptFileBlocksProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$CorruptFileBlocksProto' start='15200' end='15868' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>At HdfsProtos.java:[lines 15200-15868]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$CorruptFileBlocksProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$CorruptFileBlocksProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$CorruptFileBlocksProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>In HdfsProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$CorruptFileBlocksProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$CorruptFileBlocksProto' start='15288' end='15288' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java' startBytecode='7' primary='true'><Message>At HdfsProtos.java:[line 15288]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='4a1d02da8acbad4356e6214f7babcae5' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$CorruptFileBlocksProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$CorruptFileBlocksProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$CorruptFileBlocksProto' start='15200' end='15868' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>At HdfsProtos.java:[lines 15200-15868]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$CorruptFileBlocksProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$CorruptFileBlocksProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$CorruptFileBlocksProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>In HdfsProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$CorruptFileBlocksProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$CorruptFileBlocksProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>In HdfsProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='ca41e663f9268e1e2d62211ee5ed9414' rank='17' abbrev='UCF' category='STYLE' priority='2' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$CorruptFileBlocksProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$CorruptFileBlocksProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$CorruptFileBlocksProto$Builder' start='15556' end='15859' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>At HdfsProtos.java:[lines 15556-15859]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$CorruptFileBlocksProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$CorruptFileBlocksProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine endBytecode='61' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$CorruptFileBlocksProto$Builder' start='15582' end='15584' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$CorruptFileBlocksProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$CorruptFileBlocksProto$Builder' start='15582' end='15582' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java' startBytecode='3' primary='true'><Message>At HdfsProtos.java:[line 15582]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='78bb6aa9495abfa1df97e26442806d49' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DataEncryptionKeyProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DataEncryptionKeyProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DataEncryptionKeyProto' start='20601' end='21600' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>At HdfsProtos.java:[lines 20601-21600]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DataEncryptionKeyProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DataEncryptionKeyProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DataEncryptionKeyProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>In HdfsProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DataEncryptionKeyProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DataEncryptionKeyProto' start='20703' end='20703' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java' startBytecode='7' primary='true'><Message>At HdfsProtos.java:[line 20703]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='5251396eb4a3d21d0f65c125a235a062' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DataEncryptionKeyProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DataEncryptionKeyProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DataEncryptionKeyProto' start='20601' end='21600' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>At HdfsProtos.java:[lines 20601-21600]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DataEncryptionKeyProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DataEncryptionKeyProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DataEncryptionKeyProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>In HdfsProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DataEncryptionKeyProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DataEncryptionKeyProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>In HdfsProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='1350492c31710919b8aedd315862960b' rank='19' abbrev='Se' category='BAD_PRACTICE' priority='3' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DataEncryptionKeyProto defines non-transient non-serializable instance field encryptionKey_</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DataEncryptionKeyProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DataEncryptionKeyProto' start='20601' end='21600' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>At HdfsProtos.java:[lines 20601-21600]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DataEncryptionKeyProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DataEncryptionKeyProto' signature='Lcom/google/protobuf/ByteString;' name='encryptionKey_' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DataEncryptionKeyProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>In HdfsProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DataEncryptionKeyProto.encryptionKey_</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/ByteString;'><SourceLine classname='com.google.protobuf.ByteString' start='60' end='967' sourcepath='com/google/protobuf/ByteString.java' sourcefile='ByteString.java'><Message>At ByteString.java:[lines 60-967]</Message></SourceLine><Message>Actual type com.google.protobuf.ByteString</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DataEncryptionKeyProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>In HdfsProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='fbb5477705df33b0ff8a79cb4fc7780b' rank='19' abbrev='Se' category='BAD_PRACTICE' priority='3' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DataEncryptionKeyProto defines non-transient non-serializable instance field nonce_</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DataEncryptionKeyProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DataEncryptionKeyProto' start='20601' end='21600' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>At HdfsProtos.java:[lines 20601-21600]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DataEncryptionKeyProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DataEncryptionKeyProto' signature='Lcom/google/protobuf/ByteString;' name='nonce_' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DataEncryptionKeyProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>In HdfsProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DataEncryptionKeyProto.nonce_</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/ByteString;'><SourceLine classname='com.google.protobuf.ByteString' start='60' end='967' sourcepath='com/google/protobuf/ByteString.java' sourcefile='ByteString.java'><Message>At ByteString.java:[lines 60-967]</Message></SourceLine><Message>Actual type com.google.protobuf.ByteString</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DataEncryptionKeyProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>In HdfsProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='97348d7bec717866df99b60df5713f26' rank='17' abbrev='UCF' category='STYLE' priority='2' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DataEncryptionKeyProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DataEncryptionKeyProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DataEncryptionKeyProto$Builder' start='21124' end='21591' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>At HdfsProtos.java:[lines 21124-21591]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DataEncryptionKeyProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DataEncryptionKeyProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine endBytecode='61' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DataEncryptionKeyProto$Builder' start='21150' end='21152' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DataEncryptionKeyProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DataEncryptionKeyProto$Builder' start='21150' end='21150' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java' startBytecode='3' primary='true'><Message>At HdfsProtos.java:[line 21150]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='5a061e54e8c9615f7d2c5add647c353b' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeIDProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeIDProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeIDProto' start='2690' end='4062' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>At HdfsProtos.java:[lines 2690-4062]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeIDProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeIDProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeIDProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>In HdfsProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeIDProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeIDProto' start='2797' end='2797' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java' startBytecode='7' primary='true'><Message>At HdfsProtos.java:[line 2797]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='5f68987d952b75449e68bb2d4facccff' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeIDProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeIDProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeIDProto' start='2690' end='4062' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>At HdfsProtos.java:[lines 2690-4062]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeIDProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeIDProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeIDProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>In HdfsProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeIDProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeIDProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>In HdfsProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='c8cc9eff1a30cb977bf162334e8ac3d9' rank='17' abbrev='UCF' category='STYLE' priority='2' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeIDProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeIDProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeIDProto$Builder' start='3359' end='4053' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>At HdfsProtos.java:[lines 3359-4053]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeIDProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeIDProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine endBytecode='61' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeIDProto$Builder' start='3385' end='3387' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeIDProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeIDProto$Builder' start='3385' end='3385' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java' startBytecode='3' primary='true'><Message>At HdfsProtos.java:[line 3385]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='119e7477ba8752a04b355b3b7de9054c' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeInfoProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeInfoProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeInfoProto' start='6915' end='8994' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>At HdfsProtos.java:[lines 6915-8994]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeInfoProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeInfoProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeInfoProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>In HdfsProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeInfoProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeInfoProto' start='7086' end='7086' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java' startBytecode='7' primary='true'><Message>At HdfsProtos.java:[line 7086]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='c90c1241548854f5373fedb24d30bce1' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeInfoProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeInfoProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeInfoProto' start='6915' end='8994' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>At HdfsProtos.java:[lines 6915-8994]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeInfoProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeInfoProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeInfoProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>In HdfsProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeInfoProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeInfoProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>In HdfsProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='8e77a2858b12eacaa209a412e9261400' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeInfosProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeInfosProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeInfosProto' start='6025' end='6715' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>At HdfsProtos.java:[lines 6025-6715]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeInfosProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeInfosProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeInfosProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>In HdfsProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeInfosProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeInfosProto' start='6108' end='6108' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java' startBytecode='7' primary='true'><Message>At HdfsProtos.java:[line 6108]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='af229146e9a5896836047913334dc326' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeInfosProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeInfosProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeInfosProto' start='6025' end='6715' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>At HdfsProtos.java:[lines 6025-6715]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeInfosProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeInfosProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeInfosProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>In HdfsProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeInfosProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeInfosProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>In HdfsProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='a8af446c9c1b1cbff7bcc4db88973fc' cweid='563' rank='20' abbrev='DLS' category='STYLE' priority='3' type='DLS_DEAD_LOCAL_STORE' instanceOccurrenceMax='0'><ShortMessage>Dead store to local variable</ShortMessage><LongMessage>Dead store to from_bitField0_ in org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeInfosProto$Builder.buildPartial()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeInfosProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeInfosProto$Builder' start='6317' end='6706' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>At HdfsProtos.java:[lines 6317-6706]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeInfosProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeInfosProto$Builder' signature='()Lorg/apache/hadoop/hdfs/protocol/proto/HdfsProtos$DatanodeInfosProto;' name='buildPartial' primary='true'><SourceLine endBytecode='44' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeInfosProto$Builder' start='6384' end='6396' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeInfosProto$Builder.buildPartial()</Message></Method><LocalVariable role='LOCAL_VARIABLE_NAMED' pc='15' name='from_bitField0_' register='2'><Message>Local variable named from_bitField0_</Message></LocalVariable><SourceLine endBytecode='14' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeInfosProto$Builder' start='6385' end='6385' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java' startBytecode='14' primary='true'><Message>At HdfsProtos.java:[line 6385]</Message></SourceLine><Property name='edu.umd.cs.findbugs.detect.DeadLocalStoreProperty.BASE_VALUE' value='true'></Property><Property name='edu.umd.cs.findbugs.detect.DeadLocalStoreProperty.CACHING_VALUE' value='true'></Property><Property name='edu.umd.cs.findbugs.detect.DeadLocalStoreProperty.LOCAL_NAME' value='from_bitField0_'></Property><Property name='edu.umd.cs.findbugs.detect.DeadLocalStoreProperty.NO_LOADS' value='true'></Property></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='af4c457998f1dd71df67743809bda049' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeLocalInfoProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeLocalInfoProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeLocalInfoProto' start='4118' end='4860' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>At HdfsProtos.java:[lines 4118-4860]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeLocalInfoProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeLocalInfoProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeLocalInfoProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>In HdfsProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeLocalInfoProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeLocalInfoProto' start='4205' end='4205' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java' startBytecode='7' primary='true'><Message>At HdfsProtos.java:[line 4205]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='224b0e78c98d892e1c219fa13b13dbe7' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeLocalInfoProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeLocalInfoProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeLocalInfoProto' start='4118' end='4860' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>At HdfsProtos.java:[lines 4118-4860]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeLocalInfoProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeLocalInfoProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeLocalInfoProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>In HdfsProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeLocalInfoProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeLocalInfoProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>In HdfsProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='5c1c8619df7236d1c54fc8c8ebf8661c' rank='17' abbrev='UCF' category='STYLE' priority='2' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeLocalInfoProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeLocalInfoProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeLocalInfoProto$Builder' start='4524' end='4851' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>At HdfsProtos.java:[lines 4524-4851]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeLocalInfoProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeLocalInfoProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine endBytecode='61' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeLocalInfoProto$Builder' start='4550' end='4552' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeLocalInfoProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeLocalInfoProto$Builder' start='4550' end='4550' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java' startBytecode='3' primary='true'><Message>At HdfsProtos.java:[line 4550]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='66052b34f1009004c2305de942eeabd5' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeStorageProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeStorageProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeStorageProto' start='9045' end='9801' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>At HdfsProtos.java:[lines 9045-9801]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeStorageProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeStorageProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeStorageProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>In HdfsProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeStorageProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeStorageProto' start='9144' end='9144' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java' startBytecode='7' primary='true'><Message>At HdfsProtos.java:[line 9144]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='11f977c4a56da43877bc16a465377afe' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeStorageProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeStorageProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeStorageProto' start='9045' end='9801' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>At HdfsProtos.java:[lines 9045-9801]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeStorageProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeStorageProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeStorageProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>In HdfsProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeStorageProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeStorageProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>In HdfsProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='bca8660e5d6122c5fa08498237a24cfc' rank='17' abbrev='UCF' category='STYLE' priority='2' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeStorageProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeStorageProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeStorageProto$Builder' start='9510' end='9792' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>At HdfsProtos.java:[lines 9510-9792]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeStorageProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeStorageProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine endBytecode='61' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeStorageProto$Builder' start='9536' end='9538' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeStorageProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeStorageProto$Builder' start='9536' end='9536' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java' startBytecode='3' primary='true'><Message>At HdfsProtos.java:[line 9536]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='613b4c8ade05adb04c62060ed93e9c59' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeVolumeInfoProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeVolumeInfoProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeVolumeInfoProto' start='4951' end='5984' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>At HdfsProtos.java:[lines 4951-5984]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeVolumeInfoProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeVolumeInfoProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeVolumeInfoProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>In HdfsProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeVolumeInfoProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeVolumeInfoProto' start='5064' end='5064' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java' startBytecode='7' primary='true'><Message>At HdfsProtos.java:[line 5064]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='5fe7e82338ce608aa91563b272606c22' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeVolumeInfoProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeVolumeInfoProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeVolumeInfoProto' start='4951' end='5984' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>At HdfsProtos.java:[lines 4951-5984]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeVolumeInfoProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeVolumeInfoProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeVolumeInfoProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>In HdfsProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeVolumeInfoProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeVolumeInfoProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>In HdfsProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='f7abd666b45652b3efe06f2a2188bd9b' rank='17' abbrev='UCF' category='STYLE' priority='2' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeVolumeInfoProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeVolumeInfoProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeVolumeInfoProto$Builder' start='5504' end='5975' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>At HdfsProtos.java:[lines 5504-5975]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeVolumeInfoProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeVolumeInfoProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine endBytecode='61' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeVolumeInfoProto$Builder' start='5530' end='5532' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeVolumeInfoProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeVolumeInfoProto$Builder' start='5530' end='5530' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java' startBytecode='3' primary='true'><Message>At HdfsProtos.java:[line 5530]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='4a38d7dc4dcc2c8ddb04196020805f5e' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DirectoryListingProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DirectoryListingProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DirectoryListingProto' start='37858' end='38639' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>At HdfsProtos.java:[lines 37858-38639]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DirectoryListingProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DirectoryListingProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DirectoryListingProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>In HdfsProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DirectoryListingProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DirectoryListingProto' start='37946' end='37946' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java' startBytecode='7' primary='true'><Message>At HdfsProtos.java:[line 37946]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='92f5daa40c34cd68819058bde42135ac' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DirectoryListingProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DirectoryListingProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DirectoryListingProto' start='37858' end='38639' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>At HdfsProtos.java:[lines 37858-38639]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DirectoryListingProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DirectoryListingProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DirectoryListingProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>In HdfsProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DirectoryListingProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DirectoryListingProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>In HdfsProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='73e29577ad77f9e023c3b107d2bc4ecc' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ECSchemaOptionEntryProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ECSchemaOptionEntryProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ECSchemaOptionEntryProto' start='28183' end='28837' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>At HdfsProtos.java:[lines 28183-28837]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ECSchemaOptionEntryProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ECSchemaOptionEntryProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ECSchemaOptionEntryProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>In HdfsProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ECSchemaOptionEntryProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ECSchemaOptionEntryProto' start='28265' end='28265' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java' startBytecode='7' primary='true'><Message>At HdfsProtos.java:[line 28265]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='a5f6bab15abf68c8242b329b4820438c' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ECSchemaOptionEntryProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ECSchemaOptionEntryProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ECSchemaOptionEntryProto' start='28183' end='28837' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>At HdfsProtos.java:[lines 28183-28837]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ECSchemaOptionEntryProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ECSchemaOptionEntryProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ECSchemaOptionEntryProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>In HdfsProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ECSchemaOptionEntryProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ECSchemaOptionEntryProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>In HdfsProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='7ac597e1835d9ee8f07a8589b520cd69' rank='17' abbrev='UCF' category='STYLE' priority='2' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ECSchemaOptionEntryProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ECSchemaOptionEntryProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ECSchemaOptionEntryProto$Builder' start='28547' end='28828' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>At HdfsProtos.java:[lines 28547-28828]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ECSchemaOptionEntryProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ECSchemaOptionEntryProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine endBytecode='61' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ECSchemaOptionEntryProto$Builder' start='28573' end='28575' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ECSchemaOptionEntryProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ECSchemaOptionEntryProto$Builder' start='28573' end='28573' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java' startBytecode='3' primary='true'><Message>At HdfsProtos.java:[line 28573]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='4345053e638da6805c224643e002a38b' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ECSchemaProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ECSchemaProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ECSchemaProto' start='28913' end='29940' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>At HdfsProtos.java:[lines 28913-29940]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ECSchemaProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ECSchemaProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ECSchemaProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>In HdfsProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ECSchemaProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ECSchemaProto' start='29011' end='29011' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java' startBytecode='7' primary='true'><Message>At HdfsProtos.java:[line 29011]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='a8f57bcfca229f4a44b0b2b923dfb882' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ECSchemaProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ECSchemaProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ECSchemaProto' start='28913' end='29940' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>At HdfsProtos.java:[lines 28913-29940]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ECSchemaProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ECSchemaProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ECSchemaProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>In HdfsProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ECSchemaProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ECSchemaProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>In HdfsProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='14014693ffbf49c2b7c55964a9aff113' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ErasureCodingPolicyProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ErasureCodingPolicyProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ErasureCodingPolicyProto' start='30018' end='30981' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>At HdfsProtos.java:[lines 30018-30981]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ErasureCodingPolicyProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ErasureCodingPolicyProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ErasureCodingPolicyProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>In HdfsProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ErasureCodingPolicyProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ErasureCodingPolicyProto' start='30129' end='30129' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java' startBytecode='7' primary='true'><Message>At HdfsProtos.java:[line 30129]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='d710cd874c5291dbbb122530b69b77a0' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ErasureCodingPolicyProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ErasureCodingPolicyProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ErasureCodingPolicyProto' start='30018' end='30981' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>At HdfsProtos.java:[lines 30018-30981]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ErasureCodingPolicyProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ErasureCodingPolicyProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ErasureCodingPolicyProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>In HdfsProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ErasureCodingPolicyProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ErasureCodingPolicyProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>In HdfsProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='504b57ec1f051056e5e6ac6d3eb1a9d2' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ExtendedBlockProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ExtendedBlockProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ExtendedBlockProto' start='867' end='1703' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>At HdfsProtos.java:[lines 867-1703]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ExtendedBlockProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ExtendedBlockProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ExtendedBlockProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>In HdfsProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ExtendedBlockProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ExtendedBlockProto' start='959' end='959' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java' startBytecode='7' primary='true'><Message>At HdfsProtos.java:[line 959]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='af03237ca302c5595da90a1113cef460' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ExtendedBlockProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ExtendedBlockProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ExtendedBlockProto' start='867' end='1703' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>At HdfsProtos.java:[lines 867-1703]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ExtendedBlockProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ExtendedBlockProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ExtendedBlockProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>In HdfsProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ExtendedBlockProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ExtendedBlockProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>In HdfsProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='2f54e11136800acbdd876951fb5e03eb' rank='17' abbrev='UCF' category='STYLE' priority='2' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ExtendedBlockProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ExtendedBlockProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ExtendedBlockProto$Builder' start='1312' end='1694' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>At HdfsProtos.java:[lines 1312-1694]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ExtendedBlockProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ExtendedBlockProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine endBytecode='61' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ExtendedBlockProto$Builder' start='1338' end='1340' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ExtendedBlockProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ExtendedBlockProto$Builder' start='1338' end='1338' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java' startBytecode='3' primary='true'><Message>At HdfsProtos.java:[line 1338]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='7bd29e7b8e7eccd47ac47fe79ba9ccdf' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$FileEncryptionInfoProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$FileEncryptionInfoProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$FileEncryptionInfoProto' start='21686' end='22716' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>At HdfsProtos.java:[lines 21686-22716]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$FileEncryptionInfoProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$FileEncryptionInfoProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$FileEncryptionInfoProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>In HdfsProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$FileEncryptionInfoProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$FileEncryptionInfoProto' start='21800' end='21800' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java' startBytecode='7' primary='true'><Message>At HdfsProtos.java:[line 21800]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='c1ace781c068f54caae85ae031bfbf86' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$FileEncryptionInfoProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$FileEncryptionInfoProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$FileEncryptionInfoProto' start='21686' end='22716' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>At HdfsProtos.java:[lines 21686-22716]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$FileEncryptionInfoProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$FileEncryptionInfoProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$FileEncryptionInfoProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>In HdfsProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$FileEncryptionInfoProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$FileEncryptionInfoProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>In HdfsProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='242b911f25b3f28fe9e70865fd26c224' rank='19' abbrev='Se' category='BAD_PRACTICE' priority='3' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$FileEncryptionInfoProto defines non-transient non-serializable instance field iv_</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$FileEncryptionInfoProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$FileEncryptionInfoProto' start='21686' end='22716' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>At HdfsProtos.java:[lines 21686-22716]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$FileEncryptionInfoProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$FileEncryptionInfoProto' signature='Lcom/google/protobuf/ByteString;' name='iv_' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$FileEncryptionInfoProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>In HdfsProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$FileEncryptionInfoProto.iv_</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/ByteString;'><SourceLine classname='com.google.protobuf.ByteString' start='60' end='967' sourcepath='com/google/protobuf/ByteString.java' sourcefile='ByteString.java'><Message>At ByteString.java:[lines 60-967]</Message></SourceLine><Message>Actual type com.google.protobuf.ByteString</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$FileEncryptionInfoProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>In HdfsProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='e0c7a6a2840d100e3f685ad41afdb899' rank='19' abbrev='Se' category='BAD_PRACTICE' priority='3' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$FileEncryptionInfoProto defines non-transient non-serializable instance field key_</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$FileEncryptionInfoProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$FileEncryptionInfoProto' start='21686' end='22716' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>At HdfsProtos.java:[lines 21686-22716]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$FileEncryptionInfoProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$FileEncryptionInfoProto' signature='Lcom/google/protobuf/ByteString;' name='key_' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$FileEncryptionInfoProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>In HdfsProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$FileEncryptionInfoProto.key_</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/ByteString;'><SourceLine classname='com.google.protobuf.ByteString' start='60' end='967' sourcepath='com/google/protobuf/ByteString.java' sourcefile='ByteString.java'><Message>At ByteString.java:[lines 60-967]</Message></SourceLine><Message>Actual type com.google.protobuf.ByteString</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$FileEncryptionInfoProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>In HdfsProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='15026c8859a628e298ac1c96d9924306' rank='17' abbrev='UCF' category='STYLE' priority='2' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$FileEncryptionInfoProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$FileEncryptionInfoProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$FileEncryptionInfoProto$Builder' start='22230' end='22707' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>At HdfsProtos.java:[lines 22230-22707]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$FileEncryptionInfoProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$FileEncryptionInfoProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine endBytecode='61' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$FileEncryptionInfoProto$Builder' start='22256' end='22258' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$FileEncryptionInfoProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$FileEncryptionInfoProto$Builder' start='22256' end='22256' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java' startBytecode='3' primary='true'><Message>At HdfsProtos.java:[line 22256]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='385d790db85c7d0eeef398eb49164e59' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$FsServerDefaultsProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$FsServerDefaultsProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$FsServerDefaultsProto' start='36526' end='37807' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>At HdfsProtos.java:[lines 36526-37807]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$FsServerDefaultsProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$FsServerDefaultsProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$FsServerDefaultsProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>In HdfsProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$FsServerDefaultsProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$FsServerDefaultsProto' start='36654' end='36654' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java' startBytecode='7' primary='true'><Message>At HdfsProtos.java:[line 36654]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='96e65ec2562c1b11a1e346e1e193fca2' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$FsServerDefaultsProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$FsServerDefaultsProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$FsServerDefaultsProto' start='36526' end='37807' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>At HdfsProtos.java:[lines 36526-37807]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$FsServerDefaultsProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$FsServerDefaultsProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$FsServerDefaultsProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>In HdfsProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$FsServerDefaultsProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$FsServerDefaultsProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>In HdfsProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='9844d8f780742fc88e27d5e204104ffc' rank='17' abbrev='UCF' category='STYLE' priority='2' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$FsServerDefaultsProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$FsServerDefaultsProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$FsServerDefaultsProto$Builder' start='37193' end='37798' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>At HdfsProtos.java:[lines 37193-37798]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$FsServerDefaultsProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$FsServerDefaultsProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine endBytecode='61' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$FsServerDefaultsProto$Builder' start='37219' end='37221' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$FsServerDefaultsProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$FsServerDefaultsProto$Builder' start='37219' end='37219' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java' startBytecode='3' primary='true'><Message>At HdfsProtos.java:[line 37219]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='4d166dbdaf6aae4f678709e9eb50ebfc' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$HdfsFileStatusProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$HdfsFileStatusProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$HdfsFileStatusProto' start='32811' end='35792' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>At HdfsProtos.java:[lines 32811-35792]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$HdfsFileStatusProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$HdfsFileStatusProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$HdfsFileStatusProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>In HdfsProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$HdfsFileStatusProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$HdfsFileStatusProto' start='33011' end='33011' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java' startBytecode='7' primary='true'><Message>At HdfsProtos.java:[line 33011]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='5e74c01e0a3a5519f8517fd50b4cc2b' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$HdfsFileStatusProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$HdfsFileStatusProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$HdfsFileStatusProto' start='32811' end='35792' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>At HdfsProtos.java:[lines 32811-35792]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$HdfsFileStatusProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$HdfsFileStatusProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$HdfsFileStatusProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>In HdfsProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$HdfsFileStatusProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$HdfsFileStatusProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>In HdfsProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='8b2fbc2362176e1d1b2a13e7055d35df' rank='19' abbrev='Se' category='BAD_PRACTICE' priority='3' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$HdfsFileStatusProto defines non-transient non-serializable instance field path_</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$HdfsFileStatusProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$HdfsFileStatusProto' start='32811' end='35792' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>At HdfsProtos.java:[lines 32811-35792]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$HdfsFileStatusProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$HdfsFileStatusProto' signature='Lcom/google/protobuf/ByteString;' name='path_' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$HdfsFileStatusProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>In HdfsProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$HdfsFileStatusProto.path_</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/ByteString;'><SourceLine classname='com.google.protobuf.ByteString' start='60' end='967' sourcepath='com/google/protobuf/ByteString.java' sourcefile='ByteString.java'><Message>At ByteString.java:[lines 60-967]</Message></SourceLine><Message>Actual type com.google.protobuf.ByteString</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$HdfsFileStatusProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>In HdfsProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='7dc164b2616c42a94db451ea469afeb9' rank='19' abbrev='Se' category='BAD_PRACTICE' priority='3' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$HdfsFileStatusProto defines non-transient non-serializable instance field symlink_</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$HdfsFileStatusProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$HdfsFileStatusProto' start='32811' end='35792' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>At HdfsProtos.java:[lines 32811-35792]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$HdfsFileStatusProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$HdfsFileStatusProto' signature='Lcom/google/protobuf/ByteString;' name='symlink_' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$HdfsFileStatusProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>In HdfsProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$HdfsFileStatusProto.symlink_</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/ByteString;'><SourceLine classname='com.google.protobuf.ByteString' start='60' end='967' sourcepath='com/google/protobuf/ByteString.java' sourcefile='ByteString.java'><Message>At ByteString.java:[lines 60-967]</Message></SourceLine><Message>Actual type com.google.protobuf.ByteString</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$HdfsFileStatusProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>In HdfsProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='a5974f3d6e4efe8b6a2184b79426883d' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$HdfsPathHandleProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$HdfsPathHandleProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$HdfsPathHandleProto' start='31856' end='32504' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>At HdfsProtos.java:[lines 31856-32504]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$HdfsPathHandleProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$HdfsPathHandleProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$HdfsPathHandleProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>In HdfsProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$HdfsPathHandleProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$HdfsPathHandleProto' start='31943' end='31943' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java' startBytecode='7' primary='true'><Message>At HdfsProtos.java:[line 31943]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='ef66354f7b2ec5ed2c2652dc4efd4563' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$HdfsPathHandleProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$HdfsPathHandleProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$HdfsPathHandleProto' start='31856' end='32504' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>At HdfsProtos.java:[lines 31856-32504]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$HdfsPathHandleProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$HdfsPathHandleProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$HdfsPathHandleProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>In HdfsProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$HdfsPathHandleProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$HdfsPathHandleProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>In HdfsProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='8f69e2e896a95b6ab8cb2ea58c25f23a' rank='17' abbrev='UCF' category='STYLE' priority='2' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$HdfsPathHandleProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$HdfsPathHandleProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$HdfsPathHandleProto$Builder' start='32223' end='32495' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>At HdfsProtos.java:[lines 32223-32495]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$HdfsPathHandleProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$HdfsPathHandleProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine endBytecode='61' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$HdfsPathHandleProto$Builder' start='32249' end='32251' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$HdfsPathHandleProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$HdfsPathHandleProto$Builder' start='32249' end='32249' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java' startBytecode='3' primary='true'><Message>At HdfsProtos.java:[line 32249]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='2bf0b52422e197b29dae3d9e574d5584' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$LocatedBlockProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$LocatedBlockProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$LocatedBlockProto' start='18018' end='20520' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>At HdfsProtos.java:[lines 18018-20520]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$LocatedBlockProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$LocatedBlockProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$LocatedBlockProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>In HdfsProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$LocatedBlockProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$LocatedBlockProto' start='18224' end='18224' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java' startBytecode='7' primary='true'><Message>At HdfsProtos.java:[line 18224]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='b470eaebf13db3ee9dc9a5abe763639b' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$LocatedBlockProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$LocatedBlockProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$LocatedBlockProto' start='18018' end='20520' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>At HdfsProtos.java:[lines 18018-20520]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$LocatedBlockProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$LocatedBlockProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$LocatedBlockProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>In HdfsProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$LocatedBlockProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$LocatedBlockProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>In HdfsProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='ef6508d5d1398ea23e521a61a2155cf2' rank='19' abbrev='Se' category='BAD_PRACTICE' priority='3' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$LocatedBlockProto defines non-transient non-serializable instance field blockIndices_</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$LocatedBlockProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$LocatedBlockProto' start='18018' end='20520' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>At HdfsProtos.java:[lines 18018-20520]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$LocatedBlockProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$LocatedBlockProto' signature='Lcom/google/protobuf/ByteString;' name='blockIndices_' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$LocatedBlockProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>In HdfsProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$LocatedBlockProto.blockIndices_</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/ByteString;'><SourceLine classname='com.google.protobuf.ByteString' start='60' end='967' sourcepath='com/google/protobuf/ByteString.java' sourcefile='ByteString.java'><Message>At ByteString.java:[lines 60-967]</Message></SourceLine><Message>Actual type com.google.protobuf.ByteString</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$LocatedBlockProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>In HdfsProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='ed60e976f208a0481ac7d7eca816499e' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$LocatedBlocksProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$LocatedBlocksProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$LocatedBlocksProto' start='26535' end='28137' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>At HdfsProtos.java:[lines 26535-28137]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$LocatedBlocksProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$LocatedBlocksProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$LocatedBlocksProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>In HdfsProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$LocatedBlocksProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$LocatedBlocksProto' start='26672' end='26672' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java' startBytecode='7' primary='true'><Message>At HdfsProtos.java:[line 26672]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='78e4313fa4cf1fb474c77a00e2688785' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$LocatedBlocksProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$LocatedBlocksProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$LocatedBlocksProto' start='26535' end='28137' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>At HdfsProtos.java:[lines 26535-28137]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$LocatedBlocksProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$LocatedBlocksProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$LocatedBlocksProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>In HdfsProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$LocatedBlocksProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$LocatedBlocksProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>In HdfsProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='843c36a0de95e3e67303db6573367526' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$PerFileEncryptionInfoProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$PerFileEncryptionInfoProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$PerFileEncryptionInfoProto' start='22768' end='23447' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>At HdfsProtos.java:[lines 22768-23447]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$PerFileEncryptionInfoProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$PerFileEncryptionInfoProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$PerFileEncryptionInfoProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>In HdfsProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$PerFileEncryptionInfoProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$PerFileEncryptionInfoProto' start='22855' end='22855' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java' startBytecode='7' primary='true'><Message>At HdfsProtos.java:[line 22855]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='4268b39595905e021cc3c5475e67b1f0' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$PerFileEncryptionInfoProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$PerFileEncryptionInfoProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$PerFileEncryptionInfoProto' start='22768' end='23447' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>At HdfsProtos.java:[lines 22768-23447]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$PerFileEncryptionInfoProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$PerFileEncryptionInfoProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$PerFileEncryptionInfoProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>In HdfsProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$PerFileEncryptionInfoProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$PerFileEncryptionInfoProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>In HdfsProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='51095066f82a968de151f1314aae3f81' rank='19' abbrev='Se' category='BAD_PRACTICE' priority='3' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$PerFileEncryptionInfoProto defines non-transient non-serializable instance field iv_</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$PerFileEncryptionInfoProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$PerFileEncryptionInfoProto' start='22768' end='23447' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>At HdfsProtos.java:[lines 22768-23447]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$PerFileEncryptionInfoProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$PerFileEncryptionInfoProto' signature='Lcom/google/protobuf/ByteString;' name='iv_' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$PerFileEncryptionInfoProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>In HdfsProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$PerFileEncryptionInfoProto.iv_</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/ByteString;'><SourceLine classname='com.google.protobuf.ByteString' start='60' end='967' sourcepath='com/google/protobuf/ByteString.java' sourcefile='ByteString.java'><Message>At ByteString.java:[lines 60-967]</Message></SourceLine><Message>Actual type com.google.protobuf.ByteString</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$PerFileEncryptionInfoProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>In HdfsProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='e96cc1c24820a7f7dd0727268b4abd40' rank='19' abbrev='Se' category='BAD_PRACTICE' priority='3' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$PerFileEncryptionInfoProto defines non-transient non-serializable instance field key_</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$PerFileEncryptionInfoProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$PerFileEncryptionInfoProto' start='22768' end='23447' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>At HdfsProtos.java:[lines 22768-23447]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$PerFileEncryptionInfoProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$PerFileEncryptionInfoProto' signature='Lcom/google/protobuf/ByteString;' name='key_' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$PerFileEncryptionInfoProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>In HdfsProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$PerFileEncryptionInfoProto.key_</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/ByteString;'><SourceLine classname='com.google.protobuf.ByteString' start='60' end='967' sourcepath='com/google/protobuf/ByteString.java' sourcefile='ByteString.java'><Message>At ByteString.java:[lines 60-967]</Message></SourceLine><Message>Actual type com.google.protobuf.ByteString</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$PerFileEncryptionInfoProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>In HdfsProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='485a9738133925db1d3d7ace9da30098' rank='17' abbrev='UCF' category='STYLE' priority='2' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$PerFileEncryptionInfoProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$PerFileEncryptionInfoProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$PerFileEncryptionInfoProto$Builder' start='23148' end='23438' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>At HdfsProtos.java:[lines 23148-23438]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$PerFileEncryptionInfoProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$PerFileEncryptionInfoProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine endBytecode='61' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$PerFileEncryptionInfoProto$Builder' start='23174' end='23176' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$PerFileEncryptionInfoProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$PerFileEncryptionInfoProto$Builder' start='23174' end='23174' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java' startBytecode='3' primary='true'><Message>At HdfsProtos.java:[line 23174]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='113da8f87d4109708a2c578f9612ef7e' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ProvidedStorageLocationProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ProvidedStorageLocationProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ProvidedStorageLocationProto' start='1759' end='2517' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>At HdfsProtos.java:[lines 1759-2517]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ProvidedStorageLocationProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ProvidedStorageLocationProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ProvidedStorageLocationProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>In HdfsProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ProvidedStorageLocationProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ProvidedStorageLocationProto' start='1851' end='1851' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java' startBytecode='7' primary='true'><Message>At HdfsProtos.java:[line 1851]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='806aef15434961d0fbc82337e78b69ba' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ProvidedStorageLocationProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ProvidedStorageLocationProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ProvidedStorageLocationProto' start='1759' end='2517' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>At HdfsProtos.java:[lines 1759-2517]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ProvidedStorageLocationProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ProvidedStorageLocationProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ProvidedStorageLocationProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>In HdfsProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ProvidedStorageLocationProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ProvidedStorageLocationProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>In HdfsProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='1fa83487130a6367a3fd35da0533633f' rank='19' abbrev='Se' category='BAD_PRACTICE' priority='3' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ProvidedStorageLocationProto defines non-transient non-serializable instance field nonce_</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ProvidedStorageLocationProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ProvidedStorageLocationProto' start='1759' end='2517' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>At HdfsProtos.java:[lines 1759-2517]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ProvidedStorageLocationProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ProvidedStorageLocationProto' signature='Lcom/google/protobuf/ByteString;' name='nonce_' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ProvidedStorageLocationProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>In HdfsProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ProvidedStorageLocationProto.nonce_</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/ByteString;'><SourceLine classname='com.google.protobuf.ByteString' start='60' end='967' sourcepath='com/google/protobuf/ByteString.java' sourcefile='ByteString.java'><Message>At ByteString.java:[lines 60-967]</Message></SourceLine><Message>Actual type com.google.protobuf.ByteString</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ProvidedStorageLocationProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>In HdfsProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='e6704b04840498ca952c86b79517a237' rank='17' abbrev='UCF' category='STYLE' priority='2' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ProvidedStorageLocationProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ProvidedStorageLocationProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ProvidedStorageLocationProto$Builder' start='2175' end='2508' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>At HdfsProtos.java:[lines 2175-2508]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ProvidedStorageLocationProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ProvidedStorageLocationProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine endBytecode='61' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ProvidedStorageLocationProto$Builder' start='2201' end='2203' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ProvidedStorageLocationProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ProvidedStorageLocationProto$Builder' start='2201' end='2201' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java' startBytecode='3' primary='true'><Message>At HdfsProtos.java:[line 2201]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='cc8aec97de3c3a47d606437611edde1c' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$QuotaUsageProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$QuotaUsageProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$QuotaUsageProto' start='12881' end='13770' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>At HdfsProtos.java:[lines 12881-13770]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$QuotaUsageProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$QuotaUsageProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$QuotaUsageProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>In HdfsProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$QuotaUsageProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$QuotaUsageProto' start='12986' end='12986' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java' startBytecode='7' primary='true'><Message>At HdfsProtos.java:[line 12986]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='a5cb0f20798adeeab1df75ee9e8a4f52' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$QuotaUsageProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$QuotaUsageProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$QuotaUsageProto' start='12881' end='13770' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>At HdfsProtos.java:[lines 12881-13770]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$QuotaUsageProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$QuotaUsageProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$QuotaUsageProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>In HdfsProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$QuotaUsageProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$QuotaUsageProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>In HdfsProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='4f1fc950e9ba64fa2b093649a5c9305a' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ReencryptionInfoProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ReencryptionInfoProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ReencryptionInfoProto' start='24499' end='25577' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>At HdfsProtos.java:[lines 24499-25577]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ReencryptionInfoProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ReencryptionInfoProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ReencryptionInfoProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>In HdfsProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ReencryptionInfoProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ReencryptionInfoProto' start='24606' end='24606' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java' startBytecode='7' primary='true'><Message>At HdfsProtos.java:[line 24606]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='6f7e60a5137d84891828215653817042' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ReencryptionInfoProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ReencryptionInfoProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ReencryptionInfoProto' start='24499' end='25577' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>At HdfsProtos.java:[lines 24499-25577]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ReencryptionInfoProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ReencryptionInfoProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ReencryptionInfoProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>In HdfsProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ReencryptionInfoProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ReencryptionInfoProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>In HdfsProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='1f94c072c9b5f997850f35c3307cb24a' rank='17' abbrev='UCF' category='STYLE' priority='2' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ReencryptionInfoProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ReencryptionInfoProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ReencryptionInfoProto$Builder' start='25065' end='25568' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>At HdfsProtos.java:[lines 25065-25568]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ReencryptionInfoProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ReencryptionInfoProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine endBytecode='61' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ReencryptionInfoProto$Builder' start='25091' end='25093' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ReencryptionInfoProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ReencryptionInfoProto$Builder' start='25091' end='25091' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java' startBytecode='3' primary='true'><Message>At HdfsProtos.java:[line 25091]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='d76be6c77b2a381e2c9b503901a97995' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$RollingUpgradeStatusProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$RollingUpgradeStatusProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$RollingUpgradeStatusProto' start='47769' end='48345' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>At HdfsProtos.java:[lines 47769-48345]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$RollingUpgradeStatusProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$RollingUpgradeStatusProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$RollingUpgradeStatusProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>In HdfsProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$RollingUpgradeStatusProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$RollingUpgradeStatusProto' start='47851' end='47851' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java' startBytecode='7' primary='true'><Message>At HdfsProtos.java:[line 47851]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='de83df4ad7a6a495012983c608d1330d' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$RollingUpgradeStatusProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$RollingUpgradeStatusProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$RollingUpgradeStatusProto' start='47769' end='48345' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>At HdfsProtos.java:[lines 47769-48345]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$RollingUpgradeStatusProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$RollingUpgradeStatusProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$RollingUpgradeStatusProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>In HdfsProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$RollingUpgradeStatusProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$RollingUpgradeStatusProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>In HdfsProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='b8aafed0cc0f9ed7a05fb5d851c07ddd' rank='17' abbrev='UCF' category='STYLE' priority='2' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$RollingUpgradeStatusProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$RollingUpgradeStatusProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$RollingUpgradeStatusProto$Builder' start='48102' end='48336' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>At HdfsProtos.java:[lines 48102-48336]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$RollingUpgradeStatusProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$RollingUpgradeStatusProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine endBytecode='61' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$RollingUpgradeStatusProto$Builder' start='48128' end='48130' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$RollingUpgradeStatusProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$RollingUpgradeStatusProto$Builder' start='48128' end='48128' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java' startBytecode='3' primary='true'><Message>At HdfsProtos.java:[line 48128]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='b4173d3efe094db62228a95adc98940a' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportCursorProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportCursorProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportCursorProto' start='43161' end='43673' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>At HdfsProtos.java:[lines 43161-43673]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportCursorProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportCursorProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportCursorProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>In HdfsProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportCursorProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportCursorProto' start='43243' end='43243' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java' startBytecode='7' primary='true'><Message>At HdfsProtos.java:[line 43243]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='8a9fdb236859ee61cf74390176d804af' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportCursorProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportCursorProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportCursorProto' start='43161' end='43673' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>At HdfsProtos.java:[lines 43161-43673]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportCursorProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportCursorProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportCursorProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>In HdfsProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportCursorProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportCursorProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>In HdfsProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='c6dec075abc5da04191754371cddc03a' rank='19' abbrev='Se' category='BAD_PRACTICE' priority='3' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportCursorProto defines non-transient non-serializable instance field startPath_</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportCursorProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportCursorProto' start='43161' end='43673' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>At HdfsProtos.java:[lines 43161-43673]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportCursorProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportCursorProto' signature='Lcom/google/protobuf/ByteString;' name='startPath_' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportCursorProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>In HdfsProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportCursorProto.startPath_</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/ByteString;'><SourceLine classname='com.google.protobuf.ByteString' start='60' end='967' sourcepath='com/google/protobuf/ByteString.java' sourcefile='ByteString.java'><Message>At ByteString.java:[lines 60-967]</Message></SourceLine><Message>Actual type com.google.protobuf.ByteString</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportCursorProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>In HdfsProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='7330542ac24a31540f559e00e49ae6e0' rank='17' abbrev='UCF' category='STYLE' priority='2' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportCursorProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportCursorProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportCursorProto$Builder' start='43466' end='43664' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>At HdfsProtos.java:[lines 43466-43664]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportCursorProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportCursorProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine endBytecode='61' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportCursorProto$Builder' start='43492' end='43494' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportCursorProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportCursorProto$Builder' start='43492' end='43492' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java' startBytecode='3' primary='true'><Message>At HdfsProtos.java:[line 43492]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='1496d327ee7b502457e62844ab67dbfd' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportEntryProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportEntryProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportEntryProto' start='40325' end='40995' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>At HdfsProtos.java:[lines 40325-40995]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportEntryProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportEntryProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportEntryProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>In HdfsProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportEntryProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportEntryProto' start='40412' end='40412' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java' startBytecode='7' primary='true'><Message>At HdfsProtos.java:[line 40412]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='b0bc51f066991066968c3832c55f98d1' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportEntryProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportEntryProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportEntryProto' start='40325' end='40995' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>At HdfsProtos.java:[lines 40325-40995]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportEntryProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportEntryProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportEntryProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>In HdfsProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportEntryProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportEntryProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>In HdfsProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='b0f9180ccbf80431ecd10e7cd5973d8f' rank='19' abbrev='Se' category='BAD_PRACTICE' priority='3' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportEntryProto defines non-transient non-serializable instance field fullpath_</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportEntryProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportEntryProto' start='40325' end='40995' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>At HdfsProtos.java:[lines 40325-40995]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportEntryProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportEntryProto' signature='Lcom/google/protobuf/ByteString;' name='fullpath_' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportEntryProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>In HdfsProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportEntryProto.fullpath_</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/ByteString;'><SourceLine classname='com.google.protobuf.ByteString' start='60' end='967' sourcepath='com/google/protobuf/ByteString.java' sourcefile='ByteString.java'><Message>At ByteString.java:[lines 60-967]</Message></SourceLine><Message>Actual type com.google.protobuf.ByteString</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportEntryProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>In HdfsProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='b812a3ad99b83611c4fa2333ff35d730' rank='19' abbrev='Se' category='BAD_PRACTICE' priority='3' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportEntryProto defines non-transient non-serializable instance field targetPath_</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportEntryProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportEntryProto' start='40325' end='40995' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>At HdfsProtos.java:[lines 40325-40995]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportEntryProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportEntryProto' signature='Lcom/google/protobuf/ByteString;' name='targetPath_' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportEntryProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>In HdfsProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportEntryProto.targetPath_</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/ByteString;'><SourceLine classname='com.google.protobuf.ByteString' start='60' end='967' sourcepath='com/google/protobuf/ByteString.java' sourcefile='ByteString.java'><Message>At ByteString.java:[lines 60-967]</Message></SourceLine><Message>Actual type com.google.protobuf.ByteString</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportEntryProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>In HdfsProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='92c7ca15c195b6fbab5757c9adeb3c00' rank='17' abbrev='UCF' category='STYLE' priority='2' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportEntryProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportEntryProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportEntryProto$Builder' start='40700' end='40986' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>At HdfsProtos.java:[lines 40700-40986]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportEntryProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportEntryProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine endBytecode='61' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportEntryProto$Builder' start='40726' end='40728' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportEntryProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportEntryProto$Builder' start='40726' end='40726' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java' startBytecode='3' primary='true'><Message>At HdfsProtos.java:[line 40726]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='68b42a09964397ad1c1691a2679c5d6e' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportListingEntryProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportListingEntryProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportListingEntryProto' start='42362' end='43130' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>At HdfsProtos.java:[lines 42362-43130]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportListingEntryProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportListingEntryProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportListingEntryProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>In HdfsProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportListingEntryProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportListingEntryProto' start='42459' end='42459' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java' startBytecode='7' primary='true'><Message>At HdfsProtos.java:[line 42459]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='3be80be97e7e7f753827f41d748d8067' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportListingEntryProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportListingEntryProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportListingEntryProto' start='42362' end='43130' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>At HdfsProtos.java:[lines 42362-43130]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportListingEntryProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportListingEntryProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportListingEntryProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>In HdfsProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportListingEntryProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportListingEntryProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>In HdfsProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='b63022e5ccabc1c0c80c7f9ded44b4f8' rank='19' abbrev='Se' category='BAD_PRACTICE' priority='3' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportListingEntryProto defines non-transient non-serializable instance field fullpath_</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportListingEntryProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportListingEntryProto' start='42362' end='43130' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>At HdfsProtos.java:[lines 42362-43130]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportListingEntryProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportListingEntryProto' signature='Lcom/google/protobuf/ByteString;' name='fullpath_' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportListingEntryProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>In HdfsProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportListingEntryProto.fullpath_</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/ByteString;'><SourceLine classname='com.google.protobuf.ByteString' start='60' end='967' sourcepath='com/google/protobuf/ByteString.java' sourcefile='ByteString.java'><Message>At ByteString.java:[lines 60-967]</Message></SourceLine><Message>Actual type com.google.protobuf.ByteString</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportListingEntryProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>In HdfsProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='255af8b2ae19af02753745e382250abe' rank='19' abbrev='Se' category='BAD_PRACTICE' priority='3' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportListingEntryProto defines non-transient non-serializable instance field targetPath_</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportListingEntryProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportListingEntryProto' start='42362' end='43130' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>At HdfsProtos.java:[lines 42362-43130]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportListingEntryProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportListingEntryProto' signature='Lcom/google/protobuf/ByteString;' name='targetPath_' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportListingEntryProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>In HdfsProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportListingEntryProto.targetPath_</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/ByteString;'><SourceLine classname='com.google.protobuf.ByteString' start='60' end='967' sourcepath='com/google/protobuf/ByteString.java' sourcefile='ByteString.java'><Message>At ByteString.java:[lines 60-967]</Message></SourceLine><Message>Actual type com.google.protobuf.ByteString</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportListingEntryProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>In HdfsProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='69f55f6999698c3569fc82a9f4dd04c4' rank='17' abbrev='UCF' category='STYLE' priority='2' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportListingEntryProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportListingEntryProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportListingEntryProto$Builder' start='42790' end='43121' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>At HdfsProtos.java:[lines 42790-43121]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportListingEntryProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportListingEntryProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine endBytecode='61' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportListingEntryProto$Builder' start='42816' end='42818' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportListingEntryProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportListingEntryProto$Builder' start='42816' end='42816' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java' startBytecode='3' primary='true'><Message>At HdfsProtos.java:[line 42816]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='f3f48fc0da71f40ff39f83aab3b4a2d6' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportListingProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportListingProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportListingProto' start='43808' end='45590' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>At HdfsProtos.java:[lines 43808-45590]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportListingProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportListingProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportListingProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>In HdfsProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportListingProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportListingProto' start='43931' end='43931' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java' startBytecode='7' primary='true'><Message>At HdfsProtos.java:[line 43931]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='c6f963814f135e57a0ea6adaa2c86d31' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportListingProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportListingProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportListingProto' start='43808' end='45590' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>At HdfsProtos.java:[lines 43808-45590]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportListingProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportListingProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportListingProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>In HdfsProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportListingProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportListingProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>In HdfsProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='bfd9c3f7f443db896d70623af3e6df46' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportProto' start='41093' end='42296' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>At HdfsProtos.java:[lines 41093-42296]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>In HdfsProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportProto' start='41191' end='41191' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java' startBytecode='7' primary='true'><Message>At HdfsProtos.java:[line 41191]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='fc2075b278e0618229da827ee3f6e93e' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportProto' start='41093' end='42296' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>At HdfsProtos.java:[lines 41093-42296]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>In HdfsProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>In HdfsProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='861922eaa91c82ccc4f5c1604f9ea630' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotInfoProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotInfoProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotInfoProto' start='46360' end='47728' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>At HdfsProtos.java:[lines 46360-47728]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotInfoProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotInfoProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotInfoProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>In HdfsProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotInfoProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotInfoProto' start='46470' end='46470' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java' startBytecode='7' primary='true'><Message>At HdfsProtos.java:[line 46470]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='e219718178961e90e412a51347faed73' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotInfoProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotInfoProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotInfoProto' start='46360' end='47728' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>At HdfsProtos.java:[lines 46360-47728]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotInfoProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotInfoProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotInfoProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>In HdfsProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotInfoProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotInfoProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>In HdfsProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='bbc539f7c1a186cd2bf201af5feab2f6' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshottableDirectoryListingProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshottableDirectoryListingProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshottableDirectoryListingProto' start='39584' end='40274' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>At HdfsProtos.java:[lines 39584-40274]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshottableDirectoryListingProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshottableDirectoryListingProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshottableDirectoryListingProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>In HdfsProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshottableDirectoryListingProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshottableDirectoryListingProto' start='39667' end='39667' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java' startBytecode='7' primary='true'><Message>At HdfsProtos.java:[line 39667]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='c53afdf4c1fc4908d7b4cec553498992' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshottableDirectoryListingProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshottableDirectoryListingProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshottableDirectoryListingProto' start='39584' end='40274' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>At HdfsProtos.java:[lines 39584-40274]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshottableDirectoryListingProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshottableDirectoryListingProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshottableDirectoryListingProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>In HdfsProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshottableDirectoryListingProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshottableDirectoryListingProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>In HdfsProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='e376417c3f28d5fa2cd24cdba65e21b3' cweid='563' rank='20' abbrev='DLS' category='STYLE' priority='3' type='DLS_DEAD_LOCAL_STORE' instanceOccurrenceMax='0'><ShortMessage>Dead store to local variable</ShortMessage><LongMessage>Dead store to from_bitField0_ in org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshottableDirectoryListingProto$Builder.buildPartial()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshottableDirectoryListingProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshottableDirectoryListingProto$Builder' start='39876' end='40265' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>At HdfsProtos.java:[lines 39876-40265]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshottableDirectoryListingProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshottableDirectoryListingProto$Builder' signature='()Lorg/apache/hadoop/hdfs/protocol/proto/HdfsProtos$SnapshottableDirectoryListingProto;' name='buildPartial' primary='true'><SourceLine endBytecode='44' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshottableDirectoryListingProto$Builder' start='39943' end='39955' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshottableDirectoryListingProto$Builder.buildPartial()</Message></Method><LocalVariable role='LOCAL_VARIABLE_NAMED' pc='15' name='from_bitField0_' register='2'><Message>Local variable named from_bitField0_</Message></LocalVariable><SourceLine endBytecode='14' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshottableDirectoryListingProto$Builder' start='39944' end='39944' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java' startBytecode='14' primary='true'><Message>At HdfsProtos.java:[line 39944]</Message></SourceLine><Property name='edu.umd.cs.findbugs.detect.DeadLocalStoreProperty.BASE_VALUE' value='true'></Property><Property name='edu.umd.cs.findbugs.detect.DeadLocalStoreProperty.CACHING_VALUE' value='true'></Property><Property name='edu.umd.cs.findbugs.detect.DeadLocalStoreProperty.LOCAL_NAME' value='from_bitField0_'></Property><Property name='edu.umd.cs.findbugs.detect.DeadLocalStoreProperty.NO_LOADS' value='true'></Property></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='b4dc6b33dbca64edc4a030df8302a6b' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshottableDirectoryStatusProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshottableDirectoryStatusProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshottableDirectoryStatusProto' start='38709' end='39543' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>At HdfsProtos.java:[lines 38709-39543]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshottableDirectoryStatusProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshottableDirectoryStatusProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshottableDirectoryStatusProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>In HdfsProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshottableDirectoryStatusProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshottableDirectoryStatusProto' start='38809' end='38809' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java' startBytecode='7' primary='true'><Message>At HdfsProtos.java:[line 38809]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='bf03d317c94da6fbf167485867a59f94' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshottableDirectoryStatusProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshottableDirectoryStatusProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshottableDirectoryStatusProto' start='38709' end='39543' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>At HdfsProtos.java:[lines 38709-39543]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshottableDirectoryStatusProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshottableDirectoryStatusProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshottableDirectoryStatusProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>In HdfsProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshottableDirectoryStatusProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshottableDirectoryStatusProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>In HdfsProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='dde50ddc997653976023c3f15093375b' rank='19' abbrev='Se' category='BAD_PRACTICE' priority='3' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshottableDirectoryStatusProto defines non-transient non-serializable instance field parentFullpath_</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshottableDirectoryStatusProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshottableDirectoryStatusProto' start='38709' end='39543' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>At HdfsProtos.java:[lines 38709-39543]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshottableDirectoryStatusProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshottableDirectoryStatusProto' signature='Lcom/google/protobuf/ByteString;' name='parentFullpath_' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshottableDirectoryStatusProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>In HdfsProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshottableDirectoryStatusProto.parentFullpath_</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/ByteString;'><SourceLine classname='com.google.protobuf.ByteString' start='60' end='967' sourcepath='com/google/protobuf/ByteString.java' sourcefile='ByteString.java'><Message>At ByteString.java:[lines 60-967]</Message></SourceLine><Message>Actual type com.google.protobuf.ByteString</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshottableDirectoryStatusProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>In HdfsProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='b1e473479fce28cd83263a148fce60a' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$StorageReportProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$StorageReportProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$StorageReportProto' start='9913' end='11131' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>At HdfsProtos.java:[lines 9913-11131]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$StorageReportProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$StorageReportProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$StorageReportProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>In HdfsProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$StorageReportProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$StorageReportProto' start='10033' end='10033' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java' startBytecode='7' primary='true'><Message>At HdfsProtos.java:[line 10033]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='6ee61ef0e5376313ad379ae3381bdb50' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$StorageReportProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$StorageReportProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$StorageReportProto' start='9913' end='11131' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>At HdfsProtos.java:[lines 9913-11131]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$StorageReportProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$StorageReportProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$StorageReportProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>In HdfsProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$StorageReportProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$StorageReportProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>In HdfsProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='d37021fb1438e7203c8b58bd78a6dbc8' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$StorageTypeQuotaInfoProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$StorageTypeQuotaInfoProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$StorageTypeQuotaInfoProto' start='14542' end='15148' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>At HdfsProtos.java:[lines 14542-15148]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$StorageTypeQuotaInfoProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$StorageTypeQuotaInfoProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$StorageTypeQuotaInfoProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>In HdfsProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$StorageTypeQuotaInfoProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$StorageTypeQuotaInfoProto' start='14635' end='14635' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java' startBytecode='7' primary='true'><Message>At HdfsProtos.java:[line 14635]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='c33a580857603ce862cb5c6be03f916d' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$StorageTypeQuotaInfoProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$StorageTypeQuotaInfoProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$StorageTypeQuotaInfoProto' start='14542' end='15148' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>At HdfsProtos.java:[lines 14542-15148]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$StorageTypeQuotaInfoProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$StorageTypeQuotaInfoProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$StorageTypeQuotaInfoProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>In HdfsProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$StorageTypeQuotaInfoProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$StorageTypeQuotaInfoProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>In HdfsProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='d880941e5206c2d0d87a8d63643d6e12' rank='17' abbrev='UCF' category='STYLE' priority='2' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$StorageTypeQuotaInfoProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$StorageTypeQuotaInfoProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$StorageTypeQuotaInfoProto$Builder' start='14895' end='15139' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>At HdfsProtos.java:[lines 14895-15139]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$StorageTypeQuotaInfoProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$StorageTypeQuotaInfoProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine endBytecode='61' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$StorageTypeQuotaInfoProto$Builder' start='14921' end='14923' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$StorageTypeQuotaInfoProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$StorageTypeQuotaInfoProto$Builder' start='14921' end='14921' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java' startBytecode='3' primary='true'><Message>At HdfsProtos.java:[line 14921]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='1feebc137751678cf42e47a82b8cbf99' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$StorageTypeQuotaInfosProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$StorageTypeQuotaInfosProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$StorageTypeQuotaInfosProto' start='13811' end='14501' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>At HdfsProtos.java:[lines 13811-14501]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$StorageTypeQuotaInfosProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$StorageTypeQuotaInfosProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$StorageTypeQuotaInfosProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>In HdfsProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$StorageTypeQuotaInfosProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$StorageTypeQuotaInfosProto' start='13894' end='13894' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java' startBytecode='7' primary='true'><Message>At HdfsProtos.java:[line 13894]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='9bf2110ab04d602e0909e4eb21998302' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$StorageTypeQuotaInfosProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$StorageTypeQuotaInfosProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$StorageTypeQuotaInfosProto' start='13811' end='14501' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>At HdfsProtos.java:[lines 13811-14501]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$StorageTypeQuotaInfosProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$StorageTypeQuotaInfosProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$StorageTypeQuotaInfosProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>In HdfsProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$StorageTypeQuotaInfosProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$StorageTypeQuotaInfosProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>In HdfsProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='48d7b768c53a1ecddf0ad6ae34bf6344' cweid='563' rank='20' abbrev='DLS' category='STYLE' priority='3' type='DLS_DEAD_LOCAL_STORE' instanceOccurrenceMax='0'><ShortMessage>Dead store to local variable</ShortMessage><LongMessage>Dead store to from_bitField0_ in org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$StorageTypeQuotaInfosProto$Builder.buildPartial()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$StorageTypeQuotaInfosProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$StorageTypeQuotaInfosProto$Builder' start='14103' end='14492' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>At HdfsProtos.java:[lines 14103-14492]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$StorageTypeQuotaInfosProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$StorageTypeQuotaInfosProto$Builder' signature='()Lorg/apache/hadoop/hdfs/protocol/proto/HdfsProtos$StorageTypeQuotaInfosProto;' name='buildPartial' primary='true'><SourceLine endBytecode='44' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$StorageTypeQuotaInfosProto$Builder' start='14170' end='14182' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$StorageTypeQuotaInfosProto$Builder.buildPartial()</Message></Method><LocalVariable role='LOCAL_VARIABLE_NAMED' pc='15' name='from_bitField0_' register='2'><Message>Local variable named from_bitField0_</Message></LocalVariable><SourceLine endBytecode='14' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$StorageTypeQuotaInfosProto$Builder' start='14171' end='14171' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java' startBytecode='14' primary='true'><Message>At HdfsProtos.java:[line 14171]</Message></SourceLine><Property name='edu.umd.cs.findbugs.detect.DeadLocalStoreProperty.BASE_VALUE' value='true'></Property><Property name='edu.umd.cs.findbugs.detect.DeadLocalStoreProperty.CACHING_VALUE' value='true'></Property><Property name='edu.umd.cs.findbugs.detect.DeadLocalStoreProperty.LOCAL_NAME' value='from_bitField0_'></Property><Property name='edu.umd.cs.findbugs.detect.DeadLocalStoreProperty.NO_LOADS' value='true'></Property></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='8bf4ebbf4537595f457269789b29174d' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$StorageTypesProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$StorageTypesProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$StorageTypesProto' start='15898' end='16399' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>At HdfsProtos.java:[lines 15898-16399]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$StorageTypesProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$StorageTypesProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$StorageTypesProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>In HdfsProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$StorageTypesProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$StorageTypesProto' start='16006' end='16006' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java' startBytecode='7' primary='true'><Message>At HdfsProtos.java:[line 16006]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='db31a67a51b35f6e2080737218aac395' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$StorageTypesProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$StorageTypesProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$StorageTypesProto' start='15898' end='16399' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>At HdfsProtos.java:[lines 15898-16399]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$StorageTypesProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$StorageTypesProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$StorageTypesProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>In HdfsProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$StorageTypesProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$StorageTypesProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>In HdfsProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='3d3551a014b5cab4f2154e785201d9b0' cweid='563' rank='20' abbrev='DLS' category='STYLE' priority='3' type='DLS_DEAD_LOCAL_STORE' instanceOccurrenceMax='0'><ShortMessage>Dead store to local variable</ShortMessage><LongMessage>Dead store to from_bitField0_ in org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$StorageTypesProto$Builder.buildPartial()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$StorageTypesProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$StorageTypesProto$Builder' start='16200' end='16390' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>At HdfsProtos.java:[lines 16200-16390]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$StorageTypesProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$StorageTypesProto$Builder' signature='()Lorg/apache/hadoop/hdfs/protocol/proto/HdfsProtos$StorageTypesProto;' name='buildPartial' primary='true'><SourceLine endBytecode='34' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$StorageTypesProto$Builder' start='16262' end='16270' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$StorageTypesProto$Builder.buildPartial()</Message></Method><LocalVariable role='LOCAL_VARIABLE_NAMED' pc='15' name='from_bitField0_' register='2'><Message>Local variable named from_bitField0_</Message></LocalVariable><SourceLine endBytecode='14' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$StorageTypesProto$Builder' start='16263' end='16263' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java' startBytecode='14' primary='true'><Message>At HdfsProtos.java:[line 16263]</Message></SourceLine><Property name='edu.umd.cs.findbugs.detect.DeadLocalStoreProperty.BASE_VALUE' value='true'></Property><Property name='edu.umd.cs.findbugs.detect.DeadLocalStoreProperty.CACHING_VALUE' value='true'></Property><Property name='edu.umd.cs.findbugs.detect.DeadLocalStoreProperty.LOCAL_NAME' value='from_bitField0_'></Property><Property name='edu.umd.cs.findbugs.detect.DeadLocalStoreProperty.NO_LOADS' value='true'></Property></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='1e17f4a5161636ee02005efd5db4ac38' rank='17' abbrev='UCF' category='STYLE' priority='2' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$StorageTypesProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$StorageTypesProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$StorageTypesProto$Builder' start='16200' end='16390' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>At HdfsProtos.java:[lines 16200-16390]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$StorageTypesProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$StorageTypesProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine endBytecode='61' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$StorageTypesProto$Builder' start='16226' end='16228' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$StorageTypesProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$StorageTypesProto$Builder' start='16226' end='16226' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java' startBytecode='3' primary='true'><Message>At HdfsProtos.java:[line 16226]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='9023fb900b7efdba8c6ba2a902862051' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$StorageUuidsProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$StorageUuidsProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$StorageUuidsProto' start='48381' end='48887' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>At HdfsProtos.java:[lines 48381-48887]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$StorageUuidsProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$StorageUuidsProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$StorageUuidsProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>In HdfsProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$StorageUuidsProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$StorageUuidsProto' start='48464' end='48464' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java' startBytecode='7' primary='true'><Message>At HdfsProtos.java:[line 48464]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='d9b50f2097c3384b725a89592d96f2ef' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$StorageUuidsProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$StorageUuidsProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$StorageUuidsProto' start='48381' end='48887' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>At HdfsProtos.java:[lines 48381-48887]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$StorageUuidsProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$StorageUuidsProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$StorageUuidsProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>In HdfsProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$StorageUuidsProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$StorageUuidsProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>In HdfsProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='f1b91ca73dc458e580bd419952ccbd03' cweid='563' rank='20' abbrev='DLS' category='STYLE' priority='3' type='DLS_DEAD_LOCAL_STORE' instanceOccurrenceMax='0'><ShortMessage>Dead store to local variable</ShortMessage><LongMessage>Dead store to from_bitField0_ in org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$StorageUuidsProto$Builder.buildPartial()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$StorageUuidsProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$StorageUuidsProto$Builder' start='48666' end='48878' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>At HdfsProtos.java:[lines 48666-48878]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$StorageUuidsProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$StorageUuidsProto$Builder' signature='()Lorg/apache/hadoop/hdfs/protocol/proto/HdfsProtos$StorageUuidsProto;' name='buildPartial' primary='true'><SourceLine endBytecode='36' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$StorageUuidsProto$Builder' start='48728' end='48737' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$StorageUuidsProto$Builder.buildPartial()</Message></Method><LocalVariable role='LOCAL_VARIABLE_NAMED' pc='15' name='from_bitField0_' register='2'><Message>Local variable named from_bitField0_</Message></LocalVariable><SourceLine endBytecode='14' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$StorageUuidsProto$Builder' start='48729' end='48729' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java' startBytecode='14' primary='true'><Message>At HdfsProtos.java:[line 48729]</Message></SourceLine><Property name='edu.umd.cs.findbugs.detect.DeadLocalStoreProperty.BASE_VALUE' value='true'></Property><Property name='edu.umd.cs.findbugs.detect.DeadLocalStoreProperty.CACHING_VALUE' value='true'></Property><Property name='edu.umd.cs.findbugs.detect.DeadLocalStoreProperty.LOCAL_NAME' value='from_bitField0_'></Property><Property name='edu.umd.cs.findbugs.detect.DeadLocalStoreProperty.NO_LOADS' value='true'></Property></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='7ecb98c130f6197439e95233c0b3a53d' rank='17' abbrev='UCF' category='STYLE' priority='2' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$StorageUuidsProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$StorageUuidsProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$StorageUuidsProto$Builder' start='48666' end='48878' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>At HdfsProtos.java:[lines 48666-48878]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$StorageUuidsProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$StorageUuidsProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine endBytecode='61' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$StorageUuidsProto$Builder' start='48692' end='48694' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$StorageUuidsProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$StorageUuidsProto$Builder' start='48692' end='48692' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java' startBytecode='3' primary='true'><Message>At HdfsProtos.java:[line 48692]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='f79736198a1c5f7bff79e65937b47a13' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ZoneEncryptionInfoProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ZoneEncryptionInfoProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ZoneEncryptionInfoProto' start='23513' end='24403' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>At HdfsProtos.java:[lines 23513-24403]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ZoneEncryptionInfoProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ZoneEncryptionInfoProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ZoneEncryptionInfoProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>In HdfsProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ZoneEncryptionInfoProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ZoneEncryptionInfoProto' start='23625' end='23625' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java' startBytecode='7' primary='true'><Message>At HdfsProtos.java:[line 23625]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='e6d65de72b0498d68c2bcdea7abe7245' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ZoneEncryptionInfoProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ZoneEncryptionInfoProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ZoneEncryptionInfoProto' start='23513' end='24403' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>At HdfsProtos.java:[lines 23513-24403]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ZoneEncryptionInfoProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ZoneEncryptionInfoProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ZoneEncryptionInfoProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>In HdfsProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ZoneEncryptionInfoProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ZoneEncryptionInfoProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' sourcefile='HdfsProtos.java'><Message>In HdfsProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='d4754dd4d69fb4f6afba8f62d91f341f' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$AppendEventProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$AppendEventProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$AppendEventProto' start='4898' end='5469' sourcepath='org/apache/hadoop/hdfs/protocol/proto/InotifyProtos.java' sourcefile='InotifyProtos.java'><Message>At InotifyProtos.java:[lines 4898-5469]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$AppendEventProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$AppendEventProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$AppendEventProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/InotifyProtos.java' sourcefile='InotifyProtos.java'><Message>In InotifyProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$AppendEventProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$AppendEventProto' start='4980' end='4980' sourcepath='org/apache/hadoop/hdfs/protocol/proto/InotifyProtos.java' sourcefile='InotifyProtos.java' startBytecode='7' primary='true'><Message>At InotifyProtos.java:[line 4980]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='caaacd8441540dcf6b9bf2f75534c18c' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$AppendEventProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$AppendEventProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$AppendEventProto' start='4898' end='5469' sourcepath='org/apache/hadoop/hdfs/protocol/proto/InotifyProtos.java' sourcefile='InotifyProtos.java'><Message>At InotifyProtos.java:[lines 4898-5469]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$AppendEventProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$AppendEventProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$AppendEventProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/InotifyProtos.java' sourcefile='InotifyProtos.java'><Message>In InotifyProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$AppendEventProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$AppendEventProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/InotifyProtos.java' sourcefile='InotifyProtos.java'><Message>In InotifyProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='8d3d06f52ae2a02f3ab213021cc4fe3f' rank='17' abbrev='UCF' category='STYLE' priority='2' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$AppendEventProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$AppendEventProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$AppendEventProto$Builder' start='5226' end='5460' sourcepath='org/apache/hadoop/hdfs/protocol/proto/InotifyProtos.java' sourcefile='InotifyProtos.java'><Message>At InotifyProtos.java:[lines 5226-5460]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$AppendEventProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$AppendEventProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine endBytecode='61' classname='org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$AppendEventProto$Builder' start='5252' end='5254' sourcepath='org/apache/hadoop/hdfs/protocol/proto/InotifyProtos.java' sourcefile='InotifyProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$AppendEventProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$AppendEventProto$Builder' start='5252' end='5252' sourcepath='org/apache/hadoop/hdfs/protocol/proto/InotifyProtos.java' sourcefile='InotifyProtos.java' startBytecode='3' primary='true'><Message>At InotifyProtos.java:[line 5252]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='cdcfccb4ca31ea12f153d47d3b90b0d5' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$CloseEventProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$CloseEventProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$CloseEventProto' start='3482' end='4149' sourcepath='org/apache/hadoop/hdfs/protocol/proto/InotifyProtos.java' sourcefile='InotifyProtos.java'><Message>At InotifyProtos.java:[lines 3482-4149]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$CloseEventProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$CloseEventProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$CloseEventProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/InotifyProtos.java' sourcefile='InotifyProtos.java'><Message>In InotifyProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$CloseEventProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$CloseEventProto' start='3569' end='3569' sourcepath='org/apache/hadoop/hdfs/protocol/proto/InotifyProtos.java' sourcefile='InotifyProtos.java' startBytecode='7' primary='true'><Message>At InotifyProtos.java:[line 3569]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='e77459aec55d7289ad3ac51c7c51969' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$CloseEventProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$CloseEventProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$CloseEventProto' start='3482' end='4149' sourcepath='org/apache/hadoop/hdfs/protocol/proto/InotifyProtos.java' sourcefile='InotifyProtos.java'><Message>At InotifyProtos.java:[lines 3482-4149]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$CloseEventProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$CloseEventProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$CloseEventProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/InotifyProtos.java' sourcefile='InotifyProtos.java'><Message>In InotifyProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$CloseEventProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$CloseEventProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/InotifyProtos.java' sourcefile='InotifyProtos.java'><Message>In InotifyProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='f9dbc4d06c9a950d8bbdc4f84cebb834' rank='17' abbrev='UCF' category='STYLE' priority='2' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$CloseEventProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$CloseEventProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$CloseEventProto$Builder' start='3856' end='4140' sourcepath='org/apache/hadoop/hdfs/protocol/proto/InotifyProtos.java' sourcefile='InotifyProtos.java'><Message>At InotifyProtos.java:[lines 3856-4140]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$CloseEventProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$CloseEventProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine endBytecode='61' classname='org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$CloseEventProto$Builder' start='3882' end='3884' sourcepath='org/apache/hadoop/hdfs/protocol/proto/InotifyProtos.java' sourcefile='InotifyProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$CloseEventProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$CloseEventProto$Builder' start='3882' end='3882' sourcepath='org/apache/hadoop/hdfs/protocol/proto/InotifyProtos.java' sourcefile='InotifyProtos.java' startBytecode='3' primary='true'><Message>At InotifyProtos.java:[line 3882]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='b694eb0cad4b5ca885ca6689a35803e5' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$CreateEventProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$CreateEventProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$CreateEventProto' start='1851' end='3436' sourcepath='org/apache/hadoop/hdfs/protocol/proto/InotifyProtos.java' sourcefile='InotifyProtos.java'><Message>At InotifyProtos.java:[lines 1851-3436]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$CreateEventProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$CreateEventProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$CreateEventProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/InotifyProtos.java' sourcefile='InotifyProtos.java'><Message>In InotifyProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$CreateEventProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$CreateEventProto' start='1987' end='1987' sourcepath='org/apache/hadoop/hdfs/protocol/proto/InotifyProtos.java' sourcefile='InotifyProtos.java' startBytecode='7' primary='true'><Message>At InotifyProtos.java:[line 1987]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='3b4f2e2a1d82d39a3751003852456112' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$CreateEventProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$CreateEventProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$CreateEventProto' start='1851' end='3436' sourcepath='org/apache/hadoop/hdfs/protocol/proto/InotifyProtos.java' sourcefile='InotifyProtos.java'><Message>At InotifyProtos.java:[lines 1851-3436]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$CreateEventProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$CreateEventProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$CreateEventProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/InotifyProtos.java' sourcefile='InotifyProtos.java'><Message>In InotifyProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$CreateEventProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$CreateEventProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/InotifyProtos.java' sourcefile='InotifyProtos.java'><Message>In InotifyProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='e2728f603e50b7a30a58e351ab981a40' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$EventBatchProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$EventBatchProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$EventBatchProto' start='940' end='1716' sourcepath='org/apache/hadoop/hdfs/protocol/proto/InotifyProtos.java' sourcefile='InotifyProtos.java'><Message>At InotifyProtos.java:[lines 940-1716]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$EventBatchProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$EventBatchProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$EventBatchProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/InotifyProtos.java' sourcefile='InotifyProtos.java'><Message>In InotifyProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$EventBatchProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$EventBatchProto' start='1028' end='1028' sourcepath='org/apache/hadoop/hdfs/protocol/proto/InotifyProtos.java' sourcefile='InotifyProtos.java' startBytecode='7' primary='true'><Message>At InotifyProtos.java:[line 1028]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='343da6a1a4733fff3683a49af5688fd6' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$EventBatchProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$EventBatchProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$EventBatchProto' start='940' end='1716' sourcepath='org/apache/hadoop/hdfs/protocol/proto/InotifyProtos.java' sourcefile='InotifyProtos.java'><Message>At InotifyProtos.java:[lines 940-1716]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$EventBatchProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$EventBatchProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$EventBatchProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/InotifyProtos.java' sourcefile='InotifyProtos.java'><Message>In InotifyProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$EventBatchProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$EventBatchProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/InotifyProtos.java' sourcefile='InotifyProtos.java'><Message>In InotifyProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='a454ba658f57519fbd6cb857c3037304' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$EventProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$EventProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$EventProto' start='373' end='894' sourcepath='org/apache/hadoop/hdfs/protocol/proto/InotifyProtos.java' sourcefile='InotifyProtos.java'><Message>At InotifyProtos.java:[lines 373-894]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$EventProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$EventProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$EventProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/InotifyProtos.java' sourcefile='InotifyProtos.java'><Message>In InotifyProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$EventProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$EventProto' start='461' end='461' sourcepath='org/apache/hadoop/hdfs/protocol/proto/InotifyProtos.java' sourcefile='InotifyProtos.java' startBytecode='7' primary='true'><Message>At InotifyProtos.java:[line 461]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='71e291a513903fc448ae7742739d6cce' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$EventProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$EventProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$EventProto' start='373' end='894' sourcepath='org/apache/hadoop/hdfs/protocol/proto/InotifyProtos.java' sourcefile='InotifyProtos.java'><Message>At InotifyProtos.java:[lines 373-894]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$EventProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$EventProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$EventProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/InotifyProtos.java' sourcefile='InotifyProtos.java'><Message>In InotifyProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$EventProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$EventProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/InotifyProtos.java' sourcefile='InotifyProtos.java'><Message>In InotifyProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='e9e5c5a0db0d7a45807a2beaf4a5150e' rank='19' abbrev='Se' category='BAD_PRACTICE' priority='3' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$EventProto defines non-transient non-serializable instance field contents_</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$EventProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$EventProto' start='373' end='894' sourcepath='org/apache/hadoop/hdfs/protocol/proto/InotifyProtos.java' sourcefile='InotifyProtos.java'><Message>At InotifyProtos.java:[lines 373-894]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$EventProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$EventProto' signature='Lcom/google/protobuf/ByteString;' name='contents_' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$EventProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/InotifyProtos.java' sourcefile='InotifyProtos.java'><Message>In InotifyProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$EventProto.contents_</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/ByteString;'><SourceLine classname='com.google.protobuf.ByteString' start='60' end='967' sourcepath='com/google/protobuf/ByteString.java' sourcefile='ByteString.java'><Message>At ByteString.java:[lines 60-967]</Message></SourceLine><Message>Actual type com.google.protobuf.ByteString</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$EventProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/InotifyProtos.java' sourcefile='InotifyProtos.java'><Message>In InotifyProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='f128b886e56060b4595ccf4199bd18ca' rank='17' abbrev='UCF' category='STYLE' priority='2' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$EventProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$EventProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$EventProto$Builder' start='684' end='885' sourcepath='org/apache/hadoop/hdfs/protocol/proto/InotifyProtos.java' sourcefile='InotifyProtos.java'><Message>At InotifyProtos.java:[lines 684-885]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$EventProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$EventProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine endBytecode='61' classname='org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$EventProto$Builder' start='710' end='712' sourcepath='org/apache/hadoop/hdfs/protocol/proto/InotifyProtos.java' sourcefile='InotifyProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$EventProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$EventProto$Builder' start='710' end='710' sourcepath='org/apache/hadoop/hdfs/protocol/proto/InotifyProtos.java' sourcefile='InotifyProtos.java' startBytecode='3' primary='true'><Message>At InotifyProtos.java:[line 710]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='74a5099a5b6c4946d79f6f59685c3e19' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$EventsListProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$EventsListProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$EventsListProto' start='9270' end='10669' sourcepath='org/apache/hadoop/hdfs/protocol/proto/InotifyProtos.java' sourcefile='InotifyProtos.java'><Message>At InotifyProtos.java:[lines 9270-10669]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$EventsListProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$EventsListProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$EventsListProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/InotifyProtos.java' sourcefile='InotifyProtos.java'><Message>In InotifyProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$EventsListProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$EventsListProto' start='9379' end='9379' sourcepath='org/apache/hadoop/hdfs/protocol/proto/InotifyProtos.java' sourcefile='InotifyProtos.java' startBytecode='7' primary='true'><Message>At InotifyProtos.java:[line 9379]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='47c082730322b7a7949bb0130bdae9fa' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$EventsListProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$EventsListProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$EventsListProto' start='9270' end='10669' sourcepath='org/apache/hadoop/hdfs/protocol/proto/InotifyProtos.java' sourcefile='InotifyProtos.java'><Message>At InotifyProtos.java:[lines 9270-10669]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$EventsListProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$EventsListProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$EventsListProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/InotifyProtos.java' sourcefile='InotifyProtos.java'><Message>In InotifyProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$EventsListProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$EventsListProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/InotifyProtos.java' sourcefile='InotifyProtos.java'><Message>In InotifyProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='1fee6317b1ecbf3a36b7eefd8fd1bd2' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$MetadataUpdateEventProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$MetadataUpdateEventProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$MetadataUpdateEventProto' start='6427' end='8544' sourcepath='org/apache/hadoop/hdfs/protocol/proto/InotifyProtos.java' sourcefile='InotifyProtos.java'><Message>At InotifyProtos.java:[lines 6427-8544]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$MetadataUpdateEventProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$MetadataUpdateEventProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$MetadataUpdateEventProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/InotifyProtos.java' sourcefile='InotifyProtos.java'><Message>In InotifyProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$MetadataUpdateEventProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$MetadataUpdateEventProto' start='6580' end='6580' sourcepath='org/apache/hadoop/hdfs/protocol/proto/InotifyProtos.java' sourcefile='InotifyProtos.java' startBytecode='7' primary='true'><Message>At InotifyProtos.java:[line 6580]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='5d0c28d79a3b07a636f01a80f954aa1b' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$MetadataUpdateEventProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$MetadataUpdateEventProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$MetadataUpdateEventProto' start='6427' end='8544' sourcepath='org/apache/hadoop/hdfs/protocol/proto/InotifyProtos.java' sourcefile='InotifyProtos.java'><Message>At InotifyProtos.java:[lines 6427-8544]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$MetadataUpdateEventProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$MetadataUpdateEventProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$MetadataUpdateEventProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/InotifyProtos.java' sourcefile='InotifyProtos.java'><Message>In InotifyProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$MetadataUpdateEventProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$MetadataUpdateEventProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/InotifyProtos.java' sourcefile='InotifyProtos.java'><Message>In InotifyProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='36172a168d85c9b8fe31a2bf59a93e2e' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$RenameEventProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$RenameEventProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$RenameEventProto' start='5520' end='6257' sourcepath='org/apache/hadoop/hdfs/protocol/proto/InotifyProtos.java' sourcefile='InotifyProtos.java'><Message>At InotifyProtos.java:[lines 5520-6257]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$RenameEventProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$RenameEventProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$RenameEventProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/InotifyProtos.java' sourcefile='InotifyProtos.java'><Message>In InotifyProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$RenameEventProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$RenameEventProto' start='5607' end='5607' sourcepath='org/apache/hadoop/hdfs/protocol/proto/InotifyProtos.java' sourcefile='InotifyProtos.java' startBytecode='7' primary='true'><Message>At InotifyProtos.java:[line 5607]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='912361943cc5cfc0af5495dd4c5f938d' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$RenameEventProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$RenameEventProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$RenameEventProto' start='5520' end='6257' sourcepath='org/apache/hadoop/hdfs/protocol/proto/InotifyProtos.java' sourcefile='InotifyProtos.java'><Message>At InotifyProtos.java:[lines 5520-6257]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$RenameEventProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$RenameEventProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$RenameEventProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/InotifyProtos.java' sourcefile='InotifyProtos.java'><Message>In InotifyProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$RenameEventProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$RenameEventProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/InotifyProtos.java' sourcefile='InotifyProtos.java'><Message>In InotifyProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='4408631e1fc5d1ad161e5e01cb1952d1' rank='17' abbrev='UCF' category='STYLE' priority='2' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$RenameEventProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$RenameEventProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$RenameEventProto$Builder' start='5921' end='6248' sourcepath='org/apache/hadoop/hdfs/protocol/proto/InotifyProtos.java' sourcefile='InotifyProtos.java'><Message>At InotifyProtos.java:[lines 5921-6248]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$RenameEventProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$RenameEventProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine endBytecode='61' classname='org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$RenameEventProto$Builder' start='5947' end='5949' sourcepath='org/apache/hadoop/hdfs/protocol/proto/InotifyProtos.java' sourcefile='InotifyProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$RenameEventProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$RenameEventProto$Builder' start='5947' end='5947' sourcepath='org/apache/hadoop/hdfs/protocol/proto/InotifyProtos.java' sourcefile='InotifyProtos.java' startBytecode='3' primary='true'><Message>At InotifyProtos.java:[line 5947]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='990c3bc54283ed2ebe474fa455bef4bb' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$TruncateEventProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$TruncateEventProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$TruncateEventProto' start='4195' end='4862' sourcepath='org/apache/hadoop/hdfs/protocol/proto/InotifyProtos.java' sourcefile='InotifyProtos.java'><Message>At InotifyProtos.java:[lines 4195-4862]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$TruncateEventProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$TruncateEventProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$TruncateEventProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/InotifyProtos.java' sourcefile='InotifyProtos.java'><Message>In InotifyProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$TruncateEventProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$TruncateEventProto' start='4282' end='4282' sourcepath='org/apache/hadoop/hdfs/protocol/proto/InotifyProtos.java' sourcefile='InotifyProtos.java' startBytecode='7' primary='true'><Message>At InotifyProtos.java:[line 4282]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='a1750f92ac260d9422f8013c8152b86f' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$TruncateEventProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$TruncateEventProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$TruncateEventProto' start='4195' end='4862' sourcepath='org/apache/hadoop/hdfs/protocol/proto/InotifyProtos.java' sourcefile='InotifyProtos.java'><Message>At InotifyProtos.java:[lines 4195-4862]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$TruncateEventProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$TruncateEventProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$TruncateEventProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/InotifyProtos.java' sourcefile='InotifyProtos.java'><Message>In InotifyProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$TruncateEventProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$TruncateEventProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/InotifyProtos.java' sourcefile='InotifyProtos.java'><Message>In InotifyProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='a2f6789887c161eef079a3f4dc210dcb' rank='17' abbrev='UCF' category='STYLE' priority='2' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$TruncateEventProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$TruncateEventProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$TruncateEventProto$Builder' start='4569' end='4853' sourcepath='org/apache/hadoop/hdfs/protocol/proto/InotifyProtos.java' sourcefile='InotifyProtos.java'><Message>At InotifyProtos.java:[lines 4569-4853]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$TruncateEventProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$TruncateEventProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine endBytecode='61' classname='org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$TruncateEventProto$Builder' start='4595' end='4597' sourcepath='org/apache/hadoop/hdfs/protocol/proto/InotifyProtos.java' sourcefile='InotifyProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$TruncateEventProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$TruncateEventProto$Builder' start='4595' end='4595' sourcepath='org/apache/hadoop/hdfs/protocol/proto/InotifyProtos.java' sourcefile='InotifyProtos.java' startBytecode='3' primary='true'><Message>At InotifyProtos.java:[line 4595]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='65eff5ae432b718da1c8374df08e15ed' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$UnlinkEventProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$UnlinkEventProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$UnlinkEventProto' start='8580' end='9159' sourcepath='org/apache/hadoop/hdfs/protocol/proto/InotifyProtos.java' sourcefile='InotifyProtos.java'><Message>At InotifyProtos.java:[lines 8580-9159]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$UnlinkEventProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$UnlinkEventProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$UnlinkEventProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/InotifyProtos.java' sourcefile='InotifyProtos.java'><Message>In InotifyProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$UnlinkEventProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$UnlinkEventProto' start='8662' end='8662' sourcepath='org/apache/hadoop/hdfs/protocol/proto/InotifyProtos.java' sourcefile='InotifyProtos.java' startBytecode='7' primary='true'><Message>At InotifyProtos.java:[line 8662]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='beb79e8df10e0e0b584dd78861e750bd' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$UnlinkEventProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$UnlinkEventProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$UnlinkEventProto' start='8580' end='9159' sourcepath='org/apache/hadoop/hdfs/protocol/proto/InotifyProtos.java' sourcefile='InotifyProtos.java'><Message>At InotifyProtos.java:[lines 8580-9159]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$UnlinkEventProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$UnlinkEventProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$UnlinkEventProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/InotifyProtos.java' sourcefile='InotifyProtos.java'><Message>In InotifyProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$UnlinkEventProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$UnlinkEventProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/InotifyProtos.java' sourcefile='InotifyProtos.java'><Message>In InotifyProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='f07325678ada88748bdf19750b76caab' rank='17' abbrev='UCF' category='STYLE' priority='2' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$UnlinkEventProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$UnlinkEventProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$UnlinkEventProto$Builder' start='8912' end='9150' sourcepath='org/apache/hadoop/hdfs/protocol/proto/InotifyProtos.java' sourcefile='InotifyProtos.java'><Message>At InotifyProtos.java:[lines 8912-9150]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$UnlinkEventProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$UnlinkEventProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine endBytecode='61' classname='org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$UnlinkEventProto$Builder' start='8938' end='8940' sourcepath='org/apache/hadoop/hdfs/protocol/proto/InotifyProtos.java' sourcefile='InotifyProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$UnlinkEventProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$UnlinkEventProto$Builder' start='8938' end='8938' sourcepath='org/apache/hadoop/hdfs/protocol/proto/InotifyProtos.java' sourcefile='InotifyProtos.java' startBytecode='3' primary='true'><Message>At InotifyProtos.java:[line 8938]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='520ab4e9fb6824b0a207cfdb1355e647' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$GetReconfigurationStatusConfigChangeProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$GetReconfigurationStatusConfigChangeProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$GetReconfigurationStatusConfigChangeProto' start='1119' end='2104' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ReconfigurationProtocolProtos.java' sourcefile='ReconfigurationProtocolProtos.java'><Message>At ReconfigurationProtocolProtos.java:[lines 1119-2104]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$GetReconfigurationStatusConfigChangeProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$GetReconfigurationStatusConfigChangeProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$GetReconfigurationStatusConfigChangeProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ReconfigurationProtocolProtos.java' sourcefile='ReconfigurationProtocolProtos.java'><Message>In ReconfigurationProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$GetReconfigurationStatusConfigChangeProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$GetReconfigurationStatusConfigChangeProto' start='1211' end='1211' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ReconfigurationProtocolProtos.java' sourcefile='ReconfigurationProtocolProtos.java' startBytecode='7' primary='true'><Message>At ReconfigurationProtocolProtos.java:[line 1211]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='9343e9259b8505e11626448db4a66b5c' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$GetReconfigurationStatusConfigChangeProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$GetReconfigurationStatusConfigChangeProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$GetReconfigurationStatusConfigChangeProto' start='1119' end='2104' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ReconfigurationProtocolProtos.java' sourcefile='ReconfigurationProtocolProtos.java'><Message>At ReconfigurationProtocolProtos.java:[lines 1119-2104]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$GetReconfigurationStatusConfigChangeProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$GetReconfigurationStatusConfigChangeProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$GetReconfigurationStatusConfigChangeProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ReconfigurationProtocolProtos.java' sourcefile='ReconfigurationProtocolProtos.java'><Message>In ReconfigurationProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$GetReconfigurationStatusConfigChangeProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$GetReconfigurationStatusConfigChangeProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ReconfigurationProtocolProtos.java' sourcefile='ReconfigurationProtocolProtos.java'><Message>In ReconfigurationProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='537c178bc4fd5830f4e79e7cd40bf18d' rank='17' abbrev='UCF' category='STYLE' priority='2' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$GetReconfigurationStatusConfigChangeProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$GetReconfigurationStatusConfigChangeProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$GetReconfigurationStatusConfigChangeProto$Builder' start='1620' end='2095' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ReconfigurationProtocolProtos.java' sourcefile='ReconfigurationProtocolProtos.java'><Message>At ReconfigurationProtocolProtos.java:[lines 1620-2095]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$GetReconfigurationStatusConfigChangeProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$GetReconfigurationStatusConfigChangeProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine endBytecode='61' classname='org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$GetReconfigurationStatusConfigChangeProto$Builder' start='1646' end='1648' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ReconfigurationProtocolProtos.java' sourcefile='ReconfigurationProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$GetReconfigurationStatusConfigChangeProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$GetReconfigurationStatusConfigChangeProto$Builder' start='1646' end='1646' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ReconfigurationProtocolProtos.java' sourcefile='ReconfigurationProtocolProtos.java' startBytecode='3' primary='true'><Message>At ReconfigurationProtocolProtos.java:[line 1646]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='94618ba5630d2e5aeab0fb7adea1ed0e' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$GetReconfigurationStatusRequestProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$GetReconfigurationStatusRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$GetReconfigurationStatusRequestProto' start='705' end='1036' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ReconfigurationProtocolProtos.java' sourcefile='ReconfigurationProtocolProtos.java'><Message>At ReconfigurationProtocolProtos.java:[lines 705-1036]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$GetReconfigurationStatusRequestProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$GetReconfigurationStatusRequestProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$GetReconfigurationStatusRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ReconfigurationProtocolProtos.java' sourcefile='ReconfigurationProtocolProtos.java'><Message>In ReconfigurationProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$GetReconfigurationStatusRequestProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$GetReconfigurationStatusRequestProto' start='776' end='776' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ReconfigurationProtocolProtos.java' sourcefile='ReconfigurationProtocolProtos.java' startBytecode='7' primary='true'><Message>At ReconfigurationProtocolProtos.java:[line 776]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='fb48905cf1b1dad5767d7e8827e2115' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$GetReconfigurationStatusRequestProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$GetReconfigurationStatusRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$GetReconfigurationStatusRequestProto' start='705' end='1036' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ReconfigurationProtocolProtos.java' sourcefile='ReconfigurationProtocolProtos.java'><Message>At ReconfigurationProtocolProtos.java:[lines 705-1036]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$GetReconfigurationStatusRequestProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$GetReconfigurationStatusRequestProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$GetReconfigurationStatusRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ReconfigurationProtocolProtos.java' sourcefile='ReconfigurationProtocolProtos.java'><Message>In ReconfigurationProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$GetReconfigurationStatusRequestProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$GetReconfigurationStatusRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ReconfigurationProtocolProtos.java' sourcefile='ReconfigurationProtocolProtos.java'><Message>In ReconfigurationProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='866e273b9b22c4b61280db02cad88d94' rank='17' abbrev='UCF' category='STYLE' priority='2' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$GetReconfigurationStatusRequestProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$GetReconfigurationStatusRequestProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$GetReconfigurationStatusRequestProto$Builder' start='928' end='1027' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ReconfigurationProtocolProtos.java' sourcefile='ReconfigurationProtocolProtos.java'><Message>At ReconfigurationProtocolProtos.java:[lines 928-1027]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$GetReconfigurationStatusRequestProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$GetReconfigurationStatusRequestProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine endBytecode='61' classname='org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$GetReconfigurationStatusRequestProto$Builder' start='954' end='956' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ReconfigurationProtocolProtos.java' sourcefile='ReconfigurationProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$GetReconfigurationStatusRequestProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$GetReconfigurationStatusRequestProto$Builder' start='954' end='954' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ReconfigurationProtocolProtos.java' sourcefile='ReconfigurationProtocolProtos.java' startBytecode='3' primary='true'><Message>At ReconfigurationProtocolProtos.java:[line 954]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='e227808fdef98ec725843064783af4a1' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$GetReconfigurationStatusResponseProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$GetReconfigurationStatusResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$GetReconfigurationStatusResponseProto' start='2160' end='3016' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ReconfigurationProtocolProtos.java' sourcefile='ReconfigurationProtocolProtos.java'><Message>At ReconfigurationProtocolProtos.java:[lines 2160-3016]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$GetReconfigurationStatusResponseProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$GetReconfigurationStatusResponseProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$GetReconfigurationStatusResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ReconfigurationProtocolProtos.java' sourcefile='ReconfigurationProtocolProtos.java'><Message>In ReconfigurationProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$GetReconfigurationStatusResponseProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$GetReconfigurationStatusResponseProto' start='2253' end='2253' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ReconfigurationProtocolProtos.java' sourcefile='ReconfigurationProtocolProtos.java' startBytecode='7' primary='true'><Message>At ReconfigurationProtocolProtos.java:[line 2253]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='5a6b87a042d5793de503e1ba22fe7fd3' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$GetReconfigurationStatusResponseProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$GetReconfigurationStatusResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$GetReconfigurationStatusResponseProto' start='2160' end='3016' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ReconfigurationProtocolProtos.java' sourcefile='ReconfigurationProtocolProtos.java'><Message>At ReconfigurationProtocolProtos.java:[lines 2160-3016]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$GetReconfigurationStatusResponseProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$GetReconfigurationStatusResponseProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$GetReconfigurationStatusResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ReconfigurationProtocolProtos.java' sourcefile='ReconfigurationProtocolProtos.java'><Message>In ReconfigurationProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$GetReconfigurationStatusResponseProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$GetReconfigurationStatusResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ReconfigurationProtocolProtos.java' sourcefile='ReconfigurationProtocolProtos.java'><Message>In ReconfigurationProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='9132fb0eb75f915a0930262c8bcf67e5' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$ListReconfigurablePropertiesRequestProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$ListReconfigurablePropertiesRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$ListReconfigurablePropertiesRequestProto' start='3031' end='3362' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ReconfigurationProtocolProtos.java' sourcefile='ReconfigurationProtocolProtos.java'><Message>At ReconfigurationProtocolProtos.java:[lines 3031-3362]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$ListReconfigurablePropertiesRequestProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$ListReconfigurablePropertiesRequestProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$ListReconfigurablePropertiesRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ReconfigurationProtocolProtos.java' sourcefile='ReconfigurationProtocolProtos.java'><Message>In ReconfigurationProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$ListReconfigurablePropertiesRequestProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$ListReconfigurablePropertiesRequestProto' start='3102' end='3102' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ReconfigurationProtocolProtos.java' sourcefile='ReconfigurationProtocolProtos.java' startBytecode='7' primary='true'><Message>At ReconfigurationProtocolProtos.java:[line 3102]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='c25ddbac6d84022d420058612900642f' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$ListReconfigurablePropertiesRequestProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$ListReconfigurablePropertiesRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$ListReconfigurablePropertiesRequestProto' start='3031' end='3362' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ReconfigurationProtocolProtos.java' sourcefile='ReconfigurationProtocolProtos.java'><Message>At ReconfigurationProtocolProtos.java:[lines 3031-3362]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$ListReconfigurablePropertiesRequestProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$ListReconfigurablePropertiesRequestProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$ListReconfigurablePropertiesRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ReconfigurationProtocolProtos.java' sourcefile='ReconfigurationProtocolProtos.java'><Message>In ReconfigurationProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$ListReconfigurablePropertiesRequestProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$ListReconfigurablePropertiesRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ReconfigurationProtocolProtos.java' sourcefile='ReconfigurationProtocolProtos.java'><Message>In ReconfigurationProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='27a3d976d7a173fd2bd942decbdd3da1' rank='17' abbrev='UCF' category='STYLE' priority='2' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$ListReconfigurablePropertiesRequestProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$ListReconfigurablePropertiesRequestProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$ListReconfigurablePropertiesRequestProto$Builder' start='3254' end='3353' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ReconfigurationProtocolProtos.java' sourcefile='ReconfigurationProtocolProtos.java'><Message>At ReconfigurationProtocolProtos.java:[lines 3254-3353]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$ListReconfigurablePropertiesRequestProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$ListReconfigurablePropertiesRequestProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine endBytecode='61' classname='org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$ListReconfigurablePropertiesRequestProto$Builder' start='3280' end='3282' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ReconfigurationProtocolProtos.java' sourcefile='ReconfigurationProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$ListReconfigurablePropertiesRequestProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$ListReconfigurablePropertiesRequestProto$Builder' start='3280' end='3280' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ReconfigurationProtocolProtos.java' sourcefile='ReconfigurationProtocolProtos.java' startBytecode='3' primary='true'><Message>At ReconfigurationProtocolProtos.java:[line 3280]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='ffe7b1bdf724c3f8a802e15ad8d4c908' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$ListReconfigurablePropertiesResponseProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$ListReconfigurablePropertiesResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$ListReconfigurablePropertiesResponseProto' start='3393' end='3894' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ReconfigurationProtocolProtos.java' sourcefile='ReconfigurationProtocolProtos.java'><Message>At ReconfigurationProtocolProtos.java:[lines 3393-3894]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$ListReconfigurablePropertiesResponseProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$ListReconfigurablePropertiesResponseProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$ListReconfigurablePropertiesResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ReconfigurationProtocolProtos.java' sourcefile='ReconfigurationProtocolProtos.java'><Message>In ReconfigurationProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$ListReconfigurablePropertiesResponseProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$ListReconfigurablePropertiesResponseProto' start='3476' end='3476' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ReconfigurationProtocolProtos.java' sourcefile='ReconfigurationProtocolProtos.java' startBytecode='7' primary='true'><Message>At ReconfigurationProtocolProtos.java:[line 3476]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='48397ce30e79ed0a3d96d849f1a947bb' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$ListReconfigurablePropertiesResponseProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$ListReconfigurablePropertiesResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$ListReconfigurablePropertiesResponseProto' start='3393' end='3894' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ReconfigurationProtocolProtos.java' sourcefile='ReconfigurationProtocolProtos.java'><Message>At ReconfigurationProtocolProtos.java:[lines 3393-3894]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$ListReconfigurablePropertiesResponseProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$ListReconfigurablePropertiesResponseProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$ListReconfigurablePropertiesResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ReconfigurationProtocolProtos.java' sourcefile='ReconfigurationProtocolProtos.java'><Message>In ReconfigurationProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$ListReconfigurablePropertiesResponseProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$ListReconfigurablePropertiesResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ReconfigurationProtocolProtos.java' sourcefile='ReconfigurationProtocolProtos.java'><Message>In ReconfigurationProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='e547567bcfb0e7a176e0159d6c0008fe' cweid='563' rank='20' abbrev='DLS' category='STYLE' priority='3' type='DLS_DEAD_LOCAL_STORE' instanceOccurrenceMax='0'><ShortMessage>Dead store to local variable</ShortMessage><LongMessage>Dead store to from_bitField0_ in org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$ListReconfigurablePropertiesResponseProto$Builder.buildPartial()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$ListReconfigurablePropertiesResponseProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$ListReconfigurablePropertiesResponseProto$Builder' start='3673' end='3885' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ReconfigurationProtocolProtos.java' sourcefile='ReconfigurationProtocolProtos.java'><Message>At ReconfigurationProtocolProtos.java:[lines 3673-3885]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$ListReconfigurablePropertiesResponseProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$ListReconfigurablePropertiesResponseProto$Builder' signature='()Lorg/apache/hadoop/hdfs/protocol/proto/ReconfigurationProtocolProtos$ListReconfigurablePropertiesResponseProto;' name='buildPartial' primary='true'><SourceLine endBytecode='36' classname='org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$ListReconfigurablePropertiesResponseProto$Builder' start='3735' end='3744' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ReconfigurationProtocolProtos.java' sourcefile='ReconfigurationProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$ListReconfigurablePropertiesResponseProto$Builder.buildPartial()</Message></Method><LocalVariable role='LOCAL_VARIABLE_NAMED' pc='15' name='from_bitField0_' register='2'><Message>Local variable named from_bitField0_</Message></LocalVariable><SourceLine endBytecode='14' classname='org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$ListReconfigurablePropertiesResponseProto$Builder' start='3736' end='3736' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ReconfigurationProtocolProtos.java' sourcefile='ReconfigurationProtocolProtos.java' startBytecode='14' primary='true'><Message>At ReconfigurationProtocolProtos.java:[line 3736]</Message></SourceLine><Property name='edu.umd.cs.findbugs.detect.DeadLocalStoreProperty.BASE_VALUE' value='true'></Property><Property name='edu.umd.cs.findbugs.detect.DeadLocalStoreProperty.CACHING_VALUE' value='true'></Property><Property name='edu.umd.cs.findbugs.detect.DeadLocalStoreProperty.LOCAL_NAME' value='from_bitField0_'></Property><Property name='edu.umd.cs.findbugs.detect.DeadLocalStoreProperty.NO_LOADS' value='true'></Property></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='8b4c4bc669856b9daed170be39ce276f' rank='17' abbrev='UCF' category='STYLE' priority='2' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$ListReconfigurablePropertiesResponseProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$ListReconfigurablePropertiesResponseProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$ListReconfigurablePropertiesResponseProto$Builder' start='3673' end='3885' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ReconfigurationProtocolProtos.java' sourcefile='ReconfigurationProtocolProtos.java'><Message>At ReconfigurationProtocolProtos.java:[lines 3673-3885]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$ListReconfigurablePropertiesResponseProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$ListReconfigurablePropertiesResponseProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine endBytecode='61' classname='org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$ListReconfigurablePropertiesResponseProto$Builder' start='3699' end='3701' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ReconfigurationProtocolProtos.java' sourcefile='ReconfigurationProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$ListReconfigurablePropertiesResponseProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$ListReconfigurablePropertiesResponseProto$Builder' start='3699' end='3699' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ReconfigurationProtocolProtos.java' sourcefile='ReconfigurationProtocolProtos.java' startBytecode='3' primary='true'><Message>At ReconfigurationProtocolProtos.java:[line 3699]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='499ff86fed6e828a5009b94a41992bc6' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$GetReconfigurationStatusRequestProto in org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$ReconfigurationProtocolService.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$ReconfigurationProtocolService' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$ReconfigurationProtocolService' start='3910' end='4212' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ReconfigurationProtocolProtos.java' sourcefile='ReconfigurationProtocolProtos.java'><Message>At ReconfigurationProtocolProtos.java:[lines 3910-4212]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$ReconfigurationProtocolService</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$ReconfigurationProtocolService' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/RpcCallback;)V' name='callMethod' primary='true'><SourceLine endBytecode='40' classname='org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$ReconfigurationProtocolService' start='4082' end='4104' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ReconfigurationProtocolProtos.java' sourcefile='ReconfigurationProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$ReconfigurationProtocolService.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ReconfigurationProtocolProtos$GetReconfigurationStatusRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$GetReconfigurationStatusRequestProto' start='705' end='1036' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ReconfigurationProtocolProtos.java' sourcefile='ReconfigurationProtocolProtos.java'><Message>At ReconfigurationProtocolProtos.java:[lines 705-1036]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$GetReconfigurationStatusRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='54' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='55' classname='org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$ReconfigurationProtocolService' start='4089' end='4089' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ReconfigurationProtocolProtos.java' sourcefile='ReconfigurationProtocolProtos.java' startBytecode='55' primary='true'><Message>At ReconfigurationProtocolProtos.java:[line 4089]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='137f4158c5279942b61d77c25ab17ea2' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$ListReconfigurablePropertiesRequestProto in org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$ReconfigurationProtocolService.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$ReconfigurationProtocolService' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$ReconfigurationProtocolService' start='3910' end='4212' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ReconfigurationProtocolProtos.java' sourcefile='ReconfigurationProtocolProtos.java'><Message>At ReconfigurationProtocolProtos.java:[lines 3910-4212]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$ReconfigurationProtocolService</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$ReconfigurationProtocolService' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/RpcCallback;)V' name='callMethod' primary='true'><SourceLine endBytecode='40' classname='org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$ReconfigurationProtocolService' start='4082' end='4104' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ReconfigurationProtocolProtos.java' sourcefile='ReconfigurationProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$ReconfigurationProtocolService.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ReconfigurationProtocolProtos$ListReconfigurablePropertiesRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$ListReconfigurablePropertiesRequestProto' start='3031' end='3362' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ReconfigurationProtocolProtos.java' sourcefile='ReconfigurationProtocolProtos.java'><Message>At ReconfigurationProtocolProtos.java:[lines 3031-3362]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$ListReconfigurablePropertiesRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='84' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='85' classname='org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$ReconfigurationProtocolService' start='4099' end='4099' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ReconfigurationProtocolProtos.java' sourcefile='ReconfigurationProtocolProtos.java' startBytecode='85' primary='true'><Message>At ReconfigurationProtocolProtos.java:[line 4099]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='f8f3a8d0af4c93ef54bebc4100a22b48' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$StartReconfigurationRequestProto in org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$ReconfigurationProtocolService.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$ReconfigurationProtocolService' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$ReconfigurationProtocolService' start='3910' end='4212' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ReconfigurationProtocolProtos.java' sourcefile='ReconfigurationProtocolProtos.java'><Message>At ReconfigurationProtocolProtos.java:[lines 3910-4212]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$ReconfigurationProtocolService</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$ReconfigurationProtocolService' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;Lcom/google/protobuf/RpcCallback;)V' name='callMethod' primary='true'><SourceLine endBytecode='40' classname='org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$ReconfigurationProtocolService' start='4082' end='4104' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ReconfigurationProtocolProtos.java' sourcefile='ReconfigurationProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$ReconfigurationProtocolService.callMethod(Descriptors$MethodDescriptor, RpcController, Message, RpcCallback)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ReconfigurationProtocolProtos$StartReconfigurationRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$StartReconfigurationRequestProto' start='21' end='352' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ReconfigurationProtocolProtos.java' sourcefile='ReconfigurationProtocolProtos.java'><Message>At ReconfigurationProtocolProtos.java:[lines 21-352]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$StartReconfigurationRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='69' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='70' classname='org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$ReconfigurationProtocolService' start='4094' end='4094' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ReconfigurationProtocolProtos.java' sourcefile='ReconfigurationProtocolProtos.java' startBytecode='70' primary='true'><Message>At ReconfigurationProtocolProtos.java:[line 4094]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='f19e1e10b6f202d62a7a3a705bd20d32' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$GetReconfigurationStatusRequestProto in org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$ReconfigurationProtocolService$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$ReconfigurationProtocolService$2' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$ReconfigurationProtocolService$2' start='3971' end='4035' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ReconfigurationProtocolProtos.java' sourcefile='ReconfigurationProtocolProtos.java'><Message>At ReconfigurationProtocolProtos.java:[lines 3971-4035]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$ReconfigurationProtocolService$2</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$ReconfigurationProtocolService$2' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;' name='callBlockingMethod' primary='true'><SourceLine endBytecode='37' classname='org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$ReconfigurationProtocolService$2' start='3982' end='3995' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ReconfigurationProtocolProtos.java' sourcefile='ReconfigurationProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$ReconfigurationProtocolService$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ReconfigurationProtocolProtos$GetReconfigurationStatusRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$GetReconfigurationStatusRequestProto' start='705' end='1036' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ReconfigurationProtocolProtos.java' sourcefile='ReconfigurationProtocolProtos.java'><Message>At ReconfigurationProtocolProtos.java:[lines 705-1036]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$GetReconfigurationStatusRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='57' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='58' classname='org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$ReconfigurationProtocolService$2' start='3989' end='3989' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ReconfigurationProtocolProtos.java' sourcefile='ReconfigurationProtocolProtos.java' startBytecode='58' primary='true'><Message>At ReconfigurationProtocolProtos.java:[line 3989]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='eba7ddae507468ebcc1d95663f9c0c09' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$ListReconfigurablePropertiesRequestProto in org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$ReconfigurationProtocolService$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$ReconfigurationProtocolService$2' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$ReconfigurationProtocolService$2' start='3971' end='4035' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ReconfigurationProtocolProtos.java' sourcefile='ReconfigurationProtocolProtos.java'><Message>At ReconfigurationProtocolProtos.java:[lines 3971-4035]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$ReconfigurationProtocolService$2</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$ReconfigurationProtocolService$2' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;' name='callBlockingMethod' primary='true'><SourceLine endBytecode='37' classname='org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$ReconfigurationProtocolService$2' start='3982' end='3995' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ReconfigurationProtocolProtos.java' sourcefile='ReconfigurationProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$ReconfigurationProtocolService$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ReconfigurationProtocolProtos$ListReconfigurablePropertiesRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$ListReconfigurablePropertiesRequestProto' start='3031' end='3362' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ReconfigurationProtocolProtos.java' sourcefile='ReconfigurationProtocolProtos.java'><Message>At ReconfigurationProtocolProtos.java:[lines 3031-3362]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$ListReconfigurablePropertiesRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='87' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='88' classname='org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$ReconfigurationProtocolService$2' start='3993' end='3993' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ReconfigurationProtocolProtos.java' sourcefile='ReconfigurationProtocolProtos.java' startBytecode='88' primary='true'><Message>At ReconfigurationProtocolProtos.java:[line 3993]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='618912694f8b84fb9c99b0f3b4e44ba2' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from com.google.protobuf.Message to org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$StartReconfigurationRequestProto in org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$ReconfigurationProtocolService$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$ReconfigurationProtocolService$2' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$ReconfigurationProtocolService$2' start='3971' end='4035' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ReconfigurationProtocolProtos.java' sourcefile='ReconfigurationProtocolProtos.java'><Message>At ReconfigurationProtocolProtos.java:[lines 3971-4035]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$ReconfigurationProtocolService$2</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$ReconfigurationProtocolService$2' signature='(Lcom/google/protobuf/Descriptors$MethodDescriptor;Lcom/google/protobuf/RpcController;Lcom/google/protobuf/Message;)Lcom/google/protobuf/Message;' name='callBlockingMethod' primary='true'><SourceLine endBytecode='37' classname='org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$ReconfigurationProtocolService$2' start='3982' end='3995' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ReconfigurationProtocolProtos.java' sourcefile='ReconfigurationProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$ReconfigurationProtocolService$2.callBlockingMethod(Descriptors$MethodDescriptor, RpcController, Message)</Message></Method><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/Message;'><SourceLine classname='com.google.protobuf.Message' sourcepath='com/google/protobuf/Message.java' sourcefile='Message.java'><Message>In Message.java</Message></SourceLine><Message>Actual type com.google.protobuf.Message</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/protocol/proto/ReconfigurationProtocolProtos$StartReconfigurationRequestProto;'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$StartReconfigurationRequestProto' start='21' end='352' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ReconfigurationProtocolProtos.java' sourcefile='ReconfigurationProtocolProtos.java'><Message>At ReconfigurationProtocolProtos.java:[lines 21-352]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$StartReconfigurationRequestProto</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='72' name='request' register='3'><Message>Value loaded from request</Message></LocalVariable><SourceLine endBytecode='73' classname='org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$ReconfigurationProtocolService$2' start='3991' end='3991' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ReconfigurationProtocolProtos.java' sourcefile='ReconfigurationProtocolProtos.java' startBytecode='73' primary='true'><Message>At ReconfigurationProtocolProtos.java:[line 3991]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='26a7f1015d0acb177b75b84e67f1dc86' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$StartReconfigurationRequestProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$StartReconfigurationRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$StartReconfigurationRequestProto' start='21' end='352' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ReconfigurationProtocolProtos.java' sourcefile='ReconfigurationProtocolProtos.java'><Message>At ReconfigurationProtocolProtos.java:[lines 21-352]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$StartReconfigurationRequestProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$StartReconfigurationRequestProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$StartReconfigurationRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ReconfigurationProtocolProtos.java' sourcefile='ReconfigurationProtocolProtos.java'><Message>In ReconfigurationProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$StartReconfigurationRequestProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$StartReconfigurationRequestProto' start='92' end='92' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ReconfigurationProtocolProtos.java' sourcefile='ReconfigurationProtocolProtos.java' startBytecode='7' primary='true'><Message>At ReconfigurationProtocolProtos.java:[line 92]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='4c7f4234324495b746a53857f4941c90' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$StartReconfigurationRequestProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$StartReconfigurationRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$StartReconfigurationRequestProto' start='21' end='352' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ReconfigurationProtocolProtos.java' sourcefile='ReconfigurationProtocolProtos.java'><Message>At ReconfigurationProtocolProtos.java:[lines 21-352]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$StartReconfigurationRequestProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$StartReconfigurationRequestProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$StartReconfigurationRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ReconfigurationProtocolProtos.java' sourcefile='ReconfigurationProtocolProtos.java'><Message>In ReconfigurationProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$StartReconfigurationRequestProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$StartReconfigurationRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ReconfigurationProtocolProtos.java' sourcefile='ReconfigurationProtocolProtos.java'><Message>In ReconfigurationProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='be4114ba04b5ee77390d1e880bac4ded' rank='17' abbrev='UCF' category='STYLE' priority='2' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$StartReconfigurationRequestProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$StartReconfigurationRequestProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$StartReconfigurationRequestProto$Builder' start='244' end='343' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ReconfigurationProtocolProtos.java' sourcefile='ReconfigurationProtocolProtos.java'><Message>At ReconfigurationProtocolProtos.java:[lines 244-343]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$StartReconfigurationRequestProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$StartReconfigurationRequestProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine endBytecode='61' classname='org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$StartReconfigurationRequestProto$Builder' start='270' end='272' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ReconfigurationProtocolProtos.java' sourcefile='ReconfigurationProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$StartReconfigurationRequestProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$StartReconfigurationRequestProto$Builder' start='270' end='270' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ReconfigurationProtocolProtos.java' sourcefile='ReconfigurationProtocolProtos.java' startBytecode='3' primary='true'><Message>At ReconfigurationProtocolProtos.java:[line 270]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='1113cd11449678afc54d692b682c8256' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$StartReconfigurationResponseProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$StartReconfigurationResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$StartReconfigurationResponseProto' start='363' end='690' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ReconfigurationProtocolProtos.java' sourcefile='ReconfigurationProtocolProtos.java'><Message>At ReconfigurationProtocolProtos.java:[lines 363-690]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$StartReconfigurationResponseProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$StartReconfigurationResponseProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$StartReconfigurationResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ReconfigurationProtocolProtos.java' sourcefile='ReconfigurationProtocolProtos.java'><Message>In ReconfigurationProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$StartReconfigurationResponseProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$StartReconfigurationResponseProto' start='434' end='434' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ReconfigurationProtocolProtos.java' sourcefile='ReconfigurationProtocolProtos.java' startBytecode='7' primary='true'><Message>At ReconfigurationProtocolProtos.java:[line 434]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='fc663ff957b6688bb9ef6cb530e138ee' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$StartReconfigurationResponseProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$StartReconfigurationResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$StartReconfigurationResponseProto' start='363' end='690' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ReconfigurationProtocolProtos.java' sourcefile='ReconfigurationProtocolProtos.java'><Message>At ReconfigurationProtocolProtos.java:[lines 363-690]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$StartReconfigurationResponseProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$StartReconfigurationResponseProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$StartReconfigurationResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ReconfigurationProtocolProtos.java' sourcefile='ReconfigurationProtocolProtos.java'><Message>In ReconfigurationProtocolProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$StartReconfigurationResponseProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$StartReconfigurationResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ReconfigurationProtocolProtos.java' sourcefile='ReconfigurationProtocolProtos.java'><Message>In ReconfigurationProtocolProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='4084ce8262e5a32a73065a14c0ba18c5' rank='17' abbrev='UCF' category='STYLE' priority='2' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$StartReconfigurationResponseProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$StartReconfigurationResponseProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$StartReconfigurationResponseProto$Builder' start='582' end='681' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ReconfigurationProtocolProtos.java' sourcefile='ReconfigurationProtocolProtos.java'><Message>At ReconfigurationProtocolProtos.java:[lines 582-681]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$StartReconfigurationResponseProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$StartReconfigurationResponseProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine endBytecode='61' classname='org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$StartReconfigurationResponseProto$Builder' start='608' end='610' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ReconfigurationProtocolProtos.java' sourcefile='ReconfigurationProtocolProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$StartReconfigurationResponseProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$StartReconfigurationResponseProto$Builder' start='608' end='608' sourcepath='org/apache/hadoop/hdfs/protocol/proto/ReconfigurationProtocolProtos.java' sourcefile='ReconfigurationProtocolProtos.java' startBytecode='3' primary='true'><Message>At ReconfigurationProtocolProtos.java:[line 608]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='31d70e2ee584b83806f12df6c5e1a2bc' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$GetXAttrsRequestProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$GetXAttrsRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$GetXAttrsRequestProto' start='2155' end='3001' sourcepath='org/apache/hadoop/hdfs/protocol/proto/XAttrProtos.java' sourcefile='XAttrProtos.java'><Message>At XAttrProtos.java:[lines 2155-3001]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$GetXAttrsRequestProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$GetXAttrsRequestProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$GetXAttrsRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/XAttrProtos.java' sourcefile='XAttrProtos.java'><Message>In XAttrProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$GetXAttrsRequestProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$GetXAttrsRequestProto' start='2243' end='2243' sourcepath='org/apache/hadoop/hdfs/protocol/proto/XAttrProtos.java' sourcefile='XAttrProtos.java' startBytecode='7' primary='true'><Message>At XAttrProtos.java:[line 2243]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='f1869f5c5eefb80af37f1a422c57dc9e' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$GetXAttrsRequestProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$GetXAttrsRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$GetXAttrsRequestProto' start='2155' end='3001' sourcepath='org/apache/hadoop/hdfs/protocol/proto/XAttrProtos.java' sourcefile='XAttrProtos.java'><Message>At XAttrProtos.java:[lines 2155-3001]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$GetXAttrsRequestProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$GetXAttrsRequestProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$GetXAttrsRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/XAttrProtos.java' sourcefile='XAttrProtos.java'><Message>In XAttrProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$GetXAttrsRequestProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$GetXAttrsRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/XAttrProtos.java' sourcefile='XAttrProtos.java'><Message>In XAttrProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='343f9a9ec76391a60fb7f11e0d11813e' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$GetXAttrsResponseProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$GetXAttrsResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$GetXAttrsResponseProto' start='3037' end='3722' sourcepath='org/apache/hadoop/hdfs/protocol/proto/XAttrProtos.java' sourcefile='XAttrProtos.java'><Message>At XAttrProtos.java:[lines 3037-3722]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$GetXAttrsResponseProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$GetXAttrsResponseProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$GetXAttrsResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/XAttrProtos.java' sourcefile='XAttrProtos.java'><Message>In XAttrProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$GetXAttrsResponseProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$GetXAttrsResponseProto' start='3120' end='3120' sourcepath='org/apache/hadoop/hdfs/protocol/proto/XAttrProtos.java' sourcefile='XAttrProtos.java' startBytecode='7' primary='true'><Message>At XAttrProtos.java:[line 3120]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='3de1a77d26e464a98bd209ca4f9907b6' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$GetXAttrsResponseProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$GetXAttrsResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$GetXAttrsResponseProto' start='3037' end='3722' sourcepath='org/apache/hadoop/hdfs/protocol/proto/XAttrProtos.java' sourcefile='XAttrProtos.java'><Message>At XAttrProtos.java:[lines 3037-3722]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$GetXAttrsResponseProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$GetXAttrsResponseProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$GetXAttrsResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/XAttrProtos.java' sourcefile='XAttrProtos.java'><Message>In XAttrProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$GetXAttrsResponseProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$GetXAttrsResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/XAttrProtos.java' sourcefile='XAttrProtos.java'><Message>In XAttrProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='cc005dce5558114894c7bd4cf3b2ff3' cweid='563' rank='20' abbrev='DLS' category='STYLE' priority='3' type='DLS_DEAD_LOCAL_STORE' instanceOccurrenceMax='0'><ShortMessage>Dead store to local variable</ShortMessage><LongMessage>Dead store to from_bitField0_ in org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$GetXAttrsResponseProto$Builder.buildPartial()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$GetXAttrsResponseProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$GetXAttrsResponseProto$Builder' start='3324' end='3713' sourcepath='org/apache/hadoop/hdfs/protocol/proto/XAttrProtos.java' sourcefile='XAttrProtos.java'><Message>At XAttrProtos.java:[lines 3324-3713]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$GetXAttrsResponseProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$GetXAttrsResponseProto$Builder' signature='()Lorg/apache/hadoop/hdfs/protocol/proto/XAttrProtos$GetXAttrsResponseProto;' name='buildPartial' primary='true'><SourceLine endBytecode='44' classname='org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$GetXAttrsResponseProto$Builder' start='3391' end='3403' sourcepath='org/apache/hadoop/hdfs/protocol/proto/XAttrProtos.java' sourcefile='XAttrProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$GetXAttrsResponseProto$Builder.buildPartial()</Message></Method><LocalVariable role='LOCAL_VARIABLE_NAMED' pc='15' name='from_bitField0_' register='2'><Message>Local variable named from_bitField0_</Message></LocalVariable><SourceLine endBytecode='14' classname='org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$GetXAttrsResponseProto$Builder' start='3392' end='3392' sourcepath='org/apache/hadoop/hdfs/protocol/proto/XAttrProtos.java' sourcefile='XAttrProtos.java' startBytecode='14' primary='true'><Message>At XAttrProtos.java:[line 3392]</Message></SourceLine><Property name='edu.umd.cs.findbugs.detect.DeadLocalStoreProperty.BASE_VALUE' value='true'></Property><Property name='edu.umd.cs.findbugs.detect.DeadLocalStoreProperty.CACHING_VALUE' value='true'></Property><Property name='edu.umd.cs.findbugs.detect.DeadLocalStoreProperty.LOCAL_NAME' value='from_bitField0_'></Property><Property name='edu.umd.cs.findbugs.detect.DeadLocalStoreProperty.NO_LOADS' value='true'></Property></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='b1b297f4301f759e82d11eac398b83c8' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$ListXAttrsRequestProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$ListXAttrsRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$ListXAttrsRequestProto' start='3748' end='4239' sourcepath='org/apache/hadoop/hdfs/protocol/proto/XAttrProtos.java' sourcefile='XAttrProtos.java'><Message>At XAttrProtos.java:[lines 3748-4239]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$ListXAttrsRequestProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$ListXAttrsRequestProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$ListXAttrsRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/XAttrProtos.java' sourcefile='XAttrProtos.java'><Message>In XAttrProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$ListXAttrsRequestProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$ListXAttrsRequestProto' start='3825' end='3825' sourcepath='org/apache/hadoop/hdfs/protocol/proto/XAttrProtos.java' sourcefile='XAttrProtos.java' startBytecode='7' primary='true'><Message>At XAttrProtos.java:[line 3825]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='7fcd9e990c36d33a21b7a210f3a4965e' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$ListXAttrsRequestProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$ListXAttrsRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$ListXAttrsRequestProto' start='3748' end='4239' sourcepath='org/apache/hadoop/hdfs/protocol/proto/XAttrProtos.java' sourcefile='XAttrProtos.java'><Message>At XAttrProtos.java:[lines 3748-4239]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$ListXAttrsRequestProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$ListXAttrsRequestProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$ListXAttrsRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/XAttrProtos.java' sourcefile='XAttrProtos.java'><Message>In XAttrProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$ListXAttrsRequestProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$ListXAttrsRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/XAttrProtos.java' sourcefile='XAttrProtos.java'><Message>In XAttrProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='df12f1d35eff83691486d6c20fb0c5b9' rank='17' abbrev='UCF' category='STYLE' priority='2' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$ListXAttrsRequestProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$ListXAttrsRequestProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$ListXAttrsRequestProto$Builder' start='4038' end='4230' sourcepath='org/apache/hadoop/hdfs/protocol/proto/XAttrProtos.java' sourcefile='XAttrProtos.java'><Message>At XAttrProtos.java:[lines 4038-4230]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$ListXAttrsRequestProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$ListXAttrsRequestProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine endBytecode='61' classname='org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$ListXAttrsRequestProto$Builder' start='4064' end='4066' sourcepath='org/apache/hadoop/hdfs/protocol/proto/XAttrProtos.java' sourcefile='XAttrProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$ListXAttrsRequestProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$ListXAttrsRequestProto$Builder' start='4064' end='4064' sourcepath='org/apache/hadoop/hdfs/protocol/proto/XAttrProtos.java' sourcefile='XAttrProtos.java' startBytecode='3' primary='true'><Message>At XAttrProtos.java:[line 4064]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='f55512c7d05569ddc08bc37c56ee46ac' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$ListXAttrsResponseProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$ListXAttrsResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$ListXAttrsResponseProto' start='4275' end='4960' sourcepath='org/apache/hadoop/hdfs/protocol/proto/XAttrProtos.java' sourcefile='XAttrProtos.java'><Message>At XAttrProtos.java:[lines 4275-4960]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$ListXAttrsResponseProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$ListXAttrsResponseProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$ListXAttrsResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/XAttrProtos.java' sourcefile='XAttrProtos.java'><Message>In XAttrProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$ListXAttrsResponseProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$ListXAttrsResponseProto' start='4358' end='4358' sourcepath='org/apache/hadoop/hdfs/protocol/proto/XAttrProtos.java' sourcefile='XAttrProtos.java' startBytecode='7' primary='true'><Message>At XAttrProtos.java:[line 4358]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='3bf550bbee59eb231ae0d884610f046e' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$ListXAttrsResponseProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$ListXAttrsResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$ListXAttrsResponseProto' start='4275' end='4960' sourcepath='org/apache/hadoop/hdfs/protocol/proto/XAttrProtos.java' sourcefile='XAttrProtos.java'><Message>At XAttrProtos.java:[lines 4275-4960]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$ListXAttrsResponseProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$ListXAttrsResponseProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$ListXAttrsResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/XAttrProtos.java' sourcefile='XAttrProtos.java'><Message>In XAttrProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$ListXAttrsResponseProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$ListXAttrsResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/XAttrProtos.java' sourcefile='XAttrProtos.java'><Message>In XAttrProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='3caa2cb548b66be4ef5eaaf9f4e77bc4' cweid='563' rank='20' abbrev='DLS' category='STYLE' priority='3' type='DLS_DEAD_LOCAL_STORE' instanceOccurrenceMax='0'><ShortMessage>Dead store to local variable</ShortMessage><LongMessage>Dead store to from_bitField0_ in org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$ListXAttrsResponseProto$Builder.buildPartial()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$ListXAttrsResponseProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$ListXAttrsResponseProto$Builder' start='4562' end='4951' sourcepath='org/apache/hadoop/hdfs/protocol/proto/XAttrProtos.java' sourcefile='XAttrProtos.java'><Message>At XAttrProtos.java:[lines 4562-4951]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$ListXAttrsResponseProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$ListXAttrsResponseProto$Builder' signature='()Lorg/apache/hadoop/hdfs/protocol/proto/XAttrProtos$ListXAttrsResponseProto;' name='buildPartial' primary='true'><SourceLine endBytecode='44' classname='org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$ListXAttrsResponseProto$Builder' start='4629' end='4641' sourcepath='org/apache/hadoop/hdfs/protocol/proto/XAttrProtos.java' sourcefile='XAttrProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$ListXAttrsResponseProto$Builder.buildPartial()</Message></Method><LocalVariable role='LOCAL_VARIABLE_NAMED' pc='15' name='from_bitField0_' register='2'><Message>Local variable named from_bitField0_</Message></LocalVariable><SourceLine endBytecode='14' classname='org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$ListXAttrsResponseProto$Builder' start='4630' end='4630' sourcepath='org/apache/hadoop/hdfs/protocol/proto/XAttrProtos.java' sourcefile='XAttrProtos.java' startBytecode='14' primary='true'><Message>At XAttrProtos.java:[line 4630]</Message></SourceLine><Property name='edu.umd.cs.findbugs.detect.DeadLocalStoreProperty.BASE_VALUE' value='true'></Property><Property name='edu.umd.cs.findbugs.detect.DeadLocalStoreProperty.CACHING_VALUE' value='true'></Property><Property name='edu.umd.cs.findbugs.detect.DeadLocalStoreProperty.LOCAL_NAME' value='from_bitField0_'></Property><Property name='edu.umd.cs.findbugs.detect.DeadLocalStoreProperty.NO_LOADS' value='true'></Property></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='b2b072504f519cf245c370ff02294444' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$RemoveXAttrRequestProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$RemoveXAttrRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$RemoveXAttrRequestProto' start='5000' end='5690' sourcepath='org/apache/hadoop/hdfs/protocol/proto/XAttrProtos.java' sourcefile='XAttrProtos.java'><Message>At XAttrProtos.java:[lines 5000-5690]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$RemoveXAttrRequestProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$RemoveXAttrRequestProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$RemoveXAttrRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/XAttrProtos.java' sourcefile='XAttrProtos.java'><Message>In XAttrProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$RemoveXAttrRequestProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$RemoveXAttrRequestProto' start='5090' end='5090' sourcepath='org/apache/hadoop/hdfs/protocol/proto/XAttrProtos.java' sourcefile='XAttrProtos.java' startBytecode='7' primary='true'><Message>At XAttrProtos.java:[line 5090]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='3bb3137c3f716a5cad0bbfea2bf5e1e1' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$RemoveXAttrRequestProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$RemoveXAttrRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$RemoveXAttrRequestProto' start='5000' end='5690' sourcepath='org/apache/hadoop/hdfs/protocol/proto/XAttrProtos.java' sourcefile='XAttrProtos.java'><Message>At XAttrProtos.java:[lines 5000-5690]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$RemoveXAttrRequestProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$RemoveXAttrRequestProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$RemoveXAttrRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/XAttrProtos.java' sourcefile='XAttrProtos.java'><Message>In XAttrProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$RemoveXAttrRequestProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$RemoveXAttrRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/XAttrProtos.java' sourcefile='XAttrProtos.java'><Message>In XAttrProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='2e0827e350d9f2fcba8bb0cd26c117c2' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$RemoveXAttrResponseProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$RemoveXAttrResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$RemoveXAttrResponseProto' start='5701' end='6028' sourcepath='org/apache/hadoop/hdfs/protocol/proto/XAttrProtos.java' sourcefile='XAttrProtos.java'><Message>At XAttrProtos.java:[lines 5701-6028]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$RemoveXAttrResponseProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$RemoveXAttrResponseProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$RemoveXAttrResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/XAttrProtos.java' sourcefile='XAttrProtos.java'><Message>In XAttrProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$RemoveXAttrResponseProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$RemoveXAttrResponseProto' start='5772' end='5772' sourcepath='org/apache/hadoop/hdfs/protocol/proto/XAttrProtos.java' sourcefile='XAttrProtos.java' startBytecode='7' primary='true'><Message>At XAttrProtos.java:[line 5772]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='715e83daeb70fb1848d96127f155c0fb' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$RemoveXAttrResponseProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$RemoveXAttrResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$RemoveXAttrResponseProto' start='5701' end='6028' sourcepath='org/apache/hadoop/hdfs/protocol/proto/XAttrProtos.java' sourcefile='XAttrProtos.java'><Message>At XAttrProtos.java:[lines 5701-6028]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$RemoveXAttrResponseProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$RemoveXAttrResponseProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$RemoveXAttrResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/XAttrProtos.java' sourcefile='XAttrProtos.java'><Message>In XAttrProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$RemoveXAttrResponseProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$RemoveXAttrResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/XAttrProtos.java' sourcefile='XAttrProtos.java'><Message>In XAttrProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='3c2f993d97c7b2a17979883d886ae063' rank='17' abbrev='UCF' category='STYLE' priority='2' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$RemoveXAttrResponseProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$RemoveXAttrResponseProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$RemoveXAttrResponseProto$Builder' start='5920' end='6019' sourcepath='org/apache/hadoop/hdfs/protocol/proto/XAttrProtos.java' sourcefile='XAttrProtos.java'><Message>At XAttrProtos.java:[lines 5920-6019]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$RemoveXAttrResponseProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$RemoveXAttrResponseProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine endBytecode='61' classname='org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$RemoveXAttrResponseProto$Builder' start='5946' end='5948' sourcepath='org/apache/hadoop/hdfs/protocol/proto/XAttrProtos.java' sourcefile='XAttrProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$RemoveXAttrResponseProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$RemoveXAttrResponseProto$Builder' start='5946' end='5946' sourcepath='org/apache/hadoop/hdfs/protocol/proto/XAttrProtos.java' sourcefile='XAttrProtos.java' startBytecode='3' primary='true'><Message>At XAttrProtos.java:[line 5946]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='79e10b95d6adae6730b8f6d4473b1349' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$SetXAttrRequestProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$SetXAttrRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$SetXAttrRequestProto' start='972' end='1766' sourcepath='org/apache/hadoop/hdfs/protocol/proto/XAttrProtos.java' sourcefile='XAttrProtos.java'><Message>At XAttrProtos.java:[lines 972-1766]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$SetXAttrRequestProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$SetXAttrRequestProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$SetXAttrRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/XAttrProtos.java' sourcefile='XAttrProtos.java'><Message>In XAttrProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$SetXAttrRequestProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$SetXAttrRequestProto' start='1067' end='1067' sourcepath='org/apache/hadoop/hdfs/protocol/proto/XAttrProtos.java' sourcefile='XAttrProtos.java' startBytecode='7' primary='true'><Message>At XAttrProtos.java:[line 1067]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='84b53bd22d225f4666ef38aa0462bc89' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$SetXAttrRequestProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$SetXAttrRequestProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$SetXAttrRequestProto' start='972' end='1766' sourcepath='org/apache/hadoop/hdfs/protocol/proto/XAttrProtos.java' sourcefile='XAttrProtos.java'><Message>At XAttrProtos.java:[lines 972-1766]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$SetXAttrRequestProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$SetXAttrRequestProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$SetXAttrRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/XAttrProtos.java' sourcefile='XAttrProtos.java'><Message>In XAttrProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$SetXAttrRequestProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$SetXAttrRequestProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/XAttrProtos.java' sourcefile='XAttrProtos.java'><Message>In XAttrProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='70cae16cd8bc1cb313d82166404e7754' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$SetXAttrResponseProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$SetXAttrResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$SetXAttrResponseProto' start='1777' end='2104' sourcepath='org/apache/hadoop/hdfs/protocol/proto/XAttrProtos.java' sourcefile='XAttrProtos.java'><Message>At XAttrProtos.java:[lines 1777-2104]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$SetXAttrResponseProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$SetXAttrResponseProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$SetXAttrResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/XAttrProtos.java' sourcefile='XAttrProtos.java'><Message>In XAttrProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$SetXAttrResponseProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$SetXAttrResponseProto' start='1848' end='1848' sourcepath='org/apache/hadoop/hdfs/protocol/proto/XAttrProtos.java' sourcefile='XAttrProtos.java' startBytecode='7' primary='true'><Message>At XAttrProtos.java:[line 1848]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='584c9d52b2c36a4d76341b019657cb4b' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$SetXAttrResponseProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$SetXAttrResponseProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$SetXAttrResponseProto' start='1777' end='2104' sourcepath='org/apache/hadoop/hdfs/protocol/proto/XAttrProtos.java' sourcefile='XAttrProtos.java'><Message>At XAttrProtos.java:[lines 1777-2104]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$SetXAttrResponseProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$SetXAttrResponseProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$SetXAttrResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/XAttrProtos.java' sourcefile='XAttrProtos.java'><Message>In XAttrProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$SetXAttrResponseProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$SetXAttrResponseProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/XAttrProtos.java' sourcefile='XAttrProtos.java'><Message>In XAttrProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='ba71250e27ec08a1fd079046d2a4526c' rank='17' abbrev='UCF' category='STYLE' priority='2' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$SetXAttrResponseProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$SetXAttrResponseProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$SetXAttrResponseProto$Builder' start='1996' end='2095' sourcepath='org/apache/hadoop/hdfs/protocol/proto/XAttrProtos.java' sourcefile='XAttrProtos.java'><Message>At XAttrProtos.java:[lines 1996-2095]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$SetXAttrResponseProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$SetXAttrResponseProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine endBytecode='61' classname='org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$SetXAttrResponseProto$Builder' start='2022' end='2024' sourcepath='org/apache/hadoop/hdfs/protocol/proto/XAttrProtos.java' sourcefile='XAttrProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$SetXAttrResponseProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$SetXAttrResponseProto$Builder' start='2022' end='2022' sourcepath='org/apache/hadoop/hdfs/protocol/proto/XAttrProtos.java' sourcefile='XAttrProtos.java' startBytecode='3' primary='true'><Message>At XAttrProtos.java:[line 2022]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='49b5fc1f37e96585c63c0debd3ecf17b' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$XAttrProto.PARSER isn't final but should be</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$XAttrProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$XAttrProto' start='134' end='914' sourcepath='org/apache/hadoop/hdfs/protocol/proto/XAttrProtos.java' sourcefile='XAttrProtos.java'><Message>At XAttrProtos.java:[lines 134-914]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$XAttrProto</Message></Class><Field isStatic='true' classname='org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$XAttrProto' signature='Lcom/google/protobuf/Parser;' name='PARSER' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$XAttrProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/XAttrProtos.java' sourcefile='XAttrProtos.java'><Message>In XAttrProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$XAttrProto.PARSER</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$XAttrProto' start='227' end='227' sourcepath='org/apache/hadoop/hdfs/protocol/proto/XAttrProtos.java' sourcefile='XAttrProtos.java' startBytecode='7' primary='true'><Message>At XAttrProtos.java:[line 227]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='1e2a20a584d4c8b26e38d96b51afd8d' rank='16' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$XAttrProto defines non-transient non-serializable instance field unknownFields</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$XAttrProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$XAttrProto' start='134' end='914' sourcepath='org/apache/hadoop/hdfs/protocol/proto/XAttrProtos.java' sourcefile='XAttrProtos.java'><Message>At XAttrProtos.java:[lines 134-914]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$XAttrProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$XAttrProto' signature='Lcom/google/protobuf/UnknownFieldSet;' name='unknownFields' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$XAttrProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/XAttrProtos.java' sourcefile='XAttrProtos.java'><Message>In XAttrProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$XAttrProto.unknownFields</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/UnknownFieldSet;'><SourceLine classname='com.google.protobuf.UnknownFieldSet' start='59' end='976' sourcepath='com/google/protobuf/UnknownFieldSet.java' sourcefile='UnknownFieldSet.java'><Message>At UnknownFieldSet.java:[lines 59-976]</Message></SourceLine><Message>Actual type com.google.protobuf.UnknownFieldSet</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$XAttrProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/XAttrProtos.java' sourcefile='XAttrProtos.java'><Message>In XAttrProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='8d587e4e19963428454d89ea2abf0df7' rank='19' abbrev='Se' category='BAD_PRACTICE' priority='3' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$XAttrProto defines non-transient non-serializable instance field value_</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$XAttrProto' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$XAttrProto' start='134' end='914' sourcepath='org/apache/hadoop/hdfs/protocol/proto/XAttrProtos.java' sourcefile='XAttrProtos.java'><Message>At XAttrProtos.java:[lines 134-914]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$XAttrProto</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$XAttrProto' signature='Lcom/google/protobuf/ByteString;' name='value_' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$XAttrProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/XAttrProtos.java' sourcefile='XAttrProtos.java'><Message>In XAttrProtos.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$XAttrProto.value_</Message></Field><Type role='TYPE_FOUND' descriptor='Lcom/google/protobuf/ByteString;'><SourceLine classname='com.google.protobuf.ByteString' start='60' end='967' sourcepath='com/google/protobuf/ByteString.java' sourcefile='ByteString.java'><Message>At ByteString.java:[lines 60-967]</Message></SourceLine><Message>Actual type com.google.protobuf.ByteString</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$XAttrProto' sourcepath='org/apache/hadoop/hdfs/protocol/proto/XAttrProtos.java' sourcefile='XAttrProtos.java'><Message>In XAttrProtos.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='1973a5a6fb59e14cd9e65f47c0efb1a1' rank='17' abbrev='UCF' category='STYLE' priority='2' type='UCF_USELESS_CONTROL_FLOW' instanceOccurrenceMax='0'><ShortMessage>Useless control flow</ShortMessage><LongMessage>Useless control flow in org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$XAttrProto$Builder.maybeForceBuilderInitialization()</LongMessage><Class classname='org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$XAttrProto$Builder' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$XAttrProto$Builder' start='619' end='905' sourcepath='org/apache/hadoop/hdfs/protocol/proto/XAttrProtos.java' sourcefile='XAttrProtos.java'><Message>At XAttrProtos.java:[lines 619-905]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$XAttrProto$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$XAttrProto$Builder' signature='()V' name='maybeForceBuilderInitialization' primary='true'><SourceLine endBytecode='61' classname='org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$XAttrProto$Builder' start='645' end='647' sourcepath='org/apache/hadoop/hdfs/protocol/proto/XAttrProtos.java' sourcefile='XAttrProtos.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$XAttrProto$Builder.maybeForceBuilderInitialization()</Message></Method><SourceLine endBytecode='3' classname='org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$XAttrProto$Builder' start='645' end='645' sourcepath='org/apache/hadoop/hdfs/protocol/proto/XAttrProtos.java' sourcefile='XAttrProtos.java' startBytecode='3' primary='true'><Message>At XAttrProtos.java:[line 645]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='69360a6b0fa30c71fd579e2f9c0bafb0' rank='20' abbrev='PZLA' category='STYLE' priority='3' type='PZLA_PREFER_ZERO_LENGTH_ARRAYS' instanceOccurrenceMax='0'><ShortMessage>Consider returning a zero length array rather than null</ShortMessage><LongMessage>Should org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.getSnapshottableDirListing() return a zero length array rather than null?</LongMessage><Class classname='org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB' start='255' end='1943' sourcepath='org/apache/hadoop/hdfs/protocolPB/ClientNamenodeProtocolTranslatorPB.java' sourcefile='ClientNamenodeProtocolTranslatorPB.java'><Message>At ClientNamenodeProtocolTranslatorPB.java:[lines 255-1943]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB' signature='()[Lorg/apache/hadoop/hdfs/protocol/SnapshottableDirectoryStatus;' name='getSnapshottableDirListing' primary='true'><SourceLine endBytecode='190' classname='org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB' start='1223' end='1233' sourcepath='org/apache/hadoop/hdfs/protocolPB/ClientNamenodeProtocolTranslatorPB.java' sourcefile='ClientNamenodeProtocolTranslatorPB.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.getSnapshottableDirListing()</Message></Method><SourceLine endBytecode='35' classname='org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB' start='1231' end='1231' sourcepath='org/apache/hadoop/hdfs/protocolPB/ClientNamenodeProtocolTranslatorPB.java' sourcefile='ClientNamenodeProtocolTranslatorPB.java' startBytecode='35' primary='true'><Message>At ClientNamenodeProtocolTranslatorPB.java:[line 1231]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='c9fe8d330d26a301162a28c6cc61b5d1' rank='20' abbrev='SIC' category='PERFORMANCE' priority='3' type='SIC_INNER_SHOULD_BE_STATIC_ANON' instanceOccurrenceMax='0'><ShortMessage>Could be refactored into a named static inner class</ShortMessage><LongMessage>The class org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB$1 could be refactored into a named _static_ inner class</LongMessage><Class role='CLASS_ANONYMOUS' classname='org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB$1'><SourceLine classname='org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB$1' start='441' end='450' sourcepath='org/apache/hadoop/hdfs/protocolPB/ClientNamenodeProtocolTranslatorPB.java' sourcefile='ClientNamenodeProtocolTranslatorPB.java'><Message>At ClientNamenodeProtocolTranslatorPB.java:[lines 441-450]</Message></SourceLine><Message>Anonymous class org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB$1</Message></Class><Class classname='org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB' start='255' end='1943' sourcepath='org/apache/hadoop/hdfs/protocolPB/ClientNamenodeProtocolTranslatorPB.java' sourcefile='ClientNamenodeProtocolTranslatorPB.java'><Message>At ClientNamenodeProtocolTranslatorPB.java:[lines 255-1943]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB' signature='()V' name='setAsyncReturnValue' primary='true'><SourceLine endBytecode='120' classname='org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB' start='439' end='454' sourcepath='org/apache/hadoop/hdfs/protocolPB/ClientNamenodeProtocolTranslatorPB.java' sourcefile='ClientNamenodeProtocolTranslatorPB.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.setAsyncReturnValue()</Message></Method><SourceLine endBytecode='10' classname='org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB' start='440' end='440' sourcepath='org/apache/hadoop/hdfs/protocolPB/ClientNamenodeProtocolTranslatorPB.java' sourcefile='ClientNamenodeProtocolTranslatorPB.java' startBytecode='10' primary='true'><Message>At ClientNamenodeProtocolTranslatorPB.java:[line 440]</Message></SourceLine><LocalVariable role='LOCAL_VARIABLE_NAMED' pc='14' name='asyncGet' register='2'><Message>Local variable named asyncGet</Message></LocalVariable></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='9e48367d30d9cdde3f3b42a81d8d24a4' rank='20' abbrev='SIC' category='PERFORMANCE' priority='3' type='SIC_INNER_SHOULD_BE_STATIC_ANON' instanceOccurrenceMax='0'><ShortMessage>Could be refactored into a named static inner class</ShortMessage><LongMessage>The class org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB$2 could be refactored into a named _static_ inner class</LongMessage><Class role='CLASS_ANONYMOUS' classname='org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB$2'><SourceLine classname='org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB$2' start='1510' end='1519' sourcepath='org/apache/hadoop/hdfs/protocolPB/ClientNamenodeProtocolTranslatorPB.java' sourcefile='ClientNamenodeProtocolTranslatorPB.java'><Message>At ClientNamenodeProtocolTranslatorPB.java:[lines 1510-1519]</Message></SourceLine><Message>Anonymous class org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB$2</Message></Class><Class classname='org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB' start='255' end='1943' sourcepath='org/apache/hadoop/hdfs/protocolPB/ClientNamenodeProtocolTranslatorPB.java' sourcefile='ClientNamenodeProtocolTranslatorPB.java'><Message>At ClientNamenodeProtocolTranslatorPB.java:[lines 255-1943]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB' signature='(Ljava/lang/String;)Lorg/apache/hadoop/fs/permission/AclStatus;' name='getAclStatus' primary='true'><SourceLine endBytecode='265' classname='org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB' start='1502' end='1528' sourcepath='org/apache/hadoop/hdfs/protocolPB/ClientNamenodeProtocolTranslatorPB.java' sourcefile='ClientNamenodeProtocolTranslatorPB.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.getAclStatus(String)</Message></Method><SourceLine endBytecode='39' classname='org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB' start='1509' end='1509' sourcepath='org/apache/hadoop/hdfs/protocolPB/ClientNamenodeProtocolTranslatorPB.java' sourcefile='ClientNamenodeProtocolTranslatorPB.java' startBytecode='39' primary='true'><Message>At ClientNamenodeProtocolTranslatorPB.java:[line 1509]</Message></SourceLine><LocalVariable role='LOCAL_VARIABLE_NAMED' pc='44' name='asyncGet' register='4'><Message>Local variable named asyncGet</Message></LocalVariable></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='c82bca5bfd153642ca0f334c06aa1bb0' rank='14' abbrev='AT' category='MT_CORRECTNESS' priority='2' type='AT_OPERATION_SEQUENCE_ON_CONCURRENT_ABSTRACTION' instanceOccurrenceMax='0'><ShortMessage>Sequence of calls to concurrent abstraction may not be atomic</ShortMessage><LongMessage>Sequence of calls to java.util.concurrent.ConcurrentHashMap may not be atomic in org.apache.hadoop.hdfs.protocolPB.PBHelperClient.getFixedByteString(String)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocolPB.PBHelperClient' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocolPB.PBHelperClient' start='225' end='3378' sourcepath='org/apache/hadoop/hdfs/protocolPB/PBHelperClient.java' sourcefile='PBHelperClient.java'><Message>At PBHelperClient.java:[lines 225-3378]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocolPB.PBHelperClient</Message></Class><Method isStatic='true' classname='org.apache.hadoop.hdfs.protocolPB.PBHelperClient' signature='(Ljava/lang/String;)Lcom/google/protobuf/ByteString;' name='getFixedByteString' primary='true'><SourceLine endBytecode='112' classname='org.apache.hadoop.hdfs.protocolPB.PBHelperClient' start='256' end='261' sourcepath='org/apache/hadoop/hdfs/protocolPB/PBHelperClient.java' sourcefile='PBHelperClient.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocolPB.PBHelperClient.getFixedByteString(String)</Message></Method><Type descriptor='Ljava/util/concurrent/ConcurrentHashMap;'><SourceLine classname='java.util.concurrent.ConcurrentHashMap' start='267' end='6311' sourcepath='java/util/concurrent/ConcurrentHashMap.java' sourcefile='ConcurrentHashMap.java'><Message>At ConcurrentHashMap.java:[lines 267-6311]</Message></SourceLine><Message>Type java.util.concurrent.ConcurrentHashMap</Message></Type><Method isStatic='false' role='METHOD_CALLED' classname='java.util.concurrent.ConcurrentHashMap' signature='(Ljava/lang/Object;Ljava/lang/Object;)Ljava/lang/Object;' name='put'><SourceLine endBytecode='31' classname='java.util.concurrent.ConcurrentHashMap' start='1006' end='1006' sourcepath='java/util/concurrent/ConcurrentHashMap.java' sourcefile='ConcurrentHashMap.java' startBytecode='0'></SourceLine><Message>Called method java.util.concurrent.ConcurrentHashMap.put(Object, Object)</Message></Method><SourceLine endBytecode='25' classname='org.apache.hadoop.hdfs.protocolPB.PBHelperClient' start='259' end='259' sourcepath='org/apache/hadoop/hdfs/protocolPB/PBHelperClient.java' sourcefile='PBHelperClient.java' startBytecode='25' primary='true'><Message>At PBHelperClient.java:[line 259]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='9730d5d054393fc6655376ef77a995c7' rank='14' abbrev='AT' category='MT_CORRECTNESS' priority='2' type='AT_OPERATION_SEQUENCE_ON_CONCURRENT_ABSTRACTION' instanceOccurrenceMax='0'><ShortMessage>Sequence of calls to concurrent abstraction may not be atomic</ShortMessage><LongMessage>Sequence of calls to java.util.concurrent.ConcurrentHashMap may not be atomic in org.apache.hadoop.hdfs.protocolPB.PBHelperClient.getFixedByteString(Text)</LongMessage><Class classname='org.apache.hadoop.hdfs.protocolPB.PBHelperClient' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocolPB.PBHelperClient' start='225' end='3378' sourcepath='org/apache/hadoop/hdfs/protocolPB/PBHelperClient.java' sourcefile='PBHelperClient.java'><Message>At PBHelperClient.java:[lines 225-3378]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocolPB.PBHelperClient</Message></Class><Method isStatic='true' classname='org.apache.hadoop.hdfs.protocolPB.PBHelperClient' signature='(Lorg/apache/hadoop/io/Text;)Lcom/google/protobuf/ByteString;' name='getFixedByteString' primary='true'><SourceLine endBytecode='125' classname='org.apache.hadoop.hdfs.protocolPB.PBHelperClient' start='247' end='252' sourcepath='org/apache/hadoop/hdfs/protocolPB/PBHelperClient.java' sourcefile='PBHelperClient.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocolPB.PBHelperClient.getFixedByteString(Text)</Message></Method><Type descriptor='Ljava/util/concurrent/ConcurrentHashMap;'><SourceLine classname='java.util.concurrent.ConcurrentHashMap' start='267' end='6311' sourcepath='java/util/concurrent/ConcurrentHashMap.java' sourcefile='ConcurrentHashMap.java'><Message>At ConcurrentHashMap.java:[lines 267-6311]</Message></SourceLine><Message>Type java.util.concurrent.ConcurrentHashMap</Message></Type><Method isStatic='false' role='METHOD_CALLED' classname='java.util.concurrent.ConcurrentHashMap' signature='(Ljava/lang/Object;Ljava/lang/Object;)Ljava/lang/Object;' name='put'><SourceLine endBytecode='31' classname='java.util.concurrent.ConcurrentHashMap' start='1006' end='1006' sourcepath='java/util/concurrent/ConcurrentHashMap.java' sourcefile='ConcurrentHashMap.java' startBytecode='0'></SourceLine><Message>Called method java.util.concurrent.ConcurrentHashMap.put(Object, Object)</Message></Method><SourceLine endBytecode='38' classname='org.apache.hadoop.hdfs.protocolPB.PBHelperClient' start='250' end='250' sourcepath='org/apache/hadoop/hdfs/protocolPB/PBHelperClient.java' sourcefile='PBHelperClient.java' startBytecode='38' primary='true'><Message>At PBHelperClient.java:[line 250]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='687d52d6370f2a74fd4fed4925a01a92' rank='20' abbrev='PZLA' category='STYLE' priority='3' type='PZLA_PREFER_ZERO_LENGTH_ARRAYS' instanceOccurrenceMax='0'><ShortMessage>Consider returning a zero length array rather than null</ShortMessage><LongMessage>Should org.apache.hadoop.hdfs.protocolPB.PBHelperClient.convert(HdfsProtos$SnapshottableDirectoryListingProto) return a zero length array rather than null?</LongMessage><Class classname='org.apache.hadoop.hdfs.protocolPB.PBHelperClient' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocolPB.PBHelperClient' start='225' end='3378' sourcepath='org/apache/hadoop/hdfs/protocolPB/PBHelperClient.java' sourcefile='PBHelperClient.java'><Message>At PBHelperClient.java:[lines 225-3378]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocolPB.PBHelperClient</Message></Class><Method isStatic='true' classname='org.apache.hadoop.hdfs.protocolPB.PBHelperClient' signature='(Lorg/apache/hadoop/hdfs/protocol/proto/HdfsProtos$SnapshottableDirectoryListingProto;)[Lorg/apache/hadoop/hdfs/protocol/SnapshottableDirectoryStatus;' name='convert' primary='true'><SourceLine endBytecode='229' classname='org.apache.hadoop.hdfs.protocolPB.PBHelperClient' start='1652' end='1664' sourcepath='org/apache/hadoop/hdfs/protocolPB/PBHelperClient.java' sourcefile='PBHelperClient.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocolPB.PBHelperClient.convert(HdfsProtos$SnapshottableDirectoryListingProto)</Message></Method><SourceLine endBytecode='5' classname='org.apache.hadoop.hdfs.protocolPB.PBHelperClient' start='1653' end='1653' sourcepath='org/apache/hadoop/hdfs/protocolPB/PBHelperClient.java' sourcefile='PBHelperClient.java' startBytecode='5' primary='true'><Message>At PBHelperClient.java:[line 1653]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='292e5267cda3cd9cb1af9a02dca2d909' rank='20' abbrev='PZLA' category='STYLE' priority='3' type='PZLA_PREFER_ZERO_LENGTH_ARRAYS' instanceOccurrenceMax='0'><ShortMessage>Consider returning a zero length array rather than null</ShortMessage><LongMessage>Should org.apache.hadoop.hdfs.protocolPB.PBHelperClient.convert(DatanodeID[]) return a zero length array rather than null?</LongMessage><Class classname='org.apache.hadoop.hdfs.protocolPB.PBHelperClient' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocolPB.PBHelperClient' start='225' end='3378' sourcepath='org/apache/hadoop/hdfs/protocolPB/PBHelperClient.java' sourcefile='PBHelperClient.java'><Message>At PBHelperClient.java:[lines 225-3378]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocolPB.PBHelperClient</Message></Class><Method isStatic='true' classname='org.apache.hadoop.hdfs.protocolPB.PBHelperClient' signature='([Lorg/apache/hadoop/hdfs/protocol/DatanodeID;)[Lorg/apache/hadoop/hdfs/protocol/proto/HdfsProtos$DatanodeIDProto;' name='convert' primary='true'><SourceLine endBytecode='157' classname='org.apache.hadoop.hdfs.protocolPB.PBHelperClient' start='1712' end='1719' sourcepath='org/apache/hadoop/hdfs/protocolPB/PBHelperClient.java' sourcefile='PBHelperClient.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocolPB.PBHelperClient.convert(DatanodeID[])</Message></Method><SourceLine endBytecode='5' classname='org.apache.hadoop.hdfs.protocolPB.PBHelperClient' start='1713' end='1713' sourcepath='org/apache/hadoop/hdfs/protocolPB/PBHelperClient.java' sourcefile='PBHelperClient.java' startBytecode='5' primary='true'><Message>At PBHelperClient.java:[line 1713]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='94413c2a6e35a83d443bf5821a50ac65' rank='20' abbrev='PZLA' category='STYLE' priority='3' type='PZLA_PREFER_ZERO_LENGTH_ARRAYS' instanceOccurrenceMax='0'><ShortMessage>Consider returning a zero length array rather than null</ShortMessage><LongMessage>Should org.apache.hadoop.hdfs.protocolPB.PBHelperClient.convert(HdfsFileStatus[]) return a zero length array rather than null?</LongMessage><Class classname='org.apache.hadoop.hdfs.protocolPB.PBHelperClient' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocolPB.PBHelperClient' start='225' end='3378' sourcepath='org/apache/hadoop/hdfs/protocolPB/PBHelperClient.java' sourcefile='PBHelperClient.java'><Message>At PBHelperClient.java:[lines 225-3378]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocolPB.PBHelperClient</Message></Class><Method isStatic='true' classname='org.apache.hadoop.hdfs.protocolPB.PBHelperClient' signature='([Lorg/apache/hadoop/hdfs/protocol/HdfsFileStatus;)[Lorg/apache/hadoop/hdfs/protocol/proto/HdfsProtos$HdfsFileStatusProto;' name='convert' primary='true'><SourceLine endBytecode='153' classname='org.apache.hadoop.hdfs.protocolPB.PBHelperClient' start='2364' end='2370' sourcepath='org/apache/hadoop/hdfs/protocolPB/PBHelperClient.java' sourcefile='PBHelperClient.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocolPB.PBHelperClient.convert(HdfsFileStatus[])</Message></Method><SourceLine endBytecode='5' classname='org.apache.hadoop.hdfs.protocolPB.PBHelperClient' start='2364' end='2364' sourcepath='org/apache/hadoop/hdfs/protocolPB/PBHelperClient.java' sourcefile='PBHelperClient.java' startBytecode='5' primary='true'><Message>At PBHelperClient.java:[line 2364]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='3fcd44c046687368fdf89f077b4816d5' rank='20' abbrev='PZLA' category='STYLE' priority='3' type='PZLA_PREFER_ZERO_LENGTH_ARRAYS' instanceOccurrenceMax='0'><ShortMessage>Consider returning a zero length array rather than null</ShortMessage><LongMessage>Should org.apache.hadoop.hdfs.protocolPB.PBHelperClient.convert(HdfsProtos$DatanodeIDProto[]) return a zero length array rather than null?</LongMessage><Class classname='org.apache.hadoop.hdfs.protocolPB.PBHelperClient' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocolPB.PBHelperClient' start='225' end='3378' sourcepath='org/apache/hadoop/hdfs/protocolPB/PBHelperClient.java' sourcefile='PBHelperClient.java'><Message>At PBHelperClient.java:[lines 225-3378]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocolPB.PBHelperClient</Message></Class><Method isStatic='true' classname='org.apache.hadoop.hdfs.protocolPB.PBHelperClient' signature='([Lorg/apache/hadoop/hdfs/protocol/proto/HdfsProtos$DatanodeIDProto;)[Lorg/apache/hadoop/hdfs/protocol/DatanodeID;' name='convert' primary='true'><SourceLine endBytecode='153' classname='org.apache.hadoop.hdfs.protocolPB.PBHelperClient' start='2132' end='2138' sourcepath='org/apache/hadoop/hdfs/protocolPB/PBHelperClient.java' sourcefile='PBHelperClient.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocolPB.PBHelperClient.convert(HdfsProtos$DatanodeIDProto[])</Message></Method><SourceLine endBytecode='5' classname='org.apache.hadoop.hdfs.protocolPB.PBHelperClient' start='2132' end='2132' sourcepath='org/apache/hadoop/hdfs/protocolPB/PBHelperClient.java' sourcefile='PBHelperClient.java' startBytecode='5' primary='true'><Message>At PBHelperClient.java:[line 2132]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='37218499a92cf477e21fe0efd0189b66' rank='20' abbrev='PZLA' category='STYLE' priority='3' type='PZLA_PREFER_ZERO_LENGTH_ARRAYS' instanceOccurrenceMax='0'><ShortMessage>Consider returning a zero length array rather than null</ShortMessage><LongMessage>Should org.apache.hadoop.hdfs.protocolPB.PBHelperClient.convert(HdfsProtos$DatanodeInfoProto[]) return a zero length array rather than null?</LongMessage><Class classname='org.apache.hadoop.hdfs.protocolPB.PBHelperClient' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocolPB.PBHelperClient' start='225' end='3378' sourcepath='org/apache/hadoop/hdfs/protocolPB/PBHelperClient.java' sourcefile='PBHelperClient.java'><Message>At PBHelperClient.java:[lines 225-3378]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocolPB.PBHelperClient</Message></Class><Method isStatic='true' classname='org.apache.hadoop.hdfs.protocolPB.PBHelperClient' signature='([Lorg/apache/hadoop/hdfs/protocol/proto/HdfsProtos$DatanodeInfoProto;)[Lorg/apache/hadoop/hdfs/protocol/DatanodeInfo;' name='convert' primary='true'><SourceLine endBytecode='137' classname='org.apache.hadoop.hdfs.protocolPB.PBHelperClient' start='2171' end='2176' sourcepath='org/apache/hadoop/hdfs/protocolPB/PBHelperClient.java' sourcefile='PBHelperClient.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocolPB.PBHelperClient.convert(HdfsProtos$DatanodeInfoProto[])</Message></Method><SourceLine endBytecode='5' classname='org.apache.hadoop.hdfs.protocolPB.PBHelperClient' start='2171' end='2171' sourcepath='org/apache/hadoop/hdfs/protocolPB/PBHelperClient.java' sourcefile='PBHelperClient.java' startBytecode='5' primary='true'><Message>At PBHelperClient.java:[line 2171]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='8088fdcb22d16e17c255442b241f440c' rank='20' abbrev='PZLA' category='STYLE' priority='3' type='PZLA_PREFER_ZERO_LENGTH_ARRAYS' instanceOccurrenceMax='0'><ShortMessage>Consider returning a zero length array rather than null</ShortMessage><LongMessage>Should org.apache.hadoop.hdfs.protocolPB.PBHelperClient.convert(HdfsProtos$HdfsFileStatusProto[]) return a zero length array rather than null?</LongMessage><Class classname='org.apache.hadoop.hdfs.protocolPB.PBHelperClient' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocolPB.PBHelperClient' start='225' end='3378' sourcepath='org/apache/hadoop/hdfs/protocolPB/PBHelperClient.java' sourcefile='PBHelperClient.java'><Message>At PBHelperClient.java:[lines 225-3378]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocolPB.PBHelperClient</Message></Class><Method isStatic='true' classname='org.apache.hadoop.hdfs.protocolPB.PBHelperClient' signature='([Lorg/apache/hadoop/hdfs/protocol/proto/HdfsProtos$HdfsFileStatusProto;)[Lorg/apache/hadoop/hdfs/protocol/HdfsFileStatus;' name='convert' primary='true'><SourceLine endBytecode='153' classname='org.apache.hadoop.hdfs.protocolPB.PBHelperClient' start='2032' end='2038' sourcepath='org/apache/hadoop/hdfs/protocolPB/PBHelperClient.java' sourcefile='PBHelperClient.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocolPB.PBHelperClient.convert(HdfsProtos$HdfsFileStatusProto[])</Message></Method><SourceLine endBytecode='5' classname='org.apache.hadoop.hdfs.protocolPB.PBHelperClient' start='2032' end='2032' sourcepath='org/apache/hadoop/hdfs/protocolPB/PBHelperClient.java' sourcefile='PBHelperClient.java' startBytecode='5' primary='true'><Message>At PBHelperClient.java:[line 2032]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='d44428596c89ea39c64d8ebb78809333' rank='20' abbrev='PZLA' category='STYLE' priority='3' type='PZLA_PREFER_ZERO_LENGTH_ARRAYS' instanceOccurrenceMax='0'><ShortMessage>Consider returning a zero length array rather than null</ShortMessage><LongMessage>Should org.apache.hadoop.hdfs.protocolPB.PBHelperClient.convertLocatedBlock(HdfsProtos$LocatedBlockProto[]) return a zero length array rather than null?</LongMessage><Class classname='org.apache.hadoop.hdfs.protocolPB.PBHelperClient' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocolPB.PBHelperClient' start='225' end='3378' sourcepath='org/apache/hadoop/hdfs/protocolPB/PBHelperClient.java' sourcefile='PBHelperClient.java'><Message>At PBHelperClient.java:[lines 225-3378]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocolPB.PBHelperClient</Message></Class><Method isStatic='true' classname='org.apache.hadoop.hdfs.protocolPB.PBHelperClient' signature='([Lorg/apache/hadoop/hdfs/protocol/proto/HdfsProtos$LocatedBlockProto;)[Lorg/apache/hadoop/hdfs/protocol/LocatedBlock;' name='convertLocatedBlock' primary='true'><SourceLine endBytecode='81' classname='org.apache.hadoop.hdfs.protocolPB.PBHelperClient' start='2198' end='2199' sourcepath='org/apache/hadoop/hdfs/protocolPB/PBHelperClient.java' sourcefile='PBHelperClient.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocolPB.PBHelperClient.convertLocatedBlock(HdfsProtos$LocatedBlockProto[])</Message></Method><SourceLine endBytecode='5' classname='org.apache.hadoop.hdfs.protocolPB.PBHelperClient' start='2198' end='2198' sourcepath='org/apache/hadoop/hdfs/protocolPB/PBHelperClient.java' sourcefile='PBHelperClient.java' startBytecode='5' primary='true'><Message>At PBHelperClient.java:[line 2198]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='f2efe3c6c611120df3e0fce1bd0a8bfa' rank='20' abbrev='PZLA' category='STYLE' priority='3' type='PZLA_PREFER_ZERO_LENGTH_ARRAYS' instanceOccurrenceMax='0'><ShortMessage>Consider returning a zero length array rather than null</ShortMessage><LongMessage>Should org.apache.hadoop.hdfs.protocolPB.PBHelperClient.convertLocatedBlocks(LocatedBlock[]) return a zero length array rather than null?</LongMessage><Class classname='org.apache.hadoop.hdfs.protocolPB.PBHelperClient' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocolPB.PBHelperClient' start='225' end='3378' sourcepath='org/apache/hadoop/hdfs/protocolPB/PBHelperClient.java' sourcefile='PBHelperClient.java'><Message>At PBHelperClient.java:[lines 225-3378]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocolPB.PBHelperClient</Message></Class><Method isStatic='true' classname='org.apache.hadoop.hdfs.protocolPB.PBHelperClient' signature='([Lorg/apache/hadoop/hdfs/protocol/LocatedBlock;)[Lorg/apache/hadoop/hdfs/protocol/proto/HdfsProtos$LocatedBlockProto;' name='convertLocatedBlocks' primary='true'><SourceLine endBytecode='89' classname='org.apache.hadoop.hdfs.protocolPB.PBHelperClient' start='988' end='989' sourcepath='org/apache/hadoop/hdfs/protocolPB/PBHelperClient.java' sourcefile='PBHelperClient.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocolPB.PBHelperClient.convertLocatedBlocks(LocatedBlock[])</Message></Method><SourceLine endBytecode='5' classname='org.apache.hadoop.hdfs.protocolPB.PBHelperClient' start='988' end='988' sourcepath='org/apache/hadoop/hdfs/protocolPB/PBHelperClient.java' sourcefile='PBHelperClient.java' startBytecode='5' primary='true'><Message>At PBHelperClient.java:[line 988]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='6f9b042fa17224352018b375a435e65f' rank='20' abbrev='PZLA' category='STYLE' priority='3' type='PZLA_PREFER_ZERO_LENGTH_ARRAYS' instanceOccurrenceMax='0'><ShortMessage>Consider returning a zero length array rather than null</ShortMessage><LongMessage>Should org.apache.hadoop.hdfs.protocolPB.PBHelperClient.convertLocatedBlocks(HdfsProtos$LocatedBlockProto[]) return a zero length array rather than null?</LongMessage><Class classname='org.apache.hadoop.hdfs.protocolPB.PBHelperClient' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.protocolPB.PBHelperClient' start='225' end='3378' sourcepath='org/apache/hadoop/hdfs/protocolPB/PBHelperClient.java' sourcefile='PBHelperClient.java'><Message>At PBHelperClient.java:[lines 225-3378]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.protocolPB.PBHelperClient</Message></Class><Method isStatic='true' classname='org.apache.hadoop.hdfs.protocolPB.PBHelperClient' signature='([Lorg/apache/hadoop/hdfs/protocol/proto/HdfsProtos$LocatedBlockProto;)[Lorg/apache/hadoop/hdfs/protocol/LocatedBlock;' name='convertLocatedBlocks' primary='true'><SourceLine endBytecode='89' classname='org.apache.hadoop.hdfs.protocolPB.PBHelperClient' start='994' end='995' sourcepath='org/apache/hadoop/hdfs/protocolPB/PBHelperClient.java' sourcefile='PBHelperClient.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.protocolPB.PBHelperClient.convertLocatedBlocks(HdfsProtos$LocatedBlockProto[])</Message></Method><SourceLine endBytecode='5' classname='org.apache.hadoop.hdfs.protocolPB.PBHelperClient' start='994' end='994' sourcepath='org/apache/hadoop/hdfs/protocolPB/PBHelperClient.java' sourcefile='PBHelperClient.java' startBytecode='5' primary='true'><Message>At PBHelperClient.java:[line 994]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='7ce8e547decb23237d2ef0e26fe79de1' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from java.io.DataInput to java.io.DataInputStream in org.apache.hadoop.hdfs.security.token.block.BlockTokenIdentifier.readFields(DataInput)</LongMessage><Class classname='org.apache.hadoop.hdfs.security.token.block.BlockTokenIdentifier' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.security.token.block.BlockTokenIdentifier' start='43' end='316' sourcepath='org/apache/hadoop/hdfs/security/token/block/BlockTokenIdentifier.java' sourcefile='BlockTokenIdentifier.java'><Message>At BlockTokenIdentifier.java:[lines 43-316]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.security.token.block.BlockTokenIdentifier</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.security.token.block.BlockTokenIdentifier' signature='(Ljava/io/DataInput;)V' name='readFields' primary='true'><SourceLine endBytecode='31' classname='org.apache.hadoop.hdfs.security.token.block.BlockTokenIdentifier' start='200' end='214' sourcepath='org/apache/hadoop/hdfs/security/token/block/BlockTokenIdentifier.java' sourcefile='BlockTokenIdentifier.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.security.token.block.BlockTokenIdentifier.readFields(DataInput)</Message></Method><Type role='TYPE_FOUND' descriptor='Ljava/io/DataInput;'><SourceLine classname='java.io.DataInput' sourcepath='java/io/DataInput.java' sourcefile='DataInput.java'><Message>In DataInput.java</Message></SourceLine><Message>Actual type java.io.DataInput</Message></Type><Type role='TYPE_EXPECTED' descriptor='Ljava/io/DataInputStream;'><SourceLine classname='java.io.DataInputStream' start='52' end='661' sourcepath='java/io/DataInputStream.java' sourcefile='DataInputStream.java'><Message>At DataInputStream.java:[lines 52-661]</Message></SourceLine><Message>Expected java.io.DataInputStream</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='5' name='in' register='1'><Message>Value loaded from in</Message></LocalVariable><SourceLine endBytecode='6' classname='org.apache.hadoop.hdfs.security.token.block.BlockTokenIdentifier' start='202' end='202' sourcepath='org/apache/hadoop/hdfs/security/token/block/BlockTokenIdentifier.java' sourcefile='BlockTokenIdentifier.java' startBytecode='6' primary='true'><Message>At BlockTokenIdentifier.java:[line 202]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='5488a9a6b3b23c93030ab5e49eb66922' cweid='374' rank='18' abbrev='EI' category='MALICIOUS_CODE' priority='2' type='EI_EXPOSE_REP' instanceOccurrenceMax='0'><ShortMessage>May expose internal representation by returning reference to mutable object</ShortMessage><LongMessage>org.apache.hadoop.hdfs.security.token.block.BlockTokenIdentifier.getBytes() may expose internal representation by returning BlockTokenIdentifier.cache</LongMessage><Class classname='org.apache.hadoop.hdfs.security.token.block.BlockTokenIdentifier' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.security.token.block.BlockTokenIdentifier' start='43' end='316' sourcepath='org/apache/hadoop/hdfs/security/token/block/BlockTokenIdentifier.java' sourcefile='BlockTokenIdentifier.java'><Message>At BlockTokenIdentifier.java:[lines 43-316]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.security.token.block.BlockTokenIdentifier</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.security.token.block.BlockTokenIdentifier' signature='()[B' name='getBytes' primary='true'><SourceLine endBytecode='74' classname='org.apache.hadoop.hdfs.security.token.block.BlockTokenIdentifier' start='314' end='316' sourcepath='org/apache/hadoop/hdfs/security/token/block/BlockTokenIdentifier.java' sourcefile='BlockTokenIdentifier.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.security.token.block.BlockTokenIdentifier.getBytes()</Message></Method><Field isStatic='false' classname='org.apache.hadoop.hdfs.security.token.block.BlockTokenIdentifier' signature='[B' name='cache' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.security.token.block.BlockTokenIdentifier' sourcepath='org/apache/hadoop/hdfs/security/token/block/BlockTokenIdentifier.java' sourcefile='BlockTokenIdentifier.java'><Message>In BlockTokenIdentifier.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.security.token.block.BlockTokenIdentifier.cache</Message></Field><SourceLine endBytecode='19' classname='org.apache.hadoop.hdfs.security.token.block.BlockTokenIdentifier' start='316' end='316' sourcepath='org/apache/hadoop/hdfs/security/token/block/BlockTokenIdentifier.java' sourcefile='BlockTokenIdentifier.java' startBytecode='19' primary='true'><Message>At BlockTokenIdentifier.java:[line 316]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='325ea688cd729c655d8a8bc5e27b0235' cweid='374' rank='18' abbrev='EI' category='MALICIOUS_CODE' priority='2' type='EI_EXPOSE_REP' instanceOccurrenceMax='0'><ShortMessage>May expose internal representation by returning reference to mutable object</ShortMessage><LongMessage>org.apache.hadoop.hdfs.security.token.block.BlockTokenIdentifier.getStorageIds() may expose internal representation by returning BlockTokenIdentifier.storageIds</LongMessage><Class classname='org.apache.hadoop.hdfs.security.token.block.BlockTokenIdentifier' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.security.token.block.BlockTokenIdentifier' start='43' end='316' sourcepath='org/apache/hadoop/hdfs/security/token/block/BlockTokenIdentifier.java' sourcefile='BlockTokenIdentifier.java'><Message>At BlockTokenIdentifier.java:[lines 43-316]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.security.token.block.BlockTokenIdentifier</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.security.token.block.BlockTokenIdentifier' signature='()[Ljava/lang/String;' name='getStorageIds' primary='true'><SourceLine endBytecode='46' classname='org.apache.hadoop.hdfs.security.token.block.BlockTokenIdentifier' start='134' end='134' sourcepath='org/apache/hadoop/hdfs/security/token/block/BlockTokenIdentifier.java' sourcefile='BlockTokenIdentifier.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.security.token.block.BlockTokenIdentifier.getStorageIds()</Message></Method><Field isStatic='false' classname='org.apache.hadoop.hdfs.security.token.block.BlockTokenIdentifier' signature='[Ljava/lang/String;' name='storageIds' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.security.token.block.BlockTokenIdentifier' sourcepath='org/apache/hadoop/hdfs/security/token/block/BlockTokenIdentifier.java' sourcefile='BlockTokenIdentifier.java'><Message>In BlockTokenIdentifier.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.security.token.block.BlockTokenIdentifier.storageIds</Message></Field><SourceLine endBytecode='4' classname='org.apache.hadoop.hdfs.security.token.block.BlockTokenIdentifier' start='134' end='134' sourcepath='org/apache/hadoop/hdfs/security/token/block/BlockTokenIdentifier.java' sourcefile='BlockTokenIdentifier.java' startBytecode='4' primary='true'><Message>At BlockTokenIdentifier.java:[line 134]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='5fc9a00e4693556df2dab461a94f8d' cweid='374' rank='18' abbrev='EI' category='MALICIOUS_CODE' priority='2' type='EI_EXPOSE_REP' instanceOccurrenceMax='0'><ShortMessage>May expose internal representation by returning reference to mutable object</ShortMessage><LongMessage>org.apache.hadoop.hdfs.security.token.block.BlockTokenIdentifier.getStorageTypes() may expose internal representation by returning BlockTokenIdentifier.storageTypes</LongMessage><Class classname='org.apache.hadoop.hdfs.security.token.block.BlockTokenIdentifier' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.security.token.block.BlockTokenIdentifier' start='43' end='316' sourcepath='org/apache/hadoop/hdfs/security/token/block/BlockTokenIdentifier.java' sourcefile='BlockTokenIdentifier.java'><Message>At BlockTokenIdentifier.java:[lines 43-316]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.security.token.block.BlockTokenIdentifier</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.security.token.block.BlockTokenIdentifier' signature='()[Lorg/apache/hadoop/fs/StorageType;' name='getStorageTypes' primary='true'><SourceLine endBytecode='46' classname='org.apache.hadoop.hdfs.security.token.block.BlockTokenIdentifier' start='130' end='130' sourcepath='org/apache/hadoop/hdfs/security/token/block/BlockTokenIdentifier.java' sourcefile='BlockTokenIdentifier.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.security.token.block.BlockTokenIdentifier.getStorageTypes()</Message></Method><Field isStatic='false' classname='org.apache.hadoop.hdfs.security.token.block.BlockTokenIdentifier' signature='[Lorg/apache/hadoop/fs/StorageType;' name='storageTypes' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.security.token.block.BlockTokenIdentifier' sourcepath='org/apache/hadoop/hdfs/security/token/block/BlockTokenIdentifier.java' sourcefile='BlockTokenIdentifier.java'><Message>In BlockTokenIdentifier.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.security.token.block.BlockTokenIdentifier.storageTypes</Message></Field><SourceLine endBytecode='4' classname='org.apache.hadoop.hdfs.security.token.block.BlockTokenIdentifier' start='130' end='130' sourcepath='org/apache/hadoop/hdfs/security/token/block/BlockTokenIdentifier.java' sourcefile='BlockTokenIdentifier.java' startBytecode='4' primary='true'><Message>At BlockTokenIdentifier.java:[line 130]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='b0197645b2dc3a5cbbc43f9ebb8b117a' rank='20' abbrev='SIC' category='PERFORMANCE' priority='3' type='SIC_INNER_SHOULD_BE_STATIC_ANON' instanceOccurrenceMax='0'><ShortMessage>Could be refactored into a named static inner class</ShortMessage><LongMessage>The class org.apache.hadoop.hdfs.server.namenode.ha.TestConfiguredFailoverProxyProvider$1 could be refactored into a named _static_ inner class</LongMessage><Class role='CLASS_ANONYMOUS' classname='org.apache.hadoop.hdfs.server.namenode.ha.TestConfiguredFailoverProxyProvider$1'><SourceLine classname='org.apache.hadoop.hdfs.server.namenode.ha.TestConfiguredFailoverProxyProvider$1' start='220' end='224' sourcepath='org/apache/hadoop/hdfs/server/namenode/ha/TestConfiguredFailoverProxyProvider.java' sourcefile='TestConfiguredFailoverProxyProvider.java'><Message>At TestConfiguredFailoverProxyProvider.java:[lines 220-224]</Message></SourceLine><Message>Anonymous class org.apache.hadoop.hdfs.server.namenode.ha.TestConfiguredFailoverProxyProvider$1</Message></Class><Class classname='org.apache.hadoop.hdfs.server.namenode.ha.TestConfiguredFailoverProxyProvider' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.server.namenode.ha.TestConfiguredFailoverProxyProvider' start='52' end='239' sourcepath='org/apache/hadoop/hdfs/server/namenode/ha/TestConfiguredFailoverProxyProvider.java' sourcefile='TestConfiguredFailoverProxyProvider.java'><Message>At TestConfiguredFailoverProxyProvider.java:[lines 52-239]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.server.namenode.ha.TestConfiguredFailoverProxyProvider</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.server.namenode.ha.TestConfiguredFailoverProxyProvider' signature='(Ljava/util/concurrent/atomic/AtomicInteger;J)Lorg/mockito/stubbing/Answer;' name='createAnswer' primary='true'><SourceLine endBytecode='72' classname='org.apache.hadoop.hdfs.server.namenode.ha.TestConfiguredFailoverProxyProvider' start='220' end='220' sourcepath='org/apache/hadoop/hdfs/server/namenode/ha/TestConfiguredFailoverProxyProvider.java' sourcefile='TestConfiguredFailoverProxyProvider.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.server.namenode.ha.TestConfiguredFailoverProxyProvider.createAnswer(AtomicInteger, long)</Message></Method><SourceLine endBytecode='7' classname='org.apache.hadoop.hdfs.server.namenode.ha.TestConfiguredFailoverProxyProvider' start='220' end='220' sourcepath='org/apache/hadoop/hdfs/server/namenode/ha/TestConfiguredFailoverProxyProvider.java' sourcefile='TestConfiguredFailoverProxyProvider.java' startBytecode='7' primary='true'><Message>At TestConfiguredFailoverProxyProvider.java:[line 220]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='bdf93746cae18487e88f3563dd1d40b2' rank='20' abbrev='SIC' category='PERFORMANCE' priority='3' type='SIC_INNER_SHOULD_BE_STATIC_ANON' instanceOccurrenceMax='0'><ShortMessage>Could be refactored into a named static inner class</ShortMessage><LongMessage>The class org.apache.hadoop.hdfs.server.namenode.ha.TestConfiguredFailoverProxyProvider$2 could be refactored into a named _static_ inner class</LongMessage><Class role='CLASS_ANONYMOUS' classname='org.apache.hadoop.hdfs.server.namenode.ha.TestConfiguredFailoverProxyProvider$2'><SourceLine classname='org.apache.hadoop.hdfs.server.namenode.ha.TestConfiguredFailoverProxyProvider$2' start='239' end='259' sourcepath='org/apache/hadoop/hdfs/server/namenode/ha/TestConfiguredFailoverProxyProvider.java' sourcefile='TestConfiguredFailoverProxyProvider.java'><Message>At TestConfiguredFailoverProxyProvider.java:[lines 239-259]</Message></SourceLine><Message>Anonymous class org.apache.hadoop.hdfs.server.namenode.ha.TestConfiguredFailoverProxyProvider$2</Message></Class><Class classname='org.apache.hadoop.hdfs.server.namenode.ha.TestConfiguredFailoverProxyProvider' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.server.namenode.ha.TestConfiguredFailoverProxyProvider' start='52' end='239' sourcepath='org/apache/hadoop/hdfs/server/namenode/ha/TestConfiguredFailoverProxyProvider.java' sourcefile='TestConfiguredFailoverProxyProvider.java'><Message>At TestConfiguredFailoverProxyProvider.java:[lines 52-239]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.server.namenode.ha.TestConfiguredFailoverProxyProvider</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.server.namenode.ha.TestConfiguredFailoverProxyProvider' signature='(Ljava/util/Map;)Lorg/apache/hadoop/hdfs/server/namenode/ha/HAProxyFactory;' name='createFactory' primary='true'><SourceLine endBytecode='105' classname='org.apache.hadoop.hdfs.server.namenode.ha.TestConfiguredFailoverProxyProvider' start='238' end='239' sourcepath='org/apache/hadoop/hdfs/server/namenode/ha/TestConfiguredFailoverProxyProvider.java' sourcefile='TestConfiguredFailoverProxyProvider.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.server.namenode.ha.TestConfiguredFailoverProxyProvider.createFactory(Map)</Message></Method><SourceLine endBytecode='8' classname='org.apache.hadoop.hdfs.server.namenode.ha.TestConfiguredFailoverProxyProvider' start='239' end='239' sourcepath='org/apache/hadoop/hdfs/server/namenode/ha/TestConfiguredFailoverProxyProvider.java' sourcefile='TestConfiguredFailoverProxyProvider.java' startBytecode='8' primary='true'><Message>At TestConfiguredFailoverProxyProvider.java:[line 239]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='5ead108e680e9f6f4c4aee4ba993a7a0' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST_OF_RETURN_VALUE' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast of return value from method</ShortMessage><LongMessage>Unchecked/unconfirmed cast from Exception to org.apache.hadoop.ipc.RemoteException of return value in org.apache.hadoop.hdfs.server.namenode.ha.TestRequestHedgingProxyProvider.testFileNotFoundExceptionWithSingleProxy()</LongMessage><Class classname='org.apache.hadoop.hdfs.server.namenode.ha.TestRequestHedgingProxyProvider' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.server.namenode.ha.TestRequestHedgingProxyProvider' start='58' end='641' sourcepath='org/apache/hadoop/hdfs/server/namenode/ha/TestRequestHedgingProxyProvider.java' sourcefile='TestRequestHedgingProxyProvider.java'><Message>At TestRequestHedgingProxyProvider.java:[lines 58-641]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.server.namenode.ha.TestRequestHedgingProxyProvider</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.server.namenode.ha.TestRequestHedgingProxyProvider' signature='()V' name='testFileNotFoundExceptionWithSingleProxy' primary='true'><SourceLine endBytecode='164' classname='org.apache.hadoop.hdfs.server.namenode.ha.TestRequestHedgingProxyProvider' start='316' end='370' sourcepath='org/apache/hadoop/hdfs/server/namenode/ha/TestRequestHedgingProxyProvider.java' sourcefile='TestRequestHedgingProxyProvider.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.server.namenode.ha.TestRequestHedgingProxyProvider.testFileNotFoundExceptionWithSingleProxy()</Message></Method><Type role='TYPE_FOUND' descriptor='Ljava/lang/Exception;'><SourceLine classname='java.lang.Exception' start='54' end='123' sourcepath='java/lang/Exception.java' sourcefile='Exception.java'><Message>At Exception.java:[lines 54-123]</Message></SourceLine><Message>Actual type Exception</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/ipc/RemoteException;'><SourceLine classname='org.apache.hadoop.ipc.RemoteException' start='41' end='137' sourcepath='org/apache/hadoop/ipc/RemoteException.java' sourcefile='RemoteException.java'><Message>At RemoteException.java:[lines 41-137]</Message></SourceLine><Message>Expected org.apache.hadoop.ipc.RemoteException</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='207' name='ex' register='6'><Message>Value loaded from ex</Message></LocalVariable><SourceLine endBytecode='209' classname='org.apache.hadoop.hdfs.server.namenode.ha.TestRequestHedgingProxyProvider' start='340' end='340' sourcepath='org/apache/hadoop/hdfs/server/namenode/ha/TestRequestHedgingProxyProvider.java' sourcefile='TestRequestHedgingProxyProvider.java' startBytecode='209' primary='true'><Message>At TestRequestHedgingProxyProvider.java:[line 340]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='abfa8b35f18fea74151731899f926f56' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST_OF_RETURN_VALUE' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast of return value from method</ShortMessage><LongMessage>Unchecked/unconfirmed cast from Exception to org.apache.hadoop.ipc.RemoteException of return value in org.apache.hadoop.hdfs.server.namenode.ha.TestRequestHedgingProxyProvider.testHedgingWhenFileNotFoundException()</LongMessage><Class classname='org.apache.hadoop.hdfs.server.namenode.ha.TestRequestHedgingProxyProvider' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.server.namenode.ha.TestRequestHedgingProxyProvider' start='58' end='641' sourcepath='org/apache/hadoop/hdfs/server/namenode/ha/TestRequestHedgingProxyProvider.java' sourcefile='TestRequestHedgingProxyProvider.java'><Message>At TestRequestHedgingProxyProvider.java:[lines 58-641]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.server.namenode.ha.TestRequestHedgingProxyProvider</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.server.namenode.ha.TestRequestHedgingProxyProvider' signature='()V' name='testHedgingWhenFileNotFoundException' primary='true'><SourceLine endBytecode='118' classname='org.apache.hadoop.hdfs.server.namenode.ha.TestRequestHedgingProxyProvider' start='539' end='574' sourcepath='org/apache/hadoop/hdfs/server/namenode/ha/TestRequestHedgingProxyProvider.java' sourcefile='TestRequestHedgingProxyProvider.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.server.namenode.ha.TestRequestHedgingProxyProvider.testHedgingWhenFileNotFoundException()</Message></Method><Type role='TYPE_FOUND' descriptor='Ljava/lang/Exception;'><SourceLine classname='java.lang.Exception' start='54' end='123' sourcepath='java/lang/Exception.java' sourcefile='Exception.java'><Message>At Exception.java:[lines 54-123]</Message></SourceLine><Message>Actual type Exception</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/ipc/RemoteException;'><SourceLine classname='org.apache.hadoop.ipc.RemoteException' start='41' end='137' sourcepath='org/apache/hadoop/ipc/RemoteException.java' sourcefile='RemoteException.java'><Message>At RemoteException.java:[lines 41-137]</Message></SourceLine><Message>Expected org.apache.hadoop.ipc.RemoteException</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='207' name='ex' register='6'><Message>Value loaded from ex</Message></LocalVariable><SourceLine endBytecode='209' classname='org.apache.hadoop.hdfs.server.namenode.ha.TestRequestHedgingProxyProvider' start='563' end='563' sourcepath='org/apache/hadoop/hdfs/server/namenode/ha/TestRequestHedgingProxyProvider.java' sourcefile='TestRequestHedgingProxyProvider.java' startBytecode='209' primary='true'><Message>At TestRequestHedgingProxyProvider.java:[line 563]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='abd42a028c61fb1ec95d5f701130b7c' cweid='571' rank='17' abbrev='BC' category='STYLE' priority='2' type='BC_VACUOUS_INSTANCEOF' instanceOccurrenceMax='0'><ShortMessage>instanceof will always return true</ShortMessage><LongMessage>instanceof will always return true for all non-null values in org.apache.hadoop.hdfs.server.namenode.ha.TestRequestHedgingProxyProvider.testSingleProxyFailover(), since all java.io.IOException are instances of java.io.IOException</LongMessage><Class classname='org.apache.hadoop.hdfs.server.namenode.ha.TestRequestHedgingProxyProvider' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.server.namenode.ha.TestRequestHedgingProxyProvider' start='58' end='641' sourcepath='org/apache/hadoop/hdfs/server/namenode/ha/TestRequestHedgingProxyProvider.java' sourcefile='TestRequestHedgingProxyProvider.java'><Message>At TestRequestHedgingProxyProvider.java:[lines 58-641]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.server.namenode.ha.TestRequestHedgingProxyProvider</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.server.namenode.ha.TestRequestHedgingProxyProvider' signature='()V' name='testSingleProxyFailover' primary='true'><SourceLine endBytecode='144' classname='org.apache.hadoop.hdfs.server.namenode.ha.TestRequestHedgingProxyProvider' start='374' end='414' sourcepath='org/apache/hadoop/hdfs/server/namenode/ha/TestRequestHedgingProxyProvider.java' sourcefile='TestRequestHedgingProxyProvider.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.server.namenode.ha.TestRequestHedgingProxyProvider.testSingleProxyFailover()</Message></Method><Type role='TYPE_FOUND' descriptor='Ljava/io/IOException;'><SourceLine classname='java.io.IOException' start='47' end='100' sourcepath='java/io/IOException.java' sourcefile='IOException.java'><Message>At IOException.java:[lines 47-100]</Message></SourceLine><Message>Actual type java.io.IOException</Message></Type><Type role='TYPE_EXPECTED' descriptor='Ljava/io/IOException;'><SourceLine classname='java.io.IOException' start='47' end='100' sourcepath='java/io/IOException.java' sourcefile='IOException.java'><Message>At IOException.java:[lines 47-100]</Message></SourceLine><Message>Expected java.io.IOException</Message></Type><SourceLine endBytecode='316' classname='org.apache.hadoop.hdfs.server.namenode.ha.TestRequestHedgingProxyProvider' start='410' end='410' sourcepath='org/apache/hadoop/hdfs/server/namenode/ha/TestRequestHedgingProxyProvider.java' sourcefile='TestRequestHedgingProxyProvider.java' startBytecode='316' primary='true'><Message>At TestRequestHedgingProxyProvider.java:[line 410]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='4d5537984b43fe1f617a16f4c133e089' rank='20' abbrev='SIC' category='PERFORMANCE' priority='3' type='SIC_INNER_SHOULD_BE_STATIC_ANON' instanceOccurrenceMax='0'><ShortMessage>Could be refactored into a named static inner class</ShortMessage><LongMessage>The class org.apache.hadoop.hdfs.server.namenode.ha.TestRequestHedgingProxyProvider$1 could be refactored into a named _static_ inner class</LongMessage><Class role='CLASS_ANONYMOUS' classname='org.apache.hadoop.hdfs.server.namenode.ha.TestRequestHedgingProxyProvider$1'><SourceLine classname='org.apache.hadoop.hdfs.server.namenode.ha.TestRequestHedgingProxyProvider$1' start='88' end='92' sourcepath='org/apache/hadoop/hdfs/server/namenode/ha/TestRequestHedgingProxyProvider.java' sourcefile='TestRequestHedgingProxyProvider.java'><Message>At TestRequestHedgingProxyProvider.java:[lines 88-92]</Message></SourceLine><Message>Anonymous class org.apache.hadoop.hdfs.server.namenode.ha.TestRequestHedgingProxyProvider$1</Message></Class><Class classname='org.apache.hadoop.hdfs.server.namenode.ha.TestRequestHedgingProxyProvider' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.server.namenode.ha.TestRequestHedgingProxyProvider' start='58' end='641' sourcepath='org/apache/hadoop/hdfs/server/namenode/ha/TestRequestHedgingProxyProvider.java' sourcefile='TestRequestHedgingProxyProvider.java'><Message>At TestRequestHedgingProxyProvider.java:[lines 58-641]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.server.namenode.ha.TestRequestHedgingProxyProvider</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.server.namenode.ha.TestRequestHedgingProxyProvider' signature='()V' name='testHedgingWhenOneFails' primary='true'><SourceLine endBytecode='336' classname='org.apache.hadoop.hdfs.server.namenode.ha.TestRequestHedgingProxyProvider' start='87' end='105' sourcepath='org/apache/hadoop/hdfs/server/namenode/ha/TestRequestHedgingProxyProvider.java' sourcefile='TestRequestHedgingProxyProvider.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.server.namenode.ha.TestRequestHedgingProxyProvider.testHedgingWhenOneFails()</Message></Method><SourceLine endBytecode='23' classname='org.apache.hadoop.hdfs.server.namenode.ha.TestRequestHedgingProxyProvider' start='88' end='88' sourcepath='org/apache/hadoop/hdfs/server/namenode/ha/TestRequestHedgingProxyProvider.java' sourcefile='TestRequestHedgingProxyProvider.java' startBytecode='23' primary='true'><Message>At TestRequestHedgingProxyProvider.java:[line 88]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='3b767e8efe683c72bffdafe59bb87b00' rank='20' abbrev='SIC' category='PERFORMANCE' priority='3' type='SIC_INNER_SHOULD_BE_STATIC_ANON' instanceOccurrenceMax='0'><ShortMessage>Could be refactored into a named static inner class</ShortMessage><LongMessage>The class org.apache.hadoop.hdfs.server.namenode.ha.TestRequestHedgingProxyProvider$10 could be refactored into a named _static_ inner class</LongMessage><Class role='CLASS_ANONYMOUS' classname='org.apache.hadoop.hdfs.server.namenode.ha.TestRequestHedgingProxyProvider$10'><SourceLine classname='org.apache.hadoop.hdfs.server.namenode.ha.TestRequestHedgingProxyProvider$10' start='438' end='446' sourcepath='org/apache/hadoop/hdfs/server/namenode/ha/TestRequestHedgingProxyProvider.java' sourcefile='TestRequestHedgingProxyProvider.java'><Message>At TestRequestHedgingProxyProvider.java:[lines 438-446]</Message></SourceLine><Message>Anonymous class org.apache.hadoop.hdfs.server.namenode.ha.TestRequestHedgingProxyProvider$10</Message></Class><Class classname='org.apache.hadoop.hdfs.server.namenode.ha.TestRequestHedgingProxyProvider' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.server.namenode.ha.TestRequestHedgingProxyProvider' start='58' end='641' sourcepath='org/apache/hadoop/hdfs/server/namenode/ha/TestRequestHedgingProxyProvider.java' sourcefile='TestRequestHedgingProxyProvider.java'><Message>At TestRequestHedgingProxyProvider.java:[lines 58-641]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.server.namenode.ha.TestRequestHedgingProxyProvider</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.server.namenode.ha.TestRequestHedgingProxyProvider' signature='()V' name='testPerformFailoverWith3Proxies' primary='true'><SourceLine endBytecode='1206' classname='org.apache.hadoop.hdfs.server.namenode.ha.TestRequestHedgingProxyProvider' start='418' end='535' sourcepath='org/apache/hadoop/hdfs/server/namenode/ha/TestRequestHedgingProxyProvider.java' sourcefile='TestRequestHedgingProxyProvider.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.server.namenode.ha.TestRequestHedgingProxyProvider.testPerformFailoverWith3Proxies()</Message></Method><SourceLine endBytecode='145' classname='org.apache.hadoop.hdfs.server.namenode.ha.TestRequestHedgingProxyProvider' start='438' end='438' sourcepath='org/apache/hadoop/hdfs/server/namenode/ha/TestRequestHedgingProxyProvider.java' sourcefile='TestRequestHedgingProxyProvider.java' startBytecode='145' primary='true'><Message>At TestRequestHedgingProxyProvider.java:[line 438]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='48132a103bca6a55f0489b5564761727' rank='20' abbrev='SIC' category='PERFORMANCE' priority='3' type='SIC_INNER_SHOULD_BE_STATIC_ANON' instanceOccurrenceMax='0'><ShortMessage>Could be refactored into a named static inner class</ShortMessage><LongMessage>The class org.apache.hadoop.hdfs.server.namenode.ha.TestRequestHedgingProxyProvider$11 could be refactored into a named _static_ inner class</LongMessage><Class role='CLASS_ANONYMOUS' classname='org.apache.hadoop.hdfs.server.namenode.ha.TestRequestHedgingProxyProvider$11'><SourceLine classname='org.apache.hadoop.hdfs.server.namenode.ha.TestRequestHedgingProxyProvider$11' start='450' end='458' sourcepath='org/apache/hadoop/hdfs/server/namenode/ha/TestRequestHedgingProxyProvider.java' sourcefile='TestRequestHedgingProxyProvider.java'><Message>At TestRequestHedgingProxyProvider.java:[lines 450-458]</Message></SourceLine><Message>Anonymous class org.apache.hadoop.hdfs.server.namenode.ha.TestRequestHedgingProxyProvider$11</Message></Class><Class classname='org.apache.hadoop.hdfs.server.namenode.ha.TestRequestHedgingProxyProvider' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.server.namenode.ha.TestRequestHedgingProxyProvider' start='58' end='641' sourcepath='org/apache/hadoop/hdfs/server/namenode/ha/TestRequestHedgingProxyProvider.java' sourcefile='TestRequestHedgingProxyProvider.java'><Message>At TestRequestHedgingProxyProvider.java:[lines 58-641]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.server.namenode.ha.TestRequestHedgingProxyProvider</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.server.namenode.ha.TestRequestHedgingProxyProvider' signature='()V' name='testPerformFailoverWith3Proxies' primary='true'><SourceLine endBytecode='1206' classname='org.apache.hadoop.hdfs.server.namenode.ha.TestRequestHedgingProxyProvider' start='418' end='535' sourcepath='org/apache/hadoop/hdfs/server/namenode/ha/TestRequestHedgingProxyProvider.java' sourcefile='TestRequestHedgingProxyProvider.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.server.namenode.ha.TestRequestHedgingProxyProvider.testPerformFailoverWith3Proxies()</Message></Method><SourceLine endBytecode='181' classname='org.apache.hadoop.hdfs.server.namenode.ha.TestRequestHedgingProxyProvider' start='450' end='450' sourcepath='org/apache/hadoop/hdfs/server/namenode/ha/TestRequestHedgingProxyProvider.java' sourcefile='TestRequestHedgingProxyProvider.java' startBytecode='181' primary='true'><Message>At TestRequestHedgingProxyProvider.java:[line 450]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='f30dbef2007f94d97d3b9168a398fdd6' rank='20' abbrev='SIC' category='PERFORMANCE' priority='3' type='SIC_INNER_SHOULD_BE_STATIC_ANON' instanceOccurrenceMax='0'><ShortMessage>Could be refactored into a named static inner class</ShortMessage><LongMessage>The class org.apache.hadoop.hdfs.server.namenode.ha.TestRequestHedgingProxyProvider$12 could be refactored into a named _static_ inner class</LongMessage><Class role='CLASS_ANONYMOUS' classname='org.apache.hadoop.hdfs.server.namenode.ha.TestRequestHedgingProxyProvider$12'><SourceLine classname='org.apache.hadoop.hdfs.server.namenode.ha.TestRequestHedgingProxyProvider$12' start='641' end='654' sourcepath='org/apache/hadoop/hdfs/server/namenode/ha/TestRequestHedgingProxyProvider.java' sourcefile='TestRequestHedgingProxyProvider.java'><Message>At TestRequestHedgingProxyProvider.java:[lines 641-654]</Message></SourceLine><Message>Anonymous class org.apache.hadoop.hdfs.server.namenode.ha.TestRequestHedgingProxyProvider$12</Message></Class><Class classname='org.apache.hadoop.hdfs.server.namenode.ha.TestRequestHedgingProxyProvider' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.server.namenode.ha.TestRequestHedgingProxyProvider' start='58' end='641' sourcepath='org/apache/hadoop/hdfs/server/namenode/ha/TestRequestHedgingProxyProvider.java' sourcefile='TestRequestHedgingProxyProvider.java'><Message>At TestRequestHedgingProxyProvider.java:[lines 58-641]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.server.namenode.ha.TestRequestHedgingProxyProvider</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.server.namenode.ha.TestRequestHedgingProxyProvider' signature='([Lorg/apache/hadoop/hdfs/protocol/ClientProtocol;)Lorg/apache/hadoop/hdfs/server/namenode/ha/HAProxyFactory;' name='createFactory' primary='true'><SourceLine endBytecode='105' classname='org.apache.hadoop.hdfs.server.namenode.ha.TestRequestHedgingProxyProvider' start='639' end='641' sourcepath='org/apache/hadoop/hdfs/server/namenode/ha/TestRequestHedgingProxyProvider.java' sourcefile='TestRequestHedgingProxyProvider.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.server.namenode.ha.TestRequestHedgingProxyProvider.createFactory(ClientProtocol[])</Message></Method><SourceLine endBytecode='14' classname='org.apache.hadoop.hdfs.server.namenode.ha.TestRequestHedgingProxyProvider' start='641' end='641' sourcepath='org/apache/hadoop/hdfs/server/namenode/ha/TestRequestHedgingProxyProvider.java' sourcefile='TestRequestHedgingProxyProvider.java' startBytecode='14' primary='true'><Message>At TestRequestHedgingProxyProvider.java:[line 641]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='343053f4c1ddb3ad5083c015e38eb230' rank='20' abbrev='SIC' category='PERFORMANCE' priority='3' type='SIC_INNER_SHOULD_BE_STATIC_ANON' instanceOccurrenceMax='0'><ShortMessage>Could be refactored into a named static inner class</ShortMessage><LongMessage>The class org.apache.hadoop.hdfs.server.namenode.ha.TestRequestHedgingProxyProvider$2 could be refactored into a named _static_ inner class</LongMessage><Class role='CLASS_ANONYMOUS' classname='org.apache.hadoop.hdfs.server.namenode.ha.TestRequestHedgingProxyProvider$2'><SourceLine classname='org.apache.hadoop.hdfs.server.namenode.ha.TestRequestHedgingProxyProvider$2' start='112' end='117' sourcepath='org/apache/hadoop/hdfs/server/namenode/ha/TestRequestHedgingProxyProvider.java' sourcefile='TestRequestHedgingProxyProvider.java'><Message>At TestRequestHedgingProxyProvider.java:[lines 112-117]</Message></SourceLine><Message>Anonymous class org.apache.hadoop.hdfs.server.namenode.ha.TestRequestHedgingProxyProvider$2</Message></Class><Class classname='org.apache.hadoop.hdfs.server.namenode.ha.TestRequestHedgingProxyProvider' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.server.namenode.ha.TestRequestHedgingProxyProvider' start='58' end='641' sourcepath='org/apache/hadoop/hdfs/server/namenode/ha/TestRequestHedgingProxyProvider.java' sourcefile='TestRequestHedgingProxyProvider.java'><Message>At TestRequestHedgingProxyProvider.java:[lines 58-641]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.server.namenode.ha.TestRequestHedgingProxyProvider</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.server.namenode.ha.TestRequestHedgingProxyProvider' signature='()V' name='testRequestNNAfterOneSuccess' primary='true'><SourceLine endBytecode='369' classname='org.apache.hadoop.hdfs.server.namenode.ha.TestRequestHedgingProxyProvider' start='109' end='140' sourcepath='org/apache/hadoop/hdfs/server/namenode/ha/TestRequestHedgingProxyProvider.java' sourcefile='TestRequestHedgingProxyProvider.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.server.namenode.ha.TestRequestHedgingProxyProvider.testRequestNNAfterOneSuccess()</Message></Method><SourceLine endBytecode='42' classname='org.apache.hadoop.hdfs.server.namenode.ha.TestRequestHedgingProxyProvider' start='112' end='112' sourcepath='org/apache/hadoop/hdfs/server/namenode/ha/TestRequestHedgingProxyProvider.java' sourcefile='TestRequestHedgingProxyProvider.java' startBytecode='42' primary='true'><Message>At TestRequestHedgingProxyProvider.java:[line 112]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='bda7148c3fefff5ad6aefc97256f9260' rank='20' abbrev='SIC' category='PERFORMANCE' priority='3' type='SIC_INNER_SHOULD_BE_STATIC_ANON' instanceOccurrenceMax='0'><ShortMessage>Could be refactored into a named static inner class</ShortMessage><LongMessage>The class org.apache.hadoop.hdfs.server.namenode.ha.TestRequestHedgingProxyProvider$3 could be refactored into a named _static_ inner class</LongMessage><Class role='CLASS_ANONYMOUS' classname='org.apache.hadoop.hdfs.server.namenode.ha.TestRequestHedgingProxyProvider$3'><SourceLine classname='org.apache.hadoop.hdfs.server.namenode.ha.TestRequestHedgingProxyProvider$3' start='121' end='125' sourcepath='org/apache/hadoop/hdfs/server/namenode/ha/TestRequestHedgingProxyProvider.java' sourcefile='TestRequestHedgingProxyProvider.java'><Message>At TestRequestHedgingProxyProvider.java:[lines 121-125]</Message></SourceLine><Message>Anonymous class org.apache.hadoop.hdfs.server.namenode.ha.TestRequestHedgingProxyProvider$3</Message></Class><Class classname='org.apache.hadoop.hdfs.server.namenode.ha.TestRequestHedgingProxyProvider' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.server.namenode.ha.TestRequestHedgingProxyProvider' start='58' end='641' sourcepath='org/apache/hadoop/hdfs/server/namenode/ha/TestRequestHedgingProxyProvider.java' sourcefile='TestRequestHedgingProxyProvider.java'><Message>At TestRequestHedgingProxyProvider.java:[lines 58-641]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.server.namenode.ha.TestRequestHedgingProxyProvider</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.server.namenode.ha.TestRequestHedgingProxyProvider' signature='()V' name='testRequestNNAfterOneSuccess' primary='true'><SourceLine endBytecode='369' classname='org.apache.hadoop.hdfs.server.namenode.ha.TestRequestHedgingProxyProvider' start='109' end='140' sourcepath='org/apache/hadoop/hdfs/server/namenode/ha/TestRequestHedgingProxyProvider.java' sourcefile='TestRequestHedgingProxyProvider.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.server.namenode.ha.TestRequestHedgingProxyProvider.testRequestNNAfterOneSuccess()</Message></Method><SourceLine endBytecode='77' classname='org.apache.hadoop.hdfs.server.namenode.ha.TestRequestHedgingProxyProvider' start='121' end='121' sourcepath='org/apache/hadoop/hdfs/server/namenode/ha/TestRequestHedgingProxyProvider.java' sourcefile='TestRequestHedgingProxyProvider.java' startBytecode='77' primary='true'><Message>At TestRequestHedgingProxyProvider.java:[line 121]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='4bb1097ab2d0ecf46861faf03ab51ef9' rank='20' abbrev='SIC' category='PERFORMANCE' priority='3' type='SIC_INNER_SHOULD_BE_STATIC_ANON' instanceOccurrenceMax='0'><ShortMessage>Could be refactored into a named static inner class</ShortMessage><LongMessage>The class org.apache.hadoop.hdfs.server.namenode.ha.TestRequestHedgingProxyProvider$4 could be refactored into a named _static_ inner class</LongMessage><Class role='CLASS_ANONYMOUS' classname='org.apache.hadoop.hdfs.server.namenode.ha.TestRequestHedgingProxyProvider$4'><SourceLine classname='org.apache.hadoop.hdfs.server.namenode.ha.TestRequestHedgingProxyProvider$4' start='145' end='155' sourcepath='org/apache/hadoop/hdfs/server/namenode/ha/TestRequestHedgingProxyProvider.java' sourcefile='TestRequestHedgingProxyProvider.java'><Message>At TestRequestHedgingProxyProvider.java:[lines 145-155]</Message></SourceLine><Message>Anonymous class org.apache.hadoop.hdfs.server.namenode.ha.TestRequestHedgingProxyProvider$4</Message></Class><Class classname='org.apache.hadoop.hdfs.server.namenode.ha.TestRequestHedgingProxyProvider' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.server.namenode.ha.TestRequestHedgingProxyProvider' start='58' end='641' sourcepath='org/apache/hadoop/hdfs/server/namenode/ha/TestRequestHedgingProxyProvider.java' sourcefile='TestRequestHedgingProxyProvider.java'><Message>At TestRequestHedgingProxyProvider.java:[lines 58-641]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.server.namenode.ha.TestRequestHedgingProxyProvider</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.server.namenode.ha.TestRequestHedgingProxyProvider' signature='()V' name='testExceptionInfo' primary='true'><SourceLine endBytecode='338' classname='org.apache.hadoop.hdfs.server.namenode.ha.TestRequestHedgingProxyProvider' start='144' end='179' sourcepath='org/apache/hadoop/hdfs/server/namenode/ha/TestRequestHedgingProxyProvider.java' sourcefile='TestRequestHedgingProxyProvider.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.server.namenode.ha.TestRequestHedgingProxyProvider.testExceptionInfo()</Message></Method><SourceLine endBytecode='23' classname='org.apache.hadoop.hdfs.server.namenode.ha.TestRequestHedgingProxyProvider' start='145' end='145' sourcepath='org/apache/hadoop/hdfs/server/namenode/ha/TestRequestHedgingProxyProvider.java' sourcefile='TestRequestHedgingProxyProvider.java' startBytecode='23' primary='true'><Message>At TestRequestHedgingProxyProvider.java:[line 145]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='7cfaed7a81b5d6f4e02bd3aae55006b4' rank='20' abbrev='SIC' category='PERFORMANCE' priority='3' type='SIC_INNER_SHOULD_BE_STATIC_ANON' instanceOccurrenceMax='0'><ShortMessage>Could be refactored into a named static inner class</ShortMessage><LongMessage>The class org.apache.hadoop.hdfs.server.namenode.ha.TestRequestHedgingProxyProvider$5 could be refactored into a named _static_ inner class</LongMessage><Class role='CLASS_ANONYMOUS' classname='org.apache.hadoop.hdfs.server.namenode.ha.TestRequestHedgingProxyProvider$5'><SourceLine classname='org.apache.hadoop.hdfs.server.namenode.ha.TestRequestHedgingProxyProvider$5' start='160' end='164' sourcepath='org/apache/hadoop/hdfs/server/namenode/ha/TestRequestHedgingProxyProvider.java' sourcefile='TestRequestHedgingProxyProvider.java'><Message>At TestRequestHedgingProxyProvider.java:[lines 160-164]</Message></SourceLine><Message>Anonymous class org.apache.hadoop.hdfs.server.namenode.ha.TestRequestHedgingProxyProvider$5</Message></Class><Class classname='org.apache.hadoop.hdfs.server.namenode.ha.TestRequestHedgingProxyProvider' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.server.namenode.ha.TestRequestHedgingProxyProvider' start='58' end='641' sourcepath='org/apache/hadoop/hdfs/server/namenode/ha/TestRequestHedgingProxyProvider.java' sourcefile='TestRequestHedgingProxyProvider.java'><Message>At TestRequestHedgingProxyProvider.java:[lines 58-641]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.server.namenode.ha.TestRequestHedgingProxyProvider</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.server.namenode.ha.TestRequestHedgingProxyProvider' signature='()V' name='testExceptionInfo' primary='true'><SourceLine endBytecode='338' classname='org.apache.hadoop.hdfs.server.namenode.ha.TestRequestHedgingProxyProvider' start='144' end='179' sourcepath='org/apache/hadoop/hdfs/server/namenode/ha/TestRequestHedgingProxyProvider.java' sourcefile='TestRequestHedgingProxyProvider.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.server.namenode.ha.TestRequestHedgingProxyProvider.testExceptionInfo()</Message></Method><SourceLine endBytecode='55' classname='org.apache.hadoop.hdfs.server.namenode.ha.TestRequestHedgingProxyProvider' start='160' end='160' sourcepath='org/apache/hadoop/hdfs/server/namenode/ha/TestRequestHedgingProxyProvider.java' sourcefile='TestRequestHedgingProxyProvider.java' startBytecode='55' primary='true'><Message>At TestRequestHedgingProxyProvider.java:[line 160]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='a18818dfccba5d412fd26a3c6d2bf091' rank='20' abbrev='SIC' category='PERFORMANCE' priority='3' type='SIC_INNER_SHOULD_BE_STATIC_ANON' instanceOccurrenceMax='0'><ShortMessage>Could be refactored into a named static inner class</ShortMessage><LongMessage>The class org.apache.hadoop.hdfs.server.namenode.ha.TestRequestHedgingProxyProvider$6 could be refactored into a named _static_ inner class</LongMessage><Class role='CLASS_ANONYMOUS' classname='org.apache.hadoop.hdfs.server.namenode.ha.TestRequestHedgingProxyProvider$6'><SourceLine classname='org.apache.hadoop.hdfs.server.namenode.ha.TestRequestHedgingProxyProvider$6' start='184' end='188' sourcepath='org/apache/hadoop/hdfs/server/namenode/ha/TestRequestHedgingProxyProvider.java' sourcefile='TestRequestHedgingProxyProvider.java'><Message>At TestRequestHedgingProxyProvider.java:[lines 184-188]</Message></SourceLine><Message>Anonymous class org.apache.hadoop.hdfs.server.namenode.ha.TestRequestHedgingProxyProvider$6</Message></Class><Class classname='org.apache.hadoop.hdfs.server.namenode.ha.TestRequestHedgingProxyProvider' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.server.namenode.ha.TestRequestHedgingProxyProvider' start='58' end='641' sourcepath='org/apache/hadoop/hdfs/server/namenode/ha/TestRequestHedgingProxyProvider.java' sourcefile='TestRequestHedgingProxyProvider.java'><Message>At TestRequestHedgingProxyProvider.java:[lines 58-641]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.server.namenode.ha.TestRequestHedgingProxyProvider</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.server.namenode.ha.TestRequestHedgingProxyProvider' signature='()V' name='testHedgingWhenOneIsSlow' primary='true'><SourceLine endBytecode='348' classname='org.apache.hadoop.hdfs.server.namenode.ha.TestRequestHedgingProxyProvider' start='183' end='202' sourcepath='org/apache/hadoop/hdfs/server/namenode/ha/TestRequestHedgingProxyProvider.java' sourcefile='TestRequestHedgingProxyProvider.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.server.namenode.ha.TestRequestHedgingProxyProvider.testHedgingWhenOneIsSlow()</Message></Method><SourceLine endBytecode='23' classname='org.apache.hadoop.hdfs.server.namenode.ha.TestRequestHedgingProxyProvider' start='184' end='184' sourcepath='org/apache/hadoop/hdfs/server/namenode/ha/TestRequestHedgingProxyProvider.java' sourcefile='TestRequestHedgingProxyProvider.java' startBytecode='23' primary='true'><Message>At TestRequestHedgingProxyProvider.java:[line 184]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='26a8de6422d193886d85735a65c52daa' rank='20' abbrev='SIC' category='PERFORMANCE' priority='3' type='SIC_INNER_SHOULD_BE_STATIC_ANON' instanceOccurrenceMax='0'><ShortMessage>Could be refactored into a named static inner class</ShortMessage><LongMessage>The class org.apache.hadoop.hdfs.server.namenode.ha.TestRequestHedgingProxyProvider$7 could be refactored into a named _static_ inner class</LongMessage><Class role='CLASS_ANONYMOUS' classname='org.apache.hadoop.hdfs.server.namenode.ha.TestRequestHedgingProxyProvider$7'><SourceLine classname='org.apache.hadoop.hdfs.server.namenode.ha.TestRequestHedgingProxyProvider$7' start='230' end='238' sourcepath='org/apache/hadoop/hdfs/server/namenode/ha/TestRequestHedgingProxyProvider.java' sourcefile='TestRequestHedgingProxyProvider.java'><Message>At TestRequestHedgingProxyProvider.java:[lines 230-238]</Message></SourceLine><Message>Anonymous class org.apache.hadoop.hdfs.server.namenode.ha.TestRequestHedgingProxyProvider$7</Message></Class><Class classname='org.apache.hadoop.hdfs.server.namenode.ha.TestRequestHedgingProxyProvider' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.server.namenode.ha.TestRequestHedgingProxyProvider' start='58' end='641' sourcepath='org/apache/hadoop/hdfs/server/namenode/ha/TestRequestHedgingProxyProvider.java' sourcefile='TestRequestHedgingProxyProvider.java'><Message>At TestRequestHedgingProxyProvider.java:[lines 58-641]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.server.namenode.ha.TestRequestHedgingProxyProvider</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.server.namenode.ha.TestRequestHedgingProxyProvider' signature='()V' name='testPerformFailover' primary='true'><SourceLine endBytecode='943' classname='org.apache.hadoop.hdfs.server.namenode.ha.TestRequestHedgingProxyProvider' start='227' end='312' sourcepath='org/apache/hadoop/hdfs/server/namenode/ha/TestRequestHedgingProxyProvider.java' sourcefile='TestRequestHedgingProxyProvider.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.server.namenode.ha.TestRequestHedgingProxyProvider.testPerformFailover()</Message></Method><SourceLine endBytecode='42' classname='org.apache.hadoop.hdfs.server.namenode.ha.TestRequestHedgingProxyProvider' start='230' end='230' sourcepath='org/apache/hadoop/hdfs/server/namenode/ha/TestRequestHedgingProxyProvider.java' sourcefile='TestRequestHedgingProxyProvider.java' startBytecode='42' primary='true'><Message>At TestRequestHedgingProxyProvider.java:[line 230]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='77d76e3df17ce1d8745637a2eb570b9d' rank='20' abbrev='SIC' category='PERFORMANCE' priority='3' type='SIC_INNER_SHOULD_BE_STATIC_ANON' instanceOccurrenceMax='0'><ShortMessage>Could be refactored into a named static inner class</ShortMessage><LongMessage>The class org.apache.hadoop.hdfs.server.namenode.ha.TestRequestHedgingProxyProvider$8 could be refactored into a named _static_ inner class</LongMessage><Class role='CLASS_ANONYMOUS' classname='org.apache.hadoop.hdfs.server.namenode.ha.TestRequestHedgingProxyProvider$8'><SourceLine classname='org.apache.hadoop.hdfs.server.namenode.ha.TestRequestHedgingProxyProvider$8' start='242' end='250' sourcepath='org/apache/hadoop/hdfs/server/namenode/ha/TestRequestHedgingProxyProvider.java' sourcefile='TestRequestHedgingProxyProvider.java'><Message>At TestRequestHedgingProxyProvider.java:[lines 242-250]</Message></SourceLine><Message>Anonymous class org.apache.hadoop.hdfs.server.namenode.ha.TestRequestHedgingProxyProvider$8</Message></Class><Class classname='org.apache.hadoop.hdfs.server.namenode.ha.TestRequestHedgingProxyProvider' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.server.namenode.ha.TestRequestHedgingProxyProvider' start='58' end='641' sourcepath='org/apache/hadoop/hdfs/server/namenode/ha/TestRequestHedgingProxyProvider.java' sourcefile='TestRequestHedgingProxyProvider.java'><Message>At TestRequestHedgingProxyProvider.java:[lines 58-641]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.server.namenode.ha.TestRequestHedgingProxyProvider</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.server.namenode.ha.TestRequestHedgingProxyProvider' signature='()V' name='testPerformFailover' primary='true'><SourceLine endBytecode='943' classname='org.apache.hadoop.hdfs.server.namenode.ha.TestRequestHedgingProxyProvider' start='227' end='312' sourcepath='org/apache/hadoop/hdfs/server/namenode/ha/TestRequestHedgingProxyProvider.java' sourcefile='TestRequestHedgingProxyProvider.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.server.namenode.ha.TestRequestHedgingProxyProvider.testPerformFailover()</Message></Method><SourceLine endBytecode='78' classname='org.apache.hadoop.hdfs.server.namenode.ha.TestRequestHedgingProxyProvider' start='242' end='242' sourcepath='org/apache/hadoop/hdfs/server/namenode/ha/TestRequestHedgingProxyProvider.java' sourcefile='TestRequestHedgingProxyProvider.java' startBytecode='78' primary='true'><Message>At TestRequestHedgingProxyProvider.java:[line 242]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='39ef666412ea96a4578948549e32d929' rank='20' abbrev='SIC' category='PERFORMANCE' priority='3' type='SIC_INNER_SHOULD_BE_STATIC_ANON' instanceOccurrenceMax='0'><ShortMessage>Could be refactored into a named static inner class</ShortMessage><LongMessage>The class org.apache.hadoop.hdfs.server.namenode.ha.TestRequestHedgingProxyProvider$9 could be refactored into a named _static_ inner class</LongMessage><Class role='CLASS_ANONYMOUS' classname='org.apache.hadoop.hdfs.server.namenode.ha.TestRequestHedgingProxyProvider$9'><SourceLine classname='org.apache.hadoop.hdfs.server.namenode.ha.TestRequestHedgingProxyProvider$9' start='426' end='434' sourcepath='org/apache/hadoop/hdfs/server/namenode/ha/TestRequestHedgingProxyProvider.java' sourcefile='TestRequestHedgingProxyProvider.java'><Message>At TestRequestHedgingProxyProvider.java:[lines 426-434]</Message></SourceLine><Message>Anonymous class org.apache.hadoop.hdfs.server.namenode.ha.TestRequestHedgingProxyProvider$9</Message></Class><Class classname='org.apache.hadoop.hdfs.server.namenode.ha.TestRequestHedgingProxyProvider' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.server.namenode.ha.TestRequestHedgingProxyProvider' start='58' end='641' sourcepath='org/apache/hadoop/hdfs/server/namenode/ha/TestRequestHedgingProxyProvider.java' sourcefile='TestRequestHedgingProxyProvider.java'><Message>At TestRequestHedgingProxyProvider.java:[lines 58-641]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.server.namenode.ha.TestRequestHedgingProxyProvider</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.server.namenode.ha.TestRequestHedgingProxyProvider' signature='()V' name='testPerformFailoverWith3Proxies' primary='true'><SourceLine endBytecode='1206' classname='org.apache.hadoop.hdfs.server.namenode.ha.TestRequestHedgingProxyProvider' start='418' end='535' sourcepath='org/apache/hadoop/hdfs/server/namenode/ha/TestRequestHedgingProxyProvider.java' sourcefile='TestRequestHedgingProxyProvider.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.server.namenode.ha.TestRequestHedgingProxyProvider.testPerformFailoverWith3Proxies()</Message></Method><SourceLine endBytecode='109' classname='org.apache.hadoop.hdfs.server.namenode.ha.TestRequestHedgingProxyProvider' start='426' end='426' sourcepath='org/apache/hadoop/hdfs/server/namenode/ha/TestRequestHedgingProxyProvider.java' sourcefile='TestRequestHedgingProxyProvider.java' startBytecode='109' primary='true'><Message>At TestRequestHedgingProxyProvider.java:[line 426]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='cb0a9b36c02b4398f5d1c81e62cc2cef' rank='20' abbrev='UwF' category='STYLE' priority='3' type='UWF_FIELD_NOT_INITIALIZED_IN_CONSTRUCTOR' instanceOccurrenceMax='0'><ShortMessage>Field not initialized in constructor but dereferenced without null check</ShortMessage><LongMessage>TestRequestHedgingProxyProvider.conf not initialized in constructor and dereferenced in org.apache.hadoop.hdfs.server.namenode.ha.TestRequestHedgingProxyProvider.testPerformFailoverWith3Proxies()</LongMessage><Class classname='org.apache.hadoop.hdfs.server.namenode.ha.TestRequestHedgingProxyProvider' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.server.namenode.ha.TestRequestHedgingProxyProvider' start='58' end='641' sourcepath='org/apache/hadoop/hdfs/server/namenode/ha/TestRequestHedgingProxyProvider.java' sourcefile='TestRequestHedgingProxyProvider.java'><Message>At TestRequestHedgingProxyProvider.java:[lines 58-641]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.server.namenode.ha.TestRequestHedgingProxyProvider</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.server.namenode.ha.TestRequestHedgingProxyProvider' signature='Lorg/apache/hadoop/conf/Configuration;' name='conf' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.server.namenode.ha.TestRequestHedgingProxyProvider' sourcepath='org/apache/hadoop/hdfs/server/namenode/ha/TestRequestHedgingProxyProvider.java' sourcefile='TestRequestHedgingProxyProvider.java'><Message>In TestRequestHedgingProxyProvider.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.server.namenode.ha.TestRequestHedgingProxyProvider.conf</Message></Field><Method isStatic='false' classname='org.apache.hadoop.hdfs.server.namenode.ha.TestRequestHedgingProxyProvider' signature='()V' name='testPerformFailoverWith3Proxies' primary='true'><SourceLine endBytecode='1206' classname='org.apache.hadoop.hdfs.server.namenode.ha.TestRequestHedgingProxyProvider' start='418' end='535' sourcepath='org/apache/hadoop/hdfs/server/namenode/ha/TestRequestHedgingProxyProvider.java' sourcefile='TestRequestHedgingProxyProvider.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.server.namenode.ha.TestRequestHedgingProxyProvider.testPerformFailoverWith3Proxies()</Message></Method><SourceLine endBytecode='28' classname='org.apache.hadoop.hdfs.server.namenode.ha.TestRequestHedgingProxyProvider' start='418' end='418' sourcepath='org/apache/hadoop/hdfs/server/namenode/ha/TestRequestHedgingProxyProvider.java' sourcefile='TestRequestHedgingProxyProvider.java' startBytecode='28' primary='true'><Message>At TestRequestHedgingProxyProvider.java:[line 418]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='d14520aa593f890144815c00d36b31a1' cweid='374' rank='18' abbrev='EI' category='MALICIOUS_CODE' priority='2' type='EI_EXPOSE_REP' instanceOccurrenceMax='0'><ShortMessage>May expose internal representation by returning reference to mutable object</ShortMessage><LongMessage>org.apache.hadoop.hdfs.server.protocol.DatanodeStorageReport.getStorageReports() may expose internal representation by returning DatanodeStorageReport.storageReports</LongMessage><Class classname='org.apache.hadoop.hdfs.server.protocol.DatanodeStorageReport' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.server.protocol.DatanodeStorageReport' start='30' end='40' sourcepath='org/apache/hadoop/hdfs/server/protocol/DatanodeStorageReport.java' sourcefile='DatanodeStorageReport.java'><Message>At DatanodeStorageReport.java:[lines 30-40]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.server.protocol.DatanodeStorageReport</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.server.protocol.DatanodeStorageReport' signature='()[Lorg/apache/hadoop/hdfs/server/protocol/StorageReport;' name='getStorageReports' primary='true'><SourceLine endBytecode='46' classname='org.apache.hadoop.hdfs.server.protocol.DatanodeStorageReport' start='40' end='40' sourcepath='org/apache/hadoop/hdfs/server/protocol/DatanodeStorageReport.java' sourcefile='DatanodeStorageReport.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.server.protocol.DatanodeStorageReport.getStorageReports()</Message></Method><Field isStatic='false' classname='org.apache.hadoop.hdfs.server.protocol.DatanodeStorageReport' signature='[Lorg/apache/hadoop/hdfs/server/protocol/StorageReport;' name='storageReports' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.server.protocol.DatanodeStorageReport' sourcepath='org/apache/hadoop/hdfs/server/protocol/DatanodeStorageReport.java' sourcefile='DatanodeStorageReport.java'><Message>In DatanodeStorageReport.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.server.protocol.DatanodeStorageReport.storageReports</Message></Field><SourceLine endBytecode='4' classname='org.apache.hadoop.hdfs.server.protocol.DatanodeStorageReport' start='40' end='40' sourcepath='org/apache/hadoop/hdfs/server/protocol/DatanodeStorageReport.java' sourcefile='DatanodeStorageReport.java' startBytecode='4' primary='true'><Message>At DatanodeStorageReport.java:[line 40]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='6690bada1a155c9d02abc5ee3556189e' cweid='374' rank='18' abbrev='EI2' category='MALICIOUS_CODE' priority='2' type='EI_EXPOSE_REP2' instanceOccurrenceMax='0'><ShortMessage>May expose internal representation by incorporating reference to mutable object</ShortMessage><LongMessage>new org.apache.hadoop.hdfs.server.protocol.DatanodeStorageReport(DatanodeInfo, StorageReport[]) may expose internal representation by storing an externally mutable object into DatanodeStorageReport.storageReports</LongMessage><Class classname='org.apache.hadoop.hdfs.server.protocol.DatanodeStorageReport' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.server.protocol.DatanodeStorageReport' start='30' end='40' sourcepath='org/apache/hadoop/hdfs/server/protocol/DatanodeStorageReport.java' sourcefile='DatanodeStorageReport.java'><Message>At DatanodeStorageReport.java:[lines 30-40]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.server.protocol.DatanodeStorageReport</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.server.protocol.DatanodeStorageReport' signature='(Lorg/apache/hadoop/hdfs/protocol/DatanodeInfo;[Lorg/apache/hadoop/hdfs/server/protocol/StorageReport;)V' name='&lt;init&gt;' primary='true'><SourceLine endBytecode='88' classname='org.apache.hadoop.hdfs.server.protocol.DatanodeStorageReport' start='30' end='33' sourcepath='org/apache/hadoop/hdfs/server/protocol/DatanodeStorageReport.java' sourcefile='DatanodeStorageReport.java' startBytecode='0'></SourceLine><Message>In method new org.apache.hadoop.hdfs.server.protocol.DatanodeStorageReport(DatanodeInfo, StorageReport[])</Message></Method><Field isStatic='false' classname='org.apache.hadoop.hdfs.server.protocol.DatanodeStorageReport' signature='[Lorg/apache/hadoop/hdfs/server/protocol/StorageReport;' name='storageReports' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.server.protocol.DatanodeStorageReport' sourcepath='org/apache/hadoop/hdfs/server/protocol/DatanodeStorageReport.java' sourcefile='DatanodeStorageReport.java'><Message>In DatanodeStorageReport.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.server.protocol.DatanodeStorageReport.storageReports</Message></Field><LocalVariable role='LOCAL_VARIABLE_NAMED' pc='11' name='storageReports' register='2'><Message>Local variable named storageReports</Message></LocalVariable><SourceLine endBytecode='11' classname='org.apache.hadoop.hdfs.server.protocol.DatanodeStorageReport' start='32' end='32' sourcepath='org/apache/hadoop/hdfs/server/protocol/DatanodeStorageReport.java' sourcefile='DatanodeStorageReport.java' startBytecode='11' primary='true'><Message>At DatanodeStorageReport.java:[line 32]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='4dc2343836b62bb7a6ed714b66a1c801' rank='12' abbrev='UL' category='MT_CORRECTNESS' priority='1' type='UL_UNRELEASED_LOCK' instanceOccurrenceMax='0'><ShortMessage>Method does not release lock on all paths</ShortMessage><LongMessage>org.apache.hadoop.hdfs.shortcircuit.DfsClientShmManager$EndpointShmManager.allocSlot(DomainPeer, MutableBoolean, String, ExtendedBlockId) does not release lock on all paths</LongMessage><Class classname='org.apache.hadoop.hdfs.shortcircuit.DfsClientShmManager$EndpointShmManager' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.shortcircuit.DfsClientShmManager$EndpointShmManager' start='83' end='368' sourcepath='org/apache/hadoop/hdfs/shortcircuit/DfsClientShmManager.java' sourcefile='DfsClientShmManager.java'><Message>At DfsClientShmManager.java:[lines 83-368]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.shortcircuit.DfsClientShmManager$EndpointShmManager</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.shortcircuit.DfsClientShmManager$EndpointShmManager' signature='(Lorg/apache/hadoop/hdfs/net/DomainPeer;Lorg/apache/commons/lang/mutable/MutableBoolean;Ljava/lang/String;Lorg/apache/hadoop/hdfs/ExtendedBlockId;)Lorg/apache/hadoop/hdfs/shortcircuit/ShortCircuitShm$Slot;' name='allocSlot' primary='true'><SourceLine endBytecode='116' classname='org.apache.hadoop.hdfs.shortcircuit.DfsClientShmManager$EndpointShmManager' start='228' end='278' sourcepath='org/apache/hadoop/hdfs/shortcircuit/DfsClientShmManager.java' sourcefile='DfsClientShmManager.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.shortcircuit.DfsClientShmManager$EndpointShmManager.allocSlot(DomainPeer, MutableBoolean, String, ExtendedBlockId)</Message></Method><SourceLine endBytecode='127' classname='org.apache.hadoop.hdfs.shortcircuit.DfsClientShmManager$EndpointShmManager' start='261' end='261' sourcepath='org/apache/hadoop/hdfs/shortcircuit/DfsClientShmManager.java' sourcefile='DfsClientShmManager.java' startBytecode='127' primary='true'><Message>At DfsClientShmManager.java:[line 261]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='49737b1b9fa250af946bbbb5537555da' rank='14' abbrev='UL' category='MT_CORRECTNESS' priority='2' type='UL_UNRELEASED_LOCK_EXCEPTION_PATH' instanceOccurrenceMax='0'><ShortMessage>Method does not release lock on all exception paths</ShortMessage><LongMessage>org.apache.hadoop.hdfs.shortcircuit.DfsClientShmManager$EndpointShmManager.allocSlot(DomainPeer, MutableBoolean, String, ExtendedBlockId) does not release lock on all exception paths</LongMessage><Class classname='org.apache.hadoop.hdfs.shortcircuit.DfsClientShmManager$EndpointShmManager' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.shortcircuit.DfsClientShmManager$EndpointShmManager' start='83' end='368' sourcepath='org/apache/hadoop/hdfs/shortcircuit/DfsClientShmManager.java' sourcefile='DfsClientShmManager.java'><Message>At DfsClientShmManager.java:[lines 83-368]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.shortcircuit.DfsClientShmManager$EndpointShmManager</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.shortcircuit.DfsClientShmManager$EndpointShmManager' signature='(Lorg/apache/hadoop/hdfs/net/DomainPeer;Lorg/apache/commons/lang/mutable/MutableBoolean;Ljava/lang/String;Lorg/apache/hadoop/hdfs/ExtendedBlockId;)Lorg/apache/hadoop/hdfs/shortcircuit/ShortCircuitShm$Slot;' name='allocSlot' primary='true'><SourceLine endBytecode='116' classname='org.apache.hadoop.hdfs.shortcircuit.DfsClientShmManager$EndpointShmManager' start='228' end='278' sourcepath='org/apache/hadoop/hdfs/shortcircuit/DfsClientShmManager.java' sourcefile='DfsClientShmManager.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.shortcircuit.DfsClientShmManager$EndpointShmManager.allocSlot(DomainPeer, MutableBoolean, String, ExtendedBlockId)</Message></Method><SourceLine endBytecode='210' classname='org.apache.hadoop.hdfs.shortcircuit.DfsClientShmManager$EndpointShmManager' start='261' end='261' sourcepath='org/apache/hadoop/hdfs/shortcircuit/DfsClientShmManager.java' sourcefile='DfsClientShmManager.java' startBytecode='210' primary='true'><Message>At DfsClientShmManager.java:[line 261]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='a47b442e8670ec99674bc4f1cb028738' rank='20' abbrev='UrF' category='STYLE' priority='3' type='URF_UNREAD_PUBLIC_OR_PROTECTED_FIELD' instanceOccurrenceMax='0'><ShortMessage>Unread public/protected field</ShortMessage><LongMessage>Unread public/protected field: org.apache.hadoop.hdfs.shortcircuit.DfsClientShmManager$PerDatanodeVisitorInfo.disabled</LongMessage><Class classname='org.apache.hadoop.hdfs.shortcircuit.DfsClientShmManager$PerDatanodeVisitorInfo' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.shortcircuit.DfsClientShmManager$PerDatanodeVisitorInfo' start='441' end='445' sourcepath='org/apache/hadoop/hdfs/shortcircuit/DfsClientShmManager.java' sourcefile='DfsClientShmManager.java'><Message>At DfsClientShmManager.java:[lines 441-445]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.shortcircuit.DfsClientShmManager$PerDatanodeVisitorInfo</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.shortcircuit.DfsClientShmManager$PerDatanodeVisitorInfo' signature='Z' name='disabled' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.shortcircuit.DfsClientShmManager$PerDatanodeVisitorInfo' sourcepath='org/apache/hadoop/hdfs/shortcircuit/DfsClientShmManager.java' sourcefile='DfsClientShmManager.java'><Message>In DfsClientShmManager.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.shortcircuit.DfsClientShmManager$PerDatanodeVisitorInfo.disabled</Message></Field><SourceLine endBytecode='16' classname='org.apache.hadoop.hdfs.shortcircuit.DfsClientShmManager$PerDatanodeVisitorInfo' start='444' end='444' sourcepath='org/apache/hadoop/hdfs/shortcircuit/DfsClientShmManager.java' sourcefile='DfsClientShmManager.java' startBytecode='16' primary='true'><Message>At DfsClientShmManager.java:[line 444]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='43cb5ed12fb4a353e2927f942d5a5c44' rank='20' abbrev='UrF' category='STYLE' priority='3' type='URF_UNREAD_PUBLIC_OR_PROTECTED_FIELD' instanceOccurrenceMax='0'><ShortMessage>Unread public/protected field</ShortMessage><LongMessage>Unread public/protected field: org.apache.hadoop.hdfs.shortcircuit.DfsClientShmManager$PerDatanodeVisitorInfo.full</LongMessage><Class classname='org.apache.hadoop.hdfs.shortcircuit.DfsClientShmManager$PerDatanodeVisitorInfo' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.shortcircuit.DfsClientShmManager$PerDatanodeVisitorInfo' start='441' end='445' sourcepath='org/apache/hadoop/hdfs/shortcircuit/DfsClientShmManager.java' sourcefile='DfsClientShmManager.java'><Message>At DfsClientShmManager.java:[lines 441-445]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.shortcircuit.DfsClientShmManager$PerDatanodeVisitorInfo</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.shortcircuit.DfsClientShmManager$PerDatanodeVisitorInfo' signature='Ljava/util/TreeMap;' name='full' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.shortcircuit.DfsClientShmManager$PerDatanodeVisitorInfo' sourcepath='org/apache/hadoop/hdfs/shortcircuit/DfsClientShmManager.java' sourcefile='DfsClientShmManager.java'><Message>In DfsClientShmManager.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.shortcircuit.DfsClientShmManager$PerDatanodeVisitorInfo.full</Message></Field><SourceLine endBytecode='6' classname='org.apache.hadoop.hdfs.shortcircuit.DfsClientShmManager$PerDatanodeVisitorInfo' start='442' end='442' sourcepath='org/apache/hadoop/hdfs/shortcircuit/DfsClientShmManager.java' sourcefile='DfsClientShmManager.java' startBytecode='6' primary='true'><Message>At DfsClientShmManager.java:[line 442]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='73522fd63b164b08902924bb8926af00' rank='20' abbrev='UrF' category='STYLE' priority='3' type='URF_UNREAD_PUBLIC_OR_PROTECTED_FIELD' instanceOccurrenceMax='0'><ShortMessage>Unread public/protected field</ShortMessage><LongMessage>Unread public/protected field: org.apache.hadoop.hdfs.shortcircuit.DfsClientShmManager$PerDatanodeVisitorInfo.notFull</LongMessage><Class classname='org.apache.hadoop.hdfs.shortcircuit.DfsClientShmManager$PerDatanodeVisitorInfo' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.shortcircuit.DfsClientShmManager$PerDatanodeVisitorInfo' start='441' end='445' sourcepath='org/apache/hadoop/hdfs/shortcircuit/DfsClientShmManager.java' sourcefile='DfsClientShmManager.java'><Message>At DfsClientShmManager.java:[lines 441-445]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.shortcircuit.DfsClientShmManager$PerDatanodeVisitorInfo</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.shortcircuit.DfsClientShmManager$PerDatanodeVisitorInfo' signature='Ljava/util/TreeMap;' name='notFull' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.shortcircuit.DfsClientShmManager$PerDatanodeVisitorInfo' sourcepath='org/apache/hadoop/hdfs/shortcircuit/DfsClientShmManager.java' sourcefile='DfsClientShmManager.java'><Message>In DfsClientShmManager.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.shortcircuit.DfsClientShmManager$PerDatanodeVisitorInfo.notFull</Message></Field><SourceLine endBytecode='11' classname='org.apache.hadoop.hdfs.shortcircuit.DfsClientShmManager$PerDatanodeVisitorInfo' start='443' end='443' sourcepath='org/apache/hadoop/hdfs/shortcircuit/DfsClientShmManager.java' sourcefile='DfsClientShmManager.java' startBytecode='11' primary='true'><Message>At DfsClientShmManager.java:[line 443]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='af04956d6553696e8344d9c84f2491a9' cweid='563' rank='20' abbrev='DLS' category='STYLE' priority='3' type='DLS_DEAD_LOCAL_STORE' instanceOccurrenceMax='0'><ShortMessage>Dead store to local variable</ShortMessage><LongMessage>Dead store to $L5 in org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache.insertEvictable(Long, ShortCircuitReplica, LinkedMap)</LongMessage><Class classname='org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache' start='72' end='1043' sourcepath='org/apache/hadoop/hdfs/shortcircuit/ShortCircuitCache.java' sourcefile='ShortCircuitCache.java'><Message>At ShortCircuitCache.java:[lines 72-1043]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache' signature='(Ljava/lang/Long;Lorg/apache/hadoop/hdfs/shortcircuit/ShortCircuitReplica;Lorg/apache/commons/collections/map/LinkedMap;)V' name='insertEvictable' primary='true'><SourceLine endBytecode='33' classname='org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache' start='616' end='622' sourcepath='org/apache/hadoop/hdfs/shortcircuit/ShortCircuitCache.java' sourcefile='ShortCircuitCache.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache.insertEvictable(Long, ShortCircuitReplica, LinkedMap)</Message></Method><LocalVariable role='LOCAL_VARIABLE_UNKNOWN' pc='22' name='?' register='5'><Message>Local variable stored in JVM register 5</Message></LocalVariable><SourceLine endBytecode='22' classname='org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache' start='617' end='617' sourcepath='org/apache/hadoop/hdfs/shortcircuit/ShortCircuitCache.java' sourcefile='ShortCircuitCache.java' startBytecode='22' primary='true'><Message>At ShortCircuitCache.java:[line 617]</Message></SourceLine><Property name='edu.umd.cs.findbugs.detect.DeadLocalStoreProperty.KILLED_BY_SUBSEQUENT_STORE' value='true'></Property><Property name='edu.umd.cs.findbugs.detect.DeadLocalStoreProperty.LOCAL_NAME' value='?'></Property><Property name='edu.umd.cs.findbugs.detect.DeadLocalStoreProperty.NO_LOADS' value='true'></Property></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='348a2103c2bfd634694733169b04901d' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST_OF_RETURN_VALUE' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast of return value from method</ShortMessage><LongMessage>Unchecked/unconfirmed cast from org.apache.hadoop.hdfs.shortcircuit.ShortCircuitShm to org.apache.hadoop.hdfs.shortcircuit.DfsClientShm of return value in org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache$SlotReleaser.run()</LongMessage><Class classname='org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache$SlotReleaser' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache$SlotReleaser' start='184' end='221' sourcepath='org/apache/hadoop/hdfs/shortcircuit/ShortCircuitCache.java' sourcefile='ShortCircuitCache.java'><Message>At ShortCircuitCache.java:[lines 184-221]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache$SlotReleaser</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache$SlotReleaser' signature='()V' name='run' primary='true'><SourceLine endBytecode='231' classname='org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache$SlotReleaser' start='190' end='221' sourcepath='org/apache/hadoop/hdfs/shortcircuit/ShortCircuitCache.java' sourcefile='ShortCircuitCache.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache$SlotReleaser.run()</Message></Method><Type role='TYPE_FOUND' descriptor='Lorg/apache/hadoop/hdfs/shortcircuit/ShortCircuitShm;'><SourceLine classname='org.apache.hadoop.hdfs.shortcircuit.ShortCircuitShm' start='51' end='639' sourcepath='org/apache/hadoop/hdfs/shortcircuit/ShortCircuitShm.java' sourcefile='ShortCircuitShm.java'><Message>At ShortCircuitShm.java:[lines 51-639]</Message></SourceLine><Message>Actual type org.apache.hadoop.hdfs.shortcircuit.ShortCircuitShm</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/hdfs/shortcircuit/DfsClientShm;'><SourceLine classname='org.apache.hadoop.hdfs.shortcircuit.DfsClientShm' start='66' end='117' sourcepath='org/apache/hadoop/hdfs/shortcircuit/DfsClientShm.java' sourcefile='DfsClientShm.java'><Message>At DfsClientShm.java:[lines 66-117]</Message></SourceLine><Message>Expected org.apache.hadoop.hdfs.shortcircuit.DfsClientShm</Message></Type><SourceLine endBytecode='25' classname='org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache$SlotReleaser' start='191' end='191' sourcepath='org/apache/hadoop/hdfs/shortcircuit/ShortCircuitCache.java' sourcefile='ShortCircuitCache.java' startBytecode='25' primary='true'><Message>At ShortCircuitCache.java:[line 191]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='91ed4e919f3e66541d02394e6011abf0' cweid='253' rank='16' abbrev='RV' category='BAD_PRACTICE' priority='2' type='RV_RETURN_VALUE_IGNORED_BAD_PRACTICE' instanceOccurrenceMax='0'><ShortMessage>Method ignores exceptional return value</ShortMessage><LongMessage>Exceptional return value of java.io.File.mkdirs() ignored in org.apache.hadoop.hdfs.shortcircuit.TestShortCircuitShm.testAllocateSlots()</LongMessage><Class classname='org.apache.hadoop.hdfs.shortcircuit.TestShortCircuitShm' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.shortcircuit.TestShortCircuitShm' start='38' end='108' sourcepath='org/apache/hadoop/hdfs/shortcircuit/TestShortCircuitShm.java' sourcefile='TestShortCircuitShm.java'><Message>At TestShortCircuitShm.java:[lines 38-108]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.shortcircuit.TestShortCircuitShm</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.shortcircuit.TestShortCircuitShm' signature='()V' name='testAllocateSlots' primary='true'><SourceLine endBytecode='872' classname='org.apache.hadoop.hdfs.shortcircuit.TestShortCircuitShm' start='67' end='108' sourcepath='org/apache/hadoop/hdfs/shortcircuit/TestShortCircuitShm.java' sourcefile='TestShortCircuitShm.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.shortcircuit.TestShortCircuitShm.testAllocateSlots()</Message></Method><Method isStatic='false' role='METHOD_CALLED' classname='java.io.File' signature='()Z' name='mkdirs'><SourceLine endBytecode='182' classname='java.io.File' start='1340' end='1354' sourcepath='java/io/File.java' sourcefile='File.java' startBytecode='0'></SourceLine><Message>Called method java.io.File.mkdirs()</Message></Method><SourceLine endBytecode='14' classname='org.apache.hadoop.hdfs.shortcircuit.TestShortCircuitShm' start='68' end='68' sourcepath='org/apache/hadoop/hdfs/shortcircuit/TestShortCircuitShm.java' sourcefile='TestShortCircuitShm.java' startBytecode='14' primary='true'><Message>At TestShortCircuitShm.java:[line 68]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='77ac032ccfc1a0516cf5499842b7acf8' cweid='253' rank='16' abbrev='RV' category='BAD_PRACTICE' priority='2' type='RV_RETURN_VALUE_IGNORED_BAD_PRACTICE' instanceOccurrenceMax='0'><ShortMessage>Method ignores exceptional return value</ShortMessage><LongMessage>Exceptional return value of java.io.File.mkdirs() ignored in org.apache.hadoop.hdfs.shortcircuit.TestShortCircuitShm.testStartupShutdown()</LongMessage><Class classname='org.apache.hadoop.hdfs.shortcircuit.TestShortCircuitShm' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.shortcircuit.TestShortCircuitShm' start='38' end='108' sourcepath='org/apache/hadoop/hdfs/shortcircuit/TestShortCircuitShm.java' sourcefile='TestShortCircuitShm.java'><Message>At TestShortCircuitShm.java:[lines 38-108]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.shortcircuit.TestShortCircuitShm</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.shortcircuit.TestShortCircuitShm' signature='()V' name='testStartupShutdown' primary='true'><SourceLine endBytecode='198' classname='org.apache.hadoop.hdfs.shortcircuit.TestShortCircuitShm' start='52' end='63' sourcepath='org/apache/hadoop/hdfs/shortcircuit/TestShortCircuitShm.java' sourcefile='TestShortCircuitShm.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.shortcircuit.TestShortCircuitShm.testStartupShutdown()</Message></Method><Method isStatic='false' role='METHOD_CALLED' classname='java.io.File' signature='()Z' name='mkdirs'><SourceLine endBytecode='182' classname='java.io.File' start='1340' end='1354' sourcepath='java/io/File.java' sourcefile='File.java' startBytecode='0'></SourceLine><Message>Called method java.io.File.mkdirs()</Message></Method><SourceLine endBytecode='14' classname='org.apache.hadoop.hdfs.shortcircuit.TestShortCircuitShm' start='53' end='53' sourcepath='org/apache/hadoop/hdfs/shortcircuit/TestShortCircuitShm.java' sourcefile='TestShortCircuitShm.java' startBytecode='14' primary='true'><Message>At TestShortCircuitShm.java:[line 53]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='1b3c189de628d156f908120b00871ad0' rank='17' abbrev='No' category='MT_CORRECTNESS' priority='3' type='NO_NOTIFY_NOT_NOTIFYALL' instanceOccurrenceMax='0'><ShortMessage>Using notify() rather than notifyAll()</ShortMessage><LongMessage>Using notify rather than notifyAll in org.apache.hadoop.hdfs.util.ByteArrayManager$FixedLengthManager.recycle(byte[])</LongMessage><Class classname='org.apache.hadoop.hdfs.util.ByteArrayManager$FixedLengthManager' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.util.ByteArrayManager$FixedLengthManager' start='144' end='221' sourcepath='org/apache/hadoop/hdfs/util/ByteArrayManager.java' sourcefile='ByteArrayManager.java'><Message>At ByteArrayManager.java:[lines 144-221]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.util.ByteArrayManager$FixedLengthManager</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.util.ByteArrayManager$FixedLengthManager' signature='([B)I' name='recycle' primary='true'><SourceLine endBytecode='260' classname='org.apache.hadoop.hdfs.util.ByteArrayManager$FixedLengthManager' start='195' end='215' sourcepath='org/apache/hadoop/hdfs/util/ByteArrayManager.java' sourcefile='ByteArrayManager.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.util.ByteArrayManager$FixedLengthManager.recycle(byte[])</Message></Method><SourceLine endBytecode='53' classname='org.apache.hadoop.hdfs.util.ByteArrayManager$FixedLengthManager' start='201' end='201' sourcepath='org/apache/hadoop/hdfs/util/ByteArrayManager.java' sourcefile='ByteArrayManager.java' startBytecode='53' primary='true'><Message>At ByteArrayManager.java:[line 201]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='eece50d2100d76ff32943f8838aa8823' cweid='253' rank='19' abbrev='RV' category='BAD_PRACTICE' priority='3' type='RV_RETURN_VALUE_IGNORED_BAD_PRACTICE' instanceOccurrenceMax='0'><ShortMessage>Method ignores exceptional return value</ShortMessage><LongMessage>Exceptional return value of java.util.Queue.offer(Object) ignored in org.apache.hadoop.hdfs.util.ByteArrayManager$FixedLengthManager.recycle(byte[])</LongMessage><Class classname='org.apache.hadoop.hdfs.util.ByteArrayManager$FixedLengthManager' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.util.ByteArrayManager$FixedLengthManager' start='144' end='221' sourcepath='org/apache/hadoop/hdfs/util/ByteArrayManager.java' sourcefile='ByteArrayManager.java'><Message>At ByteArrayManager.java:[lines 144-221]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.util.ByteArrayManager$FixedLengthManager</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.util.ByteArrayManager$FixedLengthManager' signature='([B)I' name='recycle' primary='true'><SourceLine endBytecode='260' classname='org.apache.hadoop.hdfs.util.ByteArrayManager$FixedLengthManager' start='195' end='215' sourcepath='org/apache/hadoop/hdfs/util/ByteArrayManager.java' sourcefile='ByteArrayManager.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.util.ByteArrayManager$FixedLengthManager.recycle(byte[])</Message></Method><Method isStatic='false' role='METHOD_CALLED' classname='java.util.Queue' signature='(Ljava/lang/Object;)Z' name='offer'><SourceLine classname='java.util.Queue' sourcepath='java/util/Queue.java' sourcefile='Queue.java'></SourceLine><Message>Called method java.util.Queue.offer(Object)</Message></Method><SourceLine endBytecode='130' classname='org.apache.hadoop.hdfs.util.ByteArrayManager$FixedLengthManager' start='213' end='213' sourcepath='org/apache/hadoop/hdfs/util/ByteArrayManager.java' sourcefile='ByteArrayManager.java' startBytecode='130' primary='true'><Message>At ByteArrayManager.java:[line 213]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='9bba85cffd18941869b7d2e7e0e9ae57' rank='20' abbrev='UrF' category='PERFORMANCE' priority='3' type='URF_UNREAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Unread field</ShortMessage><LongMessage>Unread field: org.apache.hadoop.hdfs.util.StripedBlockUtil$StripingCell.ecPolicy</LongMessage><Class classname='org.apache.hadoop.hdfs.util.StripedBlockUtil$StripingCell' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.util.StripedBlockUtil$StripingCell' start='580' end='614' sourcepath='org/apache/hadoop/hdfs/util/StripedBlockUtil.java' sourcefile='StripedBlockUtil.java'><Message>At StripedBlockUtil.java:[lines 580-614]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.util.StripedBlockUtil$StripingCell</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.util.StripedBlockUtil$StripingCell' signature='Lorg/apache/hadoop/hdfs/protocol/ErasureCodingPolicy;' name='ecPolicy' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.util.StripedBlockUtil$StripingCell' sourcepath='org/apache/hadoop/hdfs/util/StripedBlockUtil.java' sourcefile='StripedBlockUtil.java'><Message>In StripedBlockUtil.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.util.StripedBlockUtil$StripingCell.ecPolicy</Message></Field><SourceLine endBytecode='6' classname='org.apache.hadoop.hdfs.util.StripedBlockUtil$StripingCell' start='597' end='597' sourcepath='org/apache/hadoop/hdfs/util/StripedBlockUtil.java' sourcefile='StripedBlockUtil.java' startBytecode='6' primary='true'><Message>At StripedBlockUtil.java:[line 597]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='60435c14db1d5973c9680d1b0d02338a' rank='20' abbrev='SIC' category='PERFORMANCE' priority='3' type='SIC_INNER_SHOULD_BE_STATIC_ANON' instanceOccurrenceMax='0'><ShortMessage>Could be refactored into a named static inner class</ShortMessage><LongMessage>The class org.apache.hadoop.hdfs.util.TestByteArrayManager$2 could be refactored into a named _static_ inner class</LongMessage><Class role='CLASS_ANONYMOUS' classname='org.apache.hadoop.hdfs.util.TestByteArrayManager$2'><SourceLine classname='org.apache.hadoop.hdfs.util.TestByteArrayManager$2' start='81' end='84' sourcepath='org/apache/hadoop/hdfs/util/TestByteArrayManager.java' sourcefile='TestByteArrayManager.java'><Message>At TestByteArrayManager.java:[lines 81-84]</Message></SourceLine><Message>Anonymous class org.apache.hadoop.hdfs.util.TestByteArrayManager$2</Message></Class><Class classname='org.apache.hadoop.hdfs.util.TestByteArrayManager' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.util.TestByteArrayManager' start='50' end='642' sourcepath='org/apache/hadoop/hdfs/util/TestByteArrayManager.java' sourcefile='TestByteArrayManager.java'><Message>At TestByteArrayManager.java:[lines 50-642]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.util.TestByteArrayManager</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.util.TestByteArrayManager' signature='()V' name='testCounter' primary='true'><SourceLine endBytecode='475' classname='org.apache.hadoop.hdfs.util.TestByteArrayManager' start='71' end='105' sourcepath='org/apache/hadoop/hdfs/util/TestByteArrayManager.java' sourcefile='TestByteArrayManager.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.util.TestByteArrayManager.testCounter()</Message></Method><SourceLine endBytecode='68' classname='org.apache.hadoop.hdfs.util.TestByteArrayManager' start='81' end='81' sourcepath='org/apache/hadoop/hdfs/util/TestByteArrayManager.java' sourcefile='TestByteArrayManager.java' startBytecode='68' primary='true'><Message>At TestByteArrayManager.java:[line 81]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='e846491fa20b87f2170043051f0ee7ae' rank='20' abbrev='SIC' category='PERFORMANCE' priority='3' type='SIC_INNER_SHOULD_BE_STATIC_ANON' instanceOccurrenceMax='0'><ShortMessage>Could be refactored into a named static inner class</ShortMessage><LongMessage>The class org.apache.hadoop.hdfs.util.TestByteArrayManager$3 could be refactored into a named _static_ inner class</LongMessage><Class role='CLASS_ANONYMOUS' classname='org.apache.hadoop.hdfs.util.TestByteArrayManager$3'><SourceLine classname='org.apache.hadoop.hdfs.util.TestByteArrayManager$3' start='331' end='361' sourcepath='org/apache/hadoop/hdfs/util/TestByteArrayManager.java' sourcefile='TestByteArrayManager.java'><Message>At TestByteArrayManager.java:[lines 331-361]</Message></SourceLine><Message>Anonymous class org.apache.hadoop.hdfs.util.TestByteArrayManager$3</Message></Class><Class classname='org.apache.hadoop.hdfs.util.TestByteArrayManager' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.util.TestByteArrayManager' start='50' end='642' sourcepath='org/apache/hadoop/hdfs/util/TestByteArrayManager.java' sourcefile='TestByteArrayManager.java'><Message>At TestByteArrayManager.java:[lines 50-642]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.util.TestByteArrayManager</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.util.TestByteArrayManager' signature='()V' name='testByteArrayManager' primary='true'><SourceLine endBytecode='847' classname='org.apache.hadoop.hdfs.util.TestByteArrayManager' start='309' end='387' sourcepath='org/apache/hadoop/hdfs/util/TestByteArrayManager.java' sourcefile='TestByteArrayManager.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.util.TestByteArrayManager.testByteArrayManager()</Message></Method><SourceLine endBytecode='151' classname='org.apache.hadoop.hdfs.util.TestByteArrayManager' start='331' end='331' sourcepath='org/apache/hadoop/hdfs/util/TestByteArrayManager.java' sourcefile='TestByteArrayManager.java' startBytecode='151' primary='true'><Message>At TestByteArrayManager.java:[line 331]</Message></SourceLine><LocalVariable role='LOCAL_VARIABLE_NAMED' pc='156' name='randomRecycler' register='13'><Message>Local variable named randomRecycler</Message></LocalVariable></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='23f94406f2252c8ddddaec82a8d3bce6' rank='20' abbrev='UrF' category='PERFORMANCE' priority='3' type='URF_UNREAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Unread field</ShortMessage><LongMessage>Unread field: org.apache.hadoop.hdfs.util.TestByteArrayManager$Runner.countThreshold</LongMessage><Class classname='org.apache.hadoop.hdfs.util.TestByteArrayManager$Runner' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.util.TestByteArrayManager$Runner' start='398' end='529' sourcepath='org/apache/hadoop/hdfs/util/TestByteArrayManager.java' sourcefile='TestByteArrayManager.java'><Message>At TestByteArrayManager.java:[lines 398-529]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.util.TestByteArrayManager$Runner</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.util.TestByteArrayManager$Runner' signature='I' name='countThreshold' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.util.TestByteArrayManager$Runner' sourcepath='org/apache/hadoop/hdfs/util/TestByteArrayManager.java' sourcefile='TestByteArrayManager.java'><Message>In TestByteArrayManager.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.util.TestByteArrayManager$Runner.countThreshold</Message></Field><SourceLine endBytecode='47' classname='org.apache.hadoop.hdfs.util.TestByteArrayManager$Runner' start='421' end='421' sourcepath='org/apache/hadoop/hdfs/util/TestByteArrayManager.java' sourcefile='TestByteArrayManager.java' startBytecode='47' primary='true'><Message>At TestByteArrayManager.java:[line 421]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='df91ecc9ab5b8725ba8005e56715d890' rank='20' abbrev='UrF' category='PERFORMANCE' priority='3' type='URF_UNREAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Unread field</ShortMessage><LongMessage>Unread field: org.apache.hadoop.hdfs.util.TestByteArrayManager$Runner.maxArrays</LongMessage><Class classname='org.apache.hadoop.hdfs.util.TestByteArrayManager$Runner' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.util.TestByteArrayManager$Runner' start='398' end='529' sourcepath='org/apache/hadoop/hdfs/util/TestByteArrayManager.java' sourcefile='TestByteArrayManager.java'><Message>At TestByteArrayManager.java:[lines 398-529]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.util.TestByteArrayManager$Runner</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.util.TestByteArrayManager$Runner' signature='I' name='maxArrays' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.util.TestByteArrayManager$Runner' sourcepath='org/apache/hadoop/hdfs/util/TestByteArrayManager.java' sourcefile='TestByteArrayManager.java'><Message>In TestByteArrayManager.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.util.TestByteArrayManager$Runner.maxArrays</Message></Field><SourceLine endBytecode='52' classname='org.apache.hadoop.hdfs.util.TestByteArrayManager$Runner' start='422' end='422' sourcepath='org/apache/hadoop/hdfs/util/TestByteArrayManager.java' sourcefile='TestByteArrayManager.java' startBytecode='52' primary='true'><Message>At TestByteArrayManager.java:[line 422]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='9f5bedd49024e613c9c504f10cd6c3ae' rank='19' abbrev='Dm' category='I18N' priority='1' type='DM_DEFAULT_ENCODING' instanceOccurrenceMax='0'><ShortMessage>Reliance on default encoding</ShortMessage><LongMessage>Found reliance on default encoding in org.apache.hadoop.hdfs.util.TestECPolicyLoader.testBadECCellsize(): new java.io.FileWriter(String)</LongMessage><Class classname='org.apache.hadoop.hdfs.util.TestECPolicyLoader' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.util.TestECPolicyLoader' start='36' end='312' sourcepath='org/apache/hadoop/hdfs/util/TestECPolicyLoader.java' sourcefile='TestECPolicyLoader.java'><Message>At TestECPolicyLoader.java:[lines 36-312]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.util.TestECPolicyLoader</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.util.TestECPolicyLoader' signature='()V' name='testBadECCellsize' primary='true'><SourceLine endBytecode='413' classname='org.apache.hadoop.hdfs.util.TestECPolicyLoader' start='237' end='271' sourcepath='org/apache/hadoop/hdfs/util/TestECPolicyLoader.java' sourcefile='TestECPolicyLoader.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.util.TestECPolicyLoader.testBadECCellsize()</Message></Method><Method isStatic='false' role='METHOD_CALLED' classname='java.io.FileWriter' signature='(Ljava/lang/String;)V' name='&lt;init&gt;'><SourceLine endBytecode='40' classname='java.io.FileWriter' start='63' end='64' sourcepath='java/io/FileWriter.java' sourcefile='FileWriter.java' startBytecode='0'></SourceLine><Message>Called method new java.io.FileWriter(String)</Message></Method><SourceLine endBytecode='11' classname='org.apache.hadoop.hdfs.util.TestECPolicyLoader' start='237' end='237' sourcepath='org/apache/hadoop/hdfs/util/TestECPolicyLoader.java' sourcefile='TestECPolicyLoader.java' startBytecode='11' primary='true'><Message>At TestECPolicyLoader.java:[line 237]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='93f77571f68057b3398a2c5c2f557e7' rank='19' abbrev='Dm' category='I18N' priority='1' type='DM_DEFAULT_ENCODING' instanceOccurrenceMax='0'><ShortMessage>Reliance on default encoding</ShortMessage><LongMessage>Found reliance on default encoding in org.apache.hadoop.hdfs.util.TestECPolicyLoader.testBadECLayoutVersion(): new java.io.FileWriter(String)</LongMessage><Class classname='org.apache.hadoop.hdfs.util.TestECPolicyLoader' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.util.TestECPolicyLoader' start='36' end='312' sourcepath='org/apache/hadoop/hdfs/util/TestECPolicyLoader.java' sourcefile='TestECPolicyLoader.java'><Message>At TestECPolicyLoader.java:[lines 36-312]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.util.TestECPolicyLoader</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.util.TestECPolicyLoader' signature='()V' name='testBadECLayoutVersion' primary='true'><SourceLine endBytecode='413' classname='org.apache.hadoop.hdfs.util.TestECPolicyLoader' start='196' end='230' sourcepath='org/apache/hadoop/hdfs/util/TestECPolicyLoader.java' sourcefile='TestECPolicyLoader.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.util.TestECPolicyLoader.testBadECLayoutVersion()</Message></Method><Method isStatic='false' role='METHOD_CALLED' classname='java.io.FileWriter' signature='(Ljava/lang/String;)V' name='&lt;init&gt;'><SourceLine endBytecode='40' classname='java.io.FileWriter' start='63' end='64' sourcepath='java/io/FileWriter.java' sourcefile='FileWriter.java' startBytecode='0'></SourceLine><Message>Called method new java.io.FileWriter(String)</Message></Method><SourceLine endBytecode='11' classname='org.apache.hadoop.hdfs.util.TestECPolicyLoader' start='196' end='196' sourcepath='org/apache/hadoop/hdfs/util/TestECPolicyLoader.java' sourcefile='TestECPolicyLoader.java' startBytecode='11' primary='true'><Message>At TestECPolicyLoader.java:[line 196]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='7c500b7daf0c31d4defafce8dea3c5da' rank='19' abbrev='Dm' category='I18N' priority='1' type='DM_DEFAULT_ENCODING' instanceOccurrenceMax='0'><ShortMessage>Reliance on default encoding</ShortMessage><LongMessage>Found reliance on default encoding in org.apache.hadoop.hdfs.util.TestECPolicyLoader.testBadECPolicy(): new java.io.FileWriter(String)</LongMessage><Class classname='org.apache.hadoop.hdfs.util.TestECPolicyLoader' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.util.TestECPolicyLoader' start='36' end='312' sourcepath='org/apache/hadoop/hdfs/util/TestECPolicyLoader.java' sourcefile='TestECPolicyLoader.java'><Message>At TestECPolicyLoader.java:[lines 36-312]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.util.TestECPolicyLoader</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.util.TestECPolicyLoader' signature='()V' name='testBadECPolicy' primary='true'><SourceLine endBytecode='413' classname='org.apache.hadoop.hdfs.util.TestECPolicyLoader' start='278' end='312' sourcepath='org/apache/hadoop/hdfs/util/TestECPolicyLoader.java' sourcefile='TestECPolicyLoader.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.util.TestECPolicyLoader.testBadECPolicy()</Message></Method><Method isStatic='false' role='METHOD_CALLED' classname='java.io.FileWriter' signature='(Ljava/lang/String;)V' name='&lt;init&gt;'><SourceLine endBytecode='40' classname='java.io.FileWriter' start='63' end='64' sourcepath='java/io/FileWriter.java' sourcefile='FileWriter.java' startBytecode='0'></SourceLine><Message>Called method new java.io.FileWriter(String)</Message></Method><SourceLine endBytecode='11' classname='org.apache.hadoop.hdfs.util.TestECPolicyLoader' start='278' end='278' sourcepath='org/apache/hadoop/hdfs/util/TestECPolicyLoader.java' sourcefile='TestECPolicyLoader.java' startBytecode='11' primary='true'><Message>At TestECPolicyLoader.java:[line 278]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='36f41398d68f5cb959c40baa0586c987' rank='19' abbrev='Dm' category='I18N' priority='1' type='DM_DEFAULT_ENCODING' instanceOccurrenceMax='0'><ShortMessage>Reliance on default encoding</ShortMessage><LongMessage>Found reliance on default encoding in org.apache.hadoop.hdfs.util.TestECPolicyLoader.testLoadECPolicy(): new java.io.FileWriter(String)</LongMessage><Class classname='org.apache.hadoop.hdfs.util.TestECPolicyLoader' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.util.TestECPolicyLoader' start='36' end='312' sourcepath='org/apache/hadoop/hdfs/util/TestECPolicyLoader.java' sourcefile='TestECPolicyLoader.java'><Message>At TestECPolicyLoader.java:[lines 36-312]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.util.TestECPolicyLoader</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.util.TestECPolicyLoader' signature='()V' name='testLoadECPolicy' primary='true'><SourceLine endBytecode='681' classname='org.apache.hadoop.hdfs.util.TestECPolicyLoader' start='49' end='99' sourcepath='org/apache/hadoop/hdfs/util/TestECPolicyLoader.java' sourcefile='TestECPolicyLoader.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.util.TestECPolicyLoader.testLoadECPolicy()</Message></Method><Method isStatic='false' role='METHOD_CALLED' classname='java.io.FileWriter' signature='(Ljava/lang/String;)V' name='&lt;init&gt;'><SourceLine endBytecode='40' classname='java.io.FileWriter' start='63' end='64' sourcepath='java/io/FileWriter.java' sourcefile='FileWriter.java' startBytecode='0'></SourceLine><Message>Called method new java.io.FileWriter(String)</Message></Method><SourceLine endBytecode='11' classname='org.apache.hadoop.hdfs.util.TestECPolicyLoader' start='49' end='49' sourcepath='org/apache/hadoop/hdfs/util/TestECPolicyLoader.java' sourcefile='TestECPolicyLoader.java' startBytecode='11' primary='true'><Message>At TestECPolicyLoader.java:[line 49]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='5811c928719bd93e4e3fa2286d99335' rank='19' abbrev='Dm' category='I18N' priority='1' type='DM_DEFAULT_ENCODING' instanceOccurrenceMax='0'><ShortMessage>Reliance on default encoding</ShortMessage><LongMessage>Found reliance on default encoding in org.apache.hadoop.hdfs.util.TestECPolicyLoader.testNullECSchemaOptionValue(): new java.io.FileWriter(String)</LongMessage><Class classname='org.apache.hadoop.hdfs.util.TestECPolicyLoader' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.util.TestECPolicyLoader' start='36' end='312' sourcepath='org/apache/hadoop/hdfs/util/TestECPolicyLoader.java' sourcefile='TestECPolicyLoader.java'><Message>At TestECPolicyLoader.java:[lines 36-312]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.util.TestECPolicyLoader</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.util.TestECPolicyLoader' signature='()V' name='testNullECSchemaOptionValue' primary='true'><SourceLine endBytecode='463' classname='org.apache.hadoop.hdfs.util.TestECPolicyLoader' start='106' end='144' sourcepath='org/apache/hadoop/hdfs/util/TestECPolicyLoader.java' sourcefile='TestECPolicyLoader.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.util.TestECPolicyLoader.testNullECSchemaOptionValue()</Message></Method><Method isStatic='false' role='METHOD_CALLED' classname='java.io.FileWriter' signature='(Ljava/lang/String;)V' name='&lt;init&gt;'><SourceLine endBytecode='40' classname='java.io.FileWriter' start='63' end='64' sourcepath='java/io/FileWriter.java' sourcefile='FileWriter.java' startBytecode='0'></SourceLine><Message>Called method new java.io.FileWriter(String)</Message></Method><SourceLine endBytecode='11' classname='org.apache.hadoop.hdfs.util.TestECPolicyLoader' start='106' end='106' sourcepath='org/apache/hadoop/hdfs/util/TestECPolicyLoader.java' sourcefile='TestECPolicyLoader.java' startBytecode='11' primary='true'><Message>At TestECPolicyLoader.java:[line 106]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='c03ba57f6e57d70e09b326a54efa46b1' rank='19' abbrev='Dm' category='I18N' priority='1' type='DM_DEFAULT_ENCODING' instanceOccurrenceMax='0'><ShortMessage>Reliance on default encoding</ShortMessage><LongMessage>Found reliance on default encoding in org.apache.hadoop.hdfs.util.TestECPolicyLoader.testRepeatECSchema(): new java.io.FileWriter(String)</LongMessage><Class classname='org.apache.hadoop.hdfs.util.TestECPolicyLoader' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.util.TestECPolicyLoader' start='36' end='312' sourcepath='org/apache/hadoop/hdfs/util/TestECPolicyLoader.java' sourcefile='TestECPolicyLoader.java'><Message>At TestECPolicyLoader.java:[lines 36-312]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.util.TestECPolicyLoader</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.util.TestECPolicyLoader' signature='()V' name='testRepeatECSchema' primary='true'><SourceLine endBytecode='453' classname='org.apache.hadoop.hdfs.util.TestECPolicyLoader' start='151' end='189' sourcepath='org/apache/hadoop/hdfs/util/TestECPolicyLoader.java' sourcefile='TestECPolicyLoader.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.util.TestECPolicyLoader.testRepeatECSchema()</Message></Method><Method isStatic='false' role='METHOD_CALLED' classname='java.io.FileWriter' signature='(Ljava/lang/String;)V' name='&lt;init&gt;'><SourceLine endBytecode='40' classname='java.io.FileWriter' start='63' end='64' sourcepath='java/io/FileWriter.java' sourcefile='FileWriter.java' startBytecode='0'></SourceLine><Message>Called method new java.io.FileWriter(String)</Message></Method><SourceLine endBytecode='11' classname='org.apache.hadoop.hdfs.util.TestECPolicyLoader' start='151' end='151' sourcepath='org/apache/hadoop/hdfs/util/TestECPolicyLoader.java' sourcefile='TestECPolicyLoader.java' startBytecode='11' primary='true'><Message>At TestECPolicyLoader.java:[line 151]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='e0c2a08f33ff087556d383785c396f63' rank='19' abbrev='Nm' category='BAD_PRACTICE' priority='3' type='NM_CONFUSING' instanceOccurrenceMax='0'><ShortMessage>Confusing method names</ShortMessage><LongMessage>Confusing to have methods org.apache.hadoop.hdfs.web.ByteRangeInputStream$URLOpener.getURL() and org.apache.hadoop.hdfs.web.WebHdfsFileSystem$AbstractFsPathRunner.getUrl()</LongMessage><Class classname='org.apache.hadoop.hdfs.web.ByteRangeInputStream$URLOpener' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.web.ByteRangeInputStream$URLOpener' start='55' end='64' sourcepath='org/apache/hadoop/hdfs/web/ByteRangeInputStream.java' sourcefile='ByteRangeInputStream.java'><Message>At ByteRangeInputStream.java:[lines 55-64]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.web.ByteRangeInputStream$URLOpener</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.web.ByteRangeInputStream$URLOpener' signature='()Ljava/net/URL;' name='getURL' primary='true'><SourceLine endBytecode='46' classname='org.apache.hadoop.hdfs.web.ByteRangeInputStream$URLOpener' start='64' end='64' sourcepath='org/apache/hadoop/hdfs/web/ByteRangeInputStream.java' sourcefile='ByteRangeInputStream.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.web.ByteRangeInputStream$URLOpener.getURL()</Message></Method><Class classname='org.apache.hadoop.hdfs.web.WebHdfsFileSystem$AbstractFsPathRunner'><SourceLine classname='org.apache.hadoop.hdfs.web.WebHdfsFileSystem$AbstractFsPathRunner' start='900' end='925' sourcepath='org/apache/hadoop/hdfs/web/WebHdfsFileSystem.java' sourcefile='WebHdfsFileSystem.java'><Message>At WebHdfsFileSystem.java:[lines 900-925]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.web.WebHdfsFileSystem$AbstractFsPathRunner</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.web.WebHdfsFileSystem$AbstractFsPathRunner' signature='()Ljava/net/URL;' name='getUrl'><SourceLine endBytecode='194' classname='org.apache.hadoop.hdfs.web.WebHdfsFileSystem$AbstractFsPathRunner' start='919' end='925' sourcepath='org/apache/hadoop/hdfs/web/WebHdfsFileSystem.java' sourcefile='WebHdfsFileSystem.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.web.WebHdfsFileSystem$AbstractFsPathRunner.getUrl()</Message></Method><SourceLine synthetic='true' endBytecode='46' classname='org.apache.hadoop.hdfs.web.ByteRangeInputStream$URLOpener' start='64' end='64' sourcepath='org/apache/hadoop/hdfs/web/ByteRangeInputStream.java' sourcefile='ByteRangeInputStream.java' startBytecode='0'><Message>At ByteRangeInputStream.java:[line 64]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='28cf9a46a347cbe27f6f025900163c9c' rank='20' abbrev='PZLA' category='STYLE' priority='3' type='PZLA_PREFER_ZERO_LENGTH_ARRAYS' instanceOccurrenceMax='0'><ShortMessage>Consider returning a zero length array rather than null</ShortMessage><LongMessage>Should org.apache.hadoop.hdfs.web.JsonUtilClient.getXAttr(Map) return a zero length array rather than null?</LongMessage><Class classname='org.apache.hadoop.hdfs.web.JsonUtilClient' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.web.JsonUtilClient' start='71' end='793' sourcepath='org/apache/hadoop/hdfs/web/JsonUtilClient.java' sourcefile='JsonUtilClient.java'><Message>At JsonUtilClient.java:[lines 71-793]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.web.JsonUtilClient</Message></Class><Method isStatic='true' classname='org.apache.hadoop.hdfs.web.JsonUtilClient' signature='(Ljava/util/Map;)[B' name='getXAttr' primary='true'><SourceLine endBytecode='165' classname='org.apache.hadoop.hdfs.web.JsonUtilClient' start='545' end='554' sourcepath='org/apache/hadoop/hdfs/web/JsonUtilClient.java' sourcefile='JsonUtilClient.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.web.JsonUtilClient.getXAttr(Map)</Message></Method><SourceLine endBytecode='5' classname='org.apache.hadoop.hdfs.web.JsonUtilClient' start='546' end='546' sourcepath='org/apache/hadoop/hdfs/web/JsonUtilClient.java' sourcefile='JsonUtilClient.java' startBytecode='5' primary='true'><Message>At JsonUtilClient.java:[line 546]</Message></SourceLine><SourceLine endBytecode='50' classname='org.apache.hadoop.hdfs.web.JsonUtilClient' start='554' end='554' sourcepath='org/apache/hadoop/hdfs/web/JsonUtilClient.java' sourcefile='JsonUtilClient.java' startBytecode='50'><Message>At JsonUtilClient.java:[line 554]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='ec4d1ab5fae9579bcbc7a06395fcdedd' rank='20' abbrev='PZLA' category='STYLE' priority='3' type='PZLA_PREFER_ZERO_LENGTH_ARRAYS' instanceOccurrenceMax='0'><ShortMessage>Consider returning a zero length array rather than null</ShortMessage><LongMessage>Should org.apache.hadoop.hdfs.web.JsonUtilClient.getXAttr(Map, String) return a zero length array rather than null?</LongMessage><Class classname='org.apache.hadoop.hdfs.web.JsonUtilClient' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.web.JsonUtilClient' start='71' end='793' sourcepath='org/apache/hadoop/hdfs/web/JsonUtilClient.java' sourcefile='JsonUtilClient.java'><Message>At JsonUtilClient.java:[lines 71-793]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.web.JsonUtilClient</Message></Class><Method isStatic='true' classname='org.apache.hadoop.hdfs.web.JsonUtilClient' signature='(Ljava/util/Map;Ljava/lang/String;)[B' name='getXAttr' primary='true'><SourceLine endBytecode='152' classname='org.apache.hadoop.hdfs.web.JsonUtilClient' start='531' end='540' sourcepath='org/apache/hadoop/hdfs/web/JsonUtilClient.java' sourcefile='JsonUtilClient.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.web.JsonUtilClient.getXAttr(Map, String)</Message></Method><SourceLine endBytecode='5' classname='org.apache.hadoop.hdfs.web.JsonUtilClient' start='532' end='532' sourcepath='org/apache/hadoop/hdfs/web/JsonUtilClient.java' sourcefile='JsonUtilClient.java' startBytecode='5' primary='true'><Message>At JsonUtilClient.java:[line 532]</Message></SourceLine><SourceLine endBytecode='27' classname='org.apache.hadoop.hdfs.web.JsonUtilClient' start='540' end='540' sourcepath='org/apache/hadoop/hdfs/web/JsonUtilClient.java' sourcefile='JsonUtilClient.java' startBytecode='27'><Message>At JsonUtilClient.java:[line 540]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='b0210fa62963ccddebfad6e712dbb2a9' rank='20' abbrev='PZLA' category='STYLE' priority='3' type='PZLA_PREFER_ZERO_LENGTH_ARRAYS' instanceOccurrenceMax='0'><ShortMessage>Consider returning a zero length array rather than null</ShortMessage><LongMessage>Should org.apache.hadoop.hdfs.web.JsonUtilClient.toByteArray(String) return a zero length array rather than null?</LongMessage><Class classname='org.apache.hadoop.hdfs.web.JsonUtilClient' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.web.JsonUtilClient' start='71' end='793' sourcepath='org/apache/hadoop/hdfs/web/JsonUtilClient.java' sourcefile='JsonUtilClient.java'><Message>At JsonUtilClient.java:[lines 71-793]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.web.JsonUtilClient</Message></Class><Method isStatic='true' classname='org.apache.hadoop.hdfs.web.JsonUtilClient' signature='(Ljava/lang/String;)[B' name='toByteArray' primary='true'><SourceLine endBytecode='69' classname='org.apache.hadoop.hdfs.web.JsonUtilClient' start='757' end='760' sourcepath='org/apache/hadoop/hdfs/web/JsonUtilClient.java' sourcefile='JsonUtilClient.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.web.JsonUtilClient.toByteArray(String)</Message></Method><SourceLine endBytecode='5' classname='org.apache.hadoop.hdfs.web.JsonUtilClient' start='758' end='758' sourcepath='org/apache/hadoop/hdfs/web/JsonUtilClient.java' sourcefile='JsonUtilClient.java' startBytecode='5' primary='true'><Message>At JsonUtilClient.java:[line 758]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='d0a55e0c1bb2c1015e0b06d0bfc7ffb3' rank='20' abbrev='PZLA' category='STYLE' priority='3' type='PZLA_PREFER_ZERO_LENGTH_ARRAYS' instanceOccurrenceMax='0'><ShortMessage>Consider returning a zero length array rather than null</ShortMessage><LongMessage>Should org.apache.hadoop.hdfs.web.JsonUtilClient.toDatanodeInfoArray(List) return a zero length array rather than null?</LongMessage><Class classname='org.apache.hadoop.hdfs.web.JsonUtilClient' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.web.JsonUtilClient' start='71' end='793' sourcepath='org/apache/hadoop/hdfs/web/JsonUtilClient.java' sourcefile='JsonUtilClient.java'><Message>At JsonUtilClient.java:[lines 71-793]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.web.JsonUtilClient</Message></Class><Method isStatic='true' classname='org.apache.hadoop.hdfs.web.JsonUtilClient' signature='(Ljava/util/List;)[Lorg/apache/hadoop/hdfs/protocol/DatanodeInfo;' name='toDatanodeInfoArray' primary='true'><SourceLine endBytecode='222' classname='org.apache.hadoop.hdfs.web.JsonUtilClient' start='347' end='357' sourcepath='org/apache/hadoop/hdfs/web/JsonUtilClient.java' sourcefile='JsonUtilClient.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.web.JsonUtilClient.toDatanodeInfoArray(List)</Message></Method><SourceLine endBytecode='5' classname='org.apache.hadoop.hdfs.web.JsonUtilClient' start='348' end='348' sourcepath='org/apache/hadoop/hdfs/web/JsonUtilClient.java' sourcefile='JsonUtilClient.java' startBytecode='5' primary='true'><Message>At JsonUtilClient.java:[line 348]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='3565769691c6071ce22ced8550edf23b' rank='20' abbrev='PZLA' category='STYLE' priority='3' type='PZLA_PREFER_ZERO_LENGTH_ARRAYS' instanceOccurrenceMax='0'><ShortMessage>Consider returning a zero length array rather than null</ShortMessage><LongMessage>Should org.apache.hadoop.hdfs.web.JsonUtilClient.toSnapshottableDirectoryList(Map) return a zero length array rather than null?</LongMessage><Class classname='org.apache.hadoop.hdfs.web.JsonUtilClient' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.web.JsonUtilClient' start='71' end='793' sourcepath='org/apache/hadoop/hdfs/web/JsonUtilClient.java' sourcefile='JsonUtilClient.java'><Message>At JsonUtilClient.java:[lines 71-793]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.web.JsonUtilClient</Message></Class><Method isStatic='true' classname='org.apache.hadoop.hdfs.web.JsonUtilClient' signature='(Ljava/util/Map;)[Lorg/apache/hadoop/hdfs/protocol/SnapshottableDirectoryStatus;' name='toSnapshottableDirectoryList' primary='true'><SourceLine endBytecode='235' classname='org.apache.hadoop.hdfs.web.JsonUtilClient' start='765' end='777' sourcepath='org/apache/hadoop/hdfs/web/JsonUtilClient.java' sourcefile='JsonUtilClient.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.web.JsonUtilClient.toSnapshottableDirectoryList(Map)</Message></Method><SourceLine endBytecode='5' classname='org.apache.hadoop.hdfs.web.JsonUtilClient' start='766' end='766' sourcepath='org/apache/hadoop/hdfs/web/JsonUtilClient.java' sourcefile='JsonUtilClient.java' startBytecode='5' primary='true'><Message>At JsonUtilClient.java:[line 766]</Message></SourceLine><SourceLine endBytecode='24' classname='org.apache.hadoop.hdfs.web.JsonUtilClient' start='770' end='770' sourcepath='org/apache/hadoop/hdfs/web/JsonUtilClient.java' sourcefile='JsonUtilClient.java' startBytecode='24'><Message>At JsonUtilClient.java:[line 770]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='c6f15948e61c50cbca7efe1901bb0dfa' rank='20' abbrev='PZLA' category='STYLE' priority='3' type='PZLA_PREFER_ZERO_LENGTH_ARRAYS' instanceOccurrenceMax='0'><ShortMessage>Consider returning a zero length array rather than null</ShortMessage><LongMessage>Should org.apache.hadoop.hdfs.web.JsonUtilClient.toStorageTypeArray(List) return a zero length array rather than null?</LongMessage><Class classname='org.apache.hadoop.hdfs.web.JsonUtilClient' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.web.JsonUtilClient' start='71' end='793' sourcepath='org/apache/hadoop/hdfs/web/JsonUtilClient.java' sourcefile='JsonUtilClient.java'><Message>At JsonUtilClient.java:[lines 71-793]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.web.JsonUtilClient</Message></Class><Method isStatic='true' classname='org.apache.hadoop.hdfs.web.JsonUtilClient' signature='(Ljava/util/List;)[Lorg/apache/hadoop/fs/StorageType;' name='toStorageTypeArray' primary='true'><SourceLine endBytecode='222' classname='org.apache.hadoop.hdfs.web.JsonUtilClient' start='364' end='374' sourcepath='org/apache/hadoop/hdfs/web/JsonUtilClient.java' sourcefile='JsonUtilClient.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.web.JsonUtilClient.toStorageTypeArray(List)</Message></Method><SourceLine endBytecode='5' classname='org.apache.hadoop.hdfs.web.JsonUtilClient' start='365' end='365' sourcepath='org/apache/hadoop/hdfs/web/JsonUtilClient.java' sourcefile='JsonUtilClient.java' startBytecode='5' primary='true'><Message>At JsonUtilClient.java:[line 365]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='77f36d3576b843da0c559e407480c4c3' rank='20' abbrev='PZLA' category='STYLE' priority='3' type='PZLA_PREFER_ZERO_LENGTH_ARRAYS' instanceOccurrenceMax='0'><ShortMessage>Consider returning a zero length array rather than null</ShortMessage><LongMessage>Should org.apache.hadoop.hdfs.web.JsonUtilClient.toStorageTypes(List) return a zero length array rather than null?</LongMessage><Class classname='org.apache.hadoop.hdfs.web.JsonUtilClient' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.web.JsonUtilClient' start='71' end='793' sourcepath='org/apache/hadoop/hdfs/web/JsonUtilClient.java' sourcefile='JsonUtilClient.java'><Message>At JsonUtilClient.java:[lines 71-793]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.web.JsonUtilClient</Message></Class><Method isStatic='true' classname='org.apache.hadoop.hdfs.web.JsonUtilClient' signature='(Ljava/util/List;)[Lorg/apache/hadoop/fs/StorageType;' name='toStorageTypes' primary='true'><SourceLine endBytecode='174' classname='org.apache.hadoop.hdfs.web.JsonUtilClient' start='672' end='679' sourcepath='org/apache/hadoop/hdfs/web/JsonUtilClient.java' sourcefile='JsonUtilClient.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.web.JsonUtilClient.toStorageTypes(List)</Message></Method><SourceLine endBytecode='5' classname='org.apache.hadoop.hdfs.web.JsonUtilClient' start='673' end='673' sourcepath='org/apache/hadoop/hdfs/web/JsonUtilClient.java' sourcefile='JsonUtilClient.java' startBytecode='5' primary='true'><Message>At JsonUtilClient.java:[line 673]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='17b0be89cc188c14dd4badf26eaa2134' rank='20' abbrev='SIC' category='PERFORMANCE' priority='3' type='SIC_INNER_SHOULD_BE_STATIC_ANON' instanceOccurrenceMax='0'><ShortMessage>Could be refactored into a named static inner class</ShortMessage><LongMessage>The class org.apache.hadoop.hdfs.web.KerberosUgiAuthenticator$1 could be refactored into a named _static_ inner class</LongMessage><Class role='CLASS_ANONYMOUS' classname='org.apache.hadoop.hdfs.web.KerberosUgiAuthenticator$1'><SourceLine classname='org.apache.hadoop.hdfs.web.KerberosUgiAuthenticator$1' start='34' end='40' sourcepath='org/apache/hadoop/hdfs/web/KerberosUgiAuthenticator.java' sourcefile='KerberosUgiAuthenticator.java'><Message>At KerberosUgiAuthenticator.java:[lines 34-40]</Message></SourceLine><Message>Anonymous class org.apache.hadoop.hdfs.web.KerberosUgiAuthenticator$1</Message></Class><Class classname='org.apache.hadoop.hdfs.web.KerberosUgiAuthenticator' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.web.KerberosUgiAuthenticator' start='31' end='34' sourcepath='org/apache/hadoop/hdfs/web/KerberosUgiAuthenticator.java' sourcefile='KerberosUgiAuthenticator.java'><Message>At KerberosUgiAuthenticator.java:[lines 31-34]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.web.KerberosUgiAuthenticator</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.web.KerberosUgiAuthenticator' signature='()Lorg/apache/hadoop/security/authentication/client/Authenticator;' name='getFallBackAuthenticator' primary='true'><SourceLine endBytecode='50' classname='org.apache.hadoop.hdfs.web.KerberosUgiAuthenticator' start='34' end='34' sourcepath='org/apache/hadoop/hdfs/web/KerberosUgiAuthenticator.java' sourcefile='KerberosUgiAuthenticator.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.web.KerberosUgiAuthenticator.getFallBackAuthenticator()</Message></Method><SourceLine endBytecode='5' classname='org.apache.hadoop.hdfs.web.KerberosUgiAuthenticator' start='34' end='34' sourcepath='org/apache/hadoop/hdfs/web/KerberosUgiAuthenticator.java' sourcefile='KerberosUgiAuthenticator.java' startBytecode='5' primary='true'><Message>At KerberosUgiAuthenticator.java:[line 34]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='f7d4d8021962b6748c59f1cd5fc766e' rank='19' abbrev='Dm' category='I18N' priority='1' type='DM_DEFAULT_ENCODING' instanceOccurrenceMax='0'><ShortMessage>Reliance on default encoding</ShortMessage><LongMessage>Found reliance on default encoding in org.apache.hadoop.hdfs.web.TestByteRangeInputStream.getMockConnection(String): String.getBytes()</LongMessage><Class classname='org.apache.hadoop.hdfs.web.TestByteRangeInputStream' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.web.TestByteRangeInputStream' start='43' end='290' sourcepath='org/apache/hadoop/hdfs/web/TestByteRangeInputStream.java' sourcefile='TestByteRangeInputStream.java'><Message>At TestByteRangeInputStream.java:[lines 43-290]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.web.TestByteRangeInputStream</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.web.TestByteRangeInputStream' signature='(Ljava/lang/String;)Ljava/net/HttpURLConnection;' name='getMockConnection' primary='true'><SourceLine endBytecode='139' classname='org.apache.hadoop.hdfs.web.TestByteRangeInputStream' start='69' end='74' sourcepath='org/apache/hadoop/hdfs/web/TestByteRangeInputStream.java' sourcefile='TestByteRangeInputStream.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.web.TestByteRangeInputStream.getMockConnection(String)</Message></Method><Method isStatic='false' role='METHOD_CALLED' classname='java.lang.String' signature='()[B' name='getBytes'><SourceLine endBytecode='37' classname='java.lang.String' start='958' end='958' sourcepath='java/lang/String.java' sourcefile='String.java' startBytecode='0'></SourceLine><Message>Called method String.getBytes()</Message></Method><SourceLine endBytecode='15' classname='org.apache.hadoop.hdfs.web.TestByteRangeInputStream' start='70' end='70' sourcepath='org/apache/hadoop/hdfs/web/TestByteRangeInputStream.java' sourcefile='TestByteRangeInputStream.java' startBytecode='15' primary='true'><Message>At TestByteRangeInputStream.java:[line 70]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='51aafc4315f25ca64e13ed407afbcc50' rank='19' abbrev='OS' category='BAD_PRACTICE' priority='3' type='OS_OPEN_STREAM_EXCEPTION_PATH' instanceOccurrenceMax='0'><ShortMessage>Method may fail to close stream on exception</ShortMessage><LongMessage>org.apache.hadoop.hdfs.web.TestByteRangeInputStream.testByteRange() may fail to close stream on exception</LongMessage><Class classname='org.apache.hadoop.hdfs.web.TestByteRangeInputStream' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.web.TestByteRangeInputStream' start='43' end='290' sourcepath='org/apache/hadoop/hdfs/web/TestByteRangeInputStream.java' sourcefile='TestByteRangeInputStream.java'><Message>At TestByteRangeInputStream.java:[lines 43-290]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.web.TestByteRangeInputStream</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.web.TestByteRangeInputStream' signature='()V' name='testByteRange' primary='true'><SourceLine endBytecode='168' classname='org.apache.hadoop.hdfs.web.TestByteRangeInputStream' start='79' end='139' sourcepath='org/apache/hadoop/hdfs/web/TestByteRangeInputStream.java' sourcefile='TestByteRangeInputStream.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.web.TestByteRangeInputStream.testByteRange()</Message></Method><Type role='TYPE_CLOSEIT' descriptor='Ljava/io/InputStream;'><SourceLine classname='java.io.InputStream' start='45' end='364' sourcepath='java/io/InputStream.java' sourcefile='InputStream.java'><Message>At InputStream.java:[lines 45-364]</Message></SourceLine><Message>Need to close java.io.InputStream </Message></Type><SourceLine endBytecode='20' classname='org.apache.hadoop.hdfs.web.TestByteRangeInputStream' start='82' end='82' sourcepath='org/apache/hadoop/hdfs/web/TestByteRangeInputStream.java' sourcefile='TestByteRangeInputStream.java' startBytecode='20' primary='true'><Message>At TestByteRangeInputStream.java:[line 82]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='bc19a8fa0a67a4a8e868cedca3863737' rank='18' abbrev='SIC' category='PERFORMANCE' priority='2' type='SIC_INNER_SHOULD_BE_STATIC' instanceOccurrenceMax='0'><ShortMessage>Should be a static inner class</ShortMessage><LongMessage>Should org.apache.hadoop.hdfs.web.TestByteRangeInputStream$ByteRangeInputStreamImpl be a _static_ inner class?</LongMessage><Class classname='org.apache.hadoop.hdfs.web.TestByteRangeInputStream$ByteRangeInputStreamImpl' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.web.TestByteRangeInputStream$ByteRangeInputStreamImpl' start='46' end='53' sourcepath='org/apache/hadoop/hdfs/web/TestByteRangeInputStream.java' sourcefile='TestByteRangeInputStream.java'><Message>At TestByteRangeInputStream.java:[lines 46-53]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.web.TestByteRangeInputStream$ByteRangeInputStreamImpl</Message></Class><SourceLine synthetic='true' classname='org.apache.hadoop.hdfs.web.TestByteRangeInputStream$ByteRangeInputStreamImpl' start='46' end='53' sourcepath='org/apache/hadoop/hdfs/web/TestByteRangeInputStream.java' sourcefile='TestByteRangeInputStream.java'><Message>At TestByteRangeInputStream.java:[lines 46-53]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='157a95c302a9d05b42fc54cbaaf68f8d' cweid='440' rank='17' abbrev='RV' category='STYLE' priority='2' type='RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT' instanceOccurrenceMax='0'><ShortMessage>Return value of method without side effect is ignored</ShortMessage><LongMessage>Return value of TestTokenAspect$DummyFs.getRenewToken() ignored, but method has no side effect</LongMessage><Class classname='org.apache.hadoop.hdfs.web.TestTokenAspect' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.web.TestTokenAspect' start='60' end='313' sourcepath='org/apache/hadoop/hdfs/web/TestTokenAspect.java' sourcefile='TestTokenAspect.java'><Message>At TestTokenAspect.java:[lines 60-313]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.web.TestTokenAspect</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.web.TestTokenAspect' signature='()V' name='testCachedInitialization' primary='true'><SourceLine endBytecode='328' classname='org.apache.hadoop.hdfs.web.TestTokenAspect' start='172' end='191' sourcepath='org/apache/hadoop/hdfs/web/TestTokenAspect.java' sourcefile='TestTokenAspect.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.web.TestTokenAspect.testCachedInitialization()</Message></Method><Method isStatic='false' role='METHOD_CALLED' classname='org.apache.hadoop.hdfs.web.TestTokenAspect$DummyFs' signature='()Lorg/apache/hadoop/security/token/Token;' name='getRenewToken'><SourceLine endBytecode='43' classname='org.apache.hadoop.hdfs.web.TestTokenAspect$DummyFs' start='106' end='106' sourcepath='org/apache/hadoop/hdfs/web/TestTokenAspect.java' sourcefile='TestTokenAspect.java' startBytecode='0'></SourceLine><Message>Called method org.apache.hadoop.hdfs.web.TestTokenAspect$DummyFs.getRenewToken()</Message></Method><SourceLine endBytecode='82' classname='org.apache.hadoop.hdfs.web.TestTokenAspect' start='178' end='178' sourcepath='org/apache/hadoop/hdfs/web/TestTokenAspect.java' sourcefile='TestTokenAspect.java' startBytecode='82' primary='true'><Message>At TestTokenAspect.java:[line 178]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='9f99cb1006a302810e7f4a1adc9e32d0' cweid='440' rank='17' abbrev='RV' category='STYLE' priority='2' type='RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT' instanceOccurrenceMax='0'><ShortMessage>Return value of method without side effect is ignored</ShortMessage><LongMessage>Return value of TestTokenAspect$DummyFs.getRenewToken() ignored, but method has no side effect</LongMessage><Class classname='org.apache.hadoop.hdfs.web.TestTokenAspect' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.web.TestTokenAspect' start='60' end='313' sourcepath='org/apache/hadoop/hdfs/web/TestTokenAspect.java' sourcefile='TestTokenAspect.java'><Message>At TestTokenAspect.java:[lines 60-313]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.web.TestTokenAspect</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.web.TestTokenAspect' signature='()V' name='testGetRemoteToken' primary='true'><SourceLine endBytecode='276' classname='org.apache.hadoop.hdfs.web.TestTokenAspect' start='195' end='211' sourcepath='org/apache/hadoop/hdfs/web/TestTokenAspect.java' sourcefile='TestTokenAspect.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.web.TestTokenAspect.testGetRemoteToken()</Message></Method><Method isStatic='false' role='METHOD_CALLED' classname='org.apache.hadoop.hdfs.web.TestTokenAspect$DummyFs' signature='()Lorg/apache/hadoop/security/token/Token;' name='getRenewToken'><SourceLine endBytecode='43' classname='org.apache.hadoop.hdfs.web.TestTokenAspect$DummyFs' start='106' end='106' sourcepath='org/apache/hadoop/hdfs/web/TestTokenAspect.java' sourcefile='TestTokenAspect.java' startBytecode='0'></SourceLine><Message>Called method org.apache.hadoop.hdfs.web.TestTokenAspect$DummyFs.getRenewToken()</Message></Method><SourceLine endBytecode='82' classname='org.apache.hadoop.hdfs.web.TestTokenAspect' start='201' end='201' sourcepath='org/apache/hadoop/hdfs/web/TestTokenAspect.java' sourcefile='TestTokenAspect.java' startBytecode='82' primary='true'><Message>At TestTokenAspect.java:[line 201]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='1c824f3c72dcdb4ff322dba16132e872' cweid='440' rank='17' abbrev='RV' category='STYLE' priority='2' type='RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT' instanceOccurrenceMax='0'><ShortMessage>Return value of method without side effect is ignored</ShortMessage><LongMessage>Return value of TestTokenAspect$DummyFs.getRenewToken() ignored, but method has no side effect</LongMessage><Class classname='org.apache.hadoop.hdfs.web.TestTokenAspect' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.web.TestTokenAspect' start='60' end='313' sourcepath='org/apache/hadoop/hdfs/web/TestTokenAspect.java' sourcefile='TestTokenAspect.java'><Message>At TestTokenAspect.java:[lines 60-313]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.web.TestTokenAspect</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.web.TestTokenAspect' signature='()V' name='testRenewal' primary='true'><SourceLine endBytecode='624' classname='org.apache.hadoop.hdfs.web.TestTokenAspect' start='271' end='313' sourcepath='org/apache/hadoop/hdfs/web/TestTokenAspect.java' sourcefile='TestTokenAspect.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.web.TestTokenAspect.testRenewal()</Message></Method><Method isStatic='false' role='METHOD_CALLED' classname='org.apache.hadoop.hdfs.web.TestTokenAspect$DummyFs' signature='()Lorg/apache/hadoop/security/token/Token;' name='getRenewToken'><SourceLine endBytecode='43' classname='org.apache.hadoop.hdfs.web.TestTokenAspect$DummyFs' start='106' end='106' sourcepath='org/apache/hadoop/hdfs/web/TestTokenAspect.java' sourcefile='TestTokenAspect.java' startBytecode='0'></SourceLine><Message>Called method org.apache.hadoop.hdfs.web.TestTokenAspect$DummyFs.getRenewToken()</Message></Method><SourceLine endBytecode='108' classname='org.apache.hadoop.hdfs.web.TestTokenAspect' start='282' end='282' sourcepath='org/apache/hadoop/hdfs/web/TestTokenAspect.java' sourcefile='TestTokenAspect.java' startBytecode='108' primary='true'><Message>At TestTokenAspect.java:[line 282]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='508a71983b3683d0e1dbbef469aa4ef1' rank='17' abbrev='ST' category='STYLE' priority='2' type='ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD' instanceOccurrenceMax='0'><ShortMessage>Write to static field from instance method</ShortMessage><LongMessage>Write to static field org.apache.hadoop.fs.DelegationTokenRenewer.renewCycle from instance method org.apache.hadoop.hdfs.web.TestTokenAspect.testRenewal()</LongMessage><Class classname='org.apache.hadoop.hdfs.web.TestTokenAspect' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.web.TestTokenAspect' start='60' end='313' sourcepath='org/apache/hadoop/hdfs/web/TestTokenAspect.java' sourcefile='TestTokenAspect.java'><Message>At TestTokenAspect.java:[lines 60-313]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.web.TestTokenAspect</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.web.TestTokenAspect' signature='()V' name='testRenewal' primary='true'><SourceLine endBytecode='624' classname='org.apache.hadoop.hdfs.web.TestTokenAspect' start='271' end='313' sourcepath='org/apache/hadoop/hdfs/web/TestTokenAspect.java' sourcefile='TestTokenAspect.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.web.TestTokenAspect.testRenewal()</Message></Method><Field isStatic='true' classname='org.apache.hadoop.fs.DelegationTokenRenewer' signature='J' name='renewCycle' primary='true'><SourceLine classname='org.apache.hadoop.fs.DelegationTokenRenewer' sourcepath='org/apache/hadoop/fs/DelegationTokenRenewer.java' sourcefile='DelegationTokenRenewer.java'><Message>In DelegationTokenRenewer.java</Message></SourceLine><Message>Field org.apache.hadoop.fs.DelegationTokenRenewer.renewCycle</Message></Field><SourceLine endBytecode='34' classname='org.apache.hadoop.hdfs.web.TestTokenAspect' start='275' end='275' sourcepath='org/apache/hadoop/hdfs/web/TestTokenAspect.java' sourcefile='TestTokenAspect.java' startBytecode='34' primary='true'><Message>At TestTokenAspect.java:[line 275]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='9adfb71ef688953fc1db7789b80203cf' rank='20' abbrev='SIC' category='PERFORMANCE' priority='3' type='SIC_INNER_SHOULD_BE_STATIC_ANON' instanceOccurrenceMax='0'><ShortMessage>Could be refactored into a named static inner class</ShortMessage><LongMessage>The class org.apache.hadoop.hdfs.web.TestURLConnectionFactory$1 could be refactored into a named _static_ inner class</LongMessage><Class role='CLASS_ANONYMOUS' classname='org.apache.hadoop.hdfs.web.TestURLConnectionFactory$1'><SourceLine classname='org.apache.hadoop.hdfs.web.TestURLConnectionFactory$1' start='41' end='47' sourcepath='org/apache/hadoop/hdfs/web/TestURLConnectionFactory.java' sourcefile='TestURLConnectionFactory.java'><Message>At TestURLConnectionFactory.java:[lines 41-47]</Message></SourceLine><Message>Anonymous class org.apache.hadoop.hdfs.web.TestURLConnectionFactory$1</Message></Class><Class classname='org.apache.hadoop.hdfs.web.TestURLConnectionFactory' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.web.TestURLConnectionFactory' start='35' end='66' sourcepath='org/apache/hadoop/hdfs/web/TestURLConnectionFactory.java' sourcefile='TestURLConnectionFactory.java'><Message>At TestURLConnectionFactory.java:[lines 35-66]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.web.TestURLConnectionFactory</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.web.TestURLConnectionFactory' signature='()V' name='testConnConfiguratior' primary='true'><SourceLine endBytecode='159' classname='org.apache.hadoop.hdfs.web.TestURLConnectionFactory' start='39' end='53' sourcepath='org/apache/hadoop/hdfs/web/TestURLConnectionFactory.java' sourcefile='TestURLConnectionFactory.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.web.TestURLConnectionFactory.testConnConfiguratior()</Message></Method><SourceLine endBytecode='25' classname='org.apache.hadoop.hdfs.web.TestURLConnectionFactory' start='41' end='41' sourcepath='org/apache/hadoop/hdfs/web/TestURLConnectionFactory.java' sourcefile='TestURLConnectionFactory.java' startBytecode='25' primary='true'><Message>At TestURLConnectionFactory.java:[line 41]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='e6be402bc697ea6aca1affb8ca20302f' cweid='391' rank='16' abbrev='DE' category='BAD_PRACTICE' priority='2' type='DE_MIGHT_IGNORE' instanceOccurrenceMax='0'><ShortMessage>Method might ignore exception</ShortMessage><LongMessage>org.apache.hadoop.hdfs.web.TestWebHdfsContentLength.testDelete() might ignore java.io.IOException</LongMessage><Class classname='org.apache.hadoop.hdfs.web.TestWebHdfsContentLength' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.web.TestWebHdfsContentLength' start='45' end='186' sourcepath='org/apache/hadoop/hdfs/web/TestWebHdfsContentLength.java' sourcefile='TestWebHdfsContentLength.java'><Message>At TestWebHdfsContentLength.java:[lines 45-186]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.web.TestWebHdfsContentLength</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.web.TestWebHdfsContentLength' signature='()V' name='testDelete' primary='true'><SourceLine endBytecode='158' classname='org.apache.hadoop.hdfs.web.TestWebHdfsContentLength' start='166' end='172' sourcepath='org/apache/hadoop/hdfs/web/TestWebHdfsContentLength.java' sourcefile='TestWebHdfsContentLength.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.web.TestWebHdfsContentLength.testDelete()</Message></Method><Class role='CLASS_EXCEPTION' classname='java.io.IOException'><SourceLine classname='java.io.IOException' start='47' end='100' sourcepath='java/io/IOException.java' sourcefile='IOException.java'><Message>At IOException.java:[lines 47-100]</Message></SourceLine><Message>Exception class java.io.IOException</Message></Class><SourceLine endBytecode='25' classname='org.apache.hadoop.hdfs.web.TestWebHdfsContentLength' start='170' end='170' sourcepath='org/apache/hadoop/hdfs/web/TestWebHdfsContentLength.java' sourcefile='TestWebHdfsContentLength.java' startBytecode='25' primary='true'><Message>At TestWebHdfsContentLength.java:[line 170]</Message></SourceLine><SourceLine endBytecode='25' classname='org.apache.hadoop.hdfs.web.TestWebHdfsContentLength' start='170' end='170' sourcepath='org/apache/hadoop/hdfs/web/TestWebHdfsContentLength.java' sourcefile='TestWebHdfsContentLength.java' startBytecode='25' primary='true'><Message>At TestWebHdfsContentLength.java:[line 170]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='178ee8327f16a08b23344b928c793fbd' cweid='391' rank='16' abbrev='DE' category='BAD_PRACTICE' priority='2' type='DE_MIGHT_IGNORE' instanceOccurrenceMax='0'><ShortMessage>Method might ignore exception</ShortMessage><LongMessage>org.apache.hadoop.hdfs.web.TestWebHdfsContentLength.testGetOp() might ignore java.io.IOException</LongMessage><Class classname='org.apache.hadoop.hdfs.web.TestWebHdfsContentLength' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.web.TestWebHdfsContentLength' start='45' end='186' sourcepath='org/apache/hadoop/hdfs/web/TestWebHdfsContentLength.java' sourcefile='TestWebHdfsContentLength.java'><Message>At TestWebHdfsContentLength.java:[lines 45-186]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.web.TestWebHdfsContentLength</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.web.TestWebHdfsContentLength' signature='()V' name='testGetOp' primary='true'><SourceLine endBytecode='157' classname='org.apache.hadoop.hdfs.web.TestWebHdfsContentLength' start='93' end='99' sourcepath='org/apache/hadoop/hdfs/web/TestWebHdfsContentLength.java' sourcefile='TestWebHdfsContentLength.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.web.TestWebHdfsContentLength.testGetOp()</Message></Method><Class role='CLASS_EXCEPTION' classname='java.io.IOException'><SourceLine classname='java.io.IOException' start='47' end='100' sourcepath='java/io/IOException.java' sourcefile='IOException.java'><Message>At IOException.java:[lines 47-100]</Message></SourceLine><Message>Exception class java.io.IOException</Message></Class><SourceLine endBytecode='24' classname='org.apache.hadoop.hdfs.web.TestWebHdfsContentLength' start='97' end='97' sourcepath='org/apache/hadoop/hdfs/web/TestWebHdfsContentLength.java' sourcefile='TestWebHdfsContentLength.java' startBytecode='24' primary='true'><Message>At TestWebHdfsContentLength.java:[line 97]</Message></SourceLine><SourceLine endBytecode='24' classname='org.apache.hadoop.hdfs.web.TestWebHdfsContentLength' start='97' end='97' sourcepath='org/apache/hadoop/hdfs/web/TestWebHdfsContentLength.java' sourcefile='TestWebHdfsContentLength.java' startBytecode='24' primary='true'><Message>At TestWebHdfsContentLength.java:[line 97]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='117dff4b3118f9d448b003be494064d2' cweid='391' rank='16' abbrev='DE' category='BAD_PRACTICE' priority='2' type='DE_MIGHT_IGNORE' instanceOccurrenceMax='0'><ShortMessage>Method might ignore exception</ShortMessage><LongMessage>org.apache.hadoop.hdfs.web.TestWebHdfsContentLength.testGetOpWithRedirect() might ignore java.io.IOException</LongMessage><Class classname='org.apache.hadoop.hdfs.web.TestWebHdfsContentLength' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.web.TestWebHdfsContentLength' start='45' end='186' sourcepath='org/apache/hadoop/hdfs/web/TestWebHdfsContentLength.java' sourcefile='TestWebHdfsContentLength.java'><Message>At TestWebHdfsContentLength.java:[lines 45-186]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.web.TestWebHdfsContentLength</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.web.TestWebHdfsContentLength' signature='()V' name='testGetOpWithRedirect' primary='true'><SourceLine endBytecode='257' classname='org.apache.hadoop.hdfs.web.TestWebHdfsContentLength' start='103' end='113' sourcepath='org/apache/hadoop/hdfs/web/TestWebHdfsContentLength.java' sourcefile='TestWebHdfsContentLength.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.web.TestWebHdfsContentLength.testGetOpWithRedirect()</Message></Method><Class role='CLASS_EXCEPTION' classname='java.io.IOException'><SourceLine classname='java.io.IOException' start='47' end='100' sourcepath='java/io/IOException.java' sourcefile='IOException.java'><Message>At IOException.java:[lines 47-100]</Message></SourceLine><Message>Exception class java.io.IOException</Message></Class><SourceLine endBytecode='43' classname='org.apache.hadoop.hdfs.web.TestWebHdfsContentLength' start='109' end='109' sourcepath='org/apache/hadoop/hdfs/web/TestWebHdfsContentLength.java' sourcefile='TestWebHdfsContentLength.java' startBytecode='43' primary='true'><Message>At TestWebHdfsContentLength.java:[line 109]</Message></SourceLine><SourceLine endBytecode='43' classname='org.apache.hadoop.hdfs.web.TestWebHdfsContentLength' start='109' end='109' sourcepath='org/apache/hadoop/hdfs/web/TestWebHdfsContentLength.java' sourcefile='TestWebHdfsContentLength.java' startBytecode='43' primary='true'><Message>At TestWebHdfsContentLength.java:[line 109]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='ee4601e324829b38d981c7234aade4b7' cweid='391' rank='16' abbrev='DE' category='BAD_PRACTICE' priority='2' type='DE_MIGHT_IGNORE' instanceOccurrenceMax='0'><ShortMessage>Method might ignore exception</ShortMessage><LongMessage>org.apache.hadoop.hdfs.web.TestWebHdfsContentLength.testPostOp() might ignore java.io.IOException</LongMessage><Class classname='org.apache.hadoop.hdfs.web.TestWebHdfsContentLength' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.web.TestWebHdfsContentLength' start='45' end='186' sourcepath='org/apache/hadoop/hdfs/web/TestWebHdfsContentLength.java' sourcefile='TestWebHdfsContentLength.java'><Message>At TestWebHdfsContentLength.java:[lines 45-186]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.web.TestWebHdfsContentLength</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.web.TestWebHdfsContentLength' signature='()V' name='testPostOp' primary='true'><SourceLine endBytecode='167' classname='org.apache.hadoop.hdfs.web.TestWebHdfsContentLength' start='141' end='147' sourcepath='org/apache/hadoop/hdfs/web/TestWebHdfsContentLength.java' sourcefile='TestWebHdfsContentLength.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.web.TestWebHdfsContentLength.testPostOp()</Message></Method><Class role='CLASS_EXCEPTION' classname='java.io.IOException'><SourceLine classname='java.io.IOException' start='47' end='100' sourcepath='java/io/IOException.java' sourcefile='IOException.java'><Message>At IOException.java:[lines 47-100]</Message></SourceLine><Message>Exception class java.io.IOException</Message></Class><SourceLine endBytecode='33' classname='org.apache.hadoop.hdfs.web.TestWebHdfsContentLength' start='145' end='145' sourcepath='org/apache/hadoop/hdfs/web/TestWebHdfsContentLength.java' sourcefile='TestWebHdfsContentLength.java' startBytecode='33' primary='true'><Message>At TestWebHdfsContentLength.java:[line 145]</Message></SourceLine><SourceLine endBytecode='33' classname='org.apache.hadoop.hdfs.web.TestWebHdfsContentLength' start='145' end='145' sourcepath='org/apache/hadoop/hdfs/web/TestWebHdfsContentLength.java' sourcefile='TestWebHdfsContentLength.java' startBytecode='33' primary='true'><Message>At TestWebHdfsContentLength.java:[line 145]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='1b221ab5e046f1ef7e0d96270ec321e4' cweid='391' rank='16' abbrev='DE' category='BAD_PRACTICE' priority='2' type='DE_MIGHT_IGNORE' instanceOccurrenceMax='0'><ShortMessage>Method might ignore exception</ShortMessage><LongMessage>org.apache.hadoop.hdfs.web.TestWebHdfsContentLength.testPostOpWithRedirect() might ignore java.io.IOException</LongMessage><Class classname='org.apache.hadoop.hdfs.web.TestWebHdfsContentLength' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.web.TestWebHdfsContentLength' start='45' end='186' sourcepath='org/apache/hadoop/hdfs/web/TestWebHdfsContentLength.java' sourcefile='TestWebHdfsContentLength.java'><Message>At TestWebHdfsContentLength.java:[lines 45-186]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.web.TestWebHdfsContentLength</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.web.TestWebHdfsContentLength' signature='()V' name='testPostOpWithRedirect' primary='true'><SourceLine endBytecode='240' classname='org.apache.hadoop.hdfs.web.TestWebHdfsContentLength' start='152' end='162' sourcepath='org/apache/hadoop/hdfs/web/TestWebHdfsContentLength.java' sourcefile='TestWebHdfsContentLength.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.web.TestWebHdfsContentLength.testPostOpWithRedirect()</Message></Method><Class role='CLASS_EXCEPTION' classname='java.io.IOException'><SourceLine classname='java.io.IOException' start='47' end='100' sourcepath='java/io/IOException.java' sourcefile='IOException.java'><Message>At IOException.java:[lines 47-100]</Message></SourceLine><Message>Exception class java.io.IOException</Message></Class><SourceLine endBytecode='47' classname='org.apache.hadoop.hdfs.web.TestWebHdfsContentLength' start='159' end='159' sourcepath='org/apache/hadoop/hdfs/web/TestWebHdfsContentLength.java' sourcefile='TestWebHdfsContentLength.java' startBytecode='47' primary='true'><Message>At TestWebHdfsContentLength.java:[line 159]</Message></SourceLine><SourceLine endBytecode='47' classname='org.apache.hadoop.hdfs.web.TestWebHdfsContentLength' start='159' end='159' sourcepath='org/apache/hadoop/hdfs/web/TestWebHdfsContentLength.java' sourcefile='TestWebHdfsContentLength.java' startBytecode='47' primary='true'><Message>At TestWebHdfsContentLength.java:[line 159]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='a57f023e3a5b67a869c9426b5f1369f2' cweid='391' rank='16' abbrev='DE' category='BAD_PRACTICE' priority='2' type='DE_MIGHT_IGNORE' instanceOccurrenceMax='0'><ShortMessage>Method might ignore exception</ShortMessage><LongMessage>org.apache.hadoop.hdfs.web.TestWebHdfsContentLength.testPutOp() might ignore java.io.IOException</LongMessage><Class classname='org.apache.hadoop.hdfs.web.TestWebHdfsContentLength' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.web.TestWebHdfsContentLength' start='45' end='186' sourcepath='org/apache/hadoop/hdfs/web/TestWebHdfsContentLength.java' sourcefile='TestWebHdfsContentLength.java'><Message>At TestWebHdfsContentLength.java:[lines 45-186]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.web.TestWebHdfsContentLength</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.web.TestWebHdfsContentLength' signature='()V' name='testPutOp' primary='true'><SourceLine endBytecode='158' classname='org.apache.hadoop.hdfs.web.TestWebHdfsContentLength' start='117' end='123' sourcepath='org/apache/hadoop/hdfs/web/TestWebHdfsContentLength.java' sourcefile='TestWebHdfsContentLength.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.web.TestWebHdfsContentLength.testPutOp()</Message></Method><Class role='CLASS_EXCEPTION' classname='java.io.IOException'><SourceLine classname='java.io.IOException' start='47' end='100' sourcepath='java/io/IOException.java' sourcefile='IOException.java'><Message>At IOException.java:[lines 47-100]</Message></SourceLine><Message>Exception class java.io.IOException</Message></Class><SourceLine endBytecode='24' classname='org.apache.hadoop.hdfs.web.TestWebHdfsContentLength' start='121' end='121' sourcepath='org/apache/hadoop/hdfs/web/TestWebHdfsContentLength.java' sourcefile='TestWebHdfsContentLength.java' startBytecode='24' primary='true'><Message>At TestWebHdfsContentLength.java:[line 121]</Message></SourceLine><SourceLine endBytecode='24' classname='org.apache.hadoop.hdfs.web.TestWebHdfsContentLength' start='121' end='121' sourcepath='org/apache/hadoop/hdfs/web/TestWebHdfsContentLength.java' sourcefile='TestWebHdfsContentLength.java' startBytecode='24' primary='true'><Message>At TestWebHdfsContentLength.java:[line 121]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='23a44ef9987d1efef2b99b8700747e2e' cweid='391' rank='16' abbrev='DE' category='BAD_PRACTICE' priority='2' type='DE_MIGHT_IGNORE' instanceOccurrenceMax='0'><ShortMessage>Method might ignore exception</ShortMessage><LongMessage>org.apache.hadoop.hdfs.web.TestWebHdfsContentLength.testPutOpWithRedirect() might ignore java.io.IOException</LongMessage><Class classname='org.apache.hadoop.hdfs.web.TestWebHdfsContentLength' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.web.TestWebHdfsContentLength' start='45' end='186' sourcepath='org/apache/hadoop/hdfs/web/TestWebHdfsContentLength.java' sourcefile='TestWebHdfsContentLength.java'><Message>At TestWebHdfsContentLength.java:[lines 45-186]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.web.TestWebHdfsContentLength</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.web.TestWebHdfsContentLength' signature='()V' name='testPutOpWithRedirect' primary='true'><SourceLine endBytecode='240' classname='org.apache.hadoop.hdfs.web.TestWebHdfsContentLength' start='127' end='137' sourcepath='org/apache/hadoop/hdfs/web/TestWebHdfsContentLength.java' sourcefile='TestWebHdfsContentLength.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.web.TestWebHdfsContentLength.testPutOpWithRedirect()</Message></Method><Class role='CLASS_EXCEPTION' classname='java.io.IOException'><SourceLine classname='java.io.IOException' start='47' end='100' sourcepath='java/io/IOException.java' sourcefile='IOException.java'><Message>At IOException.java:[lines 47-100]</Message></SourceLine><Message>Exception class java.io.IOException</Message></Class><SourceLine endBytecode='47' classname='org.apache.hadoop.hdfs.web.TestWebHdfsContentLength' start='134' end='134' sourcepath='org/apache/hadoop/hdfs/web/TestWebHdfsContentLength.java' sourcefile='TestWebHdfsContentLength.java' startBytecode='47' primary='true'><Message>At TestWebHdfsContentLength.java:[line 134]</Message></SourceLine><SourceLine endBytecode='47' classname='org.apache.hadoop.hdfs.web.TestWebHdfsContentLength' start='134' end='134' sourcepath='org/apache/hadoop/hdfs/web/TestWebHdfsContentLength.java' sourcefile='TestWebHdfsContentLength.java' startBytecode='47' primary='true'><Message>At TestWebHdfsContentLength.java:[line 134]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='3fc682877a7d7be88f958b38cac2b428' rank='20' abbrev='SIC' category='PERFORMANCE' priority='3' type='SIC_INNER_SHOULD_BE_STATIC_ANON' instanceOccurrenceMax='0'><ShortMessage>Could be refactored into a named static inner class</ShortMessage><LongMessage>The class org.apache.hadoop.hdfs.web.TestWebHdfsContentLength$1 could be refactored into a named _static_ inner class</LongMessage><Class role='CLASS_ANONYMOUS' classname='org.apache.hadoop.hdfs.web.TestWebHdfsContentLength$1'><SourceLine classname='org.apache.hadoop.hdfs.web.TestWebHdfsContentLength$1' start='186' end='212' sourcepath='org/apache/hadoop/hdfs/web/TestWebHdfsContentLength.java' sourcefile='TestWebHdfsContentLength.java'><Message>At TestWebHdfsContentLength.java:[lines 186-212]</Message></SourceLine><Message>Anonymous class org.apache.hadoop.hdfs.web.TestWebHdfsContentLength$1</Message></Class><Class classname='org.apache.hadoop.hdfs.web.TestWebHdfsContentLength' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.web.TestWebHdfsContentLength' start='45' end='186' sourcepath='org/apache/hadoop/hdfs/web/TestWebHdfsContentLength.java' sourcefile='TestWebHdfsContentLength.java'><Message>At TestWebHdfsContentLength.java:[lines 45-186]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.web.TestWebHdfsContentLength</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.web.TestWebHdfsContentLength' signature='(Ljava/lang/String;)Ljava/util/concurrent/Future;' name='contentLengthFuture' primary='true'><SourceLine endBytecode='69' classname='org.apache.hadoop.hdfs.web.TestWebHdfsContentLength' start='186' end='186' sourcepath='org/apache/hadoop/hdfs/web/TestWebHdfsContentLength.java' sourcefile='TestWebHdfsContentLength.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.web.TestWebHdfsContentLength.contentLengthFuture(String)</Message></Method><SourceLine endBytecode='9' classname='org.apache.hadoop.hdfs.web.TestWebHdfsContentLength' start='186' end='186' sourcepath='org/apache/hadoop/hdfs/web/TestWebHdfsContentLength.java' sourcefile='TestWebHdfsContentLength.java' startBytecode='9' primary='true'><Message>At TestWebHdfsContentLength.java:[line 186]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='c00f3b095c9d6a41dea68d25d234ccb5' rank='18' abbrev='UrF' category='STYLE' priority='2' type='URF_UNREAD_PUBLIC_OR_PROTECTED_FIELD' instanceOccurrenceMax='0'><ShortMessage>Unread public/protected field</ShortMessage><LongMessage>Unread public/protected field: org.apache.hadoop.hdfs.web.TestWebHdfsContentLength.timeout</LongMessage><Class classname='org.apache.hadoop.hdfs.web.TestWebHdfsContentLength' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.web.TestWebHdfsContentLength' start='45' end='186' sourcepath='org/apache/hadoop/hdfs/web/TestWebHdfsContentLength.java' sourcefile='TestWebHdfsContentLength.java'><Message>At TestWebHdfsContentLength.java:[lines 45-186]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.web.TestWebHdfsContentLength</Message></Class><Field isStatic='false' classname='org.apache.hadoop.hdfs.web.TestWebHdfsContentLength' signature='Lorg/junit/rules/Timeout;' name='timeout' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.web.TestWebHdfsContentLength' sourcepath='org/apache/hadoop/hdfs/web/TestWebHdfsContentLength.java' sourcefile='TestWebHdfsContentLength.java'><Message>In TestWebHdfsContentLength.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.web.TestWebHdfsContentLength.timeout</Message></Field><SourceLine endBytecode='15' classname='org.apache.hadoop.hdfs.web.TestWebHdfsContentLength' start='62' end='62' sourcepath='org/apache/hadoop/hdfs/web/TestWebHdfsContentLength.java' sourcefile='TestWebHdfsContentLength.java' startBytecode='15' primary='true'><Message>At TestWebHdfsContentLength.java:[line 62]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='8299bebe6530254ff300fcf2cafb8f37' rank='19' abbrev='Dm' category='I18N' priority='1' type='DM_DEFAULT_ENCODING' instanceOccurrenceMax='0'><ShortMessage>Reliance on default encoding</ShortMessage><LongMessage>Found reliance on default encoding in org.apache.hadoop.hdfs.web.TestWebHdfsContentLength$1.call(): String.getBytes()</LongMessage><Class classname='org.apache.hadoop.hdfs.web.TestWebHdfsContentLength$1' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.web.TestWebHdfsContentLength$1' start='186' end='212' sourcepath='org/apache/hadoop/hdfs/web/TestWebHdfsContentLength.java' sourcefile='TestWebHdfsContentLength.java'><Message>At TestWebHdfsContentLength.java:[lines 186-212]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.web.TestWebHdfsContentLength$1</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.web.TestWebHdfsContentLength$1' signature='()Ljava/lang/String;' name='call' primary='true'><SourceLine endBytecode='307' classname='org.apache.hadoop.hdfs.web.TestWebHdfsContentLength$1' start='189' end='212' sourcepath='org/apache/hadoop/hdfs/web/TestWebHdfsContentLength.java' sourcefile='TestWebHdfsContentLength.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.web.TestWebHdfsContentLength$1.call()</Message></Method><Method isStatic='false' role='METHOD_CALLED' classname='java.lang.String' signature='()[B' name='getBytes'><SourceLine endBytecode='37' classname='java.lang.String' start='958' end='958' sourcepath='java/lang/String.java' sourcefile='String.java' startBytecode='0'></SourceLine><Message>Called method String.getBytes()</Message></Method><SourceLine endBytecode='22' classname='org.apache.hadoop.hdfs.web.TestWebHdfsContentLength$1' start='192' end='192' sourcepath='org/apache/hadoop/hdfs/web/TestWebHdfsContentLength.java' sourcefile='TestWebHdfsContentLength.java' startBytecode='22' primary='true'><Message>At TestWebHdfsContentLength.java:[line 192]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='5534e6357bc9a8a1d4c7131476a3d062' rank='20' abbrev='PZLA' category='STYLE' priority='3' type='PZLA_PREFER_ZERO_LENGTH_ARRAYS' instanceOccurrenceMax='0'><ShortMessage>Consider returning a zero length array rather than null</ShortMessage><LongMessage>Should org.apache.hadoop.hdfs.web.WebHdfsFileSystem.getFileBlockLocations(FileStatus, long, long) return a zero length array rather than null?</LongMessage><Class classname='org.apache.hadoop.hdfs.web.WebHdfsFileSystem' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.web.WebHdfsFileSystem' start='136' end='1958' sourcepath='org/apache/hadoop/hdfs/web/WebHdfsFileSystem.java' sourcefile='WebHdfsFileSystem.java'><Message>At WebHdfsFileSystem.java:[lines 136-1958]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.web.WebHdfsFileSystem</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.web.WebHdfsFileSystem' signature='(Lorg/apache/hadoop/fs/FileStatus;JJ)[Lorg/apache/hadoop/fs/BlockLocation;' name='getFileBlockLocations' primary='true'><SourceLine endBytecode='106' classname='org.apache.hadoop.hdfs.web.WebHdfsFileSystem' start='1742' end='1745' sourcepath='org/apache/hadoop/hdfs/web/WebHdfsFileSystem.java' sourcefile='WebHdfsFileSystem.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.web.WebHdfsFileSystem.getFileBlockLocations(FileStatus, long, long)</Message></Method><SourceLine endBytecode='5' classname='org.apache.hadoop.hdfs.web.WebHdfsFileSystem' start='1743' end='1743' sourcepath='org/apache/hadoop/hdfs/web/WebHdfsFileSystem.java' sourcefile='WebHdfsFileSystem.java' startBytecode='5' primary='true'><Message>At WebHdfsFileSystem.java:[line 1743]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='4a859108daaca6924d7b7071ac5c343e' rank='20' abbrev='SIC' category='PERFORMANCE' priority='3' type='SIC_INNER_SHOULD_BE_STATIC_ANON' instanceOccurrenceMax='0'><ShortMessage>Could be refactored into a named static inner class</ShortMessage><LongMessage>The class org.apache.hadoop.hdfs.web.WebHdfsFileSystem$1 could be refactored into a named _static_ inner class</LongMessage><Class role='CLASS_ANONYMOUS' classname='org.apache.hadoop.hdfs.web.WebHdfsFileSystem$1'><SourceLine classname='org.apache.hadoop.hdfs.web.WebHdfsFileSystem$1' start='295' end='298' sourcepath='org/apache/hadoop/hdfs/web/WebHdfsFileSystem.java' sourcefile='WebHdfsFileSystem.java'><Message>At WebHdfsFileSystem.java:[lines 295-298]</Message></SourceLine><Message>Anonymous class org.apache.hadoop.hdfs.web.WebHdfsFileSystem$1</Message></Class><Class classname='org.apache.hadoop.hdfs.web.WebHdfsFileSystem' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.web.WebHdfsFileSystem' start='136' end='1958' sourcepath='org/apache/hadoop/hdfs/web/WebHdfsFileSystem.java' sourcefile='WebHdfsFileSystem.java'><Message>At WebHdfsFileSystem.java:[lines 136-1958]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.web.WebHdfsFileSystem</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.web.WebHdfsFileSystem' signature='(Ljava/net/URI;Lorg/apache/hadoop/conf/Configuration;)V' name='initialize' primary='true'><SourceLine endBytecode='807' classname='org.apache.hadoop.hdfs.web.WebHdfsFileSystem' start='205' end='301' sourcepath='org/apache/hadoop/hdfs/web/WebHdfsFileSystem.java' sourcefile='WebHdfsFileSystem.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.web.WebHdfsFileSystem.initialize(URI, Configuration)</Message></Method><SourceLine endBytecode='388' classname='org.apache.hadoop.hdfs.web.WebHdfsFileSystem' start='293' end='293' sourcepath='org/apache/hadoop/hdfs/web/WebHdfsFileSystem.java' sourcefile='WebHdfsFileSystem.java' startBytecode='388' primary='true'><Message>At WebHdfsFileSystem.java:[line 293]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='ae1e4b780a8f3986eef5e36f57acb96b' rank='20' abbrev='SIC' category='PERFORMANCE' priority='3' type='SIC_INNER_SHOULD_BE_STATIC_ANON' instanceOccurrenceMax='0'><ShortMessage>Could be refactored into a named static inner class</ShortMessage><LongMessage>The class org.apache.hadoop.hdfs.web.WebHdfsFileSystem$2 could be refactored into a named _static_ inner class</LongMessage><Class role='CLASS_ANONYMOUS' classname='org.apache.hadoop.hdfs.web.WebHdfsFileSystem$2'><SourceLine classname='org.apache.hadoop.hdfs.web.WebHdfsFileSystem$2' start='351' end='351' sourcepath='org/apache/hadoop/hdfs/web/WebHdfsFileSystem.java' sourcefile='WebHdfsFileSystem.java'><Message>At WebHdfsFileSystem.java:[line 351]</Message></SourceLine><Message>Anonymous class org.apache.hadoop.hdfs.web.WebHdfsFileSystem$2</Message></Class><Class classname='org.apache.hadoop.hdfs.web.WebHdfsFileSystem' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.web.WebHdfsFileSystem' start='136' end='1958' sourcepath='org/apache/hadoop/hdfs/web/WebHdfsFileSystem.java' sourcefile='WebHdfsFileSystem.java'><Message>At WebHdfsFileSystem.java:[lines 136-1958]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.web.WebHdfsFileSystem</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.web.WebHdfsFileSystem' signature='()V' name='&lt;init&gt;' primary='true'><SourceLine endBytecode='83' classname='org.apache.hadoop.hdfs.web.WebHdfsFileSystem' start='136' end='350' sourcepath='org/apache/hadoop/hdfs/web/WebHdfsFileSystem.java' sourcefile='WebHdfsFileSystem.java' startBytecode='0'></SourceLine><Message>In method new org.apache.hadoop.hdfs.web.WebHdfsFileSystem()</Message></Method><SourceLine endBytecode='19' classname='org.apache.hadoop.hdfs.web.WebHdfsFileSystem' start='351' end='351' sourcepath='org/apache/hadoop/hdfs/web/WebHdfsFileSystem.java' sourcefile='WebHdfsFileSystem.java' startBytecode='19' primary='true'><Message>At WebHdfsFileSystem.java:[line 351]</Message></SourceLine><Field isStatic='false' classname='org.apache.hadoop.hdfs.web.WebHdfsFileSystem' signature='Lorg/apache/hadoop/security/token/TokenSelector;' name='tokenSelector' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.web.WebHdfsFileSystem' sourcepath='org/apache/hadoop/hdfs/web/WebHdfsFileSystem.java' sourcefile='WebHdfsFileSystem.java'><Message>In WebHdfsFileSystem.java</Message></SourceLine><Message>Field org.apache.hadoop.hdfs.web.WebHdfsFileSystem.tokenSelector</Message></Field></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='9aa21311d756ea1fc950fc99a094a84' cweid='396' rank='20' abbrev='REC' category='STYLE' priority='3' type='REC_CATCH_EXCEPTION' instanceOccurrenceMax='0'><ShortMessage>Exception is caught when Exception is not thrown</ShortMessage><LongMessage>Exception is caught when Exception is not thrown in org.apache.hadoop.hdfs.web.oauth2.ConfRefreshTokenBasedAccessTokenProvider.refresh()</LongMessage><Class classname='org.apache.hadoop.hdfs.web.oauth2.ConfRefreshTokenBasedAccessTokenProvider' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.web.oauth2.ConfRefreshTokenBasedAccessTokenProvider' start='58' end='144' sourcepath='org/apache/hadoop/hdfs/web/oauth2/ConfRefreshTokenBasedAccessTokenProvider.java' sourcefile='ConfRefreshTokenBasedAccessTokenProvider.java'><Message>At ConfRefreshTokenBasedAccessTokenProvider.java:[lines 58-144]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.web.oauth2.ConfRefreshTokenBasedAccessTokenProvider</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.web.oauth2.ConfRefreshTokenBasedAccessTokenProvider' signature='()V' name='refresh' primary='true'><SourceLine endBytecode='516' classname='org.apache.hadoop.hdfs.web.oauth2.ConfRefreshTokenBasedAccessTokenProvider' start='109' end='141' sourcepath='org/apache/hadoop/hdfs/web/oauth2/ConfRefreshTokenBasedAccessTokenProvider.java' sourcefile='ConfRefreshTokenBasedAccessTokenProvider.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.web.oauth2.ConfRefreshTokenBasedAccessTokenProvider.refresh()</Message></Method><SourceLine endBytecode='229' classname='org.apache.hadoop.hdfs.web.oauth2.ConfRefreshTokenBasedAccessTokenProvider' start='138' end='138' sourcepath='org/apache/hadoop/hdfs/web/oauth2/ConfRefreshTokenBasedAccessTokenProvider.java' sourcefile='ConfRefreshTokenBasedAccessTokenProvider.java' startBytecode='229' primary='true'><Message>At ConfRefreshTokenBasedAccessTokenProvider.java:[line 138]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='dbce6e4c0bc85056660cc447f88080b9' cweid='396' rank='20' abbrev='REC' category='STYLE' priority='3' type='REC_CATCH_EXCEPTION' instanceOccurrenceMax='0'><ShortMessage>Exception is caught when Exception is not thrown</ShortMessage><LongMessage>Exception is caught when Exception is not thrown in org.apache.hadoop.hdfs.web.oauth2.CredentialBasedAccessTokenProvider.refresh()</LongMessage><Class classname='org.apache.hadoop.hdfs.web.oauth2.CredentialBasedAccessTokenProvider' primary='true'><SourceLine classname='org.apache.hadoop.hdfs.web.oauth2.CredentialBasedAccessTokenProvider' start='58' end='136' sourcepath='org/apache/hadoop/hdfs/web/oauth2/CredentialBasedAccessTokenProvider.java' sourcefile='CredentialBasedAccessTokenProvider.java'><Message>At CredentialBasedAccessTokenProvider.java:[lines 58-136]</Message></SourceLine><Message>In class org.apache.hadoop.hdfs.web.oauth2.CredentialBasedAccessTokenProvider</Message></Class><Method isStatic='false' classname='org.apache.hadoop.hdfs.web.oauth2.CredentialBasedAccessTokenProvider' signature='()V' name='refresh' primary='true'><SourceLine endBytecode='516' classname='org.apache.hadoop.hdfs.web.oauth2.CredentialBasedAccessTokenProvider' start='103' end='136' sourcepath='org/apache/hadoop/hdfs/web/oauth2/CredentialBasedAccessTokenProvider.java' sourcefile='CredentialBasedAccessTokenProvider.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.hdfs.web.oauth2.CredentialBasedAccessTokenProvider.refresh()</Message></Method><SourceLine endBytecode='229' classname='org.apache.hadoop.hdfs.web.oauth2.CredentialBasedAccessTokenProvider' start='133' end='133' sourcepath='org/apache/hadoop/hdfs/web/oauth2/CredentialBasedAccessTokenProvider.java' sourcefile='CredentialBasedAccessTokenProvider.java' startBytecode='229' primary='true'><Message>At CredentialBasedAccessTokenProvider.java:[line 133]</Message></SourceLine></BugInstance><BugCategory category='BAD_PRACTICE'><Description>Bad practice</Description></BugCategory><BugCategory category='MALICIOUS_CODE'><Description>Malicious code vulnerability</Description></BugCategory><BugCategory category='PERFORMANCE'><Description>Performance</Description></BugCategory><BugCategory category='STYLE'><Description>Dodgy code</Description></BugCategory><BugCategory category='MT_CORRECTNESS'><Description>Multithreaded correctness</Description></BugCategory><BugCategory category='I18N'><Description>Internationalization</Description></BugCategory><BugPattern abbrev='UwF' category='STYLE' type='UWF_FIELD_NOT_INITIALIZED_IN_CONSTRUCTOR'><ShortDescription>Field not initialized in constructor but dereferenced without null check</ShortDescription><Details>

  &lt;p&gt; This field is never initialized within any constructor, and is therefore could be null after
the object is constructed. Elsewhere, it is loaded and dereferenced without a null check.
This could be a either an error or a questionable design, since
it means a null pointer exception will be generated if that field is dereferenced
before being initialized.
&lt;/p&gt;

    </Details></BugPattern><BugPattern abbrev='DLS' category='STYLE' type='DLS_DEAD_LOCAL_STORE'><ShortDescription>Dead store to local variable</ShortDescription><Details>

&lt;p&gt;
This instruction assigns a value to a local variable,
but the value is not read or used in any subsequent instruction.
Often, this indicates an error, because the value computed is never
used.
&lt;/p&gt;
&lt;p&gt;
Note that Sun's javac compiler often generates dead stores for
final local variables.  Because SpotBugs is a bytecode-based tool,
there is no easy way to eliminate these false positives.
&lt;/p&gt;

    </Details></BugPattern><BugPattern cweid='374' abbrev='EI2' category='MALICIOUS_CODE' type='EI_EXPOSE_REP2'><ShortDescription>May expose internal representation by incorporating reference to mutable object</ShortDescription><Details>

  &lt;p&gt; This code stores a reference to an externally mutable object into the
  internal representation of the object.&amp;nbsp;
   If instances
   are accessed by untrusted code, and unchecked changes to
   the mutable object would compromise security or other
   important properties, you will need to do something different.
  Storing a copy of the object is better approach in many situations.&lt;/p&gt;

    </Details></BugPattern><BugPattern abbrev='VO' category='MT_CORRECTNESS' type='VO_VOLATILE_REFERENCE_TO_ARRAY'><ShortDescription>A volatile reference to an array doesn't treat the array elements as volatile</ShortDescription><Details>

&lt;p&gt;This declares a volatile reference to an array, which might not be what
you want. With a volatile reference to an array, reads and writes of
the reference to the array are treated as volatile, but the array elements
are non-volatile. To get volatile array elements, you will need to use
one of the atomic array classes in java.util.concurrent (provided
in Java 5.0).&lt;/p&gt;

    </Details></BugPattern><BugPattern abbrev='UL' category='MT_CORRECTNESS' type='UL_UNRELEASED_LOCK'><ShortDescription>Method does not release lock on all paths</ShortDescription><Details>

&lt;p&gt; This method acquires a JSR-166 (&lt;code&gt;java.util.concurrent&lt;/code&gt;) lock,
but does not release it on all paths out of the method.  In general, the correct idiom
for using a JSR-166 lock is:
&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Lock l = ...;
l.lock();
try {
    // do something
} finally {
    l.unlock();
}
&lt;/code&gt;&lt;/pre&gt;

    </Details></BugPattern><BugPattern abbrev='RV' category='STYLE' type='RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT'><ShortDescription>Return value of method without side effect is ignored</ShortDescription><Details>

&lt;p&gt;This code calls a method and ignores the return value. However our analysis shows that
the method (including its implementations in subclasses if any) does not produce any effect
other than return value. Thus this call can be removed.
&lt;/p&gt;
&lt;p&gt;We are trying to reduce the false positives as much as possible, but in some cases this warning might be wrong.
Common false-positive cases include:&lt;/p&gt;
&lt;p&gt;- The method is designed to be overridden and produce a side effect in other projects which are out of the scope of the analysis.&lt;/p&gt;
&lt;p&gt;- The method is called to trigger the class loading which may have a side effect.&lt;/p&gt;
&lt;p&gt;- The method is called just to get some exception.&lt;/p&gt;
&lt;p&gt;If you feel that our assumption is incorrect, you can use a @CheckReturnValue annotation
to instruct SpotBugs that ignoring the return value of this method is acceptable.
&lt;/p&gt;

    </Details></BugPattern><BugPattern abbrev='No' category='MT_CORRECTNESS' type='NO_NOTIFY_NOT_NOTIFYALL'><ShortDescription>Using notify() rather than notifyAll()</ShortDescription><Details>

  &lt;p&gt; This method calls &lt;code&gt;notify()&lt;/code&gt; rather than &lt;code&gt;notifyAll()&lt;/code&gt;.&amp;nbsp;
  Java monitors are often used for multiple conditions.&amp;nbsp; Calling &lt;code&gt;notify()&lt;/code&gt;
  only wakes up one thread, meaning that the thread woken up might not be the
  one waiting for the condition that the caller just satisfied.&lt;/p&gt;

    </Details></BugPattern><BugPattern abbrev='SIC' category='PERFORMANCE' type='SIC_INNER_SHOULD_BE_STATIC'><ShortDescription>Should be a static inner class</ShortDescription><Details>

  &lt;p&gt; This class is an inner class, but does not use its embedded reference
  to the object which created it.&amp;nbsp; This reference makes the instances
  of the class larger, and may keep the reference to the creator object
  alive longer than necessary.&amp;nbsp; If possible, the class should be
   made static.
&lt;/p&gt;

    </Details></BugPattern><BugPattern abbrev='MS' category='MALICIOUS_CODE' type='MS_SHOULD_BE_FINAL'><ShortDescription>Field isn't final but should be</ShortDescription><Details>

   &lt;p&gt;
This static field public but not final, and
could be changed by malicious code or
        by accident from another package.
        The field could be made final to avoid
        this vulnerability.&lt;/p&gt;

    </Details></BugPattern><BugPattern abbrev='Dm' category='PERFORMANCE' type='DM_STRING_TOSTRING'><ShortDescription>Method invokes toString() method on a String</ShortDescription><Details>

  &lt;p&gt; Calling &lt;code&gt;String.toString()&lt;/code&gt; is just a redundant operation.
  Just use the String.&lt;/p&gt;

    </Details></BugPattern><BugPattern abbrev='UrF' category='PERFORMANCE' type='URF_UNREAD_FIELD'><ShortDescription>Unread field</ShortDescription><Details>

  &lt;p&gt; This field is never read.&amp;nbsp; Consider removing it from the class.&lt;/p&gt;

    </Details></BugPattern><BugPattern abbrev='BC' category='STYLE' type='BC_UNCONFIRMED_CAST'><ShortDescription>Unchecked/unconfirmed cast</ShortDescription><Details>

&lt;p&gt;
This cast is unchecked, and not all instances of the type casted from can be cast to
the type it is being cast to. Check that your program logic ensures that this
cast will not fail.
&lt;/p&gt;

    </Details></BugPattern><BugPattern cweid='396' abbrev='REC' category='STYLE' type='REC_CATCH_EXCEPTION'><ShortDescription>Exception is caught when Exception is not thrown</ShortDescription><Details>
  
  &lt;p&gt;
  This method uses a try-catch block that catches Exception objects, but Exception is not
  thrown within the try block, and RuntimeException is not explicitly caught.  It is a common bug pattern to
  say try { ... } catch (Exception e) { something } as a shorthand for catching a number of types of exception
  each of whose catch blocks is identical, but this construct also accidentally catches RuntimeException as well,
  masking potential bugs.
  &lt;/p&gt;
  &lt;p&gt;A better approach is to either explicitly catch the specific exceptions that are thrown,
  or to explicitly catch RuntimeException exception, rethrow it, and then catch all non-Runtime Exceptions, as shown below:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;try {
    ...
} catch (RuntimeException e) {
    throw e;
} catch (Exception e) {
    ... deal with all non-runtime exceptions ...
}
&lt;/code&gt;&lt;/pre&gt;
  
     </Details></BugPattern><BugPattern abbrev='UM' category='PERFORMANCE' type='UM_UNNECESSARY_MATH'><ShortDescription>Method calls static Math class method on a constant value</ShortDescription><Details>

&lt;p&gt; This method uses a static method from java.lang.Math on a constant value. This method's
result in this case, can be determined statically, and is faster and sometimes more accurate to
just use the constant. Methods detected are:
&lt;/p&gt;
&lt;table&gt;
&lt;tr&gt;
   &lt;th&gt;Method&lt;/th&gt; &lt;th&gt;Parameter&lt;/th&gt;
&lt;/tr&gt;
&lt;tr&gt;
   &lt;td&gt;abs&lt;/td&gt; &lt;td&gt;-any-&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
   &lt;td&gt;acos&lt;/td&gt; &lt;td&gt;0.0 or 1.0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
   &lt;td&gt;asin&lt;/td&gt; &lt;td&gt;0.0 or 1.0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
   &lt;td&gt;atan&lt;/td&gt; &lt;td&gt;0.0 or 1.0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
   &lt;td&gt;atan2&lt;/td&gt; &lt;td&gt;0.0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
   &lt;td&gt;cbrt&lt;/td&gt; &lt;td&gt;0.0 or 1.0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
   &lt;td&gt;ceil&lt;/td&gt; &lt;td&gt;-any-&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
   &lt;td&gt;cos&lt;/td&gt; &lt;td&gt;0.0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
   &lt;td&gt;cosh&lt;/td&gt; &lt;td&gt;0.0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
   &lt;td&gt;exp&lt;/td&gt; &lt;td&gt;0.0 or 1.0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
   &lt;td&gt;expm1&lt;/td&gt; &lt;td&gt;0.0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
   &lt;td&gt;floor&lt;/td&gt; &lt;td&gt;-any-&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
   &lt;td&gt;log&lt;/td&gt; &lt;td&gt;0.0 or 1.0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
   &lt;td&gt;log10&lt;/td&gt; &lt;td&gt;0.0 or 1.0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
   &lt;td&gt;rint&lt;/td&gt; &lt;td&gt;-any-&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
   &lt;td&gt;round&lt;/td&gt; &lt;td&gt;-any-&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
   &lt;td&gt;sin&lt;/td&gt; &lt;td&gt;0.0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
   &lt;td&gt;sinh&lt;/td&gt; &lt;td&gt;0.0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
   &lt;td&gt;sqrt&lt;/td&gt; &lt;td&gt;0.0 or 1.0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
   &lt;td&gt;tan&lt;/td&gt; &lt;td&gt;0.0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
   &lt;td&gt;tanh&lt;/td&gt; &lt;td&gt;0.0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
   &lt;td&gt;toDegrees&lt;/td&gt; &lt;td&gt;0.0 or 1.0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
   &lt;td&gt;toRadians&lt;/td&gt; &lt;td&gt;0.0&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;

    </Details></BugPattern><BugPattern abbrev='ST' category='STYLE' type='ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD'><ShortDescription>Write to static field from instance method</ShortDescription><Details>

  &lt;p&gt; This instance method writes to a static field. This is tricky to get
correct if multiple instances are being manipulated,
and generally bad practice.
&lt;/p&gt;

    </Details></BugPattern><BugPattern abbrev='BC' category='STYLE' type='BC_UNCONFIRMED_CAST_OF_RETURN_VALUE'><ShortDescription>Unchecked/unconfirmed cast of return value from method</ShortDescription><Details>

&lt;p&gt;
This code performs an unchecked cast of the return value of a method.
The code might be calling the method in such a way that the cast is guaranteed to be
safe, but SpotBugs is unable to verify that the cast is safe.  Check that your program logic ensures that this
cast will not fail.
&lt;/p&gt;

    </Details></BugPattern><BugPattern cweid='374' abbrev='EI' category='MALICIOUS_CODE' type='EI_EXPOSE_REP'><ShortDescription>May expose internal representation by returning reference to mutable object</ShortDescription><Details>

  &lt;p&gt; Returning a reference to a mutable object value stored in one of the object's fields
  exposes the internal representation of the object.&amp;nbsp;
   If instances
   are accessed by untrusted code, and unchecked changes to
   the mutable object would compromise security or other
   important properties, you will need to do something different.
  Returning a new copy of the object is better approach in many situations.&lt;/p&gt;

    </Details></BugPattern><BugPattern abbrev='SIC' category='PERFORMANCE' type='SIC_INNER_SHOULD_BE_STATIC_ANON'><ShortDescription>Could be refactored into a named static inner class</ShortDescription><Details>

  &lt;p&gt; This class is an inner class, but does not use its embedded reference
  to the object which created it.&amp;nbsp; This reference makes the instances
  of the class larger, and may keep the reference to the creator object
  alive longer than necessary.&amp;nbsp; If possible, the class should be
  made into a &lt;em&gt;static&lt;/em&gt; inner class. Since anonymous inner
classes cannot be marked as static, doing this will require refactoring
the inner class so that it is a named inner class.&lt;/p&gt;

    </Details></BugPattern><BugPattern abbrev='UL' category='MT_CORRECTNESS' type='UL_UNRELEASED_LOCK_EXCEPTION_PATH'><ShortDescription>Method does not release lock on all exception paths</ShortDescription><Details>

&lt;p&gt; This method acquires a JSR-166 (&lt;code&gt;java.util.concurrent&lt;/code&gt;) lock,
but does not release it on all exception paths out of the method.  In general, the correct idiom
for using a JSR-166 lock is:
&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Lock l = ...;
l.lock();
try {
    // do something
} finally {
    l.unlock();
}
&lt;/code&gt;&lt;/pre&gt;

    </Details></BugPattern><BugPattern abbrev='CI' category='STYLE' type='CI_CONFUSED_INHERITANCE'><ShortDescription>Class is final but declares protected field</ShortDescription><Details>
      
      &lt;p&gt;
      This class is declared to be final, but declares fields to be protected. Since the class
      is final, it can not be derived from, and the use of protected is confusing. The access
      modifier for the field should be changed to private or public to represent the true
      use for the field.
      &lt;/p&gt;
      
    </Details></BugPattern><BugPattern abbrev='Dm' category='I18N' type='DM_DEFAULT_ENCODING'><ShortDescription>Reliance on default encoding</ShortDescription><Details>

&lt;p&gt; Found a call to a method which will perform a byte to String (or String to byte) conversion, and will assume that the default platform encoding is suitable. This will cause the application behaviour to vary between platforms. Use an alternative API and specify a charset name or Charset object explicitly.  &lt;/p&gt;

      </Details></BugPattern><BugPattern abbrev='Se' category='BAD_PRACTICE' type='SE_BAD_FIELD'><ShortDescription>Non-transient non-serializable instance field in serializable class</ShortDescription><Details>

&lt;p&gt; This Serializable class defines a non-primitive instance field which is neither transient,
Serializable, or &lt;code&gt;java.lang.Object&lt;/code&gt;, and does not appear to implement
the &lt;code&gt;Externalizable&lt;/code&gt; interface or the
&lt;code&gt;readObject()&lt;/code&gt; and &lt;code&gt;writeObject()&lt;/code&gt; methods.&amp;nbsp;
Objects of this class will not be deserialized correctly if a non-Serializable
object is stored in this field.&lt;/p&gt;

    </Details></BugPattern><BugPattern abbrev='UCF' category='STYLE' type='UCF_USELESS_CONTROL_FLOW'><ShortDescription>Useless control flow</ShortDescription><Details>

&lt;p&gt; This method contains a useless control flow statement, where
control flow continues onto the same place regardless of whether or not
the branch is taken. For example,
this is caused by having an empty statement
block for an &lt;code&gt;if&lt;/code&gt; statement:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;if (argv.length == 0) {
    // TODO: handle this case
}
&lt;/code&gt;&lt;/pre&gt;

    </Details></BugPattern><BugPattern cweid='571' abbrev='BC' category='STYLE' type='BC_VACUOUS_INSTANCEOF'><ShortDescription>instanceof will always return true</ShortDescription><Details>

&lt;p&gt;
This instanceof test will always return true (unless the value being tested is null).
Although this is safe, make sure it isn't
an indication of some misunderstanding or some other logic error.
If you really want to test the value for being null, perhaps it would be clearer to do
better to do a null test rather than an instanceof test.
&lt;/p&gt;

    </Details></BugPattern><BugPattern abbrev='UrF' category='STYLE' type='URF_UNREAD_PUBLIC_OR_PROTECTED_FIELD'><ShortDescription>Unread public/protected field</ShortDescription><Details>

  &lt;p&gt; This field is never read.&amp;nbsp;
The field is public or protected, so perhaps
    it is intended to be used with classes not seen as part of the analysis. If not,
consider removing it from the class.&lt;/p&gt;

    </Details></BugPattern><BugPattern abbrev='RI' category='STYLE' type='RI_REDUNDANT_INTERFACES'><ShortDescription>Class implements same interface as superclass</ShortDescription><Details>
   
    &lt;p&gt;
    This class declares that it implements an interface that is also implemented by a superclass.
    This is redundant because once a superclass implements an interface, all subclasses by default also
    implement this interface. It may point out that the inheritance hierarchy has changed since
    this class was created, and consideration should be given to the ownership of
    the interface's implementation.
    &lt;/p&gt;
    
     </Details></BugPattern><BugPattern abbrev='PZLA' category='STYLE' type='PZLA_PREFER_ZERO_LENGTH_ARRAYS'><ShortDescription>Consider returning a zero length array rather than null</ShortDescription><Details>

&lt;p&gt; It is often a better design to
return a length zero array rather than a null reference to indicate that there
are no results (i.e., an empty list of results).
This way, no explicit check for null is needed by clients of the method.&lt;/p&gt;

&lt;p&gt;On the other hand, using null to indicate
"there is no answer to this question" is probably appropriate.
For example, &lt;code&gt;File.listFiles()&lt;/code&gt; returns an empty list
if given a directory containing no files, and returns null if the file
is not a directory.&lt;/p&gt;

    </Details></BugPattern><BugPattern abbrev='OS' category='BAD_PRACTICE' type='OS_OPEN_STREAM_EXCEPTION_PATH'><ShortDescription>Method may fail to close stream on exception</ShortDescription><Details>

&lt;p&gt; The method creates an IO stream object, does not assign it to any
fields, pass it to other methods, or return it, and does not appear to close
it on all possible exception paths out of the method.&amp;nbsp;
This may result in a file descriptor leak.&amp;nbsp; It is generally a good
idea to use a &lt;code&gt;finally&lt;/code&gt; block to ensure that streams are
closed.&lt;/p&gt;

    </Details></BugPattern><BugPattern abbrev='SS' category='PERFORMANCE' type='SS_SHOULD_BE_STATIC'><ShortDescription>Unread field: should this field be static?</ShortDescription><Details>

  &lt;p&gt; This class contains an instance final field that
   is initialized to a compile-time static value.
   Consider making the field static.&lt;/p&gt;

    </Details></BugPattern><BugPattern abbrev='AT' category='MT_CORRECTNESS' type='AT_OPERATION_SEQUENCE_ON_CONCURRENT_ABSTRACTION'><ShortDescription>Sequence of calls to concurrent abstraction may not be atomic</ShortDescription><Details>
          
        &lt;p&gt;This code contains a sequence of calls to a concurrent  abstraction
            (such as a concurrent hash map).
            These calls will not be executed atomically.
          
      </Details></BugPattern><BugPattern abbrev='DE' category='BAD_PRACTICE' type='DE_MIGHT_IGNORE'><ShortDescription>Method might ignore exception</ShortDescription><Details>

  &lt;p&gt; This method might ignore an exception.&amp;nbsp; In general, exceptions
  should be handled or reported in some way, or they should be thrown
  out of the method.&lt;/p&gt;

    </Details></BugPattern><BugPattern abbrev='IS' category='MT_CORRECTNESS' type='IS2_INCONSISTENT_SYNC'><ShortDescription>Inconsistent synchronization</ShortDescription><Details>

  &lt;p&gt; The fields of this class appear to be accessed inconsistently with respect
  to synchronization.&amp;nbsp; This bug report indicates that the bug pattern detector
  judged that
  &lt;/p&gt;
  &lt;ul&gt;
  &lt;li&gt; The class contains a mix of locked and unlocked accesses,&lt;/li&gt;
  &lt;li&gt; The class is &lt;b&gt;not&lt;/b&gt; annotated as javax.annotation.concurrent.NotThreadSafe,&lt;/li&gt;
  &lt;li&gt; At least one locked access was performed by one of the class's own methods, and&lt;/li&gt;
  &lt;li&gt; The number of unsynchronized field accesses (reads and writes) was no more than
       one third of all accesses, with writes being weighed twice as high as reads&lt;/li&gt;
  &lt;/ul&gt;

  &lt;p&gt; A typical bug matching this bug pattern is forgetting to synchronize
  one of the methods in a class that is intended to be thread-safe.&lt;/p&gt;

  &lt;p&gt; You can select the nodes labeled "Unsynchronized access" to show the
  code locations where the detector believed that a field was accessed
  without synchronization.&lt;/p&gt;

  &lt;p&gt; Note that there are various sources of inaccuracy in this detector;
  for example, the detector cannot statically detect all situations in which
  a lock is held.&amp;nbsp; Also, even when the detector is accurate in
  distinguishing locked vs. unlocked accesses, the code in question may still
  be correct.&lt;/p&gt;


    </Details></BugPattern><BugPattern abbrev='Se' category='BAD_PRACTICE' type='SE_TRANSIENT_FIELD_NOT_RESTORED'><ShortDescription>Transient field that isn't set by deserialization. </ShortDescription><Details>

  &lt;p&gt; This class contains a field that is updated at multiple places in the class, thus it seems to be part of the state of the class. However, since the field is marked as transient and not set in readObject or readResolve, it will contain the default value in any
deserialized instance of the class.
&lt;/p&gt;

    </Details></BugPattern><BugPattern abbrev='SnVI' category='BAD_PRACTICE' type='SE_NO_SERIALVERSIONID'><ShortDescription>Class is Serializable, but doesn't define serialVersionUID</ShortDescription><Details>

  &lt;p&gt; This class implements the &lt;code&gt;Serializable&lt;/code&gt; interface, but does
  not define a &lt;code&gt;serialVersionUID&lt;/code&gt; field.&amp;nbsp;
  A change as simple as adding a reference to a .class object
    will add synthetic fields to the class,
   which will unfortunately change the implicit
   serialVersionUID (e.g., adding a reference to &lt;code&gt;String.class&lt;/code&gt;
   will generate a static field &lt;code&gt;class$java$lang$String&lt;/code&gt;).
   Also, different source code to bytecode compilers may use different
   naming conventions for synthetic variables generated for
   references to class objects or inner classes.
   To ensure interoperability of Serializable across versions,
   consider adding an explicit serialVersionUID.&lt;/p&gt;

    </Details></BugPattern><BugPattern abbrev='UC' category='STYLE' type='UC_USELESS_CONDITION'><ShortDescription>Condition has no effect</ShortDescription><Details>

&lt;p&gt;This condition always produces the same result as the value of the involved variable that was narrowed before.
Probably something else was meant or the condition can be removed.&lt;/p&gt;

    </Details></BugPattern><BugPattern abbrev='Nm' category='BAD_PRACTICE' type='NM_CONFUSING'><ShortDescription>Confusing method names</ShortDescription><Details>

  &lt;p&gt; The referenced methods have names that differ only by capitalization.&lt;/p&gt;

    </Details></BugPattern><BugPattern cweid='253' abbrev='RV' category='BAD_PRACTICE' type='RV_RETURN_VALUE_IGNORED_BAD_PRACTICE'><ShortDescription>Method ignores exceptional return value</ShortDescription><Details>

   &lt;p&gt; This method returns a value that is not checked. The return value should be checked
since it can indicate an unusual or unexpected function execution. For
example, the &lt;code&gt;File.delete()&lt;/code&gt; method returns false
if the file could not be successfully deleted (rather than
throwing an Exception).
If you don't check the result, you won't notice if the method invocation
signals unexpected behavior by returning an atypical return value.
&lt;/p&gt;

    </Details></BugPattern><BugPattern abbrev='Dm' category='I18N' type='DM_CONVERT_CASE'><ShortDescription>Consider using Locale parameterized version of invoked method</ShortDescription><Details>

  &lt;p&gt; A String is being converted to upper or lowercase, using the platform's default encoding. This may
      result in improper conversions when used with international characters. Use the &lt;/p&gt;
      &lt;ul&gt;
    &lt;li&gt;String.toUpperCase( Locale l )&lt;/li&gt;
    &lt;li&gt;String.toLowerCase( Locale l )&lt;/li&gt;
    &lt;/ul&gt;
      &lt;p&gt;versions instead.&lt;/p&gt;

    </Details></BugPattern><BugCode abbrev='BC'><Description>Bad casts of object references</Description></BugCode><BugCode cweid='391' abbrev='DE'><Description>Dropped or ignored exception</Description></BugCode><BugCode cweid='440' abbrev='RV'><Description>Bad use of return value from method</Description></BugCode><BugCode abbrev='UwF'><Description>Unwritten field</Description></BugCode><BugCode abbrev='SnVI'><Description>Serializable class with no Version ID</Description></BugCode><BugCode cweid='563' abbrev='DLS'><Description>Dead local store</Description></BugCode><BugCode abbrev='UC'><Description>Useless code</Description></BugCode><BugCode abbrev='EI2'><Description>Storing reference to mutable object</Description></BugCode><BugCode abbrev='UL'><Description>Lock not released on all paths</Description></BugCode><BugCode abbrev='UM'><Description>Unnecessary Math on constants</Description></BugCode><BugCode abbrev='PZLA'><Description>Prefer zero length arrays to null to indicate no results</Description></BugCode><BugCode abbrev='Nm'><Description>Confusing method name</Description></BugCode><BugCode abbrev='SS'><Description>Unread field should be static</Description></BugCode><BugCode abbrev='No'><Description>Using notify() rather than notifyAll()</Description></BugCode><BugCode abbrev='ST'><Description>Misuse of static fields</Description></BugCode><BugCode abbrev='EI'><Description>Method returning array may expose internal representation</Description></BugCode><BugCode abbrev='OS'><Description>Stream not closed on all paths</Description></BugCode><BugCode cweid='218' abbrev='MS'><Description>Mutable static field</Description></BugCode><BugCode abbrev='CI'><Description>Confused Inheritance</Description></BugCode><BugCode abbrev='UrF'><Description>Unread field</Description></BugCode><BugCode abbrev='Dm'><Description>Dubious method used</Description></BugCode><BugCode cweid='366' abbrev='IS'><Description>Inconsistent synchronization</Description></BugCode><BugCode abbrev='SIC'><Description>Inner class could be made static</Description></BugCode><BugCode abbrev='REC'><Description>RuntimeException capture</Description></BugCode><BugCode abbrev='Se'><Description>Incorrect definition of Serializable class</Description></BugCode><BugCode abbrev='AT'><Description>Possible atomicity violation</Description></BugCode><BugCode abbrev='RI'><Description>Redundant Interfaces</Description></BugCode><BugCode abbrev='VO'><Description>Use of volatile</Description></BugCode><BugCode abbrev='UCF'><Description>Useless control flow</Description></BugCode><Errors missingClasses='0' errors='0'></Errors><FindBugsSummary num_packages='23' total_classes='2112' priority_1='345' priority_2='599' priority_3='456' total_size='176289' clock_seconds='50.87' referenced_classes='2994' vm_version='25.222-b10' total_bugs='1400' java_version='1.8.0_222' gc_seconds='4.54' alloc_mbytes='478.00' cpu_seconds='187.72' peak_mbytes='579.91' timestamp='Wed, 11 Sep 2019 10:34:46 +0200'><FileStats path='org/apache/hadoop/fs/CacheFlag.java' size='15' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/fs/Hdfs.java' size='224' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/fs/HdfsBlockLocation.java' size='13' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/fs/SWebHdfs.java' size='9' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/fs/TestUrlStreamHandlerFactory.java' size='47' bugHash='b14ad757b778ddcdd5ec2c4f8d0406ab' bugCount='3'></FileStats><FileStats path='org/apache/hadoop/fs/TestXAttr.java' size='64' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/fs/WebHdfs.java' size='9' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/fs/XAttr.java' size='84' bugHash='b522928b9e2c4aa57a90a10e89a85f2a' bugCount='2'></FileStats><FileStats path='org/apache/hadoop/hdfs/AddBlockFlag.java' size='20' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/BlockMissingException.java' size='13' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/BlockReader.java' size='11' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/CannotObtainBlockLengthException.java' size='11' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/ClientContext.java' size='97' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/DFSClient.java' size='1298' bugHash='402d78654109b139954bb7a51993e564' bugCount='4'></FileStats><FileStats path='org/apache/hadoop/hdfs/DFSClientFaultInjector.java' size='31' bugHash='7807e18b7ee14931df57f4e7d67940db' bugCount='2'></FileStats><FileStats path='org/apache/hadoop/hdfs/DFSHedgedReadMetrics.java' size='24' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/DFSInotifyEventInputStream.java' size='83' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/DFSInputStream.java' size='906' bugHash='74a22411717ceb42749e98981b2b1024' bugCount='3'></FileStats><FileStats path='org/apache/hadoop/hdfs/DFSOpsCountStatistics.java' size='169' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/DFSOutputStream.java' size='542' bugHash='f7dfac60a3eaa8439072e50edc8446e8' bugCount='2'></FileStats><FileStats path='org/apache/hadoop/hdfs/DFSPacket.java' size='149' bugHash='6ce790587c5c4bb0ceec368de8364384' bugCount='2'></FileStats><FileStats path='org/apache/hadoop/hdfs/DFSStripedInputStream.java' size='256' bugHash='929c5d9844291718e362c9ecdff8fffa' bugCount='2'></FileStats><FileStats path='org/apache/hadoop/hdfs/DFSStripedOutputStream.java' size='730' bugHash='791fcda1ccc19dca13d7c01822b8311b' bugCount='8'></FileStats><FileStats path='org/apache/hadoop/hdfs/DFSUtilClient.java' size='374' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/DataStreamer.java' size='1157' bugHash='efa53b4f6f7aa706ba03b06a11c3e475' bugCount='7'></FileStats><FileStats path='org/apache/hadoop/hdfs/DistributedFileSystem.java' size='1929' bugHash='6a5dc4ca516b7610af78e7c2c29e3d3b' bugCount='5'></FileStats><FileStats path='org/apache/hadoop/hdfs/ExceptionLastSeen.java' size='26' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/ExtendedBlockId.java' size='29' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/FileChecksumHelper.java' size='366' bugHash='e9e2154c5e7f9adacd505f162f214765' bugCount='2'></FileStats><FileStats path='org/apache/hadoop/hdfs/HAUtilClient.java' size='46' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/HdfsConfiguration.java' size='24' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/HdfsKMSUtil.java' size='82' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/KeyProviderCache.java' size='61' bugHash='38d980b254ed18b08e5966977deb9001' bugCount='2'></FileStats><FileStats path='org/apache/hadoop/hdfs/NameNodeProxiesClient.java' size='123' bugHash='10c2f69b22c78cc2211f110378b8415f' bugCount='2'></FileStats><FileStats path='org/apache/hadoop/hdfs/PeerCache.java' size='155' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/PositionStripeReader.java' size='42' bugHash='c04176bcd4b482fd30ace8c70d3ccf1d' bugCount='1'></FileStats><FileStats path='org/apache/hadoop/hdfs/ReadStatistics.java' size='50' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/ReaderStrategy.java' size='77' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/RemotePeerFactory.java' size='2' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/ReplicaAccessor.java' size='10' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/ReplicaAccessorBuilder.java' size='13' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/StatefulStripeReader.java' size='39' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/StripeReader.java' size='245' bugHash='270ca45da99053b82892e14ab9e19768' bugCount='1'></FileStats><FileStats path='org/apache/hadoop/hdfs/StripedDataStreamer.java' size='81' bugHash='d75db91c46456fa65b7f674e221faa3e' bugCount='1'></FileStats><FileStats path='org/apache/hadoop/hdfs/TestDFSOpsCountStatistics.java' size='121' bugHash='011608d92ff79d364494dba89b4bfe41' bugCount='1'></FileStats><FileStats path='org/apache/hadoop/hdfs/TestDFSPacket.java' size='51' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/TestDefaultNameNodePort.java' size='24' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/TestPeerCache.java' size='154' bugHash='404e26a778ef5e3ce1f0127589959f08' bugCount='1'></FileStats><FileStats path='org/apache/hadoop/hdfs/UnknownCipherSuiteException.java' size='4' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/UnknownCryptoProtocolVersionException.java' size='8' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/XAttrHelper.java' size='73' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/client/BlockReportOptions.java' size='24' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/client/CreateEncryptionZoneFlag.java' size='22' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/client/HdfsAdmin.java' size='122' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/client/HdfsClientConfigKeys.java' size='256' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/client/HdfsDataInputStream.java' size='27' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/client/HdfsDataOutputStream.java' size='38' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/client/HdfsUtils.java' size='28' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/client/impl/BlockReaderFactory.java' size='395' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/client/impl/BlockReaderLocal.java' size='364' bugHash='04dcd0d79f06a51d6426c50ec2ee6c67' bugCount='1'></FileStats><FileStats path='org/apache/hadoop/hdfs/client/impl/BlockReaderLocalLegacy.java' size='340' bugHash='3289d83a1132cf1e00e8304eca9e4b62' bugCount='3'></FileStats><FileStats path='org/apache/hadoop/hdfs/client/impl/BlockReaderRemote.java' size='191' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/client/impl/BlockReaderUtil.java' size='22' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/client/impl/CorruptFileBlockIterator.java' size='47' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/client/impl/DfsClientConf.java' size='306' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/client/impl/ExternalBlockReader.java' size='51' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/client/impl/LeaseRenewer.java' size='263' bugHash='5d8ad6d79c3ca92247c20cf8de2c5282' bugCount='1'></FileStats><FileStats path='org/apache/hadoop/hdfs/client/impl/SnapshotDiffReportGenerator.java' size='149' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/client/impl/TestLeaseRenewer.java' size='106' bugHash='ceaa5eb5e983ea5a3e9c6d04ed478164' bugCount='8'></FileStats><FileStats path='org/apache/hadoop/hdfs/client/impl/metrics/BlockReaderIoProvider.java' size='40' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/client/impl/metrics/BlockReaderLocalMetrics.java' size='19' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/client/impl/metrics/package-info.java' size='1' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/client/package-info.java' size='1' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/inotify/Event.java' size='439' bugHash='7f5c2173b69623dd24c2e89d2ace4156' bugCount='1'></FileStats><FileStats path='org/apache/hadoop/hdfs/inotify/EventBatch.java' size='12' bugHash='419ed41ea6bedfa30562d17796c6eb14' bugCount='2'></FileStats><FileStats path='org/apache/hadoop/hdfs/inotify/EventBatchList.java' size='20' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/inotify/MissingEventsException.java' size='17' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/net/BasicInetPeer.java' size='44' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/net/DomainPeer.java' size='45' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/net/EncryptedPeer.java' size='50' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/net/NioInetPeer.java' size='47' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/net/Peer.java' size='15' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/protocol/AclException.java' size='5' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/protocol/AddErasureCodingPolicyResponse.java' size='44' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/protocol/AlreadyBeingCreatedException.java' size='5' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/protocol/Block.java' size='128' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/protocol/BlockChecksumOptions.java' size='18' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/protocol/BlockChecksumType.java' size='12' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/protocol/BlockLocalPathInfo.java' size='20' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/protocol/BlockStoragePolicy.java' size='108' bugHash='06894753ec65fced5ae8634d0c15097c' bugCount='6'></FileStats><FileStats path='org/apache/hadoop/hdfs/protocol/BlockType.java' size='18' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/protocol/CacheDirectiveEntry.java' size='12' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/protocol/CacheDirectiveInfo.java' size='131' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/protocol/CacheDirectiveIterator.java' size='52' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/protocol/CacheDirectiveStats.java' size='55' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/protocol/CachePoolEntry.java' size='12' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/protocol/CachePoolInfo.java' size='97' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/protocol/CachePoolIterator.java' size='17' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/protocol/CachePoolStats.java' size='55' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/protocol/ClientDatanodeProtocol.java' size='19' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/protocol/ClientProtocol.java' size='117' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/protocol/CorruptFileBlocks.java' size='29' bugHash='40178ae252b1b8fef830f2d1dcc1698b' bugCount='2'></FileStats><FileStats path='org/apache/hadoop/hdfs/protocol/DSQuotaExceededException.java' size='17' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/protocol/DatanodeAdminProperties.java' size='35' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/protocol/DatanodeID.java' size='130' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/protocol/DatanodeInfo.java' size='513' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/protocol/DatanodeInfoWithStorage.java' size='22' bugHash='84bb7c346a9f6840c234aa603c04977e' bugCount='1'></FileStats><FileStats path='org/apache/hadoop/hdfs/protocol/DatanodeLocalInfo.java' size='20' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/protocol/DatanodeVolumeInfo.java' size='47' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/protocol/DirectoryListing.java' size='22' bugHash='203106aac0bd73972c23fe6835095d5e' bugCount='3'></FileStats><FileStats path='org/apache/hadoop/hdfs/protocol/ECBlockGroupStats.java' size='37' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/protocol/EncryptionZone.java' size='49' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/protocol/EncryptionZoneIterator.java' size='17' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/protocol/ErasureCodingPolicy.java' size='71' bugHash='fd461e049c71e779611567c4faf41fbf' bugCount='1'></FileStats><FileStats path='org/apache/hadoop/hdfs/protocol/ErasureCodingPolicyInfo.java' size='47' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/protocol/ErasureCodingPolicyState.java' size='31' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/protocol/ExtendedBlock.java' size='64' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/protocol/FsPermissionExtension.java' size='32' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/protocol/HdfsConstants.java' size='106' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/protocol/HdfsFileStatus.java' size='200' bugHash='6732344e26e973476d6580d90a715a7e' bugCount='1'></FileStats><FileStats path='org/apache/hadoop/hdfs/protocol/HdfsLocatedFileStatus.java' size='66' bugHash='5effcf7b36efad0190c033701d73c824' bugCount='3'></FileStats><FileStats path='org/apache/hadoop/hdfs/protocol/HdfsNamedFileStatus.java' size='56' bugHash='6afb4c7b36a23347332d8f454eb6e74f' bugCount='3'></FileStats><FileStats path='org/apache/hadoop/hdfs/protocol/HdfsPathHandle.java' size='58' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/protocol/LastBlockWithStatus.java' size='12' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/protocol/LocatedBlock.java' size='118' bugHash='66b2c7b897fc7d7d68e046eb90f82562' bugCount='7'></FileStats><FileStats path='org/apache/hadoop/hdfs/protocol/LocatedBlocks.java' size='95' bugHash='46a3753ae512d38e3711c4abdd4f766c' bugCount='1'></FileStats><FileStats path='org/apache/hadoop/hdfs/protocol/LocatedStripedBlock.java' size='34' bugHash='9d4a2bd8994f597971aed09686f9c1d4' bugCount='3'></FileStats><FileStats path='org/apache/hadoop/hdfs/protocol/NSQuotaExceededException.java' size='21' bugHash='f5384dc836be7e6c744b0723bed23f0e' bugCount='1'></FileStats><FileStats path='org/apache/hadoop/hdfs/protocol/OpenFileEntry.java' size='20' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/protocol/OpenFilesIterator.java' size='44' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/protocol/ProvidedStorageLocation.java' size='36' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/protocol/QuotaByStorageTypeExceededException.java' size='19' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/protocol/QuotaExceededException.java' size='21' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/protocol/ReconfigurationProtocol.java' size='5' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/protocol/ReencryptionStatus.java' size='122' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/protocol/ReencryptionStatusIterator.java' size='17' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/protocol/ReplicatedBlockStats.java' size='41' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/protocol/RollingUpgradeInfo.java' size='66' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/protocol/RollingUpgradeStatus.java' size='24' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/protocol/SnapshotAccessControlException.java' size='8' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/protocol/SnapshotDiffReport.java' size='118' bugHash='bf909912369826447e9ea86253b5794f' bugCount='5'></FileStats><FileStats path='org/apache/hadoop/hdfs/protocol/SnapshotDiffReportListing.java' size='73' bugHash='269bca5b971aa9b490111dda71a48b0c' bugCount='5'></FileStats><FileStats path='org/apache/hadoop/hdfs/protocol/SnapshottableDirectoryStatus.java' size='123' bugHash='495cee68e5aa5d220cf03a23415c0eb5' bugCount='3'></FileStats><FileStats path='org/apache/hadoop/hdfs/protocol/StripedBlockInfo.java' size='24' bugHash='a18306e74c91bd2fe4c277665f8c7a5f' bugCount='6'></FileStats><FileStats path='org/apache/hadoop/hdfs/protocol/SystemErasureCodingPolicies.java' size='42' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/protocol/TestBlockType.java' size='33' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/protocol/TestErasureCodingPolicy.java' size='57' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/protocol/TestErasureCodingPolicyInfo.java' size='30' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/protocol/TestExtendedBlock.java' size='33' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/protocol/TestHdfsFileStatusMethods.java' size='50' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/protocol/UnresolvedPathException.java' size='27' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/protocol/ZoneReencryptionStatus.java' size='165' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/protocol/datatransfer/BlockConstructionStage.java' size='31' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/protocol/datatransfer/BlockPinningException.java' size='5' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/protocol/datatransfer/DataTransferProtoUtil.java' size='56' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/protocol/datatransfer/DataTransferProtocol.java' size='15' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/protocol/datatransfer/IOStreamPair.java' size='12' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/protocol/datatransfer/InvalidEncryptionKeyException.java' size='8' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/protocol/datatransfer/Op.java' size='45' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/protocol/datatransfer/PacketHeader.java' size='100' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/protocol/datatransfer/PacketReceiver.java' size='133' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/protocol/datatransfer/PipelineAck.java' size='124' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/protocol/datatransfer/ReplaceDatanodeOnFailure.java' size='89' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/protocol/datatransfer/Sender.java' size='143' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/protocol/datatransfer/TrustedChannelResolver.java' size='17' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/protocol/datatransfer/sasl/DataEncryptionKeyFactory.java' size='2' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/protocol/datatransfer/sasl/DataTransferSaslUtil.java' size='185' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/protocol/datatransfer/sasl/SaslDataTransferClient.java' size='149' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/protocol/datatransfer/sasl/SaslParticipant.java' size='47' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/protocol/datatransfer/sasl/SaslResponseWithNegotiatedCipherOption.java' size='8' bugHash='7657d10551d726af828be4697665935b' bugCount='1'></FileStats><FileStats path='org/apache/hadoop/hdfs/protocol/proto/AclProtos.java' size='5927' bugHash='dc4100275dfe4342b86f85da6526535d' bugCount='40'></FileStats><FileStats path='org/apache/hadoop/hdfs/protocol/proto/ClientDatanodeProtocolProtos.java' size='9535' bugHash='b78de038b74d37cc54cb3be7a3135419' bugCount='114'></FileStats><FileStats path='org/apache/hadoop/hdfs/protocol/proto/ClientNamenodeProtocolProtos.java' size='60797' bugHash='cc19507d7bcdf03438e99adbbf6d2634' bugCount='656'></FileStats><FileStats path='org/apache/hadoop/hdfs/protocol/proto/DataTransferProtos.java' size='15417' bugHash='15946a804ac3cc6d0a1710662a0fd405' bugCount='68'></FileStats><FileStats path='org/apache/hadoop/hdfs/protocol/proto/EncryptionZonesProtos.java' size='5165' bugHash='aa0efdb27f6e1b874129e737611e8b7b' bugCount='33'></FileStats><FileStats path='org/apache/hadoop/hdfs/protocol/proto/ErasureCodingProtos.java' size='7273' bugHash='d297b86e608fad2c5a42410eee737052' bugCount='59'></FileStats><FileStats path='org/apache/hadoop/hdfs/protocol/proto/HdfsProtos.java' size='28296' bugHash='d3f7d098f63adef6d2bd7ffaf917294a' bugCount='140'></FileStats><FileStats path='org/apache/hadoop/hdfs/protocol/proto/InotifyProtos.java' size='6209' bugHash='d4616661641e4a3ad011c99bd7766d5e' bugCount='27'></FileStats><FileStats path='org/apache/hadoop/hdfs/protocol/proto/ReconfigurationProtocolProtos.java' size='2599' bugHash='5c648b669f99992bf710424cfd739633' bugCount='27'></FileStats><FileStats path='org/apache/hadoop/hdfs/protocol/proto/XAttrProtos.java' size='3718' bugHash='f82615dc8ae45d0c426e6eadc006156b' bugCount='25'></FileStats><FileStats path='org/apache/hadoop/hdfs/protocolPB/ClientDatanodeProtocolPB.java' size='1' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/protocolPB/ClientDatanodeProtocolTranslatorPB.java' size='199' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/protocolPB/ClientNamenodeProtocolPB.java' size='1' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/protocolPB/ClientNamenodeProtocolTranslatorPB.java' size='1040' bugHash='4751a2cce2b4aa150d9838603a9d40e7' bugCount='3'></FileStats><FileStats path='org/apache/hadoop/hdfs/protocolPB/PBHelperClient.java' size='2136' bugHash='3156dc5107c4519084ce34271245d386' bugCount='11'></FileStats><FileStats path='org/apache/hadoop/hdfs/protocolPB/ReconfigurationProtocolPB.java' size='1' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/protocolPB/ReconfigurationProtocolTranslatorPB.java' size='47' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/protocolPB/ReconfigurationProtocolUtils.java' size='22' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/security/token/block/BlockTokenIdentifier.java' size='193' bugHash='707bd385236eb76f6f553e138285266c' bugCount='4'></FileStats><FileStats path='org/apache/hadoop/hdfs/security/token/block/BlockTokenSelector.java' size='11' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/security/token/block/DataEncryptionKey.java' size='18' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/security/token/block/InvalidBlockTokenException.java' size='8' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/security/token/delegation/DelegationTokenIdentifier.java' size='57' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/security/token/delegation/DelegationTokenSelector.java' size='14' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/server/datanode/BlockMetadataHeader.java' size='58' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/server/datanode/CachingStrategy.java' size='37' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/server/datanode/DiskBalancerWorkItem.java' size='86' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/server/datanode/DiskBalancerWorkStatus.java' size='111' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/server/datanode/ReplicaNotFoundException.java' size='16' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/server/namenode/NotReplicatedYetException.java' size='5' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/server/namenode/RetryStartFileException.java' size='8' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/server/namenode/SafeModeException.java' size='5' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/server/namenode/ha/AbstractNNFailoverProxyProvider.java' size='10' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/server/namenode/ha/ClientHAProxyFactory.java' size='7' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/server/namenode/ha/ConfiguredFailoverProxyProvider.java' size='83' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/server/namenode/ha/HAProxyFactory.java' size='3' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/server/namenode/ha/IPFailoverProxyProvider.java' size='40' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/server/namenode/ha/RequestHedgingProxyProvider.java' size='139' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/server/namenode/ha/TestConfiguredFailoverProxyProvider.java' size='140' bugHash='5495e249697af54e93c78af28a212983' bugCount='2'></FileStats><FileStats path='org/apache/hadoop/hdfs/server/namenode/ha/TestRequestHedgingProxyProvider.java' size='472' bugHash='ec0458bb3cbdb678af57da2288394311' bugCount='16'></FileStats><FileStats path='org/apache/hadoop/hdfs/server/namenode/ha/WrappedFailoverProxyProvider.java' size='18' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/server/protocol/DatanodeStorage.java' size='53' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/server/protocol/DatanodeStorageReport.java' size='12' bugHash='e7d24fc3ba0e75215716bd20c0d98bbf' bugCount='2'></FileStats><FileStats path='org/apache/hadoop/hdfs/server/protocol/SlowDiskReports.java' size='61' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/server/protocol/SlowPeerReports.java' size='27' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/server/protocol/StorageReport.java' size='35' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/shortcircuit/ClientMmap.java' size='22' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/shortcircuit/DfsClientShm.java' size='31' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/shortcircuit/DfsClientShmManager.java' size='207' bugHash='08be9a4ea55bc48ad6974991620ff773' bugCount='5'></FileStats><FileStats path='org/apache/hadoop/hdfs/shortcircuit/DomainSocketFactory.java' size='108' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/shortcircuit/ShortCircuitCache.java' size='505' bugHash='83b6a9ec7a14598b6b9c7b6d1fca876e' bugCount='2'></FileStats><FileStats path='org/apache/hadoop/hdfs/shortcircuit/ShortCircuitReplica.java' size='117' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/shortcircuit/ShortCircuitReplicaInfo.java' size='33' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/shortcircuit/ShortCircuitShm.java' size='268' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/shortcircuit/TestShortCircuitShm.java' size='67' bugHash='3a4991a38bb76102c2a9b9a20c028f06' bugCount='2'></FileStats><FileStats path='org/apache/hadoop/hdfs/util/ByteArrayManager.java' size='200' bugHash='9df554cb640144bf2fa2bd7f1f9d28a3' bugCount='2'></FileStats><FileStats path='org/apache/hadoop/hdfs/util/ByteBufferOutputStream.java' size='12' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/util/CombinedHostsFileReader.java' size='33' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/util/CombinedHostsFileWriter.java' size='10' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/util/ECPolicyLoader.java' size='138' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/util/IOUtilsClient.java' size='21' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/util/LongBitFormat.java' size='27' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/util/StripedBlockUtil.java' size='389' bugHash='bc41eea95052ec51da18a5d756e6809d' bugCount='1'></FileStats><FileStats path='org/apache/hadoop/hdfs/util/TestByteArrayManager.java' size='435' bugHash='c65cc00c2f512e8572b67553fbdf2f54' bugCount='4'></FileStats><FileStats path='org/apache/hadoop/hdfs/util/TestECPolicyLoader.java' size='227' bugHash='a0cc273e8d09d7a36385b72e4f66958b' bugCount='6'></FileStats><FileStats path='org/apache/hadoop/hdfs/web/ByteRangeInputStream.java' size='156' bugHash='67543ff6b5c1953d0732d9022b38c9fb' bugCount='1'></FileStats><FileStats path='org/apache/hadoop/hdfs/web/JsonUtilClient.java' size='473' bugHash='d36438d622d156528ea2fbdcf379bfb4' bugCount='7'></FileStats><FileStats path='org/apache/hadoop/hdfs/web/KerberosUgiAuthenticator.java' size='13' bugHash='93b9d0a4c7d76523476194fc10a0de70' bugCount='1'></FileStats><FileStats path='org/apache/hadoop/hdfs/web/SWebHdfsFileSystem.java' size='11' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/web/TestByteRangeInputStream.java' size='167' bugHash='980318bbcd8fb83d5e8a0fafa4da78e7' bugCount='3'></FileStats><FileStats path='org/apache/hadoop/hdfs/web/TestOffsetUrlInputStream.java' size='21' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/web/TestTokenAspect.java' size='162' bugHash='0d602810d181691c86b0744fe7791b4f' bugCount='4'></FileStats><FileStats path='org/apache/hadoop/hdfs/web/TestURLConnectionFactory.java' size='30' bugHash='cbf2075866949b5949b5adc1525f32a5' bugCount='1'></FileStats><FileStats path='org/apache/hadoop/hdfs/web/TestWebHDFSOAuth2.java' size='85' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/web/TestWebHdfsContentLength.java' size='125' bugHash='5e7561229c5ab546f26813440172fea7' bugCount='10'></FileStats><FileStats path='org/apache/hadoop/hdfs/web/TokenAspect.java' size='80' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/web/URLConnectionFactory.java' size='95' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/web/WebHdfsConstants.java' size='27' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/web/WebHdfsFileSystem.java' size='1382' bugHash='0bc308211b9b4bc0f447c9738f7a09bb' bugCount='3'></FileStats><FileStats path='org/apache/hadoop/hdfs/web/oauth2/AccessTokenProvider.java' size='10' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/web/oauth2/AccessTokenTimer.java' size='28' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/web/oauth2/ConfCredentialBasedAccessTokenProvider.java' size='16' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/web/oauth2/ConfRefreshTokenBasedAccessTokenProvider.java' size='56' bugHash='4fc28e29ebf76f4297dd743436e9ce10' bugCount='1'></FileStats><FileStats path='org/apache/hadoop/hdfs/web/oauth2/CredentialBasedAccessTokenProvider.java' size='53' bugHash='4b843f9ba9303a5f42195d6c91802efb' bugCount='1'></FileStats><FileStats path='org/apache/hadoop/hdfs/web/oauth2/OAuth2ConnectionConfigurator.java' size='23' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/web/oauth2/OAuth2Constants.java' size='16' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/web/oauth2/TestAccessTokenTimer.java' size='23' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/web/oauth2/TestClientCredentialTimeBasedTokenRefresher.java' size='52' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/web/oauth2/TestRefreshTokenTimeBasedTokenRefresher.java' size='50' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/web/oauth2/Utils.java' size='20' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/web/oauth2/package-info.java' size='1' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/web/resources/AccessTimeParam.java' size='17' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/web/resources/AclPermissionParam.java' size='45' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/web/resources/BlockSizeParam.java' size='20' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/web/resources/BooleanParam.java' size='22' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/web/resources/BufferSizeParam.java' size='20' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/web/resources/ConcatSourcesParam.java' size='25' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/web/resources/CreateFlagParam.java' size='17' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/web/resources/CreateParentParam.java' size='16' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/web/resources/DelegationParam.java' size='13' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/web/resources/DeleteOpParam.java' size='42' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/web/resources/DestinationParam.java' size='19' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/web/resources/DoAsParam.java' size='13' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/web/resources/EnumParam.java' size='16' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/web/resources/EnumSetParam.java' size='41' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/web/resources/ExcludeDatanodesParam.java' size='13' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/web/resources/FsActionParam.java' size='19' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/web/resources/GetOpParam.java' size='83' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/web/resources/GroupParam.java' size='13' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/web/resources/HttpOpParam.java' size='63' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/web/resources/IntegerParam.java' size='38' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/web/resources/LengthParam.java' size='20' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/web/resources/LongParam.java' size='38' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/web/resources/ModificationTimeParam.java' size='17' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/web/resources/NewLengthParam.java' size='17' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/web/resources/NoRedirectParam.java' size='16' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/web/resources/OffsetParam.java' size='20' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/web/resources/OldSnapshotNameParam.java' size='13' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/web/resources/OverwriteParam.java' size='16' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/web/resources/OwnerParam.java' size='13' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/web/resources/Param.java' size='52' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/web/resources/PermissionParam.java' size='35' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/web/resources/PostOpParam.java' size='48' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/web/resources/PutOpParam.java' size='89' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/web/resources/RecursiveParam.java' size='16' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/web/resources/RenameOptionSetParam.java' size='17' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/web/resources/RenewerParam.java' size='13' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/web/resources/ReplicationParam.java' size='19' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/web/resources/ShortParam.java' size='38' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/web/resources/SnapshotNameParam.java' size='13' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/web/resources/StartAfterParam.java' size='13' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/web/resources/StoragePolicyParam.java' size='13' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/web/resources/StringParam.java' size='22' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/web/resources/TokenArgumentParam.java' size='13' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/web/resources/UnmaskedPermissionParam.java' size='13' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/web/resources/UserParam.java' size='34' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/web/resources/XAttrEncodingParam.java' size='18' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/web/resources/XAttrNameParam.java' size='15' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/web/resources/XAttrSetFlagParam.java' size='19' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/hdfs/web/resources/XAttrValueParam.java' size='16' bugCount='0'></FileStats><PackageStats package='org.apache.hadoop.fs' total_bugs='5' priority_2='4' priority_3='1' total_size='465' total_types='15'><ClassStats bugs='0' size='15' interface='false' sourceFile='CacheFlag.java' class='org.apache.hadoop.fs.CacheFlag'></ClassStats><ClassStats bugs='0' size='177' interface='false' sourceFile='Hdfs.java' class='org.apache.hadoop.fs.Hdfs'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='Hdfs.java' class='org.apache.hadoop.fs.Hdfs$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='Hdfs.java' class='org.apache.hadoop.fs.Hdfs$2'></ClassStats><ClassStats bugs='0' size='30' interface='false' sourceFile='Hdfs.java' class='org.apache.hadoop.fs.Hdfs$DirListingIterator'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='HdfsBlockLocation.java' class='org.apache.hadoop.fs.HdfsBlockLocation'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='SWebHdfs.java' class='org.apache.hadoop.fs.SWebHdfs'></ClassStats><ClassStats bugs='3' size='36' priority_2='2' priority_3='1' interface='false' sourceFile='TestUrlStreamHandlerFactory.java' class='org.apache.hadoop.fs.TestUrlStreamHandlerFactory'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='TestUrlStreamHandlerFactory.java' class='org.apache.hadoop.fs.TestUrlStreamHandlerFactory$1'></ClassStats><ClassStats bugs='0' size='64' interface='false' sourceFile='TestXAttr.java' class='org.apache.hadoop.fs.TestXAttr'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='WebHdfs.java' class='org.apache.hadoop.fs.WebHdfs'></ClassStats><ClassStats bugs='1' size='48' priority_2='1' interface='false' sourceFile='XAttr.java' class='org.apache.hadoop.fs.XAttr'></ClassStats><ClassStats bugs='0' size='1' interface='false' sourceFile='XAttr.java' class='org.apache.hadoop.fs.XAttr$1'></ClassStats><ClassStats bugs='1' size='18' priority_2='1' interface='false' sourceFile='XAttr.java' class='org.apache.hadoop.fs.XAttr$Builder'></ClassStats><ClassStats bugs='0' size='17' interface='false' sourceFile='XAttr.java' class='org.apache.hadoop.fs.XAttr$NameSpace'></ClassStats></PackageStats><PackageStats package='org.apache.hadoop.hdfs' total_bugs='46' priority_2='5' priority_3='41' total_size='9706' total_types='156'><ClassStats bugs='0' size='20' interface='false' sourceFile='AddBlockFlag.java' class='org.apache.hadoop.hdfs.AddBlockFlag'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='BlockMissingException.java' class='org.apache.hadoop.hdfs.BlockMissingException'></ClassStats><ClassStats bugs='0' size='11' interface='true' sourceFile='BlockReader.java' class='org.apache.hadoop.hdfs.BlockReader'></ClassStats><ClassStats bugs='0' size='34' interface='false' sourceFile='ReaderStrategy.java' class='org.apache.hadoop.hdfs.ByteArrayStrategy'></ClassStats><ClassStats bugs='0' size='36' interface='false' sourceFile='ReaderStrategy.java' class='org.apache.hadoop.hdfs.ByteBufferStrategy'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='CannotObtainBlockLengthException.java' class='org.apache.hadoop.hdfs.CannotObtainBlockLengthException'></ClassStats><ClassStats bugs='0' size='97' interface='false' sourceFile='ClientContext.java' class='org.apache.hadoop.hdfs.ClientContext'></ClassStats><ClassStats bugs='4' size='1238' priority_3='4' interface='false' sourceFile='DFSClient.java' class='org.apache.hadoop.hdfs.DFSClient'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='DFSClient.java' class='org.apache.hadoop.hdfs.DFSClient$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='DFSClient.java' class='org.apache.hadoop.hdfs.DFSClient$2'></ClassStats><ClassStats bugs='0' size='4' interface='false' sourceFile='DFSClient.java' class='org.apache.hadoop.hdfs.DFSClient$DFSDataInputStream'></ClassStats><ClassStats bugs='0' size='39' interface='false' sourceFile='DFSClient.java' class='org.apache.hadoop.hdfs.DFSClient$Renewer'></ClassStats><ClassStats bugs='2' size='31' priority_3='2' interface='false' sourceFile='DFSClientFaultInjector.java' class='org.apache.hadoop.hdfs.DFSClientFaultInjector'></ClassStats><ClassStats bugs='0' size='24' interface='false' sourceFile='DFSHedgedReadMetrics.java' class='org.apache.hadoop.hdfs.DFSHedgedReadMetrics'></ClassStats><ClassStats bugs='0' size='83' interface='false' sourceFile='DFSInotifyEventInputStream.java' class='org.apache.hadoop.hdfs.DFSInotifyEventInputStream'></ClassStats><ClassStats bugs='3' size='868' priority_2='2' priority_3='1' interface='false' sourceFile='DFSInputStream.java' class='org.apache.hadoop.hdfs.DFSInputStream'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='DFSInputStream.java' class='org.apache.hadoop.hdfs.DFSInputStream$1'></ClassStats><ClassStats bugs='0' size='14' interface='false' sourceFile='DFSInputStream.java' class='org.apache.hadoop.hdfs.DFSInputStream$2'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='DFSInputStream.java' class='org.apache.hadoop.hdfs.DFSInputStream$DNAddrPair'></ClassStats><ClassStats bugs='0' size='28' interface='false' sourceFile='DFSOpsCountStatistics.java' class='org.apache.hadoop.hdfs.DFSOpsCountStatistics'></ClassStats><ClassStats bugs='0' size='1' interface='false' sourceFile='DFSOpsCountStatistics.java' class='org.apache.hadoop.hdfs.DFSOpsCountStatistics$1'></ClassStats><ClassStats bugs='0' size='19' interface='false' sourceFile='DFSOpsCountStatistics.java' class='org.apache.hadoop.hdfs.DFSOpsCountStatistics$LongIterator'></ClassStats><ClassStats bugs='0' size='121' interface='false' sourceFile='DFSOpsCountStatistics.java' class='org.apache.hadoop.hdfs.DFSOpsCountStatistics$OpType'></ClassStats><ClassStats bugs='2' size='542' priority_3='2' interface='false' sourceFile='DFSOutputStream.java' class='org.apache.hadoop.hdfs.DFSOutputStream'></ClassStats><ClassStats bugs='2' size='149' priority_2='2' interface='false' sourceFile='DFSPacket.java' class='org.apache.hadoop.hdfs.DFSPacket'></ClassStats><ClassStats bugs='2' size='256' priority_3='2' interface='false' sourceFile='DFSStripedInputStream.java' class='org.apache.hadoop.hdfs.DFSStripedInputStream'></ClassStats><ClassStats bugs='8' size='602' priority_3='8' interface='false' sourceFile='DFSStripedOutputStream.java' class='org.apache.hadoop.hdfs.DFSStripedOutputStream'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='DFSStripedOutputStream.java' class='org.apache.hadoop.hdfs.DFSStripedOutputStream$1'></ClassStats><ClassStats bugs='0' size='49' interface='false' sourceFile='DFSStripedOutputStream.java' class='org.apache.hadoop.hdfs.DFSStripedOutputStream$CellBuffers'></ClassStats><ClassStats bugs='0' size='40' interface='false' sourceFile='DFSStripedOutputStream.java' class='org.apache.hadoop.hdfs.DFSStripedOutputStream$Coordinator'></ClassStats><ClassStats bugs='0' size='29' interface='false' sourceFile='DFSStripedOutputStream.java' class='org.apache.hadoop.hdfs.DFSStripedOutputStream$MultipleBlockingQueue'></ClassStats><ClassStats bugs='0' size='340' interface='false' sourceFile='DFSUtilClient.java' class='org.apache.hadoop.hdfs.DFSUtilClient'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='DFSUtilClient.java' class='org.apache.hadoop.hdfs.DFSUtilClient$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='DFSUtilClient.java' class='org.apache.hadoop.hdfs.DFSUtilClient$2'></ClassStats><ClassStats bugs='0' size='16' interface='false' sourceFile='DFSUtilClient.java' class='org.apache.hadoop.hdfs.DFSUtilClient$CorruptedBlocks'></ClassStats><ClassStats bugs='5' size='843' priority_3='5' interface='false' sourceFile='DataStreamer.java' class='org.apache.hadoop.hdfs.DataStreamer'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='DataStreamer.java' class='org.apache.hadoop.hdfs.DataStreamer$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='DataStreamer.java' class='org.apache.hadoop.hdfs.DataStreamer$2'></ClassStats><ClassStats bugs='0' size='26' interface='false' sourceFile='DataStreamer.java' class='org.apache.hadoop.hdfs.DataStreamer$BlockToWrite'></ClassStats><ClassStats bugs='0' size='99' interface='false' sourceFile='DataStreamer.java' class='org.apache.hadoop.hdfs.DataStreamer$ErrorState'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='DataStreamer.java' class='org.apache.hadoop.hdfs.DataStreamer$ErrorType'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='DataStreamer.java' class='org.apache.hadoop.hdfs.DataStreamer$LastExceptionInStreamer'></ClassStats><ClassStats bugs='0' size='20' interface='false' sourceFile='DataStreamer.java' class='org.apache.hadoop.hdfs.DataStreamer$RefetchEncryptionKeyPolicy'></ClassStats><ClassStats bugs='2' size='100' priority_2='1' priority_3='1' interface='false' sourceFile='DataStreamer.java' class='org.apache.hadoop.hdfs.DataStreamer$ResponseProcessor'></ClassStats><ClassStats bugs='0' size='35' interface='false' sourceFile='DataStreamer.java' class='org.apache.hadoop.hdfs.DataStreamer$StreamerStreams'></ClassStats><ClassStats bugs='3' size='848' priority_3='3' interface='false' sourceFile='DistributedFileSystem.java' class='org.apache.hadoop.hdfs.DistributedFileSystem'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='DistributedFileSystem.java' class='org.apache.hadoop.hdfs.DistributedFileSystem$1'></ClassStats><ClassStats bugs='0' size='24' interface='false' sourceFile='DistributedFileSystem.java' class='org.apache.hadoop.hdfs.DistributedFileSystem$10'></ClassStats><ClassStats bugs='0' size='17' interface='false' sourceFile='DistributedFileSystem.java' class='org.apache.hadoop.hdfs.DistributedFileSystem$11'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='DistributedFileSystem.java' class='org.apache.hadoop.hdfs.DistributedFileSystem$12'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='DistributedFileSystem.java' class='org.apache.hadoop.hdfs.DistributedFileSystem$13'></ClassStats><ClassStats bugs='0' size='15' interface='false' sourceFile='DistributedFileSystem.java' class='org.apache.hadoop.hdfs.DistributedFileSystem$14'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='DistributedFileSystem.java' class='org.apache.hadoop.hdfs.DistributedFileSystem$15'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='DistributedFileSystem.java' class='org.apache.hadoop.hdfs.DistributedFileSystem$16'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='DistributedFileSystem.java' class='org.apache.hadoop.hdfs.DistributedFileSystem$17'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='DistributedFileSystem.java' class='org.apache.hadoop.hdfs.DistributedFileSystem$18'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='DistributedFileSystem.java' class='org.apache.hadoop.hdfs.DistributedFileSystem$19'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='DistributedFileSystem.java' class='org.apache.hadoop.hdfs.DistributedFileSystem$2'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='DistributedFileSystem.java' class='org.apache.hadoop.hdfs.DistributedFileSystem$20'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='DistributedFileSystem.java' class='org.apache.hadoop.hdfs.DistributedFileSystem$21'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='DistributedFileSystem.java' class='org.apache.hadoop.hdfs.DistributedFileSystem$22'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='DistributedFileSystem.java' class='org.apache.hadoop.hdfs.DistributedFileSystem$23'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='DistributedFileSystem.java' class='org.apache.hadoop.hdfs.DistributedFileSystem$24'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='DistributedFileSystem.java' class='org.apache.hadoop.hdfs.DistributedFileSystem$25'></ClassStats><ClassStats bugs='1' size='10' priority_3='1' interface='false' sourceFile='DistributedFileSystem.java' class='org.apache.hadoop.hdfs.DistributedFileSystem$26'></ClassStats><ClassStats bugs='0' size='14' interface='false' sourceFile='DistributedFileSystem.java' class='org.apache.hadoop.hdfs.DistributedFileSystem$27'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='DistributedFileSystem.java' class='org.apache.hadoop.hdfs.DistributedFileSystem$28'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='DistributedFileSystem.java' class='org.apache.hadoop.hdfs.DistributedFileSystem$29'></ClassStats><ClassStats bugs='0' size='14' interface='false' sourceFile='DistributedFileSystem.java' class='org.apache.hadoop.hdfs.DistributedFileSystem$3'></ClassStats><ClassStats bugs='0' size='14' interface='false' sourceFile='DistributedFileSystem.java' class='org.apache.hadoop.hdfs.DistributedFileSystem$30'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='DistributedFileSystem.java' class='org.apache.hadoop.hdfs.DistributedFileSystem$31'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='DistributedFileSystem.java' class='org.apache.hadoop.hdfs.DistributedFileSystem$32'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='DistributedFileSystem.java' class='org.apache.hadoop.hdfs.DistributedFileSystem$33'></ClassStats><ClassStats bugs='0' size='14' interface='false' sourceFile='DistributedFileSystem.java' class='org.apache.hadoop.hdfs.DistributedFileSystem$34'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='DistributedFileSystem.java' class='org.apache.hadoop.hdfs.DistributedFileSystem$35'></ClassStats><ClassStats bugs='0' size='14' interface='false' sourceFile='DistributedFileSystem.java' class='org.apache.hadoop.hdfs.DistributedFileSystem$36'></ClassStats><ClassStats bugs='0' size='14' interface='false' sourceFile='DistributedFileSystem.java' class='org.apache.hadoop.hdfs.DistributedFileSystem$37'></ClassStats><ClassStats bugs='0' size='17' interface='false' sourceFile='DistributedFileSystem.java' class='org.apache.hadoop.hdfs.DistributedFileSystem$38'></ClassStats><ClassStats bugs='0' size='17' interface='false' sourceFile='DistributedFileSystem.java' class='org.apache.hadoop.hdfs.DistributedFileSystem$39'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='DistributedFileSystem.java' class='org.apache.hadoop.hdfs.DistributedFileSystem$4'></ClassStats><ClassStats bugs='0' size='15' interface='false' sourceFile='DistributedFileSystem.java' class='org.apache.hadoop.hdfs.DistributedFileSystem$40'></ClassStats><ClassStats bugs='0' size='19' interface='false' sourceFile='DistributedFileSystem.java' class='org.apache.hadoop.hdfs.DistributedFileSystem$41'></ClassStats><ClassStats bugs='0' size='18' interface='false' sourceFile='DistributedFileSystem.java' class='org.apache.hadoop.hdfs.DistributedFileSystem$42'></ClassStats><ClassStats bugs='1' size='15' priority_3='1' interface='false' sourceFile='DistributedFileSystem.java' class='org.apache.hadoop.hdfs.DistributedFileSystem$43'></ClassStats><ClassStats bugs='0' size='18' interface='false' sourceFile='DistributedFileSystem.java' class='org.apache.hadoop.hdfs.DistributedFileSystem$44'></ClassStats><ClassStats bugs='0' size='14' interface='false' sourceFile='DistributedFileSystem.java' class='org.apache.hadoop.hdfs.DistributedFileSystem$45'></ClassStats><ClassStats bugs='0' size='15' interface='false' sourceFile='DistributedFileSystem.java' class='org.apache.hadoop.hdfs.DistributedFileSystem$46'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='DistributedFileSystem.java' class='org.apache.hadoop.hdfs.DistributedFileSystem$47'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='DistributedFileSystem.java' class='org.apache.hadoop.hdfs.DistributedFileSystem$48'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='DistributedFileSystem.java' class='org.apache.hadoop.hdfs.DistributedFileSystem$49'></ClassStats><ClassStats bugs='0' size='14' interface='false' sourceFile='DistributedFileSystem.java' class='org.apache.hadoop.hdfs.DistributedFileSystem$5'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='DistributedFileSystem.java' class='org.apache.hadoop.hdfs.DistributedFileSystem$50'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='DistributedFileSystem.java' class='org.apache.hadoop.hdfs.DistributedFileSystem$51'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='DistributedFileSystem.java' class='org.apache.hadoop.hdfs.DistributedFileSystem$52'></ClassStats><ClassStats bugs='0' size='17' interface='false' sourceFile='DistributedFileSystem.java' class='org.apache.hadoop.hdfs.DistributedFileSystem$53'></ClassStats><ClassStats bugs='0' size='14' interface='false' sourceFile='DistributedFileSystem.java' class='org.apache.hadoop.hdfs.DistributedFileSystem$54'></ClassStats><ClassStats bugs='0' size='17' interface='false' sourceFile='DistributedFileSystem.java' class='org.apache.hadoop.hdfs.DistributedFileSystem$55'></ClassStats><ClassStats bugs='0' size='17' interface='false' sourceFile='DistributedFileSystem.java' class='org.apache.hadoop.hdfs.DistributedFileSystem$56'></ClassStats><ClassStats bugs='0' size='16' interface='false' sourceFile='DistributedFileSystem.java' class='org.apache.hadoop.hdfs.DistributedFileSystem$57'></ClassStats><ClassStats bugs='0' size='15' interface='false' sourceFile='DistributedFileSystem.java' class='org.apache.hadoop.hdfs.DistributedFileSystem$58'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='DistributedFileSystem.java' class='org.apache.hadoop.hdfs.DistributedFileSystem$59'></ClassStats><ClassStats bugs='0' size='15' interface='false' sourceFile='DistributedFileSystem.java' class='org.apache.hadoop.hdfs.DistributedFileSystem$6'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='DistributedFileSystem.java' class='org.apache.hadoop.hdfs.DistributedFileSystem$60'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='DistributedFileSystem.java' class='org.apache.hadoop.hdfs.DistributedFileSystem$61'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='DistributedFileSystem.java' class='org.apache.hadoop.hdfs.DistributedFileSystem$62'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='DistributedFileSystem.java' class='org.apache.hadoop.hdfs.DistributedFileSystem$63'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='DistributedFileSystem.java' class='org.apache.hadoop.hdfs.DistributedFileSystem$64'></ClassStats><ClassStats bugs='0' size='17' interface='false' sourceFile='DistributedFileSystem.java' class='org.apache.hadoop.hdfs.DistributedFileSystem$65'></ClassStats><ClassStats bugs='0' size='14' interface='false' sourceFile='DistributedFileSystem.java' class='org.apache.hadoop.hdfs.DistributedFileSystem$66'></ClassStats><ClassStats bugs='0' size='16' interface='false' sourceFile='DistributedFileSystem.java' class='org.apache.hadoop.hdfs.DistributedFileSystem$67'></ClassStats><ClassStats bugs='0' size='24' interface='false' sourceFile='DistributedFileSystem.java' class='org.apache.hadoop.hdfs.DistributedFileSystem$7'></ClassStats><ClassStats bugs='0' size='18' interface='false' sourceFile='DistributedFileSystem.java' class='org.apache.hadoop.hdfs.DistributedFileSystem$8'></ClassStats><ClassStats bugs='0' size='24' interface='false' sourceFile='DistributedFileSystem.java' class='org.apache.hadoop.hdfs.DistributedFileSystem$9'></ClassStats><ClassStats bugs='0' size='58' interface='false' sourceFile='DistributedFileSystem.java' class='org.apache.hadoop.hdfs.DistributedFileSystem$DirListingIterator'></ClassStats><ClassStats bugs='0' size='61' interface='false' sourceFile='DistributedFileSystem.java' class='org.apache.hadoop.hdfs.DistributedFileSystem$HdfsDataOutputStreamBuilder'></ClassStats><ClassStats bugs='0' size='32' interface='false' sourceFile='DistributedFileSystem.java' class='org.apache.hadoop.hdfs.DistributedFileSystem$SnapshotDiffReportListingIterator'></ClassStats><ClassStats bugs='0' size='26' interface='false' sourceFile='ExceptionLastSeen.java' class='org.apache.hadoop.hdfs.ExceptionLastSeen'></ClassStats><ClassStats bugs='0' size='29' interface='false' sourceFile='ExtendedBlockId.java' class='org.apache.hadoop.hdfs.ExtendedBlockId'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='FileChecksumHelper.java' class='org.apache.hadoop.hdfs.FileChecksumHelper'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='FileChecksumHelper.java' class='org.apache.hadoop.hdfs.FileChecksumHelper$1'></ClassStats><ClassStats bugs='1' size='216' priority_3='1' interface='false' sourceFile='FileChecksumHelper.java' class='org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer'></ClassStats><ClassStats bugs='0' size='70' interface='false' sourceFile='FileChecksumHelper.java' class='org.apache.hadoop.hdfs.FileChecksumHelper$ReplicatedFileChecksumComputer'></ClassStats><ClassStats bugs='1' size='65' priority_3='1' interface='false' sourceFile='FileChecksumHelper.java' class='org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer'></ClassStats><ClassStats bugs='0' size='46' interface='false' sourceFile='HAUtilClient.java' class='org.apache.hadoop.hdfs.HAUtilClient'></ClassStats><ClassStats bugs='0' size='24' interface='false' sourceFile='HdfsConfiguration.java' class='org.apache.hadoop.hdfs.HdfsConfiguration'></ClassStats><ClassStats bugs='0' size='82' interface='false' sourceFile='HdfsKMSUtil.java' class='org.apache.hadoop.hdfs.HdfsKMSUtil'></ClassStats><ClassStats bugs='2' size='38' priority_3='2' interface='false' sourceFile='KeyProviderCache.java' class='org.apache.hadoop.hdfs.KeyProviderCache'></ClassStats><ClassStats bugs='0' size='14' interface='false' sourceFile='KeyProviderCache.java' class='org.apache.hadoop.hdfs.KeyProviderCache$1'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='KeyProviderCache.java' class='org.apache.hadoop.hdfs.KeyProviderCache$2'></ClassStats><ClassStats bugs='2' size='107' priority_3='2' interface='false' sourceFile='NameNodeProxiesClient.java' class='org.apache.hadoop.hdfs.NameNodeProxiesClient'></ClassStats><ClassStats bugs='0' size='16' interface='false' sourceFile='NameNodeProxiesClient.java' class='org.apache.hadoop.hdfs.NameNodeProxiesClient$ProxyAndInfo'></ClassStats><ClassStats bugs='0' size='116' interface='false' sourceFile='PeerCache.java' class='org.apache.hadoop.hdfs.PeerCache'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='PeerCache.java' class='org.apache.hadoop.hdfs.PeerCache$1'></ClassStats><ClassStats bugs='0' size='15' interface='false' sourceFile='PeerCache.java' class='org.apache.hadoop.hdfs.PeerCache$Key'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='PeerCache.java' class='org.apache.hadoop.hdfs.PeerCache$Value'></ClassStats><ClassStats bugs='1' size='42' priority_3='1' interface='false' sourceFile='PositionStripeReader.java' class='org.apache.hadoop.hdfs.PositionStripeReader'></ClassStats><ClassStats bugs='0' size='50' interface='false' sourceFile='ReadStatistics.java' class='org.apache.hadoop.hdfs.ReadStatistics'></ClassStats><ClassStats bugs='0' size='7' interface='true' sourceFile='ReaderStrategy.java' class='org.apache.hadoop.hdfs.ReaderStrategy'></ClassStats><ClassStats bugs='0' size='2' interface='true' sourceFile='RemotePeerFactory.java' class='org.apache.hadoop.hdfs.RemotePeerFactory'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='ReplicaAccessor.java' class='org.apache.hadoop.hdfs.ReplicaAccessor'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='ReplicaAccessorBuilder.java' class='org.apache.hadoop.hdfs.ReplicaAccessorBuilder'></ClassStats><ClassStats bugs='0' size='39' interface='false' sourceFile='StatefulStripeReader.java' class='org.apache.hadoop.hdfs.StatefulStripeReader'></ClassStats><ClassStats bugs='1' size='210' priority_3='1' interface='false' sourceFile='StripeReader.java' class='org.apache.hadoop.hdfs.StripeReader'></ClassStats><ClassStats bugs='0' size='18' interface='false' sourceFile='StripeReader.java' class='org.apache.hadoop.hdfs.StripeReader$BlockReaderInfo'></ClassStats><ClassStats bugs='0' size='17' interface='false' sourceFile='StripeReader.java' class='org.apache.hadoop.hdfs.StripeReader$ReaderRetryPolicy'></ClassStats><ClassStats bugs='1' size='81' priority_3='1' interface='false' sourceFile='StripedDataStreamer.java' class='org.apache.hadoop.hdfs.StripedDataStreamer'></ClassStats><ClassStats bugs='1' size='103' priority_3='1' interface='false' sourceFile='TestDFSOpsCountStatistics.java' class='org.apache.hadoop.hdfs.TestDFSOpsCountStatistics'></ClassStats><ClassStats bugs='0' size='18' interface='false' sourceFile='TestDFSOpsCountStatistics.java' class='org.apache.hadoop.hdfs.TestDFSOpsCountStatistics$1'></ClassStats><ClassStats bugs='0' size='51' interface='false' sourceFile='TestDFSPacket.java' class='org.apache.hadoop.hdfs.TestDFSPacket'></ClassStats><ClassStats bugs='0' size='24' interface='false' sourceFile='TestDefaultNameNodePort.java' class='org.apache.hadoop.hdfs.TestDefaultNameNodePort'></ClassStats><ClassStats bugs='0' size='99' interface='false' sourceFile='TestPeerCache.java' class='org.apache.hadoop.hdfs.TestPeerCache'></ClassStats><ClassStats bugs='1' size='49' priority_3='1' interface='false' sourceFile='TestPeerCache.java' class='org.apache.hadoop.hdfs.TestPeerCache$FakePeer'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='TestPeerCache.java' class='org.apache.hadoop.hdfs.TestPeerCache$FakePeer$1'></ClassStats><ClassStats bugs='0' size='4' interface='false' sourceFile='UnknownCipherSuiteException.java' class='org.apache.hadoop.hdfs.UnknownCipherSuiteException'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='UnknownCryptoProtocolVersionException.java' class='org.apache.hadoop.hdfs.UnknownCryptoProtocolVersionException'></ClassStats><ClassStats bugs='0' size='73' interface='false' sourceFile='XAttrHelper.java' class='org.apache.hadoop.hdfs.XAttrHelper'></ClassStats></PackageStats><PackageStats package='org.apache.hadoop.hdfs.client' total_bugs='0' total_size='518' total_types='25'><ClassStats bugs='0' size='12' interface='false' sourceFile='BlockReportOptions.java' class='org.apache.hadoop.hdfs.client.BlockReportOptions'></ClassStats><ClassStats bugs='0' size='1' interface='false' sourceFile='BlockReportOptions.java' class='org.apache.hadoop.hdfs.client.BlockReportOptions$1'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='BlockReportOptions.java' class='org.apache.hadoop.hdfs.client.BlockReportOptions$Factory'></ClassStats><ClassStats bugs='0' size='22' interface='false' sourceFile='CreateEncryptionZoneFlag.java' class='org.apache.hadoop.hdfs.client.CreateEncryptionZoneFlag'></ClassStats><ClassStats bugs='0' size='122' interface='false' sourceFile='HdfsAdmin.java' class='org.apache.hadoop.hdfs.client.HdfsAdmin'></ClassStats><ClassStats bugs='0' size='105' interface='true' sourceFile='HdfsClientConfigKeys.java' class='org.apache.hadoop.hdfs.client.HdfsClientConfigKeys'></ClassStats><ClassStats bugs='0' size='8' interface='true' sourceFile='HdfsClientConfigKeys.java' class='org.apache.hadoop.hdfs.client.HdfsClientConfigKeys$BlockWrite'></ClassStats><ClassStats bugs='0' size='10' interface='true' sourceFile='HdfsClientConfigKeys.java' class='org.apache.hadoop.hdfs.client.HdfsClientConfigKeys$BlockWrite$ReplaceDatanodeOnFailure'></ClassStats><ClassStats bugs='0' size='31' interface='true' sourceFile='HdfsClientConfigKeys.java' class='org.apache.hadoop.hdfs.client.HdfsClientConfigKeys$DeprecatedKeys'></ClassStats><ClassStats bugs='0' size='15' interface='true' sourceFile='HdfsClientConfigKeys.java' class='org.apache.hadoop.hdfs.client.HdfsClientConfigKeys$Failover'></ClassStats><ClassStats bugs='0' size='6' interface='true' sourceFile='HdfsClientConfigKeys.java' class='org.apache.hadoop.hdfs.client.HdfsClientConfigKeys$HedgedRead'></ClassStats><ClassStats bugs='0' size='14' interface='true' sourceFile='HdfsClientConfigKeys.java' class='org.apache.hadoop.hdfs.client.HdfsClientConfigKeys$HttpClient'></ClassStats><ClassStats bugs='0' size='10' interface='true' sourceFile='HdfsClientConfigKeys.java' class='org.apache.hadoop.hdfs.client.HdfsClientConfigKeys$Mmap'></ClassStats><ClassStats bugs='0' size='3' interface='true' sourceFile='HdfsClientConfigKeys.java' class='org.apache.hadoop.hdfs.client.HdfsClientConfigKeys$Read'></ClassStats><ClassStats bugs='0' size='16' interface='true' sourceFile='HdfsClientConfigKeys.java' class='org.apache.hadoop.hdfs.client.HdfsClientConfigKeys$Read$ShortCircuit'></ClassStats><ClassStats bugs='0' size='14' interface='true' sourceFile='HdfsClientConfigKeys.java' class='org.apache.hadoop.hdfs.client.HdfsClientConfigKeys$Retry'></ClassStats><ClassStats bugs='0' size='4' interface='true' sourceFile='HdfsClientConfigKeys.java' class='org.apache.hadoop.hdfs.client.HdfsClientConfigKeys$ShortCircuit'></ClassStats><ClassStats bugs='0' size='4' interface='true' sourceFile='HdfsClientConfigKeys.java' class='org.apache.hadoop.hdfs.client.HdfsClientConfigKeys$StripedRead'></ClassStats><ClassStats bugs='0' size='6' interface='true' sourceFile='HdfsClientConfigKeys.java' class='org.apache.hadoop.hdfs.client.HdfsClientConfigKeys$Write'></ClassStats><ClassStats bugs='0' size='10' interface='true' sourceFile='HdfsClientConfigKeys.java' class='org.apache.hadoop.hdfs.client.HdfsClientConfigKeys$Write$ByteArrayManager'></ClassStats><ClassStats bugs='0' size='27' interface='false' sourceFile='HdfsDataInputStream.java' class='org.apache.hadoop.hdfs.client.HdfsDataInputStream'></ClassStats><ClassStats bugs='0' size='27' interface='false' sourceFile='HdfsDataOutputStream.java' class='org.apache.hadoop.hdfs.client.HdfsDataOutputStream'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='HdfsDataOutputStream.java' class='org.apache.hadoop.hdfs.client.HdfsDataOutputStream$SyncFlag'></ClassStats><ClassStats bugs='0' size='28' interface='false' sourceFile='HdfsUtils.java' class='org.apache.hadoop.hdfs.client.HdfsUtils'></ClassStats><ClassStats bugs='0' size='1' interface='true' sourceFile='package-info.java' class='org.apache.hadoop.hdfs.client.package-info'></ClassStats></PackageStats><PackageStats package='org.apache.hadoop.hdfs.client.impl' total_bugs='13' priority_2='6' priority_3='7' total_size='2234' total_types='29'><ClassStats bugs='0' size='376' interface='false' sourceFile='BlockReaderFactory.java' class='org.apache.hadoop.hdfs.client.impl.BlockReaderFactory'></ClassStats><ClassStats bugs='0' size='4' interface='false' sourceFile='BlockReaderFactory.java' class='org.apache.hadoop.hdfs.client.impl.BlockReaderFactory$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='BlockReaderFactory.java' class='org.apache.hadoop.hdfs.client.impl.BlockReaderFactory$BlockReaderPeer'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='BlockReaderFactory.java' class='org.apache.hadoop.hdfs.client.impl.BlockReaderFactory$FailureInjector'></ClassStats><ClassStats bugs='1' size='310' priority_3='1' interface='false' sourceFile='BlockReaderLocal.java' class='org.apache.hadoop.hdfs.client.impl.BlockReaderLocal'></ClassStats><ClassStats bugs='0' size='1' interface='false' sourceFile='BlockReaderLocal.java' class='org.apache.hadoop.hdfs.client.impl.BlockReaderLocal$1'></ClassStats><ClassStats bugs='0' size='53' interface='false' sourceFile='BlockReaderLocal.java' class='org.apache.hadoop.hdfs.client.impl.BlockReaderLocal$Builder'></ClassStats><ClassStats bugs='0' size='284' interface='false' sourceFile='BlockReaderLocalLegacy.java' class='org.apache.hadoop.hdfs.client.impl.BlockReaderLocalLegacy'></ClassStats><ClassStats bugs='3' size='38' priority_3='3' interface='false' sourceFile='BlockReaderLocalLegacy.java' class='org.apache.hadoop.hdfs.client.impl.BlockReaderLocalLegacy$LocalDatanodeInfo'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='BlockReaderLocalLegacy.java' class='org.apache.hadoop.hdfs.client.impl.BlockReaderLocalLegacy$LocalDatanodeInfo$1'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='BlockReaderLocalLegacy.java' class='org.apache.hadoop.hdfs.client.impl.BlockReaderLocalLegacy$LocalDatanodeInfo$2'></ClassStats><ClassStats bugs='0' size='191' interface='false' sourceFile='BlockReaderRemote.java' class='org.apache.hadoop.hdfs.client.impl.BlockReaderRemote'></ClassStats><ClassStats bugs='0' size='22' interface='false' sourceFile='BlockReaderUtil.java' class='org.apache.hadoop.hdfs.client.impl.BlockReaderUtil'></ClassStats><ClassStats bugs='0' size='47' interface='false' sourceFile='CorruptFileBlockIterator.java' class='org.apache.hadoop.hdfs.client.impl.CorruptFileBlockIterator'></ClassStats><ClassStats bugs='0' size='202' interface='false' sourceFile='DfsClientConf.java' class='org.apache.hadoop.hdfs.client.impl.DfsClientConf'></ClassStats><ClassStats bugs='0' size='104' interface='false' sourceFile='DfsClientConf.java' class='org.apache.hadoop.hdfs.client.impl.DfsClientConf$ShortCircuitConf'></ClassStats><ClassStats bugs='0' size='51' interface='false' sourceFile='ExternalBlockReader.java' class='org.apache.hadoop.hdfs.client.impl.ExternalBlockReader'></ClassStats><ClassStats bugs='1' size='187' priority_3='1' interface='false' sourceFile='LeaseRenewer.java' class='org.apache.hadoop.hdfs.client.impl.LeaseRenewer'></ClassStats><ClassStats bugs='0' size='20' interface='false' sourceFile='LeaseRenewer.java' class='org.apache.hadoop.hdfs.client.impl.LeaseRenewer$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='LeaseRenewer.java' class='org.apache.hadoop.hdfs.client.impl.LeaseRenewer$2'></ClassStats><ClassStats bugs='0' size='23' interface='false' sourceFile='LeaseRenewer.java' class='org.apache.hadoop.hdfs.client.impl.LeaseRenewer$Factory'></ClassStats><ClassStats bugs='0' size='26' interface='false' sourceFile='LeaseRenewer.java' class='org.apache.hadoop.hdfs.client.impl.LeaseRenewer$Factory$Key'></ClassStats><ClassStats bugs='0' size='101' interface='false' sourceFile='SnapshotDiffReportGenerator.java' class='org.apache.hadoop.hdfs.client.impl.SnapshotDiffReportGenerator'></ClassStats><ClassStats bugs='0' size='17' interface='false' sourceFile='SnapshotDiffReportGenerator.java' class='org.apache.hadoop.hdfs.client.impl.SnapshotDiffReportGenerator$1'></ClassStats><ClassStats bugs='0' size='14' interface='false' sourceFile='SnapshotDiffReportGenerator.java' class='org.apache.hadoop.hdfs.client.impl.SnapshotDiffReportGenerator$ChildrenDiff'></ClassStats><ClassStats bugs='0' size='17' interface='false' sourceFile='SnapshotDiffReportGenerator.java' class='org.apache.hadoop.hdfs.client.impl.SnapshotDiffReportGenerator$RenameEntry'></ClassStats><ClassStats bugs='8' size='81' priority_2='6' priority_3='2' interface='false' sourceFile='TestLeaseRenewer.java' class='org.apache.hadoop.hdfs.client.impl.TestLeaseRenewer'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='TestLeaseRenewer.java' class='org.apache.hadoop.hdfs.client.impl.TestLeaseRenewer$1'></ClassStats><ClassStats bugs='0' size='16' interface='false' sourceFile='TestLeaseRenewer.java' class='org.apache.hadoop.hdfs.client.impl.TestLeaseRenewer$2'></ClassStats></PackageStats><PackageStats package='org.apache.hadoop.hdfs.client.impl.metrics' total_bugs='0' total_size='60' total_types='3'><ClassStats bugs='0' size='40' interface='false' sourceFile='BlockReaderIoProvider.java' class='org.apache.hadoop.hdfs.client.impl.metrics.BlockReaderIoProvider'></ClassStats><ClassStats bugs='0' size='19' interface='false' sourceFile='BlockReaderLocalMetrics.java' class='org.apache.hadoop.hdfs.client.impl.metrics.BlockReaderLocalMetrics'></ClassStats><ClassStats bugs='0' size='1' interface='true' sourceFile='package-info.java' class='org.apache.hadoop.hdfs.client.impl.metrics.package-info'></ClassStats></PackageStats><PackageStats package='org.apache.hadoop.hdfs.inotify' total_bugs='3' priority_2='2' priority_3='1' total_size='488' total_types='20'><ClassStats bugs='0' size='8' interface='false' sourceFile='Event.java' class='org.apache.hadoop.hdfs.inotify.Event'></ClassStats><ClassStats bugs='0' size='4' interface='false' sourceFile='Event.java' class='org.apache.hadoop.hdfs.inotify.Event$1'></ClassStats><ClassStats bugs='0' size='16' interface='false' sourceFile='Event.java' class='org.apache.hadoop.hdfs.inotify.Event$AppendEvent'></ClassStats><ClassStats bugs='0' size='15' interface='false' sourceFile='Event.java' class='org.apache.hadoop.hdfs.inotify.Event$AppendEvent$Builder'></ClassStats><ClassStats bugs='0' size='18' interface='false' sourceFile='Event.java' class='org.apache.hadoop.hdfs.inotify.Event$CloseEvent'></ClassStats><ClassStats bugs='1' size='61' priority_3='1' interface='false' sourceFile='Event.java' class='org.apache.hadoop.hdfs.inotify.Event$CreateEvent'></ClassStats><ClassStats bugs='0' size='56' interface='false' sourceFile='Event.java' class='org.apache.hadoop.hdfs.inotify.Event$CreateEvent$Builder'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='Event.java' class='org.apache.hadoop.hdfs.inotify.Event$CreateEvent$INodeType'></ClassStats><ClassStats bugs='0' size='15' interface='false' sourceFile='Event.java' class='org.apache.hadoop.hdfs.inotify.Event$EventType'></ClassStats><ClassStats bugs='0' size='72' interface='false' sourceFile='Event.java' class='org.apache.hadoop.hdfs.inotify.Event$MetadataUpdateEvent'></ClassStats><ClassStats bugs='0' size='60' interface='false' sourceFile='Event.java' class='org.apache.hadoop.hdfs.inotify.Event$MetadataUpdateEvent$Builder'></ClassStats><ClassStats bugs='0' size='14' interface='false' sourceFile='Event.java' class='org.apache.hadoop.hdfs.inotify.Event$MetadataUpdateEvent$MetadataType'></ClassStats><ClassStats bugs='0' size='20' interface='false' sourceFile='Event.java' class='org.apache.hadoop.hdfs.inotify.Event$RenameEvent'></ClassStats><ClassStats bugs='0' size='20' interface='false' sourceFile='Event.java' class='org.apache.hadoop.hdfs.inotify.Event$RenameEvent$Builder'></ClassStats><ClassStats bugs='0' size='18' interface='false' sourceFile='Event.java' class='org.apache.hadoop.hdfs.inotify.Event$TruncateEvent'></ClassStats><ClassStats bugs='0' size='16' interface='false' sourceFile='Event.java' class='org.apache.hadoop.hdfs.inotify.Event$UnlinkEvent'></ClassStats><ClassStats bugs='0' size='15' interface='false' sourceFile='Event.java' class='org.apache.hadoop.hdfs.inotify.Event$UnlinkEvent$Builder'></ClassStats><ClassStats bugs='2' size='12' priority_2='2' interface='false' sourceFile='EventBatch.java' class='org.apache.hadoop.hdfs.inotify.EventBatch'></ClassStats><ClassStats bugs='0' size='20' interface='false' sourceFile='EventBatchList.java' class='org.apache.hadoop.hdfs.inotify.EventBatchList'></ClassStats><ClassStats bugs='0' size='17' interface='false' sourceFile='MissingEventsException.java' class='org.apache.hadoop.hdfs.inotify.MissingEventsException'></ClassStats></PackageStats><PackageStats package='org.apache.hadoop.hdfs.net' total_bugs='0' total_size='201' total_types='5'><ClassStats bugs='0' size='44' interface='false' sourceFile='BasicInetPeer.java' class='org.apache.hadoop.hdfs.net.BasicInetPeer'></ClassStats><ClassStats bugs='0' size='45' interface='false' sourceFile='DomainPeer.java' class='org.apache.hadoop.hdfs.net.DomainPeer'></ClassStats><ClassStats bugs='0' size='50' interface='false' sourceFile='EncryptedPeer.java' class='org.apache.hadoop.hdfs.net.EncryptedPeer'></ClassStats><ClassStats bugs='0' size='47' interface='false' sourceFile='NioInetPeer.java' class='org.apache.hadoop.hdfs.net.NioInetPeer'></ClassStats><ClassStats bugs='0' size='15' interface='true' sourceFile='Peer.java' class='org.apache.hadoop.hdfs.net.Peer'></ClassStats></PackageStats><PackageStats package='org.apache.hadoop.hdfs.protocol' total_bugs='51' priority_2='41' priority_3='10' total_size='4072' total_types='102'><ClassStats bugs='0' size='5' interface='false' sourceFile='AclException.java' class='org.apache.hadoop.hdfs.protocol.AclException'></ClassStats><ClassStats bugs='0' size='44' interface='false' sourceFile='AddErasureCodingPolicyResponse.java' class='org.apache.hadoop.hdfs.protocol.AddErasureCodingPolicyResponse'></ClassStats><ClassStats bugs='0' size='5' interface='false' sourceFile='AlreadyBeingCreatedException.java' class='org.apache.hadoop.hdfs.protocol.AlreadyBeingCreatedException'></ClassStats><ClassStats bugs='0' size='123' interface='false' sourceFile='Block.java' class='org.apache.hadoop.hdfs.protocol.Block'></ClassStats><ClassStats bugs='0' size='5' interface='false' sourceFile='Block.java' class='org.apache.hadoop.hdfs.protocol.Block$1'></ClassStats><ClassStats bugs='0' size='18' interface='false' sourceFile='BlockChecksumOptions.java' class='org.apache.hadoop.hdfs.protocol.BlockChecksumOptions'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='BlockChecksumType.java' class='org.apache.hadoop.hdfs.protocol.BlockChecksumType'></ClassStats><ClassStats bugs='0' size='20' interface='false' sourceFile='BlockLocalPathInfo.java' class='org.apache.hadoop.hdfs.protocol.BlockLocalPathInfo'></ClassStats><ClassStats bugs='6' size='108' priority_2='6' interface='false' sourceFile='BlockStoragePolicy.java' class='org.apache.hadoop.hdfs.protocol.BlockStoragePolicy'></ClassStats><ClassStats bugs='0' size='18' interface='false' sourceFile='BlockType.java' class='org.apache.hadoop.hdfs.protocol.BlockType'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='CacheDirectiveEntry.java' class='org.apache.hadoop.hdfs.protocol.CacheDirectiveEntry'></ClassStats><ClassStats bugs='0' size='63' interface='false' sourceFile='CacheDirectiveInfo.java' class='org.apache.hadoop.hdfs.protocol.CacheDirectiveInfo'></ClassStats><ClassStats bugs='0' size='34' interface='false' sourceFile='CacheDirectiveInfo.java' class='org.apache.hadoop.hdfs.protocol.CacheDirectiveInfo$Builder'></ClassStats><ClassStats bugs='0' size='34' interface='false' sourceFile='CacheDirectiveInfo.java' class='org.apache.hadoop.hdfs.protocol.CacheDirectiveInfo$Expiration'></ClassStats><ClassStats bugs='0' size='36' interface='false' sourceFile='CacheDirectiveIterator.java' class='org.apache.hadoop.hdfs.protocol.CacheDirectiveIterator'></ClassStats><ClassStats bugs='0' size='16' interface='false' sourceFile='CacheDirectiveIterator.java' class='org.apache.hadoop.hdfs.protocol.CacheDirectiveIterator$SingleEntry'></ClassStats><ClassStats bugs='0' size='28' interface='false' sourceFile='CacheDirectiveStats.java' class='org.apache.hadoop.hdfs.protocol.CacheDirectiveStats'></ClassStats><ClassStats bugs='0' size='1' interface='false' sourceFile='CacheDirectiveStats.java' class='org.apache.hadoop.hdfs.protocol.CacheDirectiveStats$1'></ClassStats><ClassStats bugs='0' size='26' interface='false' sourceFile='CacheDirectiveStats.java' class='org.apache.hadoop.hdfs.protocol.CacheDirectiveStats$Builder'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='CachePoolEntry.java' class='org.apache.hadoop.hdfs.protocol.CachePoolEntry'></ClassStats><ClassStats bugs='0' size='97' interface='false' sourceFile='CachePoolInfo.java' class='org.apache.hadoop.hdfs.protocol.CachePoolInfo'></ClassStats><ClassStats bugs='0' size='17' interface='false' sourceFile='CachePoolIterator.java' class='org.apache.hadoop.hdfs.protocol.CachePoolIterator'></ClassStats><ClassStats bugs='0' size='28' interface='false' sourceFile='CachePoolStats.java' class='org.apache.hadoop.hdfs.protocol.CachePoolStats'></ClassStats><ClassStats bugs='0' size='1' interface='false' sourceFile='CachePoolStats.java' class='org.apache.hadoop.hdfs.protocol.CachePoolStats$1'></ClassStats><ClassStats bugs='0' size='26' interface='false' sourceFile='CachePoolStats.java' class='org.apache.hadoop.hdfs.protocol.CachePoolStats$Builder'></ClassStats><ClassStats bugs='0' size='19' interface='true' sourceFile='ClientDatanodeProtocol.java' class='org.apache.hadoop.hdfs.protocol.ClientDatanodeProtocol'></ClassStats><ClassStats bugs='0' size='117' interface='true' sourceFile='ClientProtocol.java' class='org.apache.hadoop.hdfs.protocol.ClientProtocol'></ClassStats><ClassStats bugs='2' size='29' priority_2='2' interface='false' sourceFile='CorruptFileBlocks.java' class='org.apache.hadoop.hdfs.protocol.CorruptFileBlocks'></ClassStats><ClassStats bugs='0' size='17' interface='false' sourceFile='DSQuotaExceededException.java' class='org.apache.hadoop.hdfs.protocol.DSQuotaExceededException'></ClassStats><ClassStats bugs='0' size='35' interface='false' sourceFile='DatanodeAdminProperties.java' class='org.apache.hadoop.hdfs.protocol.DatanodeAdminProperties'></ClassStats><ClassStats bugs='0' size='130' interface='false' sourceFile='DatanodeID.java' class='org.apache.hadoop.hdfs.protocol.DatanodeID'></ClassStats><ClassStats bugs='0' size='356' interface='false' sourceFile='DatanodeInfo.java' class='org.apache.hadoop.hdfs.protocol.DatanodeInfo'></ClassStats><ClassStats bugs='0' size='1' interface='false' sourceFile='DatanodeInfo.java' class='org.apache.hadoop.hdfs.protocol.DatanodeInfo$1'></ClassStats><ClassStats bugs='0' size='27' interface='false' sourceFile='DatanodeInfo.java' class='org.apache.hadoop.hdfs.protocol.DatanodeInfo$AdminStates'></ClassStats><ClassStats bugs='0' size='129' interface='false' sourceFile='DatanodeInfo.java' class='org.apache.hadoop.hdfs.protocol.DatanodeInfo$DatanodeInfoBuilder'></ClassStats><ClassStats bugs='1' size='22' priority_3='1' interface='false' sourceFile='DatanodeInfoWithStorage.java' class='org.apache.hadoop.hdfs.protocol.DatanodeInfoWithStorage'></ClassStats><ClassStats bugs='0' size='20' interface='false' sourceFile='DatanodeLocalInfo.java' class='org.apache.hadoop.hdfs.protocol.DatanodeLocalInfo'></ClassStats><ClassStats bugs='0' size='47' interface='false' sourceFile='DatanodeVolumeInfo.java' class='org.apache.hadoop.hdfs.protocol.DatanodeVolumeInfo'></ClassStats><ClassStats bugs='3' size='22' priority_2='2' priority_3='1' interface='false' sourceFile='DirectoryListing.java' class='org.apache.hadoop.hdfs.protocol.DirectoryListing'></ClassStats><ClassStats bugs='0' size='37' interface='false' sourceFile='ECBlockGroupStats.java' class='org.apache.hadoop.hdfs.protocol.ECBlockGroupStats'></ClassStats><ClassStats bugs='0' size='49' interface='false' sourceFile='EncryptionZone.java' class='org.apache.hadoop.hdfs.protocol.EncryptionZone'></ClassStats><ClassStats bugs='0' size='17' interface='false' sourceFile='EncryptionZoneIterator.java' class='org.apache.hadoop.hdfs.protocol.EncryptionZoneIterator'></ClassStats><ClassStats bugs='1' size='71' priority_3='1' interface='false' sourceFile='ErasureCodingPolicy.java' class='org.apache.hadoop.hdfs.protocol.ErasureCodingPolicy'></ClassStats><ClassStats bugs='0' size='47' interface='false' sourceFile='ErasureCodingPolicyInfo.java' class='org.apache.hadoop.hdfs.protocol.ErasureCodingPolicyInfo'></ClassStats><ClassStats bugs='0' size='31' interface='false' sourceFile='ErasureCodingPolicyState.java' class='org.apache.hadoop.hdfs.protocol.ErasureCodingPolicyState'></ClassStats><ClassStats bugs='0' size='64' interface='false' sourceFile='ExtendedBlock.java' class='org.apache.hadoop.hdfs.protocol.ExtendedBlock'></ClassStats><ClassStats bugs='0' size='32' interface='false' sourceFile='FsPermissionExtension.java' class='org.apache.hadoop.hdfs.protocol.FsPermissionExtension'></ClassStats><ClassStats bugs='0' size='41' interface='false' sourceFile='HdfsConstants.java' class='org.apache.hadoop.hdfs.protocol.HdfsConstants'></ClassStats><ClassStats bugs='0' size='14' interface='false' sourceFile='HdfsConstants.java' class='org.apache.hadoop.hdfs.protocol.HdfsConstants$DatanodeReportType'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='HdfsConstants.java' class='org.apache.hadoop.hdfs.protocol.HdfsConstants$ReencryptAction'></ClassStats><ClassStats bugs='0' size='19' interface='false' sourceFile='HdfsConstants.java' class='org.apache.hadoop.hdfs.protocol.HdfsConstants$RollingUpgradeAction'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='HdfsConstants.java' class='org.apache.hadoop.hdfs.protocol.HdfsConstants$SafeModeAction'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='HdfsConstants.java' class='org.apache.hadoop.hdfs.protocol.HdfsConstants$UpgradeAction'></ClassStats><ClassStats bugs='1' size='82' priority_3='1' interface='true' sourceFile='HdfsFileStatus.java' class='org.apache.hadoop.hdfs.protocol.HdfsFileStatus'></ClassStats><ClassStats bugs='0' size='4' interface='false' sourceFile='HdfsFileStatus.java' class='org.apache.hadoop.hdfs.protocol.HdfsFileStatus$1'></ClassStats><ClassStats bugs='0' size='99' interface='false' sourceFile='HdfsFileStatus.java' class='org.apache.hadoop.hdfs.protocol.HdfsFileStatus$Builder'></ClassStats><ClassStats bugs='0' size='15' interface='false' sourceFile='HdfsFileStatus.java' class='org.apache.hadoop.hdfs.protocol.HdfsFileStatus$Flags'></ClassStats><ClassStats bugs='3' size='66' priority_2='2' priority_3='1' interface='false' sourceFile='HdfsLocatedFileStatus.java' class='org.apache.hadoop.hdfs.protocol.HdfsLocatedFileStatus'></ClassStats><ClassStats bugs='3' size='56' priority_2='2' priority_3='1' interface='false' sourceFile='HdfsNamedFileStatus.java' class='org.apache.hadoop.hdfs.protocol.HdfsNamedFileStatus'></ClassStats><ClassStats bugs='0' size='58' interface='false' sourceFile='HdfsPathHandle.java' class='org.apache.hadoop.hdfs.protocol.HdfsPathHandle'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='LastBlockWithStatus.java' class='org.apache.hadoop.hdfs.protocol.LastBlockWithStatus'></ClassStats><ClassStats bugs='7' size='103' priority_2='6' priority_3='1' interface='false' sourceFile='LocatedBlock.java' class='org.apache.hadoop.hdfs.protocol.LocatedBlock'></ClassStats><ClassStats bugs='0' size='1' interface='false' sourceFile='LocatedBlock.java' class='org.apache.hadoop.hdfs.protocol.LocatedBlock$1'></ClassStats><ClassStats bugs='0' size='14' interface='false' sourceFile='LocatedBlock.java' class='org.apache.hadoop.hdfs.protocol.LocatedBlock$ProvidedLastComparator'></ClassStats><ClassStats bugs='1' size='80' priority_3='1' interface='false' sourceFile='LocatedBlocks.java' class='org.apache.hadoop.hdfs.protocol.LocatedBlocks'></ClassStats><ClassStats bugs='0' size='15' interface='false' sourceFile='LocatedBlocks.java' class='org.apache.hadoop.hdfs.protocol.LocatedBlocks$1'></ClassStats><ClassStats bugs='3' size='34' priority_2='3' interface='false' sourceFile='LocatedStripedBlock.java' class='org.apache.hadoop.hdfs.protocol.LocatedStripedBlock'></ClassStats><ClassStats bugs='1' size='21' priority_3='1' interface='false' sourceFile='NSQuotaExceededException.java' class='org.apache.hadoop.hdfs.protocol.NSQuotaExceededException'></ClassStats><ClassStats bugs='0' size='20' interface='false' sourceFile='OpenFileEntry.java' class='org.apache.hadoop.hdfs.protocol.OpenFileEntry'></ClassStats><ClassStats bugs='0' size='22' interface='false' sourceFile='OpenFilesIterator.java' class='org.apache.hadoop.hdfs.protocol.OpenFilesIterator'></ClassStats><ClassStats bugs='0' size='22' interface='false' sourceFile='OpenFilesIterator.java' class='org.apache.hadoop.hdfs.protocol.OpenFilesIterator$OpenFilesType'></ClassStats><ClassStats bugs='0' size='36' interface='false' sourceFile='ProvidedStorageLocation.java' class='org.apache.hadoop.hdfs.protocol.ProvidedStorageLocation'></ClassStats><ClassStats bugs='0' size='19' interface='false' sourceFile='QuotaByStorageTypeExceededException.java' class='org.apache.hadoop.hdfs.protocol.QuotaByStorageTypeExceededException'></ClassStats><ClassStats bugs='0' size='21' interface='false' sourceFile='QuotaExceededException.java' class='org.apache.hadoop.hdfs.protocol.QuotaExceededException'></ClassStats><ClassStats bugs='0' size='5' interface='true' sourceFile='ReconfigurationProtocol.java' class='org.apache.hadoop.hdfs.protocol.ReconfigurationProtocol'></ClassStats><ClassStats bugs='0' size='122' interface='false' sourceFile='ReencryptionStatus.java' class='org.apache.hadoop.hdfs.protocol.ReencryptionStatus'></ClassStats><ClassStats bugs='0' size='17' interface='false' sourceFile='ReencryptionStatusIterator.java' class='org.apache.hadoop.hdfs.protocol.ReencryptionStatusIterator'></ClassStats><ClassStats bugs='0' size='41' interface='false' sourceFile='ReplicatedBlockStats.java' class='org.apache.hadoop.hdfs.protocol.ReplicatedBlockStats'></ClassStats><ClassStats bugs='0' size='46' interface='false' sourceFile='RollingUpgradeInfo.java' class='org.apache.hadoop.hdfs.protocol.RollingUpgradeInfo'></ClassStats><ClassStats bugs='0' size='20' interface='false' sourceFile='RollingUpgradeInfo.java' class='org.apache.hadoop.hdfs.protocol.RollingUpgradeInfo$Bean'></ClassStats><ClassStats bugs='0' size='24' interface='false' sourceFile='RollingUpgradeStatus.java' class='org.apache.hadoop.hdfs.protocol.RollingUpgradeStatus'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='SnapshotAccessControlException.java' class='org.apache.hadoop.hdfs.protocol.SnapshotAccessControlException'></ClassStats><ClassStats bugs='0' size='35' interface='false' sourceFile='SnapshotDiffReport.java' class='org.apache.hadoop.hdfs.protocol.SnapshotDiffReport'></ClassStats><ClassStats bugs='4' size='50' priority_2='4' interface='false' sourceFile='SnapshotDiffReport.java' class='org.apache.hadoop.hdfs.protocol.SnapshotDiffReport$DiffReportEntry'></ClassStats><ClassStats bugs='1' size='33' priority_3='1' interface='false' sourceFile='SnapshotDiffReport.java' class='org.apache.hadoop.hdfs.protocol.SnapshotDiffReport$DiffType'></ClassStats><ClassStats bugs='1' size='38' priority_2='1' interface='false' sourceFile='SnapshotDiffReportListing.java' class='org.apache.hadoop.hdfs.protocol.SnapshotDiffReportListing'></ClassStats><ClassStats bugs='4' size='35' priority_2='4' interface='false' sourceFile='SnapshotDiffReportListing.java' class='org.apache.hadoop.hdfs.protocol.SnapshotDiffReportListing$DiffReportListingEntry'></ClassStats><ClassStats bugs='3' size='81' priority_2='3' interface='false' sourceFile='SnapshottableDirectoryStatus.java' class='org.apache.hadoop.hdfs.protocol.SnapshottableDirectoryStatus'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='SnapshottableDirectoryStatus.java' class='org.apache.hadoop.hdfs.protocol.SnapshottableDirectoryStatus$1'></ClassStats><ClassStats bugs='0' size='32' interface='false' sourceFile='SnapshottableDirectoryStatus.java' class='org.apache.hadoop.hdfs.protocol.SnapshottableDirectoryStatus$Bean'></ClassStats><ClassStats bugs='6' size='24' priority_2='6' interface='false' sourceFile='StripedBlockInfo.java' class='org.apache.hadoop.hdfs.protocol.StripedBlockInfo'></ClassStats><ClassStats bugs='0' size='42' interface='false' sourceFile='SystemErasureCodingPolicies.java' class='org.apache.hadoop.hdfs.protocol.SystemErasureCodingPolicies'></ClassStats><ClassStats bugs='0' size='33' interface='false' sourceFile='TestBlockType.java' class='org.apache.hadoop.hdfs.protocol.TestBlockType'></ClassStats><ClassStats bugs='0' size='57' interface='false' sourceFile='TestErasureCodingPolicy.java' class='org.apache.hadoop.hdfs.protocol.TestErasureCodingPolicy'></ClassStats><ClassStats bugs='0' size='30' interface='false' sourceFile='TestErasureCodingPolicyInfo.java' class='org.apache.hadoop.hdfs.protocol.TestErasureCodingPolicyInfo'></ClassStats><ClassStats bugs='0' size='33' interface='false' sourceFile='TestExtendedBlock.java' class='org.apache.hadoop.hdfs.protocol.TestExtendedBlock'></ClassStats><ClassStats bugs='0' size='24' interface='false' sourceFile='TestHdfsFileStatusMethods.java' class='org.apache.hadoop.hdfs.protocol.TestHdfsFileStatusMethods'></ClassStats><ClassStats bugs='0' size='26' interface='false' sourceFile='TestHdfsFileStatusMethods.java' class='org.apache.hadoop.hdfs.protocol.TestHdfsFileStatusMethods$MethodSignature'></ClassStats><ClassStats bugs='0' size='27' interface='false' sourceFile='UnresolvedPathException.java' class='org.apache.hadoop.hdfs.protocol.UnresolvedPathException'></ClassStats><ClassStats bugs='0' size='90' interface='false' sourceFile='ZoneReencryptionStatus.java' class='org.apache.hadoop.hdfs.protocol.ZoneReencryptionStatus'></ClassStats><ClassStats bugs='0' size='62' interface='false' sourceFile='ZoneReencryptionStatus.java' class='org.apache.hadoop.hdfs.protocol.ZoneReencryptionStatus$Builder'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='ZoneReencryptionStatus.java' class='org.apache.hadoop.hdfs.protocol.ZoneReencryptionStatus$State'></ClassStats></PackageStats><PackageStats package='org.apache.hadoop.hdfs.protocol.datatransfer' total_bugs='0' total_size='778' total_types='20'><ClassStats bugs='0' size='31' interface='false' sourceFile='BlockConstructionStage.java' class='org.apache.hadoop.hdfs.protocol.datatransfer.BlockConstructionStage'></ClassStats><ClassStats bugs='0' size='5' interface='false' sourceFile='BlockPinningException.java' class='org.apache.hadoop.hdfs.protocol.datatransfer.BlockPinningException'></ClassStats><ClassStats bugs='0' size='56' interface='false' sourceFile='DataTransferProtoUtil.java' class='org.apache.hadoop.hdfs.protocol.datatransfer.DataTransferProtoUtil'></ClassStats><ClassStats bugs='0' size='15' interface='true' sourceFile='DataTransferProtocol.java' class='org.apache.hadoop.hdfs.protocol.datatransfer.DataTransferProtocol'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='IOStreamPair.java' class='org.apache.hadoop.hdfs.protocol.datatransfer.IOStreamPair'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='InvalidEncryptionKeyException.java' class='org.apache.hadoop.hdfs.protocol.datatransfer.InvalidEncryptionKeyException'></ClassStats><ClassStats bugs='0' size='45' interface='false' sourceFile='Op.java' class='org.apache.hadoop.hdfs.protocol.datatransfer.Op'></ClassStats><ClassStats bugs='0' size='100' interface='false' sourceFile='PacketHeader.java' class='org.apache.hadoop.hdfs.protocol.datatransfer.PacketHeader'></ClassStats><ClassStats bugs='0' size='133' interface='false' sourceFile='PacketReceiver.java' class='org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver'></ClassStats><ClassStats bugs='0' size='74' interface='false' sourceFile='PipelineAck.java' class='org.apache.hadoop.hdfs.protocol.datatransfer.PipelineAck'></ClassStats><ClassStats bugs='0' size='25' interface='false' sourceFile='PipelineAck.java' class='org.apache.hadoop.hdfs.protocol.datatransfer.PipelineAck$ECN'></ClassStats><ClassStats bugs='0' size='25' interface='false' sourceFile='PipelineAck.java' class='org.apache.hadoop.hdfs.protocol.datatransfer.PipelineAck$StatusFormat'></ClassStats><ClassStats bugs='0' size='51' interface='false' sourceFile='ReplaceDatanodeOnFailure.java' class='org.apache.hadoop.hdfs.protocol.datatransfer.ReplaceDatanodeOnFailure'></ClassStats><ClassStats bugs='0' size='5' interface='false' sourceFile='ReplaceDatanodeOnFailure.java' class='org.apache.hadoop.hdfs.protocol.datatransfer.ReplaceDatanodeOnFailure$1'></ClassStats><ClassStats bugs='0' size='5' interface='false' sourceFile='ReplaceDatanodeOnFailure.java' class='org.apache.hadoop.hdfs.protocol.datatransfer.ReplaceDatanodeOnFailure$2'></ClassStats><ClassStats bugs='0' size='5' interface='false' sourceFile='ReplaceDatanodeOnFailure.java' class='org.apache.hadoop.hdfs.protocol.datatransfer.ReplaceDatanodeOnFailure$3'></ClassStats><ClassStats bugs='0' size='2' interface='true' sourceFile='ReplaceDatanodeOnFailure.java' class='org.apache.hadoop.hdfs.protocol.datatransfer.ReplaceDatanodeOnFailure$Condition'></ClassStats><ClassStats bugs='0' size='21' interface='false' sourceFile='ReplaceDatanodeOnFailure.java' class='org.apache.hadoop.hdfs.protocol.datatransfer.ReplaceDatanodeOnFailure$Policy'></ClassStats><ClassStats bugs='0' size='143' interface='false' sourceFile='Sender.java' class='org.apache.hadoop.hdfs.protocol.datatransfer.Sender'></ClassStats><ClassStats bugs='0' size='17' interface='false' sourceFile='TrustedChannelResolver.java' class='org.apache.hadoop.hdfs.protocol.datatransfer.TrustedChannelResolver'></ClassStats></PackageStats><PackageStats package='org.apache.hadoop.hdfs.protocol.datatransfer.sasl' total_bugs='1' priority_2='1' total_size='391' total_types='6'><ClassStats bugs='0' size='2' interface='true' sourceFile='DataEncryptionKeyFactory.java' class='org.apache.hadoop.hdfs.protocol.datatransfer.sasl.DataEncryptionKeyFactory'></ClassStats><ClassStats bugs='0' size='185' interface='false' sourceFile='DataTransferSaslUtil.java' class='org.apache.hadoop.hdfs.protocol.datatransfer.sasl.DataTransferSaslUtil'></ClassStats><ClassStats bugs='0' size='121' interface='false' sourceFile='SaslDataTransferClient.java' class='org.apache.hadoop.hdfs.protocol.datatransfer.sasl.SaslDataTransferClient'></ClassStats><ClassStats bugs='0' size='28' interface='false' sourceFile='SaslDataTransferClient.java' class='org.apache.hadoop.hdfs.protocol.datatransfer.sasl.SaslDataTransferClient$SaslClientCallbackHandler'></ClassStats><ClassStats bugs='0' size='47' interface='false' sourceFile='SaslParticipant.java' class='org.apache.hadoop.hdfs.protocol.datatransfer.sasl.SaslParticipant'></ClassStats><ClassStats bugs='1' size='8' priority_2='1' interface='false' sourceFile='SaslResponseWithNegotiatedCipherOption.java' class='org.apache.hadoop.hdfs.protocol.datatransfer.sasl.SaslResponseWithNegotiatedCipherOption'></ClassStats></PackageStats><PackageStats package='org.apache.hadoop.hdfs.protocol.proto' priority_1='336' total_bugs='1189' priority_2='516' priority_3='337' total_size='144936' total_types='1451'><ClassStats bugs='0' size='106' interface='false' sourceFile='AclProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.AclProtos'></ClassStats><ClassStats bugs='0' size='66' interface='false' sourceFile='AclProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.AclProtos$1'></ClassStats><ClassStats bugs='2' size='268' priority_1='1' priority_2='1' interface='false' sourceFile='AclProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.AclProtos$AclEntryProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='AclProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.AclProtos$AclEntryProto$1'></ClassStats><ClassStats bugs='0' size='42' interface='false' sourceFile='AclProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.AclProtos$AclEntryProto$AclEntryScopeProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='AclProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.AclProtos$AclEntryProto$AclEntryScopeProto$1'></ClassStats><ClassStats bugs='0' size='50' interface='false' sourceFile='AclProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.AclProtos$AclEntryProto$AclEntryTypeProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='AclProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.AclProtos$AclEntryProto$AclEntryTypeProto$1'></ClassStats><ClassStats bugs='1' size='216' priority_2='1' interface='false' sourceFile='AclProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.AclProtos$AclEntryProto$Builder'></ClassStats><ClassStats bugs='0' size='66' interface='false' sourceFile='AclProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.AclProtos$AclEntryProto$FsActionProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='AclProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.AclProtos$AclEntryProto$FsActionProto$1'></ClassStats><ClassStats bugs='0' size='10' interface='true' sourceFile='AclProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.AclProtos$AclEntryProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='322' priority_1='1' priority_2='1' interface='false' sourceFile='AclProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.AclProtos$AclStatusProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='AclProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.AclProtos$AclStatusProto$1'></ClassStats><ClassStats bugs='0' size='431' interface='false' sourceFile='AclProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.AclProtos$AclStatusProto$Builder'></ClassStats><ClassStats bugs='0' size='17' interface='true' sourceFile='AclProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.AclProtos$AclStatusProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='165' priority_1='1' priority_2='1' interface='false' sourceFile='AclProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.AclProtos$FsPermissionProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='AclProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.AclProtos$FsPermissionProto$1'></ClassStats><ClassStats bugs='1' size='111' priority_2='1' interface='false' sourceFile='AclProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.AclProtos$FsPermissionProto$Builder'></ClassStats><ClassStats bugs='0' size='3' interface='true' sourceFile='AclProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.AclProtos$FsPermissionProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='181' priority_1='1' priority_2='1' interface='false' sourceFile='AclProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.AclProtos$GetAclStatusRequestProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='AclProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.AclProtos$GetAclStatusRequestProto$1'></ClassStats><ClassStats bugs='1' size='137' priority_2='1' interface='false' sourceFile='AclProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.AclProtos$GetAclStatusRequestProto$Builder'></ClassStats><ClassStats bugs='0' size='4' interface='true' sourceFile='AclProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.AclProtos$GetAclStatusRequestProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='177' priority_1='1' priority_2='1' interface='false' sourceFile='AclProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.AclProtos$GetAclStatusResponseProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='AclProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.AclProtos$GetAclStatusResponseProto$1'></ClassStats><ClassStats bugs='0' size='161' interface='false' sourceFile='AclProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.AclProtos$GetAclStatusResponseProto$Builder'></ClassStats><ClassStats bugs='0' size='4' interface='true' sourceFile='AclProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.AclProtos$GetAclStatusResponseProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='218' priority_1='1' priority_2='1' interface='false' sourceFile='AclProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.AclProtos$ModifyAclEntriesRequestProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='AclProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.AclProtos$ModifyAclEntriesRequestProto$1'></ClassStats><ClassStats bugs='0' size='284' interface='false' sourceFile='AclProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.AclProtos$ModifyAclEntriesRequestProto$Builder'></ClassStats><ClassStats bugs='0' size='9' interface='true' sourceFile='AclProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.AclProtos$ModifyAclEntriesRequestProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='137' priority_1='1' priority_2='1' interface='false' sourceFile='AclProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.AclProtos$ModifyAclEntriesResponseProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='AclProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.AclProtos$ModifyAclEntriesResponseProto$1'></ClassStats><ClassStats bugs='1' size='83' priority_2='1' interface='false' sourceFile='AclProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.AclProtos$ModifyAclEntriesResponseProto$Builder'></ClassStats><ClassStats bugs='0' size='1' interface='true' sourceFile='AclProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.AclProtos$ModifyAclEntriesResponseProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='218' priority_1='1' priority_2='1' interface='false' sourceFile='AclProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveAclEntriesRequestProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='AclProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveAclEntriesRequestProto$1'></ClassStats><ClassStats bugs='0' size='284' interface='false' sourceFile='AclProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveAclEntriesRequestProto$Builder'></ClassStats><ClassStats bugs='0' size='9' interface='true' sourceFile='AclProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveAclEntriesRequestProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='137' priority_1='1' priority_2='1' interface='false' sourceFile='AclProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveAclEntriesResponseProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='AclProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveAclEntriesResponseProto$1'></ClassStats><ClassStats bugs='1' size='83' priority_2='1' interface='false' sourceFile='AclProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveAclEntriesResponseProto$Builder'></ClassStats><ClassStats bugs='0' size='1' interface='true' sourceFile='AclProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveAclEntriesResponseProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='181' priority_1='1' priority_2='1' interface='false' sourceFile='AclProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveAclRequestProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='AclProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveAclRequestProto$1'></ClassStats><ClassStats bugs='1' size='137' priority_2='1' interface='false' sourceFile='AclProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveAclRequestProto$Builder'></ClassStats><ClassStats bugs='0' size='4' interface='true' sourceFile='AclProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveAclRequestProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='137' priority_1='1' priority_2='1' interface='false' sourceFile='AclProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveAclResponseProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='AclProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveAclResponseProto$1'></ClassStats><ClassStats bugs='1' size='83' priority_2='1' interface='false' sourceFile='AclProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveAclResponseProto$Builder'></ClassStats><ClassStats bugs='0' size='1' interface='true' sourceFile='AclProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveAclResponseProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='181' priority_1='1' priority_2='1' interface='false' sourceFile='AclProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveDefaultAclRequestProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='AclProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveDefaultAclRequestProto$1'></ClassStats><ClassStats bugs='1' size='137' priority_2='1' interface='false' sourceFile='AclProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveDefaultAclRequestProto$Builder'></ClassStats><ClassStats bugs='0' size='4' interface='true' sourceFile='AclProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveDefaultAclRequestProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='137' priority_1='1' priority_2='1' interface='false' sourceFile='AclProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveDefaultAclResponseProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='AclProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveDefaultAclResponseProto$1'></ClassStats><ClassStats bugs='1' size='83' priority_2='1' interface='false' sourceFile='AclProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveDefaultAclResponseProto$Builder'></ClassStats><ClassStats bugs='0' size='1' interface='true' sourceFile='AclProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.AclProtos$RemoveDefaultAclResponseProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='218' priority_1='1' priority_2='1' interface='false' sourceFile='AclProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.AclProtos$SetAclRequestProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='AclProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.AclProtos$SetAclRequestProto$1'></ClassStats><ClassStats bugs='0' size='284' interface='false' sourceFile='AclProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.AclProtos$SetAclRequestProto$Builder'></ClassStats><ClassStats bugs='0' size='9' interface='true' sourceFile='AclProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.AclProtos$SetAclRequestProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='137' priority_1='1' priority_2='1' interface='false' sourceFile='AclProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.AclProtos$SetAclResponseProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='AclProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.AclProtos$SetAclResponseProto$1'></ClassStats><ClassStats bugs='1' size='83' priority_2='1' interface='false' sourceFile='AclProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.AclProtos$SetAclResponseProto$Builder'></ClassStats><ClassStats bugs='0' size='1' interface='true' sourceFile='AclProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.AclProtos$SetAclResponseProtoOrBuilder'></ClassStats><ClassStats bugs='0' size='187' interface='false' sourceFile='ClientDatanodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos'></ClassStats><ClassStats bugs='0' size='118' interface='false' sourceFile='ClientDatanodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$1'></ClassStats><ClassStats bugs='2' size='181' priority_1='1' priority_2='1' interface='false' sourceFile='ClientDatanodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$CancelPlanRequestProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientDatanodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$CancelPlanRequestProto$1'></ClassStats><ClassStats bugs='1' size='137' priority_2='1' interface='false' sourceFile='ClientDatanodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$CancelPlanRequestProto$Builder'></ClassStats><ClassStats bugs='0' size='4' interface='true' sourceFile='ClientDatanodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$CancelPlanRequestProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='137' priority_1='1' priority_2='1' interface='false' sourceFile='ClientDatanodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$CancelPlanResponseProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientDatanodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$CancelPlanResponseProto$1'></ClassStats><ClassStats bugs='1' size='83' priority_2='1' interface='false' sourceFile='ClientDatanodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$CancelPlanResponseProto$Builder'></ClassStats><ClassStats bugs='0' size='1' interface='true' sourceFile='ClientDatanodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$CancelPlanResponseProtoOrBuilder'></ClassStats><ClassStats bugs='17' size='132' priority_3='17' interface='false' sourceFile='ClientDatanodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService'></ClassStats><ClassStats bugs='0' size='55' interface='false' sourceFile='ClientDatanodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService$1'></ClassStats><ClassStats bugs='17' size='72' priority_3='17' interface='false' sourceFile='ClientDatanodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService$2'></ClassStats><ClassStats bugs='0' size='18' interface='true' sourceFile='ClientDatanodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService$BlockingInterface'></ClassStats><ClassStats bugs='0' size='76' interface='false' sourceFile='ClientDatanodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService$BlockingStub'></ClassStats><ClassStats bugs='0' size='18' interface='true' sourceFile='ClientDatanodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService$Interface'></ClassStats><ClassStats bugs='0' size='129' interface='false' sourceFile='ClientDatanodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService$Stub'></ClassStats><ClassStats bugs='2' size='207' priority_1='1' priority_2='1' interface='false' sourceFile='ClientDatanodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$DeleteBlockPoolRequestProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientDatanodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$DeleteBlockPoolRequestProto$1'></ClassStats><ClassStats bugs='1' size='161' priority_2='1' interface='false' sourceFile='ClientDatanodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$DeleteBlockPoolRequestProto$Builder'></ClassStats><ClassStats bugs='0' size='6' interface='true' sourceFile='ClientDatanodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$DeleteBlockPoolRequestProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='137' priority_1='1' priority_2='1' interface='false' sourceFile='ClientDatanodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$DeleteBlockPoolResponseProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientDatanodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$DeleteBlockPoolResponseProto$1'></ClassStats><ClassStats bugs='1' size='83' priority_2='1' interface='false' sourceFile='ClientDatanodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$DeleteBlockPoolResponseProto$Builder'></ClassStats><ClassStats bugs='0' size='1' interface='true' sourceFile='ClientDatanodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$DeleteBlockPoolResponseProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='181' priority_1='1' priority_2='1' interface='false' sourceFile='ClientDatanodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$DiskBalancerSettingRequestProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientDatanodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$DiskBalancerSettingRequestProto$1'></ClassStats><ClassStats bugs='1' size='137' priority_2='1' interface='false' sourceFile='ClientDatanodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$DiskBalancerSettingRequestProto$Builder'></ClassStats><ClassStats bugs='0' size='4' interface='true' sourceFile='ClientDatanodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$DiskBalancerSettingRequestProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='181' priority_1='1' priority_2='1' interface='false' sourceFile='ClientDatanodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$DiskBalancerSettingResponseProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientDatanodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$DiskBalancerSettingResponseProto$1'></ClassStats><ClassStats bugs='1' size='137' priority_2='1' interface='false' sourceFile='ClientDatanodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$DiskBalancerSettingResponseProto$Builder'></ClassStats><ClassStats bugs='0' size='4' interface='true' sourceFile='ClientDatanodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$DiskBalancerSettingResponseProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='137' priority_1='1' priority_2='1' interface='false' sourceFile='ClientDatanodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$EvictWritersRequestProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientDatanodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$EvictWritersRequestProto$1'></ClassStats><ClassStats bugs='1' size='83' priority_2='1' interface='false' sourceFile='ClientDatanodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$EvictWritersRequestProto$Builder'></ClassStats><ClassStats bugs='0' size='1' interface='true' sourceFile='ClientDatanodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$EvictWritersRequestProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='137' priority_1='1' priority_2='1' interface='false' sourceFile='ClientDatanodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$EvictWritersResponseProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientDatanodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$EvictWritersResponseProto$1'></ClassStats><ClassStats bugs='1' size='83' priority_2='1' interface='false' sourceFile='ClientDatanodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$EvictWritersResponseProto$Builder'></ClassStats><ClassStats bugs='0' size='1' interface='true' sourceFile='ClientDatanodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$EvictWritersResponseProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='137' priority_1='1' priority_2='1' interface='false' sourceFile='ClientDatanodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetBalancerBandwidthRequestProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientDatanodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetBalancerBandwidthRequestProto$1'></ClassStats><ClassStats bugs='1' size='83' priority_2='1' interface='false' sourceFile='ClientDatanodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetBalancerBandwidthRequestProto$Builder'></ClassStats><ClassStats bugs='0' size='1' interface='true' sourceFile='ClientDatanodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetBalancerBandwidthRequestProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='165' priority_1='1' priority_2='1' interface='false' sourceFile='ClientDatanodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetBalancerBandwidthResponseProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientDatanodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetBalancerBandwidthResponseProto$1'></ClassStats><ClassStats bugs='1' size='111' priority_2='1' interface='false' sourceFile='ClientDatanodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetBalancerBandwidthResponseProto$Builder'></ClassStats><ClassStats bugs='0' size='3' interface='true' sourceFile='ClientDatanodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetBalancerBandwidthResponseProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='214' priority_1='1' priority_2='1' interface='false' sourceFile='ClientDatanodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetBlockLocalPathInfoRequestProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientDatanodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetBlockLocalPathInfoRequestProto$1'></ClassStats><ClassStats bugs='0' size='235' interface='false' sourceFile='ClientDatanodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetBlockLocalPathInfoRequestProto$Builder'></ClassStats><ClassStats bugs='0' size='7' interface='true' sourceFile='ClientDatanodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetBlockLocalPathInfoRequestProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='260' priority_1='1' priority_2='1' interface='false' sourceFile='ClientDatanodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetBlockLocalPathInfoResponseProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientDatanodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetBlockLocalPathInfoResponseProto$1'></ClassStats><ClassStats bugs='0' size='261' interface='false' sourceFile='ClientDatanodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetBlockLocalPathInfoResponseProto$Builder'></ClassStats><ClassStats bugs='0' size='10' interface='true' sourceFile='ClientDatanodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetBlockLocalPathInfoResponseProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='137' priority_1='1' priority_2='1' interface='false' sourceFile='ClientDatanodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetDatanodeInfoRequestProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientDatanodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetDatanodeInfoRequestProto$1'></ClassStats><ClassStats bugs='1' size='83' priority_2='1' interface='false' sourceFile='ClientDatanodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetDatanodeInfoRequestProto$Builder'></ClassStats><ClassStats bugs='0' size='1' interface='true' sourceFile='ClientDatanodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetDatanodeInfoRequestProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='177' priority_1='1' priority_2='1' interface='false' sourceFile='ClientDatanodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetDatanodeInfoResponseProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientDatanodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetDatanodeInfoResponseProto$1'></ClassStats><ClassStats bugs='0' size='161' interface='false' sourceFile='ClientDatanodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetDatanodeInfoResponseProto$Builder'></ClassStats><ClassStats bugs='0' size='4' interface='true' sourceFile='ClientDatanodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetDatanodeInfoResponseProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='177' priority_1='1' priority_2='1' interface='false' sourceFile='ClientDatanodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetReplicaVisibleLengthRequestProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientDatanodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetReplicaVisibleLengthRequestProto$1'></ClassStats><ClassStats bugs='0' size='161' interface='false' sourceFile='ClientDatanodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetReplicaVisibleLengthRequestProto$Builder'></ClassStats><ClassStats bugs='0' size='4' interface='true' sourceFile='ClientDatanodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetReplicaVisibleLengthRequestProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='165' priority_1='1' priority_2='1' interface='false' sourceFile='ClientDatanodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetReplicaVisibleLengthResponseProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientDatanodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetReplicaVisibleLengthResponseProto$1'></ClassStats><ClassStats bugs='1' size='111' priority_2='1' interface='false' sourceFile='ClientDatanodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetReplicaVisibleLengthResponseProto$Builder'></ClassStats><ClassStats bugs='0' size='3' interface='true' sourceFile='ClientDatanodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetReplicaVisibleLengthResponseProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='137' priority_1='1' priority_2='1' interface='false' sourceFile='ClientDatanodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetVolumeReportRequestProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientDatanodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetVolumeReportRequestProto$1'></ClassStats><ClassStats bugs='1' size='83' priority_2='1' interface='false' sourceFile='ClientDatanodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetVolumeReportRequestProto$Builder'></ClassStats><ClassStats bugs='0' size='1' interface='true' sourceFile='ClientDatanodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetVolumeReportRequestProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='174' priority_1='1' priority_2='1' interface='false' sourceFile='ClientDatanodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetVolumeReportResponseProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientDatanodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetVolumeReportResponseProto$1'></ClassStats><ClassStats bugs='1' size='232' priority_3='1' interface='false' sourceFile='ClientDatanodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetVolumeReportResponseProto$Builder'></ClassStats><ClassStats bugs='0' size='6' interface='true' sourceFile='ClientDatanodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$GetVolumeReportResponseProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='137' priority_1='1' priority_2='1' interface='false' sourceFile='ClientDatanodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$QueryPlanStatusRequestProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientDatanodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$QueryPlanStatusRequestProto$1'></ClassStats><ClassStats bugs='1' size='83' priority_2='1' interface='false' sourceFile='ClientDatanodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$QueryPlanStatusRequestProto$Builder'></ClassStats><ClassStats bugs='0' size='1' interface='true' sourceFile='ClientDatanodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$QueryPlanStatusRequestProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='279' priority_1='1' priority_2='1' interface='false' sourceFile='ClientDatanodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$QueryPlanStatusResponseProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientDatanodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$QueryPlanStatusResponseProto$1'></ClassStats><ClassStats bugs='1' size='253' priority_2='1' interface='false' sourceFile='ClientDatanodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$QueryPlanStatusResponseProto$Builder'></ClassStats><ClassStats bugs='0' size='12' interface='true' sourceFile='ClientDatanodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$QueryPlanStatusResponseProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='137' priority_1='1' priority_2='1' interface='false' sourceFile='ClientDatanodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$RefreshNamenodesRequestProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientDatanodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$RefreshNamenodesRequestProto$1'></ClassStats><ClassStats bugs='1' size='83' priority_2='1' interface='false' sourceFile='ClientDatanodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$RefreshNamenodesRequestProto$Builder'></ClassStats><ClassStats bugs='0' size='1' interface='true' sourceFile='ClientDatanodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$RefreshNamenodesRequestProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='137' priority_1='1' priority_2='1' interface='false' sourceFile='ClientDatanodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$RefreshNamenodesResponseProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientDatanodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$RefreshNamenodesResponseProto$1'></ClassStats><ClassStats bugs='1' size='83' priority_2='1' interface='false' sourceFile='ClientDatanodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$RefreshNamenodesResponseProto$Builder'></ClassStats><ClassStats bugs='0' size='1' interface='true' sourceFile='ClientDatanodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$RefreshNamenodesResponseProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='165' priority_1='1' priority_2='1' interface='false' sourceFile='ClientDatanodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ShutdownDatanodeRequestProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientDatanodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ShutdownDatanodeRequestProto$1'></ClassStats><ClassStats bugs='1' size='111' priority_2='1' interface='false' sourceFile='ClientDatanodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ShutdownDatanodeRequestProto$Builder'></ClassStats><ClassStats bugs='0' size='3' interface='true' sourceFile='ClientDatanodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ShutdownDatanodeRequestProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='137' priority_1='1' priority_2='1' interface='false' sourceFile='ClientDatanodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ShutdownDatanodeResponseProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientDatanodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ShutdownDatanodeResponseProto$1'></ClassStats><ClassStats bugs='1' size='83' priority_2='1' interface='false' sourceFile='ClientDatanodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ShutdownDatanodeResponseProto$Builder'></ClassStats><ClassStats bugs='0' size='1' interface='true' sourceFile='ClientDatanodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ShutdownDatanodeResponseProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='311' priority_1='1' priority_2='1' interface='false' sourceFile='ClientDatanodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$SubmitDiskBalancerPlanRequestProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientDatanodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$SubmitDiskBalancerPlanRequestProto$1'></ClassStats><ClassStats bugs='1' size='281' priority_2='1' interface='false' sourceFile='ClientDatanodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$SubmitDiskBalancerPlanRequestProto$Builder'></ClassStats><ClassStats bugs='0' size='14' interface='true' sourceFile='ClientDatanodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$SubmitDiskBalancerPlanRequestProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='137' priority_1='1' priority_2='1' interface='false' sourceFile='ClientDatanodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$SubmitDiskBalancerPlanResponseProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientDatanodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$SubmitDiskBalancerPlanResponseProto$1'></ClassStats><ClassStats bugs='1' size='83' priority_2='1' interface='false' sourceFile='ClientDatanodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$SubmitDiskBalancerPlanResponseProto$Builder'></ClassStats><ClassStats bugs='0' size='1' interface='true' sourceFile='ClientDatanodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$SubmitDiskBalancerPlanResponseProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='165' priority_1='1' priority_2='1' interface='false' sourceFile='ClientDatanodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$TriggerBlockReportRequestProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientDatanodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$TriggerBlockReportRequestProto$1'></ClassStats><ClassStats bugs='1' size='111' priority_2='1' interface='false' sourceFile='ClientDatanodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$TriggerBlockReportRequestProto$Builder'></ClassStats><ClassStats bugs='0' size='3' interface='true' sourceFile='ClientDatanodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$TriggerBlockReportRequestProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='137' priority_1='1' priority_2='1' interface='false' sourceFile='ClientDatanodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$TriggerBlockReportResponseProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientDatanodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$TriggerBlockReportResponseProto$1'></ClassStats><ClassStats bugs='1' size='83' priority_2='1' interface='false' sourceFile='ClientDatanodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$TriggerBlockReportResponseProto$Builder'></ClassStats><ClassStats bugs='0' size='1' interface='true' sourceFile='ClientDatanodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$TriggerBlockReportResponseProtoOrBuilder'></ClassStats><ClassStats bugs='0' size='982' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos'></ClassStats><ClassStats bugs='0' size='763' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$1'></ClassStats><ClassStats bugs='2' size='283' priority_1='1' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AbandonBlockRequestProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AbandonBlockRequestProto$1'></ClassStats><ClassStats bugs='0' size='283' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AbandonBlockRequestProto$Builder'></ClassStats><ClassStats bugs='0' size='12' interface='true' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AbandonBlockRequestProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='137' priority_1='1' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AbandonBlockResponseProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AbandonBlockResponseProto$1'></ClassStats><ClassStats bugs='1' size='83' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AbandonBlockResponseProto$Builder'></ClassStats><ClassStats bugs='0' size='1' interface='true' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AbandonBlockResponseProtoOrBuilder'></ClassStats><ClassStats bugs='0' size='38' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AddBlockFlagProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AddBlockFlagProto$1'></ClassStats><ClassStats bugs='2' size='401' priority_1='1' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AddBlockRequestProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AddBlockRequestProto$1'></ClassStats><ClassStats bugs='0' size='539' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AddBlockRequestProto$Builder'></ClassStats><ClassStats bugs='0' size='24' interface='true' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AddBlockRequestProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='177' priority_1='1' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AddBlockResponseProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AddBlockResponseProto$1'></ClassStats><ClassStats bugs='0' size='161' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AddBlockResponseProto$Builder'></ClassStats><ClassStats bugs='0' size='4' interface='true' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AddBlockResponseProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='199' priority_1='1' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AddCacheDirectiveRequestProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AddCacheDirectiveRequestProto$1'></ClassStats><ClassStats bugs='0' size='183' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AddCacheDirectiveRequestProto$Builder'></ClassStats><ClassStats bugs='0' size='6' interface='true' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AddCacheDirectiveRequestProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='165' priority_1='1' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AddCacheDirectiveResponseProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AddCacheDirectiveResponseProto$1'></ClassStats><ClassStats bugs='1' size='111' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AddCacheDirectiveResponseProto$Builder'></ClassStats><ClassStats bugs='0' size='3' interface='true' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AddCacheDirectiveResponseProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='151' priority_1='1' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AddCachePoolRequestProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AddCachePoolRequestProto$1'></ClassStats><ClassStats bugs='0' size='136' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AddCachePoolRequestProto$Builder'></ClassStats><ClassStats bugs='0' size='4' interface='true' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AddCachePoolRequestProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='116' priority_1='1' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AddCachePoolResponseProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AddCachePoolResponseProto$1'></ClassStats><ClassStats bugs='1' size='75' priority_3='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AddCachePoolResponseProto$Builder'></ClassStats><ClassStats bugs='0' size='1' interface='true' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AddCachePoolResponseProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='153' priority_1='1' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AllowSnapshotRequestProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AllowSnapshotRequestProto$1'></ClassStats><ClassStats bugs='1' size='110' priority_3='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AllowSnapshotRequestProto$Builder'></ClassStats><ClassStats bugs='0' size='4' interface='true' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AllowSnapshotRequestProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='116' priority_1='1' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AllowSnapshotResponseProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AllowSnapshotResponseProto$1'></ClassStats><ClassStats bugs='1' size='75' priority_3='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AllowSnapshotResponseProto$Builder'></ClassStats><ClassStats bugs='0' size='1' interface='true' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AllowSnapshotResponseProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='246' priority_1='1' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AppendRequestProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AppendRequestProto$1'></ClassStats><ClassStats bugs='1' size='209' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AppendRequestProto$Builder'></ClassStats><ClassStats bugs='0' size='9' interface='true' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AppendRequestProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='210' priority_1='1' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AppendResponseProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AppendResponseProto$1'></ClassStats><ClassStats bugs='0' size='233' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AppendResponseProto$Builder'></ClassStats><ClassStats bugs='0' size='7' interface='true' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$AppendResponseProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='198' priority_1='1' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CacheDirectiveEntryProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CacheDirectiveEntryProto$1'></ClassStats><ClassStats bugs='0' size='196' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CacheDirectiveEntryProto$Builder'></ClassStats><ClassStats bugs='0' size='7' interface='true' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CacheDirectiveEntryProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='191' priority_1='1' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CacheDirectiveInfoExpirationProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CacheDirectiveInfoExpirationProto$1'></ClassStats><ClassStats bugs='1' size='135' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CacheDirectiveInfoExpirationProto$Builder'></ClassStats><ClassStats bugs='0' size='5' interface='true' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CacheDirectiveInfoExpirationProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='299' priority_1='1' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CacheDirectiveInfoProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CacheDirectiveInfoProto$1'></ClassStats><ClassStats bugs='0' size='300' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CacheDirectiveInfoProto$Builder'></ClassStats><ClassStats bugs='0' size='14' interface='true' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CacheDirectiveInfoProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='269' priority_1='1' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CacheDirectiveStatsProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CacheDirectiveStatsProto$1'></ClassStats><ClassStats bugs='1' size='207' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CacheDirectiveStatsProto$Builder'></ClassStats><ClassStats bugs='0' size='11' interface='true' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CacheDirectiveStatsProtoOrBuilder'></ClassStats><ClassStats bugs='0' size='38' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CacheFlagProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CacheFlagProto$1'></ClassStats><ClassStats bugs='2' size='184' priority_1='1' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CachePoolEntryProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CachePoolEntryProto$1'></ClassStats><ClassStats bugs='0' size='195' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CachePoolEntryProto$Builder'></ClassStats><ClassStats bugs='0' size='7' interface='true' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CachePoolEntryProtoOrBuilder'></ClassStats><ClassStats bugs='4' size='311' priority_1='1' priority_2='1' priority_3='2' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CachePoolInfoProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CachePoolInfoProto$1'></ClassStats><ClassStats bugs='1' size='244' priority_3='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CachePoolInfoProto$Builder'></ClassStats><ClassStats bugs='0' size='18' interface='true' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CachePoolInfoProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='242' priority_1='1' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CachePoolStatsProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CachePoolStatsProto$1'></ClassStats><ClassStats bugs='1' size='166' priority_3='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CachePoolStatsProto$Builder'></ClassStats><ClassStats bugs='0' size='11' interface='true' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CachePoolStatsProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='181' priority_1='1' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CheckAccessRequestProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CheckAccessRequestProto$1'></ClassStats><ClassStats bugs='1' size='131' priority_3='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CheckAccessRequestProto$Builder'></ClassStats><ClassStats bugs='0' size='6' interface='true' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CheckAccessRequestProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='116' priority_1='1' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CheckAccessResponseProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CheckAccessResponseProto$1'></ClassStats><ClassStats bugs='1' size='75' priority_3='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CheckAccessResponseProto$Builder'></ClassStats><ClassStats bugs='0' size='1' interface='true' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CheckAccessResponseProtoOrBuilder'></ClassStats><ClassStats bugs='103' size='495' priority_3='103' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol'></ClassStats><ClassStats bugs='0' size='240' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$1'></ClassStats><ClassStats bugs='103' size='383' priority_3='103' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2'></ClassStats><ClassStats bugs='0' size='104' interface='true' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$BlockingInterface'></ClassStats><ClassStats bugs='0' size='458' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$BlockingStub'></ClassStats><ClassStats bugs='0' size='104' interface='true' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Interface'></ClassStats><ClassStats bugs='0' size='521' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$Stub'></ClassStats><ClassStats bugs='2' size='281' priority_1='1' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CompleteRequestProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CompleteRequestProto$1'></ClassStats><ClassStats bugs='0' size='282' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CompleteRequestProto$Builder'></ClassStats><ClassStats bugs='0' size='12' interface='true' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CompleteRequestProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='165' priority_1='1' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CompleteResponseProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CompleteResponseProto$1'></ClassStats><ClassStats bugs='1' size='111' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CompleteResponseProto$Builder'></ClassStats><ClassStats bugs='0' size='3' interface='true' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CompleteResponseProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='214' priority_1='1' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ConcatRequestProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ConcatRequestProto$1'></ClassStats><ClassStats bugs='1' size='196' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ConcatRequestProto$Builder'></ClassStats><ClassStats bugs='0' size='8' interface='true' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ConcatRequestProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='137' priority_1='1' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ConcatResponseProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ConcatResponseProto$1'></ClassStats><ClassStats bugs='1' size='83' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ConcatResponseProto$Builder'></ClassStats><ClassStats bugs='0' size='1' interface='true' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ConcatResponseProtoOrBuilder'></ClassStats><ClassStats bugs='0' size='58' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateFlagProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateFlagProto$1'></ClassStats><ClassStats bugs='3' size='487' priority_1='1' priority_2='1' priority_3='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateRequestProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateRequestProto$1'></ClassStats><ClassStats bugs='0' size='529' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateRequestProto$Builder'></ClassStats><ClassStats bugs='0' size='27' interface='true' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateRequestProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='175' priority_1='1' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateResponseProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateResponseProto$1'></ClassStats><ClassStats bugs='0' size='160' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateResponseProto$Builder'></ClassStats><ClassStats bugs='0' size='4' interface='true' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateResponseProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='186' priority_1='1' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateSnapshotRequestProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateSnapshotRequestProto$1'></ClassStats><ClassStats bugs='1' size='143' priority_3='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateSnapshotRequestProto$Builder'></ClassStats><ClassStats bugs='0' size='7' interface='true' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateSnapshotRequestProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='153' priority_1='1' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateSnapshotResponseProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateSnapshotResponseProto$1'></ClassStats><ClassStats bugs='1' size='110' priority_3='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateSnapshotResponseProto$Builder'></ClassStats><ClassStats bugs='0' size='4' interface='true' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateSnapshotResponseProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='245' priority_1='1' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateSymlinkRequestProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateSymlinkRequestProto$1'></ClassStats><ClassStats bugs='0' size='221' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateSymlinkRequestProto$Builder'></ClassStats><ClassStats bugs='0' size='12' interface='true' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateSymlinkRequestProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='116' priority_1='1' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateSymlinkResponseProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateSymlinkResponseProto$1'></ClassStats><ClassStats bugs='1' size='75' priority_3='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateSymlinkResponseProto$Builder'></ClassStats><ClassStats bugs='0' size='1' interface='true' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$CreateSymlinkResponseProtoOrBuilder'></ClassStats><ClassStats bugs='0' size='58' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DatanodeReportTypeProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DatanodeReportTypeProto$1'></ClassStats><ClassStats bugs='2' size='213' priority_1='1' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DatanodeStorageReportProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DatanodeStorageReportProto$1'></ClassStats><ClassStats bugs='0' size='308' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DatanodeStorageReportProto$Builder'></ClassStats><ClassStats bugs='0' size='9' interface='true' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DatanodeStorageReportProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='207' priority_1='1' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DeleteRequestProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DeleteRequestProto$1'></ClassStats><ClassStats bugs='1' size='161' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DeleteRequestProto$Builder'></ClassStats><ClassStats bugs='0' size='6' interface='true' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DeleteRequestProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='165' priority_1='1' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DeleteResponseProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DeleteResponseProto$1'></ClassStats><ClassStats bugs='1' size='111' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DeleteResponseProto$Builder'></ClassStats><ClassStats bugs='0' size='3' interface='true' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DeleteResponseProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='187' priority_1='1' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DeleteSnapshotRequestProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DeleteSnapshotRequestProto$1'></ClassStats><ClassStats bugs='1' size='143' priority_3='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DeleteSnapshotRequestProto$Builder'></ClassStats><ClassStats bugs='0' size='7' interface='true' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DeleteSnapshotRequestProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='116' priority_1='1' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DeleteSnapshotResponseProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DeleteSnapshotResponseProto$1'></ClassStats><ClassStats bugs='1' size='75' priority_3='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DeleteSnapshotResponseProto$Builder'></ClassStats><ClassStats bugs='0' size='1' interface='true' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DeleteSnapshotResponseProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='153' priority_1='1' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DisallowSnapshotRequestProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DisallowSnapshotRequestProto$1'></ClassStats><ClassStats bugs='1' size='110' priority_3='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DisallowSnapshotRequestProto$Builder'></ClassStats><ClassStats bugs='0' size='4' interface='true' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DisallowSnapshotRequestProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='116' priority_1='1' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DisallowSnapshotResponseProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DisallowSnapshotResponseProto$1'></ClassStats><ClassStats bugs='1' size='75' priority_3='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DisallowSnapshotResponseProto$Builder'></ClassStats><ClassStats bugs='0' size='1' interface='true' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$DisallowSnapshotResponseProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='137' priority_1='1' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$FinalizeUpgradeRequestProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$FinalizeUpgradeRequestProto$1'></ClassStats><ClassStats bugs='1' size='83' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$FinalizeUpgradeRequestProto$Builder'></ClassStats><ClassStats bugs='0' size='1' interface='true' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$FinalizeUpgradeRequestProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='137' priority_1='1' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$FinalizeUpgradeResponseProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$FinalizeUpgradeResponseProto$1'></ClassStats><ClassStats bugs='1' size='83' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$FinalizeUpgradeResponseProto$Builder'></ClassStats><ClassStats bugs='0' size='1' interface='true' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$FinalizeUpgradeResponseProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='234' priority_1='1' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$FsyncRequestProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$FsyncRequestProto$1'></ClassStats><ClassStats bugs='1' size='179' priority_3='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$FsyncRequestProto$Builder'></ClassStats><ClassStats bugs='0' size='11' interface='true' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$FsyncRequestProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='116' priority_1='1' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$FsyncResponseProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$FsyncResponseProto$1'></ClassStats><ClassStats bugs='1' size='75' priority_3='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$FsyncResponseProto$Builder'></ClassStats><ClassStats bugs='0' size='1' interface='true' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$FsyncResponseProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='416' priority_1='1' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetAdditionalDatanodeRequestProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetAdditionalDatanodeRequestProto$1'></ClassStats><ClassStats bugs='0' size='660' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetAdditionalDatanodeRequestProto$Builder'></ClassStats><ClassStats bugs='0' size='28' interface='true' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetAdditionalDatanodeRequestProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='177' priority_1='1' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetAdditionalDatanodeResponseProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetAdditionalDatanodeResponseProto$1'></ClassStats><ClassStats bugs='0' size='161' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetAdditionalDatanodeResponseProto$Builder'></ClassStats><ClassStats bugs='0' size='4' interface='true' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetAdditionalDatanodeResponseProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='233' priority_1='1' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetBlockLocationsRequestProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetBlockLocationsRequestProto$1'></ClassStats><ClassStats bugs='1' size='185' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetBlockLocationsRequestProto$Builder'></ClassStats><ClassStats bugs='0' size='8' interface='true' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetBlockLocationsRequestProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='175' priority_1='1' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetBlockLocationsResponseProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetBlockLocationsResponseProto$1'></ClassStats><ClassStats bugs='0' size='160' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetBlockLocationsResponseProto$Builder'></ClassStats><ClassStats bugs='0' size='4' interface='true' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetBlockLocationsResponseProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='153' priority_1='1' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetContentSummaryRequestProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetContentSummaryRequestProto$1'></ClassStats><ClassStats bugs='1' size='110' priority_3='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetContentSummaryRequestProto$Builder'></ClassStats><ClassStats bugs='0' size='4' interface='true' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetContentSummaryRequestProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='153' priority_1='1' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetContentSummaryResponseProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetContentSummaryResponseProto$1'></ClassStats><ClassStats bugs='0' size='137' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetContentSummaryResponseProto$Builder'></ClassStats><ClassStats bugs='0' size='4' interface='true' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetContentSummaryResponseProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='116' priority_1='1' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetCurrentEditLogTxidRequestProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetCurrentEditLogTxidRequestProto$1'></ClassStats><ClassStats bugs='1' size='75' priority_3='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetCurrentEditLogTxidRequestProto$Builder'></ClassStats><ClassStats bugs='0' size='1' interface='true' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetCurrentEditLogTxidRequestProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='143' priority_1='1' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetCurrentEditLogTxidResponseProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetCurrentEditLogTxidResponseProto$1'></ClassStats><ClassStats bugs='1' size='95' priority_3='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetCurrentEditLogTxidResponseProto$Builder'></ClassStats><ClassStats bugs='0' size='3' interface='true' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetCurrentEditLogTxidResponseProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='116' priority_1='1' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDataEncryptionKeyRequestProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDataEncryptionKeyRequestProto$1'></ClassStats><ClassStats bugs='1' size='75' priority_3='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDataEncryptionKeyRequestProto$Builder'></ClassStats><ClassStats bugs='0' size='1' interface='true' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDataEncryptionKeyRequestProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='152' priority_1='1' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDataEncryptionKeyResponseProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDataEncryptionKeyResponseProto$1'></ClassStats><ClassStats bugs='0' size='137' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDataEncryptionKeyResponseProto$Builder'></ClassStats><ClassStats bugs='0' size='4' interface='true' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDataEncryptionKeyResponseProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='170' priority_1='1' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDatanodeReportRequestProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDatanodeReportRequestProto$1'></ClassStats><ClassStats bugs='1' size='114' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDatanodeReportRequestProto$Builder'></ClassStats><ClassStats bugs='0' size='3' interface='true' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDatanodeReportRequestProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='174' priority_1='1' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDatanodeReportResponseProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDatanodeReportResponseProto$1'></ClassStats><ClassStats bugs='1' size='232' priority_3='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDatanodeReportResponseProto$Builder'></ClassStats><ClassStats bugs='0' size='6' interface='true' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDatanodeReportResponseProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='170' priority_1='1' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDatanodeStorageReportRequestProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDatanodeStorageReportRequestProto$1'></ClassStats><ClassStats bugs='1' size='114' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDatanodeStorageReportRequestProto$Builder'></ClassStats><ClassStats bugs='0' size='3' interface='true' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDatanodeStorageReportRequestProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='174' priority_1='1' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDatanodeStorageReportResponseProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDatanodeStorageReportResponseProto$1'></ClassStats><ClassStats bugs='1' size='232' priority_3='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDatanodeStorageReportResponseProto$Builder'></ClassStats><ClassStats bugs='0' size='6' interface='true' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetDatanodeStorageReportResponseProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='143' priority_1='1' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetEditsFromTxidRequestProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetEditsFromTxidRequestProto$1'></ClassStats><ClassStats bugs='1' size='95' priority_3='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetEditsFromTxidRequestProto$Builder'></ClassStats><ClassStats bugs='0' size='3' interface='true' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetEditsFromTxidRequestProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='153' priority_1='1' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetEditsFromTxidResponseProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetEditsFromTxidResponseProto$1'></ClassStats><ClassStats bugs='0' size='137' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetEditsFromTxidResponseProto$Builder'></ClassStats><ClassStats bugs='0' size='4' interface='true' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetEditsFromTxidResponseProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='181' priority_1='1' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFileInfoRequestProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFileInfoRequestProto$1'></ClassStats><ClassStats bugs='1' size='137' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFileInfoRequestProto$Builder'></ClassStats><ClassStats bugs='0' size='4' interface='true' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFileInfoRequestProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='175' priority_1='1' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFileInfoResponseProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFileInfoResponseProto$1'></ClassStats><ClassStats bugs='0' size='160' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFileInfoResponseProto$Builder'></ClassStats><ClassStats bugs='0' size='4' interface='true' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFileInfoResponseProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='153' priority_1='1' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFileLinkInfoRequestProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFileLinkInfoRequestProto$1'></ClassStats><ClassStats bugs='1' size='110' priority_3='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFileLinkInfoRequestProto$Builder'></ClassStats><ClassStats bugs='0' size='4' interface='true' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFileLinkInfoRequestProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='152' priority_1='1' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFileLinkInfoResponseProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFileLinkInfoResponseProto$1'></ClassStats><ClassStats bugs='0' size='137' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFileLinkInfoResponseProto$Builder'></ClassStats><ClassStats bugs='0' size='4' interface='true' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFileLinkInfoResponseProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='137' priority_1='1' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsECBlockGroupStatsRequestProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsECBlockGroupStatsRequestProto$1'></ClassStats><ClassStats bugs='1' size='83' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsECBlockGroupStatsRequestProto$Builder'></ClassStats><ClassStats bugs='0' size='1' interface='true' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsECBlockGroupStatsRequestProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='269' priority_1='1' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsECBlockGroupStatsResponseProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsECBlockGroupStatsResponseProto$1'></ClassStats><ClassStats bugs='1' size='207' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsECBlockGroupStatsResponseProto$Builder'></ClassStats><ClassStats bugs='0' size='11' interface='true' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsECBlockGroupStatsResponseProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='137' priority_1='1' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsReplicatedBlockStatsRequestProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsReplicatedBlockStatsRequestProto$1'></ClassStats><ClassStats bugs='1' size='83' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsReplicatedBlockStatsRequestProto$Builder'></ClassStats><ClassStats bugs='0' size='1' interface='true' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsReplicatedBlockStatsRequestProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='295' priority_1='1' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsReplicatedBlockStatsResponseProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsReplicatedBlockStatsResponseProto$1'></ClassStats><ClassStats bugs='1' size='231' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsReplicatedBlockStatsResponseProto$Builder'></ClassStats><ClassStats bugs='0' size='13' interface='true' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsReplicatedBlockStatsResponseProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='364' priority_1='1' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsStatsResponseProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsStatsResponseProto$1'></ClassStats><ClassStats bugs='1' size='297' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsStatsResponseProto$Builder'></ClassStats><ClassStats bugs='0' size='19' interface='true' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsStatsResponseProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='137' priority_1='1' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsStatusRequestProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsStatusRequestProto$1'></ClassStats><ClassStats bugs='1' size='83' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsStatusRequestProto$Builder'></ClassStats><ClassStats bugs='0' size='1' interface='true' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFsStatusRequestProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='153' priority_1='1' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetLinkTargetRequestProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetLinkTargetRequestProto$1'></ClassStats><ClassStats bugs='1' size='110' priority_3='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetLinkTargetRequestProto$Builder'></ClassStats><ClassStats bugs='0' size='4' interface='true' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetLinkTargetRequestProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='152' priority_1='1' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetLinkTargetResponseProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetLinkTargetResponseProto$1'></ClassStats><ClassStats bugs='1' size='110' priority_3='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetLinkTargetResponseProto$Builder'></ClassStats><ClassStats bugs='0' size='4' interface='true' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetLinkTargetResponseProtoOrBuilder'></ClassStats><ClassStats bugs='3' size='233' priority_1='1' priority_2='1' priority_3='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetListingRequestProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetListingRequestProto$1'></ClassStats><ClassStats bugs='1' size='188' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetListingRequestProto$Builder'></ClassStats><ClassStats bugs='0' size='8' interface='true' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetListingRequestProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='175' priority_1='1' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetListingResponseProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetListingResponseProto$1'></ClassStats><ClassStats bugs='0' size='160' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetListingResponseProto$Builder'></ClassStats><ClassStats bugs='0' size='4' interface='true' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetListingResponseProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='201' priority_1='1' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetLocatedFileInfoRequestProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetLocatedFileInfoRequestProto$1'></ClassStats><ClassStats bugs='1' size='157' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetLocatedFileInfoRequestProto$Builder'></ClassStats><ClassStats bugs='0' size='6' interface='true' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetLocatedFileInfoRequestProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='175' priority_1='1' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetLocatedFileInfoResponseProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetLocatedFileInfoResponseProto$1'></ClassStats><ClassStats bugs='0' size='160' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetLocatedFileInfoResponseProto$Builder'></ClassStats><ClassStats bugs='0' size='4' interface='true' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetLocatedFileInfoResponseProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='181' priority_1='1' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetPreferredBlockSizeRequestProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetPreferredBlockSizeRequestProto$1'></ClassStats><ClassStats bugs='1' size='137' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetPreferredBlockSizeRequestProto$Builder'></ClassStats><ClassStats bugs='0' size='4' interface='true' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetPreferredBlockSizeRequestProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='165' priority_1='1' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetPreferredBlockSizeResponseProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetPreferredBlockSizeResponseProto$1'></ClassStats><ClassStats bugs='1' size='111' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetPreferredBlockSizeResponseProto$Builder'></ClassStats><ClassStats bugs='0' size='3' interface='true' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetPreferredBlockSizeResponseProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='153' priority_1='1' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetQuotaUsageRequestProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetQuotaUsageRequestProto$1'></ClassStats><ClassStats bugs='1' size='110' priority_3='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetQuotaUsageRequestProto$Builder'></ClassStats><ClassStats bugs='0' size='4' interface='true' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetQuotaUsageRequestProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='153' priority_1='1' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetQuotaUsageResponseProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetQuotaUsageResponseProto$1'></ClassStats><ClassStats bugs='0' size='137' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetQuotaUsageResponseProto$Builder'></ClassStats><ClassStats bugs='0' size='4' interface='true' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetQuotaUsageResponseProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='137' priority_1='1' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetServerDefaultsRequestProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetServerDefaultsRequestProto$1'></ClassStats><ClassStats bugs='1' size='83' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetServerDefaultsRequestProto$Builder'></ClassStats><ClassStats bugs='0' size='1' interface='true' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetServerDefaultsRequestProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='177' priority_1='1' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetServerDefaultsResponseProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetServerDefaultsResponseProto$1'></ClassStats><ClassStats bugs='0' size='161' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetServerDefaultsResponseProto$Builder'></ClassStats><ClassStats bugs='0' size='4' interface='true' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetServerDefaultsResponseProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='301' priority_1='1' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshotDiffReportListingRequestProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshotDiffReportListingRequestProto$1'></ClassStats><ClassStats bugs='0' size='310' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshotDiffReportListingRequestProto$Builder'></ClassStats><ClassStats bugs='0' size='13' interface='true' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshotDiffReportListingRequestProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='177' priority_1='1' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshotDiffReportListingResponseProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshotDiffReportListingResponseProto$1'></ClassStats><ClassStats bugs='0' size='161' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshotDiffReportListingResponseProto$Builder'></ClassStats><ClassStats bugs='0' size='4' interface='true' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshotDiffReportListingResponseProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='265' priority_1='1' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshotDiffReportRequestProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshotDiffReportRequestProto$1'></ClassStats><ClassStats bugs='1' size='237' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshotDiffReportRequestProto$Builder'></ClassStats><ClassStats bugs='0' size='10' interface='true' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshotDiffReportRequestProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='177' priority_1='1' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshotDiffReportResponseProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshotDiffReportResponseProto$1'></ClassStats><ClassStats bugs='0' size='161' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshotDiffReportResponseProto$Builder'></ClassStats><ClassStats bugs='0' size='4' interface='true' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshotDiffReportResponseProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='137' priority_1='1' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshottableDirListingRequestProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshottableDirListingRequestProto$1'></ClassStats><ClassStats bugs='1' size='83' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshottableDirListingRequestProto$Builder'></ClassStats><ClassStats bugs='0' size='1' interface='true' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshottableDirListingRequestProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='175' priority_1='1' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshottableDirListingResponseProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshottableDirListingResponseProto$1'></ClassStats><ClassStats bugs='0' size='160' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshottableDirListingResponseProto$Builder'></ClassStats><ClassStats bugs='0' size='4' interface='true' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetSnapshottableDirListingResponseProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='137' priority_1='1' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetStoragePoliciesRequestProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetStoragePoliciesRequestProto$1'></ClassStats><ClassStats bugs='1' size='83' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetStoragePoliciesRequestProto$Builder'></ClassStats><ClassStats bugs='0' size='1' interface='true' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetStoragePoliciesRequestProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='174' priority_1='1' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetStoragePoliciesResponseProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetStoragePoliciesResponseProto$1'></ClassStats><ClassStats bugs='1' size='232' priority_3='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetStoragePoliciesResponseProto$Builder'></ClassStats><ClassStats bugs='0' size='6' interface='true' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetStoragePoliciesResponseProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='181' priority_1='1' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetStoragePolicyRequestProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetStoragePolicyRequestProto$1'></ClassStats><ClassStats bugs='1' size='137' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetStoragePolicyRequestProto$Builder'></ClassStats><ClassStats bugs='0' size='4' interface='true' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetStoragePolicyRequestProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='177' priority_1='1' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetStoragePolicyResponseProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetStoragePolicyResponseProto$1'></ClassStats><ClassStats bugs='0' size='161' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetStoragePolicyResponseProto$Builder'></ClassStats><ClassStats bugs='0' size='4' interface='true' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetStoragePolicyResponseProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='181' priority_1='1' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$IsFileClosedRequestProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$IsFileClosedRequestProto$1'></ClassStats><ClassStats bugs='1' size='137' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$IsFileClosedRequestProto$Builder'></ClassStats><ClassStats bugs='0' size='4' interface='true' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$IsFileClosedRequestProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='165' priority_1='1' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$IsFileClosedResponseProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$IsFileClosedResponseProto$1'></ClassStats><ClassStats bugs='1' size='111' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$IsFileClosedResponseProto$Builder'></ClassStats><ClassStats bugs='0' size='3' interface='true' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$IsFileClosedResponseProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='203' priority_1='1' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListCacheDirectivesRequestProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListCacheDirectivesRequestProto$1'></ClassStats><ClassStats bugs='0' size='185' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListCacheDirectivesRequestProto$Builder'></ClassStats><ClassStats bugs='0' size='6' interface='true' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListCacheDirectivesRequestProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='186' priority_1='1' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListCacheDirectivesResponseProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListCacheDirectivesResponseProto$1'></ClassStats><ClassStats bugs='0' size='217' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListCacheDirectivesResponseProto$Builder'></ClassStats><ClassStats bugs='0' size='8' interface='true' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListCacheDirectivesResponseProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='153' priority_1='1' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListCachePoolsRequestProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListCachePoolsRequestProto$1'></ClassStats><ClassStats bugs='1' size='110' priority_3='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListCachePoolsRequestProto$Builder'></ClassStats><ClassStats bugs='0' size='4' interface='true' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListCachePoolsRequestProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='186' priority_1='1' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListCachePoolsResponseProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListCachePoolsResponseProto$1'></ClassStats><ClassStats bugs='0' size='217' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListCachePoolsResponseProto$Builder'></ClassStats><ClassStats bugs='0' size='8' interface='true' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListCachePoolsResponseProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='220' priority_1='1' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListCorruptFileBlocksRequestProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListCorruptFileBlocksRequestProto$1'></ClassStats><ClassStats bugs='1' size='185' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListCorruptFileBlocksRequestProto$Builder'></ClassStats><ClassStats bugs='0' size='7' interface='true' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListCorruptFileBlocksRequestProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='177' priority_1='1' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListCorruptFileBlocksResponseProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListCorruptFileBlocksResponseProto$1'></ClassStats><ClassStats bugs='0' size='161' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListCorruptFileBlocksResponseProto$Builder'></ClassStats><ClassStats bugs='0' size='4' interface='true' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListCorruptFileBlocksResponseProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='225' priority_1='1' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListOpenFilesRequestProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListOpenFilesRequestProto$1'></ClassStats><ClassStats bugs='1' size='168' priority_3='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListOpenFilesRequestProto$Builder'></ClassStats><ClassStats bugs='0' size='9' interface='true' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListOpenFilesRequestProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='236' priority_1='1' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListOpenFilesResponseProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListOpenFilesResponseProto$1'></ClassStats><ClassStats bugs='0' size='258' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListOpenFilesResponseProto$Builder'></ClassStats><ClassStats bugs='0' size='11' interface='true' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ListOpenFilesResponseProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='181' priority_1='1' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$MetaSaveRequestProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$MetaSaveRequestProto$1'></ClassStats><ClassStats bugs='1' size='137' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$MetaSaveRequestProto$Builder'></ClassStats><ClassStats bugs='0' size='4' interface='true' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$MetaSaveRequestProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='137' priority_1='1' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$MetaSaveResponseProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$MetaSaveResponseProto$1'></ClassStats><ClassStats bugs='1' size='83' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$MetaSaveResponseProto$Builder'></ClassStats><ClassStats bugs='0' size='1' interface='true' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$MetaSaveResponseProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='280' priority_1='1' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$MkdirsRequestProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$MkdirsRequestProto$1'></ClassStats><ClassStats bugs='0' size='308' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$MkdirsRequestProto$Builder'></ClassStats><ClassStats bugs='0' size='12' interface='true' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$MkdirsRequestProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='165' priority_1='1' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$MkdirsResponseProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$MkdirsResponseProto$1'></ClassStats><ClassStats bugs='1' size='111' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$MkdirsResponseProto$Builder'></ClassStats><ClassStats bugs='0' size='3' interface='true' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$MkdirsResponseProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='199' priority_1='1' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ModifyCacheDirectiveRequestProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ModifyCacheDirectiveRequestProto$1'></ClassStats><ClassStats bugs='0' size='183' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ModifyCacheDirectiveRequestProto$Builder'></ClassStats><ClassStats bugs='0' size='6' interface='true' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ModifyCacheDirectiveRequestProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='137' priority_1='1' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ModifyCacheDirectiveResponseProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ModifyCacheDirectiveResponseProto$1'></ClassStats><ClassStats bugs='1' size='83' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ModifyCacheDirectiveResponseProto$Builder'></ClassStats><ClassStats bugs='0' size='1' interface='true' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ModifyCacheDirectiveResponseProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='151' priority_1='1' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ModifyCachePoolRequestProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ModifyCachePoolRequestProto$1'></ClassStats><ClassStats bugs='0' size='136' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ModifyCachePoolRequestProto$Builder'></ClassStats><ClassStats bugs='0' size='4' interface='true' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ModifyCachePoolRequestProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='116' priority_1='1' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ModifyCachePoolResponseProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ModifyCachePoolResponseProto$1'></ClassStats><ClassStats bugs='1' size='75' priority_3='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ModifyCachePoolResponseProto$Builder'></ClassStats><ClassStats bugs='0' size='1' interface='true' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ModifyCachePoolResponseProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='246' priority_1='1' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$OpenFilesBatchResponseProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$OpenFilesBatchResponseProto$1'></ClassStats><ClassStats bugs='1' size='195' priority_3='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$OpenFilesBatchResponseProto$Builder'></ClassStats><ClassStats bugs='0' size='12' interface='true' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$OpenFilesBatchResponseProtoOrBuilder'></ClassStats><ClassStats bugs='0' size='42' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$OpenFilesTypeProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$OpenFilesTypeProto$1'></ClassStats><ClassStats bugs='2' size='223' priority_1='1' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RecoverLeaseRequestProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RecoverLeaseRequestProto$1'></ClassStats><ClassStats bugs='1' size='187' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RecoverLeaseRequestProto$Builder'></ClassStats><ClassStats bugs='0' size='7' interface='true' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RecoverLeaseRequestProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='165' priority_1='1' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RecoverLeaseResponseProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RecoverLeaseResponseProto$1'></ClassStats><ClassStats bugs='1' size='111' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RecoverLeaseResponseProto$Builder'></ClassStats><ClassStats bugs='0' size='3' interface='true' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RecoverLeaseResponseProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='137' priority_1='1' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RefreshNodesRequestProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RefreshNodesRequestProto$1'></ClassStats><ClassStats bugs='1' size='83' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RefreshNodesRequestProto$Builder'></ClassStats><ClassStats bugs='0' size='1' interface='true' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RefreshNodesRequestProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='137' priority_1='1' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RefreshNodesResponseProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RefreshNodesResponseProto$1'></ClassStats><ClassStats bugs='1' size='83' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RefreshNodesResponseProto$Builder'></ClassStats><ClassStats bugs='0' size='1' interface='true' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RefreshNodesResponseProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='165' priority_1='1' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RemoveCacheDirectiveRequestProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RemoveCacheDirectiveRequestProto$1'></ClassStats><ClassStats bugs='1' size='111' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RemoveCacheDirectiveRequestProto$Builder'></ClassStats><ClassStats bugs='0' size='3' interface='true' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RemoveCacheDirectiveRequestProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='137' priority_1='1' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RemoveCacheDirectiveResponseProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RemoveCacheDirectiveResponseProto$1'></ClassStats><ClassStats bugs='1' size='83' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RemoveCacheDirectiveResponseProto$Builder'></ClassStats><ClassStats bugs='0' size='1' interface='true' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RemoveCacheDirectiveResponseProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='153' priority_1='1' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RemoveCachePoolRequestProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RemoveCachePoolRequestProto$1'></ClassStats><ClassStats bugs='1' size='110' priority_3='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RemoveCachePoolRequestProto$Builder'></ClassStats><ClassStats bugs='0' size='4' interface='true' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RemoveCachePoolRequestProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='116' priority_1='1' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RemoveCachePoolResponseProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RemoveCachePoolResponseProto$1'></ClassStats><ClassStats bugs='1' size='75' priority_3='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RemoveCachePoolResponseProto$Builder'></ClassStats><ClassStats bugs='0' size='1' interface='true' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RemoveCachePoolResponseProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='272' priority_1='1' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$Rename2RequestProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$Rename2RequestProto$1'></ClassStats><ClassStats bugs='1' size='233' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$Rename2RequestProto$Builder'></ClassStats><ClassStats bugs='0' size='11' interface='true' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$Rename2RequestProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='137' priority_1='1' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$Rename2ResponseProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$Rename2ResponseProto$1'></ClassStats><ClassStats bugs='1' size='83' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$Rename2ResponseProto$Builder'></ClassStats><ClassStats bugs='0' size='1' interface='true' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$Rename2ResponseProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='223' priority_1='1' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenameRequestProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenameRequestProto$1'></ClassStats><ClassStats bugs='1' size='187' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenameRequestProto$Builder'></ClassStats><ClassStats bugs='0' size='7' interface='true' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenameRequestProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='165' priority_1='1' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenameResponseProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenameResponseProto$1'></ClassStats><ClassStats bugs='1' size='111' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenameResponseProto$Builder'></ClassStats><ClassStats bugs='0' size='3' interface='true' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenameResponseProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='221' priority_1='1' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenameSnapshotRequestProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenameSnapshotRequestProto$1'></ClassStats><ClassStats bugs='1' size='176' priority_3='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenameSnapshotRequestProto$Builder'></ClassStats><ClassStats bugs='0' size='10' interface='true' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenameSnapshotRequestProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='116' priority_1='1' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenameSnapshotResponseProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenameSnapshotResponseProto$1'></ClassStats><ClassStats bugs='1' size='75' priority_3='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenameSnapshotResponseProto$Builder'></ClassStats><ClassStats bugs='0' size='1' interface='true' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenameSnapshotResponseProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='181' priority_1='1' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenewLeaseRequestProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenewLeaseRequestProto$1'></ClassStats><ClassStats bugs='1' size='137' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenewLeaseRequestProto$Builder'></ClassStats><ClassStats bugs='0' size='4' interface='true' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenewLeaseRequestProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='137' priority_1='1' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenewLeaseResponseProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenewLeaseResponseProto$1'></ClassStats><ClassStats bugs='1' size='83' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenewLeaseResponseProto$Builder'></ClassStats><ClassStats bugs='0' size='1' interface='true' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenewLeaseResponseProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='174' priority_1='1' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ReportBadBlocksRequestProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ReportBadBlocksRequestProto$1'></ClassStats><ClassStats bugs='1' size='232' priority_3='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ReportBadBlocksRequestProto$Builder'></ClassStats><ClassStats bugs='0' size='6' interface='true' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ReportBadBlocksRequestProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='137' priority_1='1' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ReportBadBlocksResponseProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ReportBadBlocksResponseProto$1'></ClassStats><ClassStats bugs='1' size='83' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ReportBadBlocksResponseProto$Builder'></ClassStats><ClassStats bugs='0' size='1' interface='true' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ReportBadBlocksResponseProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='181' priority_1='1' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RestoreFailedStorageRequestProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RestoreFailedStorageRequestProto$1'></ClassStats><ClassStats bugs='1' size='137' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RestoreFailedStorageRequestProto$Builder'></ClassStats><ClassStats bugs='0' size='4' interface='true' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RestoreFailedStorageRequestProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='165' priority_1='1' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RestoreFailedStorageResponseProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RestoreFailedStorageResponseProto$1'></ClassStats><ClassStats bugs='1' size='111' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RestoreFailedStorageResponseProto$Builder'></ClassStats><ClassStats bugs='0' size='3' interface='true' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RestoreFailedStorageResponseProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='137' priority_1='1' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RollEditsRequestProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RollEditsRequestProto$1'></ClassStats><ClassStats bugs='1' size='83' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RollEditsRequestProto$Builder'></ClassStats><ClassStats bugs='0' size='1' interface='true' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RollEditsRequestProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='165' priority_1='1' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RollEditsResponseProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RollEditsResponseProto$1'></ClassStats><ClassStats bugs='1' size='111' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RollEditsResponseProto$Builder'></ClassStats><ClassStats bugs='0' size='3' interface='true' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RollEditsResponseProtoOrBuilder'></ClassStats><ClassStats bugs='0' size='46' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RollingUpgradeActionProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RollingUpgradeActionProto$1'></ClassStats><ClassStats bugs='2' size='254' priority_1='1' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RollingUpgradeInfoProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RollingUpgradeInfoProto$1'></ClassStats><ClassStats bugs='0' size='233' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RollingUpgradeInfoProto$Builder'></ClassStats><ClassStats bugs='0' size='10' interface='true' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RollingUpgradeInfoProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='170' priority_1='1' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RollingUpgradeRequestProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RollingUpgradeRequestProto$1'></ClassStats><ClassStats bugs='1' size='114' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RollingUpgradeRequestProto$Builder'></ClassStats><ClassStats bugs='0' size='3' interface='true' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RollingUpgradeRequestProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='175' priority_1='1' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RollingUpgradeResponseProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RollingUpgradeResponseProto$1'></ClassStats><ClassStats bugs='0' size='160' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RollingUpgradeResponseProto$Builder'></ClassStats><ClassStats bugs='0' size='4' interface='true' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RollingUpgradeResponseProtoOrBuilder'></ClassStats><ClassStats bugs='0' size='50' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SafeModeActionProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SafeModeActionProto$1'></ClassStats><ClassStats bugs='2' size='185' priority_1='1' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SaveNamespaceRequestProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SaveNamespaceRequestProto$1'></ClassStats><ClassStats bugs='1' size='131' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SaveNamespaceRequestProto$Builder'></ClassStats><ClassStats bugs='0' size='5' interface='true' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SaveNamespaceRequestProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='162' priority_1='1' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SaveNamespaceResponseProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SaveNamespaceResponseProto$1'></ClassStats><ClassStats bugs='1' size='110' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SaveNamespaceResponseProto$Builder'></ClassStats><ClassStats bugs='0' size='3' interface='true' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SaveNamespaceResponseProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='143' priority_1='1' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetBalancerBandwidthRequestProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetBalancerBandwidthRequestProto$1'></ClassStats><ClassStats bugs='1' size='95' priority_3='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetBalancerBandwidthRequestProto$Builder'></ClassStats><ClassStats bugs='0' size='3' interface='true' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetBalancerBandwidthRequestProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='116' priority_1='1' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetBalancerBandwidthResponseProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetBalancerBandwidthResponseProto$1'></ClassStats><ClassStats bugs='1' size='75' priority_3='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetBalancerBandwidthResponseProto$Builder'></ClassStats><ClassStats bugs='0' size='1' interface='true' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetBalancerBandwidthResponseProtoOrBuilder'></ClassStats><ClassStats bugs='3' size='259' priority_1='1' priority_2='1' priority_3='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetOwnerRequestProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetOwnerRequestProto$1'></ClassStats><ClassStats bugs='1' size='233' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetOwnerRequestProto$Builder'></ClassStats><ClassStats bugs='0' size='10' interface='true' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetOwnerRequestProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='137' priority_1='1' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetOwnerResponseProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetOwnerResponseProto$1'></ClassStats><ClassStats bugs='1' size='83' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetOwnerResponseProto$Builder'></ClassStats><ClassStats bugs='0' size='1' interface='true' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetOwnerResponseProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='219' priority_1='1' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetPermissionRequestProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetPermissionRequestProto$1'></ClassStats><ClassStats bugs='0' size='211' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetPermissionRequestProto$Builder'></ClassStats><ClassStats bugs='0' size='7' interface='true' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetPermissionRequestProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='137' priority_1='1' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetPermissionResponseProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetPermissionResponseProto$1'></ClassStats><ClassStats bugs='1' size='83' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetPermissionResponseProto$Builder'></ClassStats><ClassStats bugs='0' size='1' interface='true' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetPermissionResponseProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='229' priority_1='1' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetQuotaRequestProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetQuotaRequestProto$1'></ClassStats><ClassStats bugs='1' size='166' priority_3='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetQuotaRequestProto$Builder'></ClassStats><ClassStats bugs='0' size='10' interface='true' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetQuotaRequestProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='116' priority_1='1' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetQuotaResponseProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetQuotaResponseProto$1'></ClassStats><ClassStats bugs='1' size='75' priority_3='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetQuotaResponseProto$Builder'></ClassStats><ClassStats bugs='0' size='1' interface='true' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetQuotaResponseProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='207' priority_1='1' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetReplicationRequestProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetReplicationRequestProto$1'></ClassStats><ClassStats bugs='1' size='161' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetReplicationRequestProto$Builder'></ClassStats><ClassStats bugs='0' size='6' interface='true' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetReplicationRequestProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='165' priority_1='1' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetReplicationResponseProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetReplicationResponseProto$1'></ClassStats><ClassStats bugs='1' size='111' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetReplicationResponseProto$Builder'></ClassStats><ClassStats bugs='0' size='3' interface='true' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetReplicationResponseProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='192' priority_1='1' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetSafeModeRequestProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetSafeModeRequestProto$1'></ClassStats><ClassStats bugs='1' size='136' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetSafeModeRequestProto$Builder'></ClassStats><ClassStats bugs='0' size='5' interface='true' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetSafeModeRequestProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='165' priority_1='1' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetSafeModeResponseProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetSafeModeResponseProto$1'></ClassStats><ClassStats bugs='1' size='111' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetSafeModeResponseProto$Builder'></ClassStats><ClassStats bugs='0' size='3' interface='true' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetSafeModeResponseProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='223' priority_1='1' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetStoragePolicyRequestProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetStoragePolicyRequestProto$1'></ClassStats><ClassStats bugs='1' size='187' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetStoragePolicyRequestProto$Builder'></ClassStats><ClassStats bugs='0' size='7' interface='true' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetStoragePolicyRequestProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='137' priority_1='1' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetStoragePolicyResponseProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetStoragePolicyResponseProto$1'></ClassStats><ClassStats bugs='1' size='83' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetStoragePolicyResponseProto$Builder'></ClassStats><ClassStats bugs='0' size='1' interface='true' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetStoragePolicyResponseProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='202' priority_1='1' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetTimesRequestProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetTimesRequestProto$1'></ClassStats><ClassStats bugs='1' size='145' priority_3='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetTimesRequestProto$Builder'></ClassStats><ClassStats bugs='0' size='8' interface='true' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetTimesRequestProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='116' priority_1='1' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetTimesResponseProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetTimesResponseProto$1'></ClassStats><ClassStats bugs='1' size='75' priority_3='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetTimesResponseProto$Builder'></ClassStats><ClassStats bugs='0' size='1' interface='true' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$SetTimesResponseProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='249' priority_1='1' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$TruncateRequestProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$TruncateRequestProto$1'></ClassStats><ClassStats bugs='1' size='211' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$TruncateRequestProto$Builder'></ClassStats><ClassStats bugs='0' size='9' interface='true' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$TruncateRequestProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='165' priority_1='1' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$TruncateResponseProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$TruncateResponseProto$1'></ClassStats><ClassStats bugs='1' size='111' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$TruncateResponseProto$Builder'></ClassStats><ClassStats bugs='0' size='3' interface='true' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$TruncateResponseProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='181' priority_1='1' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UnsetStoragePolicyRequestProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UnsetStoragePolicyRequestProto$1'></ClassStats><ClassStats bugs='1' size='137' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UnsetStoragePolicyRequestProto$Builder'></ClassStats><ClassStats bugs='0' size='4' interface='true' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UnsetStoragePolicyRequestProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='137' priority_1='1' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UnsetStoragePolicyResponseProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UnsetStoragePolicyResponseProto$1'></ClassStats><ClassStats bugs='1' size='83' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UnsetStoragePolicyResponseProto$Builder'></ClassStats><ClassStats bugs='0' size='1' interface='true' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UnsetStoragePolicyResponseProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='186' priority_1='1' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpdateBlockForPipelineRequestProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpdateBlockForPipelineRequestProto$1'></ClassStats><ClassStats bugs='0' size='170' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpdateBlockForPipelineRequestProto$Builder'></ClassStats><ClassStats bugs='0' size='7' interface='true' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpdateBlockForPipelineRequestProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='153' priority_1='1' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpdateBlockForPipelineResponseProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpdateBlockForPipelineResponseProto$1'></ClassStats><ClassStats bugs='0' size='137' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpdateBlockForPipelineResponseProto$Builder'></ClassStats><ClassStats bugs='0' size='4' interface='true' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpdateBlockForPipelineResponseProtoOrBuilder'></ClassStats><ClassStats bugs='6' size='301' priority_1='1' priority_2='1' priority_3='4' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpdatePipelineRequestProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpdatePipelineRequestProto$1'></ClassStats><ClassStats bugs='0' size='401' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpdatePipelineRequestProto$Builder'></ClassStats><ClassStats bugs='0' size='19' interface='true' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpdatePipelineRequestProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='116' priority_1='1' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpdatePipelineResponseProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpdatePipelineResponseProto$1'></ClassStats><ClassStats bugs='1' size='75' priority_3='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpdatePipelineResponseProto$Builder'></ClassStats><ClassStats bugs='0' size='1' interface='true' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpdatePipelineResponseProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='137' priority_1='1' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpgradeStatusRequestProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpgradeStatusRequestProto$1'></ClassStats><ClassStats bugs='1' size='83' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpgradeStatusRequestProto$Builder'></ClassStats><ClassStats bugs='0' size='1' interface='true' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpgradeStatusRequestProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='165' priority_1='1' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpgradeStatusResponseProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpgradeStatusResponseProto$1'></ClassStats><ClassStats bugs='1' size='111' priority_2='1' interface='false' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpgradeStatusResponseProto$Builder'></ClassStats><ClassStats bugs='0' size='3' interface='true' sourceFile='ClientNamenodeProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$UpgradeStatusResponseProtoOrBuilder'></ClassStats><ClassStats bugs='0' size='186' interface='false' sourceFile='DataTransferProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos'></ClassStats><ClassStats bugs='0' size='118' interface='false' sourceFile='DataTransferProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$1'></ClassStats><ClassStats bugs='2' size='247' priority_1='1' priority_2='1' interface='false' sourceFile='DataTransferProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$BaseHeaderProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='DataTransferProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$BaseHeaderProto$1'></ClassStats><ClassStats bugs='0' size='307' interface='false' sourceFile='DataTransferProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$BaseHeaderProto$Builder'></ClassStats><ClassStats bugs='0' size='10' interface='true' sourceFile='DataTransferProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$BaseHeaderProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='340' priority_1='1' priority_2='1' interface='false' sourceFile='DataTransferProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$BlockOpResponseProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='DataTransferProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$BlockOpResponseProto$1'></ClassStats><ClassStats bugs='0' size='378' interface='false' sourceFile='DataTransferProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$BlockOpResponseProto$Builder'></ClassStats><ClassStats bugs='0' size='17' interface='true' sourceFile='DataTransferProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$BlockOpResponseProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='185' priority_1='1' priority_2='1' interface='false' sourceFile='DataTransferProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$CachingStrategyProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='DataTransferProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$CachingStrategyProto$1'></ClassStats><ClassStats bugs='1' size='131' priority_2='1' interface='false' sourceFile='DataTransferProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$CachingStrategyProto$Builder'></ClassStats><ClassStats bugs='0' size='5' interface='true' sourceFile='DataTransferProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$CachingStrategyProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='195' priority_1='1' priority_2='1' interface='false' sourceFile='DataTransferProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ChecksumProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='DataTransferProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ChecksumProto$1'></ClassStats><ClassStats bugs='1' size='138' priority_2='1' interface='false' sourceFile='DataTransferProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ChecksumProto$Builder'></ClassStats><ClassStats bugs='0' size='5' interface='true' sourceFile='DataTransferProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ChecksumProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='218' priority_1='1' priority_2='1' interface='false' sourceFile='DataTransferProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ClientOperationHeaderProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='DataTransferProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ClientOperationHeaderProto$1'></ClassStats><ClassStats bugs='0' size='211' interface='false' sourceFile='DataTransferProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ClientOperationHeaderProto$Builder'></ClassStats><ClassStats bugs='0' size='7' interface='true' sourceFile='DataTransferProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ClientOperationHeaderProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='170' priority_1='1' priority_2='1' interface='false' sourceFile='DataTransferProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ClientReadStatusProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='DataTransferProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ClientReadStatusProto$1'></ClassStats><ClassStats bugs='1' size='114' priority_2='1' interface='false' sourceFile='DataTransferProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ClientReadStatusProto$Builder'></ClassStats><ClassStats bugs='0' size='3' interface='true' sourceFile='DataTransferProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ClientReadStatusProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='170' priority_1='1' priority_2='1' interface='false' sourceFile='DataTransferProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$DNTransferAckProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='DataTransferProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$DNTransferAckProto$1'></ClassStats><ClassStats bugs='1' size='114' priority_2='1' interface='false' sourceFile='DataTransferProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$DNTransferAckProto$Builder'></ClassStats><ClassStats bugs='0' size='3' interface='true' sourceFile='DataTransferProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$DNTransferAckProtoOrBuilder'></ClassStats><ClassStats bugs='3' size='268' priority_1='1' priority_2='1' priority_3='1' interface='false' sourceFile='DataTransferProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$DataTransferEncryptorMessageProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='DataTransferProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$DataTransferEncryptorMessageProto$1'></ClassStats><ClassStats bugs='0' size='334' interface='false' sourceFile='DataTransferProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$DataTransferEncryptorMessageProto$Builder'></ClassStats><ClassStats bugs='0' size='46' interface='false' sourceFile='DataTransferProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$DataTransferEncryptorMessageProto$DataTransferEncryptorStatus'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='DataTransferProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$DataTransferEncryptorMessageProto$DataTransferEncryptorStatus$1'></ClassStats><ClassStats bugs='0' size='13' interface='true' sourceFile='DataTransferProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$DataTransferEncryptorMessageProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='191' priority_1='1' priority_2='1' interface='false' sourceFile='DataTransferProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$DataTransferTraceInfoProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='DataTransferProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$DataTransferTraceInfoProto$1'></ClassStats><ClassStats bugs='1' size='135' priority_2='1' interface='false' sourceFile='DataTransferProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$DataTransferTraceInfoProto$Builder'></ClassStats><ClassStats bugs='0' size='5' interface='true' sourceFile='DataTransferProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$DataTransferTraceInfoProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='208' priority_1='1' priority_2='1' interface='false' sourceFile='DataTransferProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpBlockChecksumProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='DataTransferProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpBlockChecksumProto$1'></ClassStats><ClassStats bugs='0' size='231' interface='false' sourceFile='DataTransferProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpBlockChecksumProto$Builder'></ClassStats><ClassStats bugs='0' size='7' interface='true' sourceFile='DataTransferProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpBlockChecksumProtoOrBuilder'></ClassStats><ClassStats bugs='3' size='276' priority_1='1' priority_2='1' priority_3='1' interface='false' sourceFile='DataTransferProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpBlockChecksumResponseProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='DataTransferProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpBlockChecksumResponseProto$1'></ClassStats><ClassStats bugs='0' size='257' interface='false' sourceFile='DataTransferProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpBlockChecksumResponseProto$Builder'></ClassStats><ClassStats bugs='0' size='12' interface='true' sourceFile='DataTransferProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpBlockChecksumResponseProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='385' priority_1='1' priority_2='1' interface='false' sourceFile='DataTransferProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpBlockGroupChecksumProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='DataTransferProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpBlockGroupChecksumProto$1'></ClassStats><ClassStats bugs='0' size='596' interface='false' sourceFile='DataTransferProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpBlockGroupChecksumProto$Builder'></ClassStats><ClassStats bugs='0' size='23' interface='true' sourceFile='DataTransferProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpBlockGroupChecksumProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='177' priority_1='1' priority_2='1' interface='false' sourceFile='DataTransferProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpCopyBlockProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='DataTransferProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpCopyBlockProto$1'></ClassStats><ClassStats bugs='0' size='161' interface='false' sourceFile='DataTransferProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpCopyBlockProto$Builder'></ClassStats><ClassStats bugs='0' size='4' interface='true' sourceFile='DataTransferProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpCopyBlockProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='181' priority_1='1' priority_2='1' interface='false' sourceFile='DataTransferProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpCustomProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='DataTransferProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpCustomProto$1'></ClassStats><ClassStats bugs='1' size='137' priority_2='1' interface='false' sourceFile='DataTransferProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpCustomProto$Builder'></ClassStats><ClassStats bugs='0' size='4' interface='true' sourceFile='DataTransferProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpCustomProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='283' priority_1='1' priority_2='1' interface='false' sourceFile='DataTransferProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpReadBlockProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='DataTransferProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpReadBlockProto$1'></ClassStats><ClassStats bugs='0' size='302' interface='false' sourceFile='DataTransferProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpReadBlockProto$Builder'></ClassStats><ClassStats bugs='0' size='13' interface='true' sourceFile='DataTransferProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpReadBlockProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='321' priority_1='1' priority_2='1' interface='false' sourceFile='DataTransferProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpReplaceBlockProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='DataTransferProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpReplaceBlockProto$1'></ClassStats><ClassStats bugs='0' size='358' interface='false' sourceFile='DataTransferProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpReplaceBlockProto$Builder'></ClassStats><ClassStats bugs='0' size='15' interface='true' sourceFile='DataTransferProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpReplaceBlockProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='260' priority_1='1' priority_2='1' interface='false' sourceFile='DataTransferProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpRequestShortCircuitAccessProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='DataTransferProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpRequestShortCircuitAccessProto$1'></ClassStats><ClassStats bugs='0' size='280' interface='false' sourceFile='DataTransferProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpRequestShortCircuitAccessProto$Builder'></ClassStats><ClassStats bugs='0' size='11' interface='true' sourceFile='DataTransferProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpRequestShortCircuitAccessProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='295' priority_1='1' priority_2='1' interface='false' sourceFile='DataTransferProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpTransferBlockProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='DataTransferProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpTransferBlockProto$1'></ClassStats><ClassStats bugs='0' size='418' interface='false' sourceFile='DataTransferProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpTransferBlockProto$Builder'></ClassStats><ClassStats bugs='0' size='16' interface='true' sourceFile='DataTransferProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpTransferBlockProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='682' priority_1='1' priority_2='1' interface='false' sourceFile='DataTransferProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpWriteBlockProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='DataTransferProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpWriteBlockProto$1'></ClassStats><ClassStats bugs='0' size='70' interface='false' sourceFile='DataTransferProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpWriteBlockProto$BlockConstructionStage'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='DataTransferProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpWriteBlockProto$BlockConstructionStage$1'></ClassStats><ClassStats bugs='0' size='921' interface='false' sourceFile='DataTransferProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpWriteBlockProto$Builder'></ClassStats><ClassStats bugs='0' size='47' interface='true' sourceFile='DataTransferProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$OpWriteBlockProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='266' priority_1='1' priority_2='1' interface='false' sourceFile='DataTransferProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$PacketHeaderProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='DataTransferProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$PacketHeaderProto$1'></ClassStats><ClassStats bugs='1' size='205' priority_2='1' interface='false' sourceFile='DataTransferProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$PacketHeaderProto$Builder'></ClassStats><ClassStats bugs='0' size='11' interface='true' sourceFile='DataTransferProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$PacketHeaderProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='287' priority_1='1' priority_2='1' interface='false' sourceFile='DataTransferProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$PipelineAckProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='DataTransferProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$PipelineAckProto$1'></ClassStats><ClassStats bugs='1' size='230' priority_2='1' interface='false' sourceFile='DataTransferProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$PipelineAckProto$Builder'></ClassStats><ClassStats bugs='0' size='11' interface='true' sourceFile='DataTransferProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$PipelineAckProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='202' priority_1='1' priority_2='1' interface='false' sourceFile='DataTransferProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ReadOpChecksumInfoProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='DataTransferProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ReadOpChecksumInfoProto$1'></ClassStats><ClassStats bugs='0' size='185' interface='false' sourceFile='DataTransferProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ReadOpChecksumInfoProto$Builder'></ClassStats><ClassStats bugs='0' size='6' interface='true' sourceFile='DataTransferProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ReadOpChecksumInfoProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='212' priority_1='1' priority_2='1' interface='false' sourceFile='DataTransferProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ReleaseShortCircuitAccessRequestProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='DataTransferProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ReleaseShortCircuitAccessRequestProto$1'></ClassStats><ClassStats bugs='0' size='234' interface='false' sourceFile='DataTransferProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ReleaseShortCircuitAccessRequestProto$Builder'></ClassStats><ClassStats bugs='0' size='7' interface='true' sourceFile='DataTransferProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ReleaseShortCircuitAccessRequestProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='208' priority_1='1' priority_2='1' interface='false' sourceFile='DataTransferProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ReleaseShortCircuitAccessResponseProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='DataTransferProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ReleaseShortCircuitAccessResponseProto$1'></ClassStats><ClassStats bugs='1' size='162' priority_2='1' interface='false' sourceFile='DataTransferProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ReleaseShortCircuitAccessResponseProto$Builder'></ClassStats><ClassStats bugs='0' size='6' interface='true' sourceFile='DataTransferProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ReleaseShortCircuitAccessResponseProtoOrBuilder'></ClassStats><ClassStats bugs='0' size='42' interface='false' sourceFile='DataTransferProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ShortCircuitFdResponse'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='DataTransferProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ShortCircuitFdResponse$1'></ClassStats><ClassStats bugs='2' size='191' priority_1='1' priority_2='1' interface='false' sourceFile='DataTransferProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ShortCircuitShmIdProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='DataTransferProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ShortCircuitShmIdProto$1'></ClassStats><ClassStats bugs='1' size='135' priority_2='1' interface='false' sourceFile='DataTransferProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ShortCircuitShmIdProto$Builder'></ClassStats><ClassStats bugs='0' size='5' interface='true' sourceFile='DataTransferProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ShortCircuitShmIdProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='217' priority_1='1' priority_2='1' interface='false' sourceFile='DataTransferProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ShortCircuitShmRequestProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='DataTransferProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ShortCircuitShmRequestProto$1'></ClassStats><ClassStats bugs='0' size='210' interface='false' sourceFile='DataTransferProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ShortCircuitShmRequestProto$Builder'></ClassStats><ClassStats bugs='0' size='7' interface='true' sourceFile='DataTransferProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ShortCircuitShmRequestProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='244' priority_1='1' priority_2='1' interface='false' sourceFile='DataTransferProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ShortCircuitShmResponseProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='DataTransferProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ShortCircuitShmResponseProto$1'></ClassStats><ClassStats bugs='0' size='235' interface='false' sourceFile='DataTransferProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ShortCircuitShmResponseProto$Builder'></ClassStats><ClassStats bugs='0' size='9' interface='true' sourceFile='DataTransferProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ShortCircuitShmResponseProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='202' priority_1='1' priority_2='1' interface='false' sourceFile='DataTransferProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ShortCircuitShmSlotProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='DataTransferProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ShortCircuitShmSlotProto$1'></ClassStats><ClassStats bugs='0' size='185' interface='false' sourceFile='DataTransferProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ShortCircuitShmSlotProto$Builder'></ClassStats><ClassStats bugs='0' size='6' interface='true' sourceFile='DataTransferProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$ShortCircuitShmSlotProtoOrBuilder'></ClassStats><ClassStats bugs='0' size='90' interface='false' sourceFile='DataTransferProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$Status'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='DataTransferProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$Status$1'></ClassStats><ClassStats bugs='0' size='89' interface='false' sourceFile='EncryptionZonesProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos'></ClassStats><ClassStats bugs='0' size='54' interface='false' sourceFile='EncryptionZonesProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$1'></ClassStats><ClassStats bugs='2' size='220' priority_1='1' priority_2='1' interface='false' sourceFile='EncryptionZonesProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$CreateEncryptionZoneRequestProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='EncryptionZonesProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$CreateEncryptionZoneRequestProto$1'></ClassStats><ClassStats bugs='1' size='185' priority_2='1' interface='false' sourceFile='EncryptionZonesProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$CreateEncryptionZoneRequestProto$Builder'></ClassStats><ClassStats bugs='0' size='7' interface='true' sourceFile='EncryptionZonesProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$CreateEncryptionZoneRequestProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='137' priority_1='1' priority_2='1' interface='false' sourceFile='EncryptionZonesProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$CreateEncryptionZoneResponseProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='EncryptionZonesProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$CreateEncryptionZoneResponseProto$1'></ClassStats><ClassStats bugs='1' size='83' priority_2='1' interface='false' sourceFile='EncryptionZonesProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$CreateEncryptionZoneResponseProto$Builder'></ClassStats><ClassStats bugs='0' size='1' interface='true' sourceFile='EncryptionZonesProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$CreateEncryptionZoneResponseProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='309' priority_1='1' priority_2='1' interface='false' sourceFile='EncryptionZonesProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$EncryptionZoneProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='EncryptionZonesProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$EncryptionZoneProto$1'></ClassStats><ClassStats bugs='1' size='265' priority_2='1' interface='false' sourceFile='EncryptionZonesProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$EncryptionZoneProto$Builder'></ClassStats><ClassStats bugs='0' size='13' interface='true' sourceFile='EncryptionZonesProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$EncryptionZoneProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='181' priority_1='1' priority_2='1' interface='false' sourceFile='EncryptionZonesProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$GetEZForPathRequestProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='EncryptionZonesProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$GetEZForPathRequestProto$1'></ClassStats><ClassStats bugs='1' size='137' priority_2='1' interface='false' sourceFile='EncryptionZonesProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$GetEZForPathRequestProto$Builder'></ClassStats><ClassStats bugs='0' size='4' interface='true' sourceFile='EncryptionZonesProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$GetEZForPathRequestProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='175' priority_1='1' priority_2='1' interface='false' sourceFile='EncryptionZonesProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$GetEZForPathResponseProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='EncryptionZonesProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$GetEZForPathResponseProto$1'></ClassStats><ClassStats bugs='0' size='160' interface='false' sourceFile='EncryptionZonesProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$GetEZForPathResponseProto$Builder'></ClassStats><ClassStats bugs='0' size='4' interface='true' sourceFile='EncryptionZonesProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$GetEZForPathResponseProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='165' priority_1='1' priority_2='1' interface='false' sourceFile='EncryptionZonesProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ListEncryptionZonesRequestProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='EncryptionZonesProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ListEncryptionZonesRequestProto$1'></ClassStats><ClassStats bugs='1' size='111' priority_2='1' interface='false' sourceFile='EncryptionZonesProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ListEncryptionZonesRequestProto$Builder'></ClassStats><ClassStats bugs='0' size='3' interface='true' sourceFile='EncryptionZonesProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ListEncryptionZonesRequestProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='202' priority_1='1' priority_2='1' interface='false' sourceFile='EncryptionZonesProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ListEncryptionZonesResponseProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='EncryptionZonesProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ListEncryptionZonesResponseProto$1'></ClassStats><ClassStats bugs='0' size='258' interface='false' sourceFile='EncryptionZonesProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ListEncryptionZonesResponseProto$Builder'></ClassStats><ClassStats bugs='0' size='8' interface='true' sourceFile='EncryptionZonesProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ListEncryptionZonesResponseProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='165' priority_1='1' priority_2='1' interface='false' sourceFile='EncryptionZonesProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ListReencryptionStatusRequestProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='EncryptionZonesProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ListReencryptionStatusRequestProto$1'></ClassStats><ClassStats bugs='1' size='111' priority_2='1' interface='false' sourceFile='EncryptionZonesProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ListReencryptionStatusRequestProto$Builder'></ClassStats><ClassStats bugs='0' size='3' interface='true' sourceFile='EncryptionZonesProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ListReencryptionStatusRequestProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='202' priority_1='1' priority_2='1' interface='false' sourceFile='EncryptionZonesProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ListReencryptionStatusResponseProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='EncryptionZonesProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ListReencryptionStatusResponseProto$1'></ClassStats><ClassStats bugs='0' size='258' interface='false' sourceFile='EncryptionZonesProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ListReencryptionStatusResponseProto$Builder'></ClassStats><ClassStats bugs='0' size='8' interface='true' sourceFile='EncryptionZonesProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ListReencryptionStatusResponseProtoOrBuilder'></ClassStats><ClassStats bugs='0' size='42' interface='false' sourceFile='EncryptionZonesProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ReencryptActionProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='EncryptionZonesProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ReencryptActionProto$1'></ClassStats><ClassStats bugs='2' size='211' priority_1='1' priority_2='1' interface='false' sourceFile='EncryptionZonesProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ReencryptEncryptionZoneRequestProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='EncryptionZonesProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ReencryptEncryptionZoneRequestProto$1'></ClassStats><ClassStats bugs='1' size='164' priority_2='1' interface='false' sourceFile='EncryptionZonesProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ReencryptEncryptionZoneRequestProto$Builder'></ClassStats><ClassStats bugs='0' size='6' interface='true' sourceFile='EncryptionZonesProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ReencryptEncryptionZoneRequestProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='137' priority_1='1' priority_2='1' interface='false' sourceFile='EncryptionZonesProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ReencryptEncryptionZoneResponseProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='EncryptionZonesProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ReencryptEncryptionZoneResponseProto$1'></ClassStats><ClassStats bugs='1' size='83' priority_2='1' interface='false' sourceFile='EncryptionZonesProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ReencryptEncryptionZoneResponseProto$Builder'></ClassStats><ClassStats bugs='0' size='1' interface='true' sourceFile='EncryptionZonesProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ReencryptEncryptionZoneResponseProtoOrBuilder'></ClassStats><ClassStats bugs='0' size='46' interface='false' sourceFile='EncryptionZonesProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ReencryptionStateProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='EncryptionZonesProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ReencryptionStateProto$1'></ClassStats><ClassStats bugs='2' size='445' priority_1='1' priority_2='1' interface='false' sourceFile='EncryptionZonesProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ZoneReencryptionStatusProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='EncryptionZonesProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ZoneReencryptionStatusProto$1'></ClassStats><ClassStats bugs='1' size='404' priority_2='1' interface='false' sourceFile='EncryptionZonesProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ZoneReencryptionStatusProto$Builder'></ClassStats><ClassStats bugs='0' size='24' interface='true' sourceFile='EncryptionZonesProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.EncryptionZonesProtos$ZoneReencryptionStatusProtoOrBuilder'></ClassStats><ClassStats bugs='0' size='137' interface='false' sourceFile='ErasureCodingProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos'></ClassStats><ClassStats bugs='0' size='86' interface='false' sourceFile='ErasureCodingProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$1'></ClassStats><ClassStats bugs='2' size='174' priority_1='1' priority_2='1' interface='false' sourceFile='ErasureCodingProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$AddErasureCodingPoliciesRequestProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ErasureCodingProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$AddErasureCodingPoliciesRequestProto$1'></ClassStats><ClassStats bugs='1' size='232' priority_3='1' interface='false' sourceFile='ErasureCodingProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$AddErasureCodingPoliciesRequestProto$Builder'></ClassStats><ClassStats bugs='0' size='6' interface='true' sourceFile='ErasureCodingProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$AddErasureCodingPoliciesRequestProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='174' priority_1='1' priority_2='1' interface='false' sourceFile='ErasureCodingProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$AddErasureCodingPoliciesResponseProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ErasureCodingProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$AddErasureCodingPoliciesResponseProto$1'></ClassStats><ClassStats bugs='1' size='232' priority_3='1' interface='false' sourceFile='ErasureCodingProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$AddErasureCodingPoliciesResponseProto$Builder'></ClassStats><ClassStats bugs='0' size='6' interface='true' sourceFile='ErasureCodingProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$AddErasureCodingPoliciesResponseProtoOrBuilder'></ClassStats><ClassStats bugs='3' size='382' priority_1='1' priority_2='1' priority_3='1' interface='false' sourceFile='ErasureCodingProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$BlockECReconstructionInfoProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ErasureCodingProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$BlockECReconstructionInfoProto$1'></ClassStats><ClassStats bugs='0' size='554' interface='false' sourceFile='ErasureCodingProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$BlockECReconstructionInfoProto$Builder'></ClassStats><ClassStats bugs='0' size='21' interface='true' sourceFile='ErasureCodingProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$BlockECReconstructionInfoProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='223' priority_1='1' priority_2='1' interface='false' sourceFile='ErasureCodingProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$CodecProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ErasureCodingProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$CodecProto$1'></ClassStats><ClassStats bugs='1' size='187' priority_2='1' interface='false' sourceFile='ErasureCodingProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$CodecProto$Builder'></ClassStats><ClassStats bugs='0' size='7' interface='true' sourceFile='ErasureCodingProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$CodecProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='181' priority_1='1' priority_2='1' interface='false' sourceFile='ErasureCodingProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$DisableErasureCodingPolicyRequestProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ErasureCodingProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$DisableErasureCodingPolicyRequestProto$1'></ClassStats><ClassStats bugs='1' size='137' priority_2='1' interface='false' sourceFile='ErasureCodingProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$DisableErasureCodingPolicyRequestProto$Builder'></ClassStats><ClassStats bugs='0' size='4' interface='true' sourceFile='ErasureCodingProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$DisableErasureCodingPolicyRequestProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='137' priority_1='1' priority_2='1' interface='false' sourceFile='ErasureCodingProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$DisableErasureCodingPolicyResponseProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ErasureCodingProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$DisableErasureCodingPolicyResponseProto$1'></ClassStats><ClassStats bugs='1' size='83' priority_2='1' interface='false' sourceFile='ErasureCodingProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$DisableErasureCodingPolicyResponseProto$Builder'></ClassStats><ClassStats bugs='0' size='1' interface='true' sourceFile='ErasureCodingProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$DisableErasureCodingPolicyResponseProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='181' priority_1='1' priority_2='1' interface='false' sourceFile='ErasureCodingProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$EnableErasureCodingPolicyRequestProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ErasureCodingProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$EnableErasureCodingPolicyRequestProto$1'></ClassStats><ClassStats bugs='1' size='137' priority_2='1' interface='false' sourceFile='ErasureCodingProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$EnableErasureCodingPolicyRequestProto$Builder'></ClassStats><ClassStats bugs='0' size='4' interface='true' sourceFile='ErasureCodingProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$EnableErasureCodingPolicyRequestProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='137' priority_1='1' priority_2='1' interface='false' sourceFile='ErasureCodingProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$EnableErasureCodingPolicyResponseProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ErasureCodingProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$EnableErasureCodingPolicyResponseProto$1'></ClassStats><ClassStats bugs='1' size='83' priority_2='1' interface='false' sourceFile='ErasureCodingProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$EnableErasureCodingPolicyResponseProto$Builder'></ClassStats><ClassStats bugs='0' size='1' interface='true' sourceFile='ErasureCodingProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$EnableErasureCodingPolicyResponseProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='137' priority_1='1' priority_2='1' interface='false' sourceFile='ErasureCodingProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingCodecsRequestProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ErasureCodingProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingCodecsRequestProto$1'></ClassStats><ClassStats bugs='1' size='83' priority_2='1' interface='false' sourceFile='ErasureCodingProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingCodecsRequestProto$Builder'></ClassStats><ClassStats bugs='0' size='1' interface='true' sourceFile='ErasureCodingProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingCodecsRequestProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='174' priority_1='1' priority_2='1' interface='false' sourceFile='ErasureCodingProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingCodecsResponseProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ErasureCodingProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingCodecsResponseProto$1'></ClassStats><ClassStats bugs='1' size='232' priority_3='1' interface='false' sourceFile='ErasureCodingProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingCodecsResponseProto$Builder'></ClassStats><ClassStats bugs='0' size='6' interface='true' sourceFile='ErasureCodingProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingCodecsResponseProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='137' priority_1='1' priority_2='1' interface='false' sourceFile='ErasureCodingProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingPoliciesRequestProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ErasureCodingProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingPoliciesRequestProto$1'></ClassStats><ClassStats bugs='1' size='83' priority_2='1' interface='false' sourceFile='ErasureCodingProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingPoliciesRequestProto$Builder'></ClassStats><ClassStats bugs='0' size='1' interface='true' sourceFile='ErasureCodingProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingPoliciesRequestProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='174' priority_1='1' priority_2='1' interface='false' sourceFile='ErasureCodingProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingPoliciesResponseProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ErasureCodingProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingPoliciesResponseProto$1'></ClassStats><ClassStats bugs='1' size='232' priority_3='1' interface='false' sourceFile='ErasureCodingProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingPoliciesResponseProto$Builder'></ClassStats><ClassStats bugs='0' size='6' interface='true' sourceFile='ErasureCodingProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingPoliciesResponseProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='181' priority_1='1' priority_2='1' interface='false' sourceFile='ErasureCodingProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingPolicyRequestProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ErasureCodingProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingPolicyRequestProto$1'></ClassStats><ClassStats bugs='1' size='137' priority_2='1' interface='false' sourceFile='ErasureCodingProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingPolicyRequestProto$Builder'></ClassStats><ClassStats bugs='0' size='4' interface='true' sourceFile='ErasureCodingProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingPolicyRequestProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='175' priority_1='1' priority_2='1' interface='false' sourceFile='ErasureCodingProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingPolicyResponseProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ErasureCodingProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingPolicyResponseProto$1'></ClassStats><ClassStats bugs='0' size='160' interface='false' sourceFile='ErasureCodingProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingPolicyResponseProto$Builder'></ClassStats><ClassStats bugs='0' size='4' interface='true' sourceFile='ErasureCodingProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$GetErasureCodingPolicyResponseProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='181' priority_1='1' priority_2='1' interface='false' sourceFile='ErasureCodingProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$RemoveErasureCodingPolicyRequestProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ErasureCodingProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$RemoveErasureCodingPolicyRequestProto$1'></ClassStats><ClassStats bugs='1' size='137' priority_2='1' interface='false' sourceFile='ErasureCodingProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$RemoveErasureCodingPolicyRequestProto$Builder'></ClassStats><ClassStats bugs='0' size='4' interface='true' sourceFile='ErasureCodingProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$RemoveErasureCodingPolicyRequestProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='137' priority_1='1' priority_2='1' interface='false' sourceFile='ErasureCodingProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$RemoveErasureCodingPolicyResponseProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ErasureCodingProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$RemoveErasureCodingPolicyResponseProto$1'></ClassStats><ClassStats bugs='1' size='83' priority_2='1' interface='false' sourceFile='ErasureCodingProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$RemoveErasureCodingPolicyResponseProto$Builder'></ClassStats><ClassStats bugs='0' size='1' interface='true' sourceFile='ErasureCodingProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$RemoveErasureCodingPolicyResponseProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='220' priority_1='1' priority_2='1' interface='false' sourceFile='ErasureCodingProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$SetErasureCodingPolicyRequestProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ErasureCodingProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$SetErasureCodingPolicyRequestProto$1'></ClassStats><ClassStats bugs='1' size='185' priority_2='1' interface='false' sourceFile='ErasureCodingProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$SetErasureCodingPolicyRequestProto$Builder'></ClassStats><ClassStats bugs='0' size='7' interface='true' sourceFile='ErasureCodingProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$SetErasureCodingPolicyRequestProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='137' priority_1='1' priority_2='1' interface='false' sourceFile='ErasureCodingProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$SetErasureCodingPolicyResponseProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ErasureCodingProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$SetErasureCodingPolicyResponseProto$1'></ClassStats><ClassStats bugs='1' size='83' priority_2='1' interface='false' sourceFile='ErasureCodingProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$SetErasureCodingPolicyResponseProto$Builder'></ClassStats><ClassStats bugs='0' size='1' interface='true' sourceFile='ErasureCodingProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$SetErasureCodingPolicyResponseProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='181' priority_1='1' priority_2='1' interface='false' sourceFile='ErasureCodingProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$UnsetErasureCodingPolicyRequestProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ErasureCodingProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$UnsetErasureCodingPolicyRequestProto$1'></ClassStats><ClassStats bugs='1' size='137' priority_2='1' interface='false' sourceFile='ErasureCodingProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$UnsetErasureCodingPolicyRequestProto$Builder'></ClassStats><ClassStats bugs='0' size='4' interface='true' sourceFile='ErasureCodingProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$UnsetErasureCodingPolicyRequestProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='137' priority_1='1' priority_2='1' interface='false' sourceFile='ErasureCodingProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$UnsetErasureCodingPolicyResponseProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ErasureCodingProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$UnsetErasureCodingPolicyResponseProto$1'></ClassStats><ClassStats bugs='1' size='83' priority_2='1' interface='false' sourceFile='ErasureCodingProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$UnsetErasureCodingPolicyResponseProto$Builder'></ClassStats><ClassStats bugs='0' size='1' interface='true' sourceFile='ErasureCodingProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ErasureCodingProtos$UnsetErasureCodingPolicyResponseProtoOrBuilder'></ClassStats><ClassStats bugs='0' size='288' interface='false' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos'></ClassStats><ClassStats bugs='0' size='186' interface='false' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$1'></ClassStats><ClassStats bugs='0' size='50' interface='false' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$AccessModeProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$AccessModeProto$1'></ClassStats><ClassStats bugs='2' size='241' priority_1='1' priority_2='1' interface='false' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$AddErasureCodingPolicyResponseProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$AddErasureCodingPolicyResponseProto$1'></ClassStats><ClassStats bugs='0' size='233' interface='false' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$AddErasureCodingPolicyResponseProto$Builder'></ClassStats><ClassStats bugs='0' size='9' interface='true' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$AddErasureCodingPolicyResponseProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='189' priority_1='1' priority_2='1' interface='false' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$BlockChecksumOptionsProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$BlockChecksumOptionsProto$1'></ClassStats><ClassStats bugs='1' size='134' priority_2='1' interface='false' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$BlockChecksumOptionsProto$Builder'></ClassStats><ClassStats bugs='0' size='5' interface='true' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$BlockChecksumOptionsProtoOrBuilder'></ClassStats><ClassStats bugs='0' size='42' interface='false' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$BlockChecksumTypeProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$BlockChecksumTypeProto$1'></ClassStats><ClassStats bugs='2' size='214' priority_1='1' priority_2='1' interface='false' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$BlockProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$BlockProto$1'></ClassStats><ClassStats bugs='1' size='157' priority_2='1' interface='false' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$BlockProto$Builder'></ClassStats><ClassStats bugs='0' size='7' interface='true' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$BlockProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='304' priority_1='1' priority_2='1' interface='false' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$BlockStoragePolicyProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$BlockStoragePolicyProto$1'></ClassStats><ClassStats bugs='0' size='373' interface='false' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$BlockStoragePolicyProto$Builder'></ClassStats><ClassStats bugs='0' size='15' interface='true' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$BlockStoragePolicyProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='417' priority_1='1' priority_2='1' interface='false' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$BlockTokenSecretProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$BlockTokenSecretProto$1'></ClassStats><ClassStats bugs='1' size='410' priority_2='1' interface='false' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$BlockTokenSecretProto$Builder'></ClassStats><ClassStats bugs='0' size='23' interface='true' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$BlockTokenSecretProtoOrBuilder'></ClassStats><ClassStats bugs='0' size='42' interface='false' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$BlockTypeProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$BlockTypeProto$1'></ClassStats><ClassStats bugs='0' size='46' interface='false' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ChecksumTypeProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ChecksumTypeProto$1'></ClassStats><ClassStats bugs='6' size='261' priority_1='1' priority_2='1' priority_3='4' interface='false' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$CipherOptionProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$CipherOptionProto$1'></ClassStats><ClassStats bugs='1' size='214' priority_2='1' interface='false' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$CipherOptionProto$Builder'></ClassStats><ClassStats bugs='0' size='11' interface='true' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$CipherOptionProtoOrBuilder'></ClassStats><ClassStats bugs='0' size='42' interface='false' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$CipherSuiteProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$CipherSuiteProto$1'></ClassStats><ClassStats bugs='2' size='461' priority_1='1' priority_2='1' interface='false' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ContentSummaryProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ContentSummaryProto$1'></ClassStats><ClassStats bugs='0' size='440' interface='false' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ContentSummaryProto$Builder'></ClassStats><ClassStats bugs='0' size='27' interface='true' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ContentSummaryProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='214' priority_1='1' priority_2='1' interface='false' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$CorruptFileBlocksProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$CorruptFileBlocksProto$1'></ClassStats><ClassStats bugs='1' size='196' priority_2='1' interface='false' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$CorruptFileBlocksProto$Builder'></ClassStats><ClassStats bugs='0' size='8' interface='true' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$CorruptFileBlocksProtoOrBuilder'></ClassStats><ClassStats bugs='0' size='42' interface='false' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$CryptoProtocolVersionProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$CryptoProtocolVersionProto$1'></ClassStats><ClassStats bugs='4' size='324' priority_1='1' priority_2='1' priority_3='2' interface='false' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DataEncryptionKeyProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DataEncryptionKeyProto$1'></ClassStats><ClassStats bugs='1' size='287' priority_2='1' interface='false' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DataEncryptionKeyProto$Builder'></ClassStats><ClassStats bugs='0' size='15' interface='true' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DataEncryptionKeyProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='366' priority_1='1' priority_2='1' interface='false' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeIDProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeIDProto$1'></ClassStats><ClassStats bugs='1' size='331' priority_2='1' interface='false' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeIDProto$Builder'></ClassStats><ClassStats bugs='0' size='18' interface='true' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeIDProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='580' priority_1='1' priority_2='1' interface='false' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeInfoProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeInfoProto$1'></ClassStats><ClassStats bugs='0' size='54' interface='false' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeInfoProto$AdminState'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeInfoProto$AdminState$1'></ClassStats><ClassStats bugs='0' size='568' interface='false' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeInfoProto$Builder'></ClassStats><ClassStats bugs='0' size='38' interface='true' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeInfoProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='174' priority_1='1' priority_2='1' interface='false' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeInfosProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeInfosProto$1'></ClassStats><ClassStats bugs='1' size='232' priority_3='1' interface='false' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeInfosProto$Builder'></ClassStats><ClassStats bugs='0' size='6' interface='true' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeInfosProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='249' priority_1='1' priority_2='1' interface='false' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeLocalInfoProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeLocalInfoProto$1'></ClassStats><ClassStats bugs='1' size='211' priority_2='1' interface='false' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeLocalInfoProto$Builder'></ClassStats><ClassStats bugs='0' size='9' interface='true' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeLocalInfoProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='236' priority_1='1' priority_2='1' interface='false' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeStorageProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeStorageProto$1'></ClassStats><ClassStats bugs='1' size='187' priority_2='1' interface='false' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeStorageProto$Builder'></ClassStats><ClassStats bugs='0' size='42' interface='false' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeStorageProto$StorageState'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeStorageProto$StorageState$1'></ClassStats><ClassStats bugs='0' size='8' interface='true' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeStorageProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='341' priority_1='1' priority_2='1' interface='false' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeVolumeInfoProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeVolumeInfoProto$1'></ClassStats><ClassStats bugs='1' size='284' priority_2='1' interface='false' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeVolumeInfoProto$Builder'></ClassStats><ClassStats bugs='0' size='16' interface='true' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DatanodeVolumeInfoProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='202' priority_1='1' priority_2='1' interface='false' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DirectoryListingProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DirectoryListingProto$1'></ClassStats><ClassStats bugs='0' size='258' interface='false' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DirectoryListingProto$Builder'></ClassStats><ClassStats bugs='0' size='8' interface='true' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$DirectoryListingProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='223' priority_1='1' priority_2='1' interface='false' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ECSchemaOptionEntryProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ECSchemaOptionEntryProto$1'></ClassStats><ClassStats bugs='1' size='187' priority_2='1' interface='false' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ECSchemaOptionEntryProto$Builder'></ClassStats><ClassStats bugs='0' size='7' interface='true' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ECSchemaOptionEntryProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='270' priority_1='1' priority_2='1' interface='false' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ECSchemaProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ECSchemaProto$1'></ClassStats><ClassStats bugs='0' size='332' interface='false' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ECSchemaProto$Builder'></ClassStats><ClassStats bugs='0' size='13' interface='true' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ECSchemaProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='290' priority_1='1' priority_2='1' interface='false' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ErasureCodingPolicyProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ErasureCodingPolicyProto$1'></ClassStats><ClassStats bugs='0' size='279' interface='false' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ErasureCodingPolicyProto$Builder'></ClassStats><ClassStats bugs='0' size='13' interface='true' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ErasureCodingPolicyProtoOrBuilder'></ClassStats><ClassStats bugs='0' size='46' interface='false' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ErasureCodingPolicyState'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ErasureCodingPolicyState$1'></ClassStats><ClassStats bugs='2' size='256' priority_1='1' priority_2='1' interface='false' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ExtendedBlockProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ExtendedBlockProto$1'></ClassStats><ClassStats bugs='1' size='207' priority_2='1' interface='false' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ExtendedBlockProto$Builder'></ClassStats><ClassStats bugs='0' size='10' interface='true' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ExtendedBlockProtoOrBuilder'></ClassStats><ClassStats bugs='4' size='335' priority_1='1' priority_2='1' priority_3='2' interface='false' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$FileEncryptionInfoProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$FileEncryptionInfoProto$1'></ClassStats><ClassStats bugs='1' size='295' priority_2='1' interface='false' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$FileEncryptionInfoProto$Builder'></ClassStats><ClassStats bugs='0' size='15' interface='true' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$FileEncryptionInfoProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='404' priority_1='1' priority_2='1' interface='false' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$FsServerDefaultsProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$FsServerDefaultsProto$1'></ClassStats><ClassStats bugs='1' size='346' priority_2='1' interface='false' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$FsServerDefaultsProto$Builder'></ClassStats><ClassStats bugs='0' size='22' interface='true' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$FsServerDefaultsProtoOrBuilder'></ClassStats><ClassStats bugs='4' size='660' priority_1='1' priority_2='1' priority_3='2' interface='false' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$HdfsFileStatusProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$HdfsFileStatusProto$1'></ClassStats><ClassStats bugs='0' size='764' interface='false' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$HdfsFileStatusProto$Builder'></ClassStats><ClassStats bugs='0' size='46' interface='false' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$HdfsFileStatusProto$FileType'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$HdfsFileStatusProto$FileType$1'></ClassStats><ClassStats bugs='0' size='50' interface='false' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$HdfsFileStatusProto$Flags'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$HdfsFileStatusProto$Flags$1'></ClassStats><ClassStats bugs='0' size='43' interface='true' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$HdfsFileStatusProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='224' priority_1='1' priority_2='1' interface='false' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$HdfsPathHandleProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$HdfsPathHandleProto$1'></ClassStats><ClassStats bugs='1' size='179' priority_2='1' interface='false' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$HdfsPathHandleProto$Builder'></ClassStats><ClassStats bugs='0' size='8' interface='true' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$HdfsPathHandleProtoOrBuilder'></ClassStats><ClassStats bugs='3' size='491' priority_1='1' priority_2='1' priority_3='1' interface='false' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$LocatedBlockProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$LocatedBlockProto$1'></ClassStats><ClassStats bugs='0' size='758' interface='false' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$LocatedBlockProto$Builder'></ClassStats><ClassStats bugs='0' size='33' interface='true' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$LocatedBlockProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='360' priority_1='1' priority_2='1' interface='false' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$LocatedBlocksProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$LocatedBlocksProto$1'></ClassStats><ClassStats bugs='0' size='525' interface='false' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$LocatedBlocksProto$Builder'></ClassStats><ClassStats bugs='0' size='21' interface='true' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$LocatedBlocksProtoOrBuilder'></ClassStats><ClassStats bugs='4' size='233' priority_1='1' priority_2='1' priority_3='2' interface='false' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$PerFileEncryptionInfoProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$PerFileEncryptionInfoProto$1'></ClassStats><ClassStats bugs='1' size='191' priority_2='1' interface='false' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$PerFileEncryptionInfoProto$Builder'></ClassStats><ClassStats bugs='0' size='8' interface='true' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$PerFileEncryptionInfoProtoOrBuilder'></ClassStats><ClassStats bugs='3' size='259' priority_1='1' priority_2='1' priority_3='1' interface='false' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ProvidedStorageLocationProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ProvidedStorageLocationProto$1'></ClassStats><ClassStats bugs='1' size='212' priority_2='1' interface='false' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ProvidedStorageLocationProto$Builder'></ClassStats><ClassStats bugs='0' size='10' interface='true' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ProvidedStorageLocationProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='279' priority_1='1' priority_2='1' interface='false' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$QuotaUsageProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$QuotaUsageProto$1'></ClassStats><ClassStats bugs='0' size='256' interface='false' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$QuotaUsageProto$Builder'></ClassStats><ClassStats bugs='0' size='12' interface='true' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$QuotaUsageProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='347' priority_1='1' priority_2='1' interface='false' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ReencryptionInfoProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ReencryptionInfoProto$1'></ClassStats><ClassStats bugs='1' size='303' priority_2='1' interface='false' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ReencryptionInfoProto$Builder'></ClassStats><ClassStats bugs='0' size='17' interface='true' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ReencryptionInfoProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='204' priority_1='1' priority_2='1' interface='false' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$RollingUpgradeStatusProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$RollingUpgradeStatusProto$1'></ClassStats><ClassStats bugs='1' size='159' priority_2='1' interface='false' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$RollingUpgradeStatusProto$Builder'></ClassStats><ClassStats bugs='0' size='6' interface='true' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$RollingUpgradeStatusProtoOrBuilder'></ClassStats><ClassStats bugs='3' size='191' priority_1='1' priority_2='1' priority_3='1' interface='false' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportCursorProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportCursorProto$1'></ClassStats><ClassStats bugs='1' size='139' priority_2='1' interface='false' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportCursorProto$Builder'></ClassStats><ClassStats bugs='0' size='5' interface='true' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportCursorProtoOrBuilder'></ClassStats><ClassStats bugs='4' size='230' priority_1='1' priority_2='1' priority_3='2' interface='false' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportEntryProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportEntryProto$1'></ClassStats><ClassStats bugs='1' size='189' priority_2='1' interface='false' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportEntryProto$Builder'></ClassStats><ClassStats bugs='0' size='8' interface='true' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportEntryProtoOrBuilder'></ClassStats><ClassStats bugs='4' size='263' priority_1='1' priority_2='1' priority_3='2' interface='false' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportListingEntryProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportListingEntryProto$1'></ClassStats><ClassStats bugs='1' size='209' priority_2='1' interface='false' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportListingEntryProto$Builder'></ClassStats><ClassStats bugs='0' size='11' interface='true' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportListingEntryProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='312' priority_1='1' priority_2='1' interface='false' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportListingProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportListingProto$1'></ClassStats><ClassStats bugs='0' size='625' interface='false' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportListingProto$Builder'></ClassStats><ClassStats bugs='0' size='21' interface='true' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportListingProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='302' priority_1='1' priority_2='1' interface='false' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportProto$1'></ClassStats><ClassStats bugs='0' size='384' interface='false' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportProto$Builder'></ClassStats><ClassStats bugs='0' size='15' interface='true' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotDiffReportProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='386' priority_1='1' priority_2='1' interface='false' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotInfoProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotInfoProto$1'></ClassStats><ClassStats bugs='0' size='411' interface='false' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotInfoProto$Builder'></ClassStats><ClassStats bugs='0' size='19' interface='true' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshotInfoProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='174' priority_1='1' priority_2='1' interface='false' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshottableDirectoryListingProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshottableDirectoryListingProto$1'></ClassStats><ClassStats bugs='1' size='232' priority_3='1' interface='false' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshottableDirectoryListingProto$Builder'></ClassStats><ClassStats bugs='0' size='6' interface='true' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshottableDirectoryListingProtoOrBuilder'></ClassStats><ClassStats bugs='3' size='254' priority_1='1' priority_2='1' priority_3='1' interface='false' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshottableDirectoryStatusProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshottableDirectoryStatusProto$1'></ClassStats><ClassStats bugs='0' size='236' interface='false' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshottableDirectoryStatusProto$Builder'></ClassStats><ClassStats bugs='0' size='10' interface='true' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$SnapshottableDirectoryStatusProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='354' priority_1='1' priority_2='1' interface='false' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$StorageReportProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$StorageReportProto$1'></ClassStats><ClassStats bugs='0' size='342' interface='false' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$StorageReportProto$Builder'></ClassStats><ClassStats bugs='0' size='19' interface='true' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$StorageReportProtoOrBuilder'></ClassStats><ClassStats bugs='0' size='54' interface='false' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$StorageTypeProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$StorageTypeProto$1'></ClassStats><ClassStats bugs='2' size='221' priority_1='1' priority_2='1' interface='false' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$StorageTypeQuotaInfoProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$StorageTypeQuotaInfoProto$1'></ClassStats><ClassStats bugs='1' size='162' priority_2='1' interface='false' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$StorageTypeQuotaInfoProto$Builder'></ClassStats><ClassStats bugs='0' size='7' interface='true' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$StorageTypeQuotaInfoProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='174' priority_1='1' priority_2='1' interface='false' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$StorageTypeQuotaInfosProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$StorageTypeQuotaInfosProto$1'></ClassStats><ClassStats bugs='1' size='232' priority_3='1' interface='false' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$StorageTypeQuotaInfosProto$Builder'></ClassStats><ClassStats bugs='0' size='6' interface='true' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$StorageTypeQuotaInfosProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='187' priority_1='1' priority_2='1' interface='false' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$StorageTypesProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$StorageTypesProto$1'></ClassStats><ClassStats bugs='2' size='136' priority_2='1' priority_3='1' interface='false' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$StorageTypesProto$Builder'></ClassStats><ClassStats bugs='0' size='4' interface='true' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$StorageTypesProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='170' priority_1='1' priority_2='1' interface='false' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$StorageUuidsProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$StorageUuidsProto$1'></ClassStats><ClassStats bugs='2' size='144' priority_2='1' priority_3='1' interface='false' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$StorageUuidsProto$Builder'></ClassStats><ClassStats bugs='0' size='5' interface='true' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$StorageUuidsProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='277' priority_1='1' priority_2='1' interface='false' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ZoneEncryptionInfoProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ZoneEncryptionInfoProto$1'></ClassStats><ClassStats bugs='0' size='264' interface='false' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ZoneEncryptionInfoProto$Builder'></ClassStats><ClassStats bugs='0' size='11' interface='true' sourceFile='HdfsProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.HdfsProtos$ZoneEncryptionInfoProtoOrBuilder'></ClassStats><ClassStats bugs='0' size='79' interface='false' sourceFile='InotifyProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.InotifyProtos'></ClassStats><ClassStats bugs='0' size='46' interface='false' sourceFile='InotifyProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$1'></ClassStats><ClassStats bugs='2' size='204' priority_1='1' priority_2='1' interface='false' sourceFile='InotifyProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$AppendEventProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='InotifyProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$AppendEventProto$1'></ClassStats><ClassStats bugs='1' size='159' priority_2='1' interface='false' sourceFile='InotifyProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$AppendEventProto$Builder'></ClassStats><ClassStats bugs='0' size='6' interface='true' sourceFile='InotifyProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$AppendEventProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='233' priority_1='1' priority_2='1' interface='false' sourceFile='InotifyProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$CloseEventProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='InotifyProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$CloseEventProto$1'></ClassStats><ClassStats bugs='1' size='185' priority_2='1' interface='false' sourceFile='InotifyProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$CloseEventProto$Builder'></ClassStats><ClassStats bugs='0' size='8' interface='true' sourceFile='InotifyProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$CloseEventProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='466' priority_1='1' priority_2='1' interface='false' sourceFile='InotifyProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$CreateEventProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='InotifyProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$CreateEventProto$1'></ClassStats><ClassStats bugs='0' size='476' interface='false' sourceFile='InotifyProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$CreateEventProto$Builder'></ClassStats><ClassStats bugs='0' size='26' interface='true' sourceFile='InotifyProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$CreateEventProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='202' priority_1='1' priority_2='1' interface='false' sourceFile='InotifyProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$EventBatchProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='InotifyProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$EventBatchProto$1'></ClassStats><ClassStats bugs='0' size='258' interface='false' sourceFile='InotifyProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$EventBatchProto$Builder'></ClassStats><ClassStats bugs='0' size='8' interface='true' sourceFile='InotifyProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$EventBatchProtoOrBuilder'></ClassStats><ClassStats bugs='3' size='195' priority_1='1' priority_2='1' priority_3='1' interface='false' sourceFile='InotifyProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$EventProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='InotifyProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$EventProto$1'></ClassStats><ClassStats bugs='1' size='141' priority_2='1' interface='false' sourceFile='InotifyProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$EventProto$Builder'></ClassStats><ClassStats bugs='0' size='5' interface='true' sourceFile='InotifyProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$EventProtoOrBuilder'></ClassStats><ClassStats bugs='0' size='62' interface='false' sourceFile='InotifyProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$EventType'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='InotifyProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$EventType$1'></ClassStats><ClassStats bugs='2' size='291' priority_1='1' priority_2='1' interface='false' sourceFile='InotifyProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$EventsListProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='InotifyProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$EventsListProto$1'></ClassStats><ClassStats bugs='0' size='453' interface='false' sourceFile='InotifyProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$EventsListProto$Builder'></ClassStats><ClassStats bugs='0' size='17' interface='true' sourceFile='InotifyProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$EventsListProtoOrBuilder'></ClassStats><ClassStats bugs='0' size='46' interface='false' sourceFile='InotifyProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$INodeType'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='InotifyProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$INodeType$1'></ClassStats><ClassStats bugs='2' size='490' priority_1='1' priority_2='1' interface='false' sourceFile='InotifyProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$MetadataUpdateEventProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='InotifyProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$MetadataUpdateEventProto$1'></ClassStats><ClassStats bugs='0' size='715' interface='false' sourceFile='InotifyProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$MetadataUpdateEventProto$Builder'></ClassStats><ClassStats bugs='0' size='33' interface='true' sourceFile='InotifyProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$MetadataUpdateEventProtoOrBuilder'></ClassStats><ClassStats bugs='0' size='58' interface='false' sourceFile='InotifyProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$MetadataUpdateType'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='InotifyProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$MetadataUpdateType$1'></ClassStats><ClassStats bugs='2' size='249' priority_1='1' priority_2='1' interface='false' sourceFile='InotifyProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$RenameEventProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='InotifyProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$RenameEventProto$1'></ClassStats><ClassStats bugs='1' size='211' priority_2='1' interface='false' sourceFile='InotifyProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$RenameEventProto$Builder'></ClassStats><ClassStats bugs='0' size='9' interface='true' sourceFile='InotifyProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$RenameEventProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='233' priority_1='1' priority_2='1' interface='false' sourceFile='InotifyProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$TruncateEventProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='InotifyProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$TruncateEventProto$1'></ClassStats><ClassStats bugs='1' size='185' priority_2='1' interface='false' sourceFile='InotifyProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$TruncateEventProto$Builder'></ClassStats><ClassStats bugs='0' size='8' interface='true' sourceFile='InotifyProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$TruncateEventProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='207' priority_1='1' priority_2='1' interface='false' sourceFile='InotifyProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$UnlinkEventProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='InotifyProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$UnlinkEventProto$1'></ClassStats><ClassStats bugs='1' size='161' priority_2='1' interface='false' sourceFile='InotifyProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$UnlinkEventProto$Builder'></ClassStats><ClassStats bugs='0' size='6' interface='true' sourceFile='InotifyProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.InotifyProtos$UnlinkEventProtoOrBuilder'></ClassStats><ClassStats bugs='0' size='58' interface='false' sourceFile='ReconfigurationProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos'></ClassStats><ClassStats bugs='0' size='34' interface='false' sourceFile='ReconfigurationProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$1'></ClassStats><ClassStats bugs='2' size='301' priority_1='1' priority_2='1' interface='false' sourceFile='ReconfigurationProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$GetReconfigurationStatusConfigChangeProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ReconfigurationProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$GetReconfigurationStatusConfigChangeProto$1'></ClassStats><ClassStats bugs='1' size='283' priority_2='1' interface='false' sourceFile='ReconfigurationProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$GetReconfigurationStatusConfigChangeProto$Builder'></ClassStats><ClassStats bugs='0' size='13' interface='true' sourceFile='ReconfigurationProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$GetReconfigurationStatusConfigChangeProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='137' priority_1='1' priority_2='1' interface='false' sourceFile='ReconfigurationProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$GetReconfigurationStatusRequestProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ReconfigurationProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$GetReconfigurationStatusRequestProto$1'></ClassStats><ClassStats bugs='1' size='83' priority_2='1' interface='false' sourceFile='ReconfigurationProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$GetReconfigurationStatusRequestProto$Builder'></ClassStats><ClassStats bugs='0' size='1' interface='true' sourceFile='ReconfigurationProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$GetReconfigurationStatusRequestProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='225' priority_1='1' priority_2='1' interface='false' sourceFile='ReconfigurationProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$GetReconfigurationStatusResponseProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ReconfigurationProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$GetReconfigurationStatusResponseProto$1'></ClassStats><ClassStats bugs='0' size='280' interface='false' sourceFile='ReconfigurationProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$GetReconfigurationStatusResponseProto$Builder'></ClassStats><ClassStats bugs='0' size='10' interface='true' sourceFile='ReconfigurationProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$GetReconfigurationStatusResponseProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='137' priority_1='1' priority_2='1' interface='false' sourceFile='ReconfigurationProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$ListReconfigurablePropertiesRequestProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ReconfigurationProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$ListReconfigurablePropertiesRequestProto$1'></ClassStats><ClassStats bugs='1' size='83' priority_2='1' interface='false' sourceFile='ReconfigurationProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$ListReconfigurablePropertiesRequestProto$Builder'></ClassStats><ClassStats bugs='0' size='1' interface='true' sourceFile='ReconfigurationProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$ListReconfigurablePropertiesRequestProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='170' priority_1='1' priority_2='1' interface='false' sourceFile='ReconfigurationProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$ListReconfigurablePropertiesResponseProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ReconfigurationProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$ListReconfigurablePropertiesResponseProto$1'></ClassStats><ClassStats bugs='2' size='144' priority_2='1' priority_3='1' interface='false' sourceFile='ReconfigurationProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$ListReconfigurablePropertiesResponseProto$Builder'></ClassStats><ClassStats bugs='0' size='5' interface='true' sourceFile='ReconfigurationProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$ListReconfigurablePropertiesResponseProtoOrBuilder'></ClassStats><ClassStats bugs='3' size='48' priority_3='3' interface='false' sourceFile='ReconfigurationProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$ReconfigurationProtocolService'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='ReconfigurationProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$ReconfigurationProtocolService$1'></ClassStats><ClassStats bugs='3' size='30' priority_3='3' interface='false' sourceFile='ReconfigurationProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$ReconfigurationProtocolService$2'></ClassStats><ClassStats bugs='0' size='4' interface='true' sourceFile='ReconfigurationProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$ReconfigurationProtocolService$BlockingInterface'></ClassStats><ClassStats bugs='0' size='20' interface='false' sourceFile='ReconfigurationProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$ReconfigurationProtocolService$BlockingStub'></ClassStats><ClassStats bugs='0' size='4' interface='true' sourceFile='ReconfigurationProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$ReconfigurationProtocolService$Interface'></ClassStats><ClassStats bugs='0' size='31' interface='false' sourceFile='ReconfigurationProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$ReconfigurationProtocolService$Stub'></ClassStats><ClassStats bugs='2' size='137' priority_1='1' priority_2='1' interface='false' sourceFile='ReconfigurationProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$StartReconfigurationRequestProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ReconfigurationProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$StartReconfigurationRequestProto$1'></ClassStats><ClassStats bugs='1' size='83' priority_2='1' interface='false' sourceFile='ReconfigurationProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$StartReconfigurationRequestProto$Builder'></ClassStats><ClassStats bugs='0' size='1' interface='true' sourceFile='ReconfigurationProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$StartReconfigurationRequestProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='137' priority_1='1' priority_2='1' interface='false' sourceFile='ReconfigurationProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$StartReconfigurationResponseProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ReconfigurationProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$StartReconfigurationResponseProto$1'></ClassStats><ClassStats bugs='1' size='83' priority_2='1' interface='false' sourceFile='ReconfigurationProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$StartReconfigurationResponseProto$Builder'></ClassStats><ClassStats bugs='0' size='1' interface='true' sourceFile='ReconfigurationProtocolProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.ReconfigurationProtocolProtos$StartReconfigurationResponseProtoOrBuilder'></ClassStats><ClassStats bugs='0' size='70' interface='false' sourceFile='XAttrProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.XAttrProtos'></ClassStats><ClassStats bugs='0' size='42' interface='false' sourceFile='XAttrProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$1'></ClassStats><ClassStats bugs='2' size='218' priority_1='1' priority_2='1' interface='false' sourceFile='XAttrProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$GetXAttrsRequestProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='XAttrProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$GetXAttrsRequestProto$1'></ClassStats><ClassStats bugs='0' size='284' interface='false' sourceFile='XAttrProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$GetXAttrsRequestProto$Builder'></ClassStats><ClassStats bugs='0' size='9' interface='true' sourceFile='XAttrProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$GetXAttrsRequestProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='174' priority_1='1' priority_2='1' interface='false' sourceFile='XAttrProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$GetXAttrsResponseProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='XAttrProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$GetXAttrsResponseProto$1'></ClassStats><ClassStats bugs='1' size='232' priority_3='1' interface='false' sourceFile='XAttrProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$GetXAttrsResponseProto$Builder'></ClassStats><ClassStats bugs='0' size='6' interface='true' sourceFile='XAttrProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$GetXAttrsResponseProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='181' priority_1='1' priority_2='1' interface='false' sourceFile='XAttrProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$ListXAttrsRequestProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='XAttrProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$ListXAttrsRequestProto$1'></ClassStats><ClassStats bugs='1' size='137' priority_2='1' interface='false' sourceFile='XAttrProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$ListXAttrsRequestProto$Builder'></ClassStats><ClassStats bugs='0' size='4' interface='true' sourceFile='XAttrProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$ListXAttrsRequestProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='174' priority_1='1' priority_2='1' interface='false' sourceFile='XAttrProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$ListXAttrsResponseProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='XAttrProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$ListXAttrsResponseProto$1'></ClassStats><ClassStats bugs='1' size='232' priority_3='1' interface='false' sourceFile='XAttrProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$ListXAttrsResponseProto$Builder'></ClassStats><ClassStats bugs='0' size='6' interface='true' sourceFile='XAttrProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$ListXAttrsResponseProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='217' priority_1='1' priority_2='1' interface='false' sourceFile='XAttrProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$RemoveXAttrRequestProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='XAttrProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$RemoveXAttrRequestProto$1'></ClassStats><ClassStats bugs='0' size='210' interface='false' sourceFile='XAttrProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$RemoveXAttrRequestProto$Builder'></ClassStats><ClassStats bugs='0' size='7' interface='true' sourceFile='XAttrProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$RemoveXAttrRequestProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='137' priority_1='1' priority_2='1' interface='false' sourceFile='XAttrProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$RemoveXAttrResponseProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='XAttrProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$RemoveXAttrResponseProto$1'></ClassStats><ClassStats bugs='1' size='83' priority_2='1' interface='false' sourceFile='XAttrProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$RemoveXAttrResponseProto$Builder'></ClassStats><ClassStats bugs='0' size='1' interface='true' sourceFile='XAttrProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$RemoveXAttrResponseProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='239' priority_1='1' priority_2='1' interface='false' sourceFile='XAttrProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$SetXAttrRequestProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='XAttrProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$SetXAttrRequestProto$1'></ClassStats><ClassStats bugs='0' size='232' interface='false' sourceFile='XAttrProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$SetXAttrRequestProto$Builder'></ClassStats><ClassStats bugs='0' size='9' interface='true' sourceFile='XAttrProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$SetXAttrRequestProtoOrBuilder'></ClassStats><ClassStats bugs='2' size='137' priority_1='1' priority_2='1' interface='false' sourceFile='XAttrProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$SetXAttrResponseProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='XAttrProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$SetXAttrResponseProto$1'></ClassStats><ClassStats bugs='1' size='83' priority_2='1' interface='false' sourceFile='XAttrProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$SetXAttrResponseProto$Builder'></ClassStats><ClassStats bugs='0' size='1' interface='true' sourceFile='XAttrProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$SetXAttrResponseProtoOrBuilder'></ClassStats><ClassStats bugs='3' size='234' priority_1='1' priority_2='1' priority_3='1' interface='false' sourceFile='XAttrProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$XAttrProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='XAttrProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$XAttrProto$1'></ClassStats><ClassStats bugs='1' size='189' priority_2='1' interface='false' sourceFile='XAttrProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$XAttrProto$Builder'></ClassStats><ClassStats bugs='0' size='54' interface='false' sourceFile='XAttrProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$XAttrProto$XAttrNamespaceProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='XAttrProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$XAttrProto$XAttrNamespaceProto$1'></ClassStats><ClassStats bugs='0' size='8' interface='true' sourceFile='XAttrProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$XAttrProtoOrBuilder'></ClassStats><ClassStats bugs='0' size='42' interface='false' sourceFile='XAttrProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$XAttrSetFlagProto'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='XAttrProtos.java' class='org.apache.hadoop.hdfs.protocol.proto.XAttrProtos$XAttrSetFlagProto$1'></ClassStats></PackageStats><PackageStats package='org.apache.hadoop.hdfs.protocolPB' total_bugs='14' priority_2='2' priority_3='12' total_size='3447' total_types='14'><ClassStats bugs='0' size='1' interface='true' sourceFile='ClientDatanodeProtocolPB.java' class='org.apache.hadoop.hdfs.protocolPB.ClientDatanodeProtocolPB'></ClassStats><ClassStats bugs='0' size='199' interface='false' sourceFile='ClientDatanodeProtocolTranslatorPB.java' class='org.apache.hadoop.hdfs.protocolPB.ClientDatanodeProtocolTranslatorPB'></ClassStats><ClassStats bugs='0' size='1' interface='true' sourceFile='ClientNamenodeProtocolPB.java' class='org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolPB'></ClassStats><ClassStats bugs='3' size='989' priority_3='3' interface='false' sourceFile='ClientNamenodeProtocolTranslatorPB.java' class='org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='ClientNamenodeProtocolTranslatorPB.java' class='org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB$1'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='ClientNamenodeProtocolTranslatorPB.java' class='org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB$2'></ClassStats><ClassStats bugs='0' size='14' interface='false' sourceFile='ClientNamenodeProtocolTranslatorPB.java' class='org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB$BatchedCacheEntries'></ClassStats><ClassStats bugs='0' size='15' interface='false' sourceFile='ClientNamenodeProtocolTranslatorPB.java' class='org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB$BatchedCachePoolEntries'></ClassStats><ClassStats bugs='11' size='2064' priority_2='2' priority_3='9' interface='false' sourceFile='PBHelperClient.java' class='org.apache.hadoop.hdfs.protocolPB.PBHelperClient'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='PBHelperClient.java' class='org.apache.hadoop.hdfs.protocolPB.PBHelperClient$1'></ClassStats><ClassStats bugs='0' size='66' interface='false' sourceFile='PBHelperClient.java' class='org.apache.hadoop.hdfs.protocolPB.PBHelperClient$2'></ClassStats><ClassStats bugs='0' size='1' interface='true' sourceFile='ReconfigurationProtocolPB.java' class='org.apache.hadoop.hdfs.protocolPB.ReconfigurationProtocolPB'></ClassStats><ClassStats bugs='0' size='47' interface='false' sourceFile='ReconfigurationProtocolTranslatorPB.java' class='org.apache.hadoop.hdfs.protocolPB.ReconfigurationProtocolTranslatorPB'></ClassStats><ClassStats bugs='0' size='22' interface='false' sourceFile='ReconfigurationProtocolUtils.java' class='org.apache.hadoop.hdfs.protocolPB.ReconfigurationProtocolUtils'></ClassStats></PackageStats><PackageStats package='org.apache.hadoop.hdfs.security.token.block' total_bugs='4' priority_2='3' priority_3='1' total_size='230' total_types='6'><ClassStats bugs='4' size='176' priority_2='3' priority_3='1' interface='false' sourceFile='BlockTokenIdentifier.java' class='org.apache.hadoop.hdfs.security.token.block.BlockTokenIdentifier'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='BlockTokenIdentifier.java' class='org.apache.hadoop.hdfs.security.token.block.BlockTokenIdentifier$AccessMode'></ClassStats><ClassStats bugs='0' size='5' interface='false' sourceFile='BlockTokenIdentifier.java' class='org.apache.hadoop.hdfs.security.token.block.BlockTokenIdentifier$Renewer'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='BlockTokenSelector.java' class='org.apache.hadoop.hdfs.security.token.block.BlockTokenSelector'></ClassStats><ClassStats bugs='0' size='18' interface='false' sourceFile='DataEncryptionKey.java' class='org.apache.hadoop.hdfs.security.token.block.DataEncryptionKey'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='InvalidBlockTokenException.java' class='org.apache.hadoop.hdfs.security.token.block.InvalidBlockTokenException'></ClassStats></PackageStats><PackageStats package='org.apache.hadoop.hdfs.security.token.delegation' total_bugs='0' total_size='71' total_types='4'><ClassStats bugs='0' size='45' interface='false' sourceFile='DelegationTokenIdentifier.java' class='org.apache.hadoop.hdfs.security.token.delegation.DelegationTokenIdentifier'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='DelegationTokenIdentifier.java' class='org.apache.hadoop.hdfs.security.token.delegation.DelegationTokenIdentifier$SWebHdfsDelegationTokenIdentifier'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='DelegationTokenIdentifier.java' class='org.apache.hadoop.hdfs.security.token.delegation.DelegationTokenIdentifier$WebHdfsDelegationTokenIdentifier'></ClassStats><ClassStats bugs='0' size='14' interface='false' sourceFile='DelegationTokenSelector.java' class='org.apache.hadoop.hdfs.security.token.delegation.DelegationTokenSelector'></ClassStats></PackageStats><PackageStats package='org.apache.hadoop.hdfs.server.datanode' total_bugs='0' total_size='308' total_types='8'><ClassStats bugs='0' size='58' interface='false' sourceFile='BlockMetadataHeader.java' class='org.apache.hadoop.hdfs.server.datanode.BlockMetadataHeader'></ClassStats><ClassStats bugs='0' size='21' interface='false' sourceFile='CachingStrategy.java' class='org.apache.hadoop.hdfs.server.datanode.CachingStrategy'></ClassStats><ClassStats bugs='0' size='16' interface='false' sourceFile='CachingStrategy.java' class='org.apache.hadoop.hdfs.server.datanode.CachingStrategy$Builder'></ClassStats><ClassStats bugs='0' size='86' interface='false' sourceFile='DiskBalancerWorkItem.java' class='org.apache.hadoop.hdfs.server.datanode.DiskBalancerWorkItem'></ClassStats><ClassStats bugs='0' size='58' interface='false' sourceFile='DiskBalancerWorkStatus.java' class='org.apache.hadoop.hdfs.server.datanode.DiskBalancerWorkStatus'></ClassStats><ClassStats bugs='0' size='32' interface='false' sourceFile='DiskBalancerWorkStatus.java' class='org.apache.hadoop.hdfs.server.datanode.DiskBalancerWorkStatus$DiskBalancerWorkEntry'></ClassStats><ClassStats bugs='0' size='21' interface='false' sourceFile='DiskBalancerWorkStatus.java' class='org.apache.hadoop.hdfs.server.datanode.DiskBalancerWorkStatus$Result'></ClassStats><ClassStats bugs='0' size='16' interface='false' sourceFile='ReplicaNotFoundException.java' class='org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException'></ClassStats></PackageStats><PackageStats package='org.apache.hadoop.hdfs.server.namenode' total_bugs='0' total_size='18' total_types='3'><ClassStats bugs='0' size='5' interface='false' sourceFile='NotReplicatedYetException.java' class='org.apache.hadoop.hdfs.server.namenode.NotReplicatedYetException'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='RetryStartFileException.java' class='org.apache.hadoop.hdfs.server.namenode.RetryStartFileException'></ClassStats><ClassStats bugs='0' size='5' interface='false' sourceFile='SafeModeException.java' class='org.apache.hadoop.hdfs.server.namenode.SafeModeException'></ClassStats></PackageStats><PackageStats package='org.apache.hadoop.hdfs.server.namenode.ha' total_bugs='18' priority_2='1' priority_3='17' total_size='912' total_types='26'><ClassStats bugs='0' size='10' interface='false' sourceFile='AbstractNNFailoverProxyProvider.java' class='org.apache.hadoop.hdfs.server.namenode.ha.AbstractNNFailoverProxyProvider'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='ClientHAProxyFactory.java' class='org.apache.hadoop.hdfs.server.namenode.ha.ClientHAProxyFactory'></ClassStats><ClassStats bugs='0' size='76' interface='false' sourceFile='ConfiguredFailoverProxyProvider.java' class='org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='ConfiguredFailoverProxyProvider.java' class='org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider$AddressRpcProxyPair'></ClassStats><ClassStats bugs='0' size='3' interface='true' sourceFile='HAProxyFactory.java' class='org.apache.hadoop.hdfs.server.namenode.ha.HAProxyFactory'></ClassStats><ClassStats bugs='0' size='40' interface='false' sourceFile='IPFailoverProxyProvider.java' class='org.apache.hadoop.hdfs.server.namenode.ha.IPFailoverProxyProvider'></ClassStats><ClassStats bugs='0' size='59' interface='false' sourceFile='RequestHedgingProxyProvider.java' class='org.apache.hadoop.hdfs.server.namenode.ha.RequestHedgingProxyProvider'></ClassStats><ClassStats bugs='0' size='69' interface='false' sourceFile='RequestHedgingProxyProvider.java' class='org.apache.hadoop.hdfs.server.namenode.ha.RequestHedgingProxyProvider$RequestHedgingInvocationHandler'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='RequestHedgingProxyProvider.java' class='org.apache.hadoop.hdfs.server.namenode.ha.RequestHedgingProxyProvider$RequestHedgingInvocationHandler$1'></ClassStats><ClassStats bugs='2' size='115' priority_3='2' interface='false' sourceFile='TestConfiguredFailoverProxyProvider.java' class='org.apache.hadoop.hdfs.server.namenode.ha.TestConfiguredFailoverProxyProvider'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='TestConfiguredFailoverProxyProvider.java' class='org.apache.hadoop.hdfs.server.namenode.ha.TestConfiguredFailoverProxyProvider$1'></ClassStats><ClassStats bugs='0' size='15' interface='false' sourceFile='TestConfiguredFailoverProxyProvider.java' class='org.apache.hadoop.hdfs.server.namenode.ha.TestConfiguredFailoverProxyProvider$2'></ClassStats><ClassStats bugs='16' size='341' priority_2='1' priority_3='15' interface='false' sourceFile='TestRequestHedgingProxyProvider.java' class='org.apache.hadoop.hdfs.server.namenode.ha.TestRequestHedgingProxyProvider'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='TestRequestHedgingProxyProvider.java' class='org.apache.hadoop.hdfs.server.namenode.ha.TestRequestHedgingProxyProvider$1'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='TestRequestHedgingProxyProvider.java' class='org.apache.hadoop.hdfs.server.namenode.ha.TestRequestHedgingProxyProvider$10'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='TestRequestHedgingProxyProvider.java' class='org.apache.hadoop.hdfs.server.namenode.ha.TestRequestHedgingProxyProvider$11'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='TestRequestHedgingProxyProvider.java' class='org.apache.hadoop.hdfs.server.namenode.ha.TestRequestHedgingProxyProvider$12'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='TestRequestHedgingProxyProvider.java' class='org.apache.hadoop.hdfs.server.namenode.ha.TestRequestHedgingProxyProvider$2'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='TestRequestHedgingProxyProvider.java' class='org.apache.hadoop.hdfs.server.namenode.ha.TestRequestHedgingProxyProvider$3'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='TestRequestHedgingProxyProvider.java' class='org.apache.hadoop.hdfs.server.namenode.ha.TestRequestHedgingProxyProvider$4'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='TestRequestHedgingProxyProvider.java' class='org.apache.hadoop.hdfs.server.namenode.ha.TestRequestHedgingProxyProvider$5'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='TestRequestHedgingProxyProvider.java' class='org.apache.hadoop.hdfs.server.namenode.ha.TestRequestHedgingProxyProvider$6'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='TestRequestHedgingProxyProvider.java' class='org.apache.hadoop.hdfs.server.namenode.ha.TestRequestHedgingProxyProvider$7'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='TestRequestHedgingProxyProvider.java' class='org.apache.hadoop.hdfs.server.namenode.ha.TestRequestHedgingProxyProvider$8'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='TestRequestHedgingProxyProvider.java' class='org.apache.hadoop.hdfs.server.namenode.ha.TestRequestHedgingProxyProvider$9'></ClassStats><ClassStats bugs='0' size='18' interface='false' sourceFile='WrappedFailoverProxyProvider.java' class='org.apache.hadoop.hdfs.server.namenode.ha.WrappedFailoverProxyProvider'></ClassStats></PackageStats><PackageStats package='org.apache.hadoop.hdfs.server.protocol' total_bugs='2' priority_2='2' total_size='188' total_types='7'><ClassStats bugs='0' size='40' interface='false' sourceFile='DatanodeStorage.java' class='org.apache.hadoop.hdfs.server.protocol.DatanodeStorage'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='DatanodeStorage.java' class='org.apache.hadoop.hdfs.server.protocol.DatanodeStorage$State'></ClassStats><ClassStats bugs='2' size='12' priority_2='2' interface='false' sourceFile='DatanodeStorageReport.java' class='org.apache.hadoop.hdfs.server.protocol.DatanodeStorageReport'></ClassStats><ClassStats bugs='0' size='37' interface='false' sourceFile='SlowDiskReports.java' class='org.apache.hadoop.hdfs.server.protocol.SlowDiskReports'></ClassStats><ClassStats bugs='0' size='24' interface='false' sourceFile='SlowDiskReports.java' class='org.apache.hadoop.hdfs.server.protocol.SlowDiskReports$DiskOp'></ClassStats><ClassStats bugs='0' size='27' interface='false' sourceFile='SlowPeerReports.java' class='org.apache.hadoop.hdfs.server.protocol.SlowPeerReports'></ClassStats><ClassStats bugs='0' size='35' interface='false' sourceFile='StorageReport.java' class='org.apache.hadoop.hdfs.server.protocol.StorageReport'></ClassStats></PackageStats><PackageStats package='org.apache.hadoop.hdfs.shortcircuit' priority_1='1' total_bugs='9' priority_2='3' priority_3='5' total_size='1358' total_types='24'><ClassStats bugs='0' size='22' interface='false' sourceFile='ClientMmap.java' class='org.apache.hadoop.hdfs.shortcircuit.ClientMmap'></ClassStats><ClassStats bugs='0' size='31' interface='false' sourceFile='DfsClientShm.java' class='org.apache.hadoop.hdfs.shortcircuit.DfsClientShm'></ClassStats><ClassStats bugs='0' size='68' interface='false' sourceFile='DfsClientShmManager.java' class='org.apache.hadoop.hdfs.shortcircuit.DfsClientShmManager'></ClassStats><ClassStats bugs='0' size='4' interface='false' sourceFile='DfsClientShmManager.java' class='org.apache.hadoop.hdfs.shortcircuit.DfsClientShmManager$1'></ClassStats><ClassStats bugs='2' size='123' priority_1='1' priority_2='1' interface='false' sourceFile='DfsClientShmManager.java' class='org.apache.hadoop.hdfs.shortcircuit.DfsClientShmManager$EndpointShmManager'></ClassStats><ClassStats bugs='3' size='10' priority_3='3' interface='false' sourceFile='DfsClientShmManager.java' class='org.apache.hadoop.hdfs.shortcircuit.DfsClientShmManager$PerDatanodeVisitorInfo'></ClassStats><ClassStats bugs='0' size='2' interface='true' sourceFile='DfsClientShmManager.java' class='org.apache.hadoop.hdfs.shortcircuit.DfsClientShmManager$Visitor'></ClassStats><ClassStats bugs='0' size='66' interface='false' sourceFile='DomainSocketFactory.java' class='org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory'></ClassStats><ClassStats bugs='0' size='19' interface='false' sourceFile='DomainSocketFactory.java' class='org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory$PathInfo'></ClassStats><ClassStats bugs='0' size='23' interface='false' sourceFile='DomainSocketFactory.java' class='org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory$PathState'></ClassStats><ClassStats bugs='1' size='421' priority_3='1' interface='false' sourceFile='ShortCircuitCache.java' class='org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache'></ClassStats><ClassStats bugs='0' size='1' interface='false' sourceFile='ShortCircuitCache.java' class='org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache$1'></ClassStats><ClassStats bugs='0' size='46' interface='false' sourceFile='ShortCircuitCache.java' class='org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache$CacheCleaner'></ClassStats><ClassStats bugs='0' size='2' interface='true' sourceFile='ShortCircuitCache.java' class='org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache$CacheVisitor'></ClassStats><ClassStats bugs='0' size='2' interface='true' sourceFile='ShortCircuitCache.java' class='org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache$ShortCircuitReplicaCreator'></ClassStats><ClassStats bugs='1' size='33' priority_3='1' interface='false' sourceFile='ShortCircuitCache.java' class='org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache$SlotReleaser'></ClassStats><ClassStats bugs='0' size='117' interface='false' sourceFile='ShortCircuitReplica.java' class='org.apache.hadoop.hdfs.shortcircuit.ShortCircuitReplica'></ClassStats><ClassStats bugs='0' size='33' interface='false' sourceFile='ShortCircuitReplicaInfo.java' class='org.apache.hadoop.hdfs.shortcircuit.ShortCircuitReplicaInfo'></ClassStats><ClassStats bugs='0' size='107' interface='false' sourceFile='ShortCircuitShm.java' class='org.apache.hadoop.hdfs.shortcircuit.ShortCircuitShm'></ClassStats><ClassStats bugs='0' size='39' interface='false' sourceFile='ShortCircuitShm.java' class='org.apache.hadoop.hdfs.shortcircuit.ShortCircuitShm$ShmId'></ClassStats><ClassStats bugs='0' size='74' interface='false' sourceFile='ShortCircuitShm.java' class='org.apache.hadoop.hdfs.shortcircuit.ShortCircuitShm$Slot'></ClassStats><ClassStats bugs='0' size='27' interface='false' sourceFile='ShortCircuitShm.java' class='org.apache.hadoop.hdfs.shortcircuit.ShortCircuitShm$SlotId'></ClassStats><ClassStats bugs='0' size='21' interface='false' sourceFile='ShortCircuitShm.java' class='org.apache.hadoop.hdfs.shortcircuit.ShortCircuitShm$SlotIterator'></ClassStats><ClassStats bugs='2' size='67' priority_2='2' interface='false' sourceFile='TestShortCircuitShm.java' class='org.apache.hadoop.hdfs.shortcircuit.TestShortCircuitShm'></ClassStats></PackageStats><PackageStats package='org.apache.hadoop.hdfs.util' priority_1='6' total_bugs='13' priority_3='7' total_size='1492' total_types='38'><ClassStats bugs='0' size='33' interface='false' sourceFile='ByteArrayManager.java' class='org.apache.hadoop.hdfs.util.ByteArrayManager'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ByteArrayManager.java' class='org.apache.hadoop.hdfs.util.ByteArrayManager$1'></ClassStats><ClassStats bugs='0' size='14' interface='false' sourceFile='ByteArrayManager.java' class='org.apache.hadoop.hdfs.util.ByteArrayManager$Conf'></ClassStats><ClassStats bugs='0' size='18' interface='false' sourceFile='ByteArrayManager.java' class='org.apache.hadoop.hdfs.util.ByteArrayManager$Counter'></ClassStats><ClassStats bugs='0' size='16' interface='false' sourceFile='ByteArrayManager.java' class='org.apache.hadoop.hdfs.util.ByteArrayManager$CounterMap'></ClassStats><ClassStats bugs='2' size='44' priority_3='2' interface='false' sourceFile='ByteArrayManager.java' class='org.apache.hadoop.hdfs.util.ByteArrayManager$FixedLengthManager'></ClassStats><ClassStats bugs='0' size='48' interface='false' sourceFile='ByteArrayManager.java' class='org.apache.hadoop.hdfs.util.ByteArrayManager$Impl'></ClassStats><ClassStats bugs='0' size='14' interface='false' sourceFile='ByteArrayManager.java' class='org.apache.hadoop.hdfs.util.ByteArrayManager$ManagerMap'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='ByteArrayManager.java' class='org.apache.hadoop.hdfs.util.ByteArrayManager$NewByteArrayWithoutLimit'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='ByteBufferOutputStream.java' class='org.apache.hadoop.hdfs.util.ByteBufferOutputStream'></ClassStats><ClassStats bugs='0' size='33' interface='false' sourceFile='CombinedHostsFileReader.java' class='org.apache.hadoop.hdfs.util.CombinedHostsFileReader'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='CombinedHostsFileWriter.java' class='org.apache.hadoop.hdfs.util.CombinedHostsFileWriter'></ClassStats><ClassStats bugs='0' size='138' interface='false' sourceFile='ECPolicyLoader.java' class='org.apache.hadoop.hdfs.util.ECPolicyLoader'></ClassStats><ClassStats bugs='0' size='21' interface='false' sourceFile='IOUtilsClient.java' class='org.apache.hadoop.hdfs.util.IOUtilsClient'></ClassStats><ClassStats bugs='0' size='27' interface='false' sourceFile='LongBitFormat.java' class='org.apache.hadoop.hdfs.util.LongBitFormat'></ClassStats><ClassStats bugs='0' size='215' interface='false' sourceFile='StripedBlockUtil.java' class='org.apache.hadoop.hdfs.util.StripedBlockUtil'></ClassStats><ClassStats bugs='0' size='22' interface='false' sourceFile='StripedBlockUtil.java' class='org.apache.hadoop.hdfs.util.StripedBlockUtil$AlignedStripe'></ClassStats><ClassStats bugs='0' size='32' interface='false' sourceFile='StripedBlockUtil.java' class='org.apache.hadoop.hdfs.util.StripedBlockUtil$ChunkByteBuffer'></ClassStats><ClassStats bugs='0' size='18' interface='false' sourceFile='StripedBlockUtil.java' class='org.apache.hadoop.hdfs.util.StripedBlockUtil$StripeRange'></ClassStats><ClassStats bugs='1' size='27' priority_3='1' interface='false' sourceFile='StripedBlockUtil.java' class='org.apache.hadoop.hdfs.util.StripedBlockUtil$StripingCell'></ClassStats><ClassStats bugs='0' size='39' interface='false' sourceFile='StripedBlockUtil.java' class='org.apache.hadoop.hdfs.util.StripedBlockUtil$StripingChunk'></ClassStats><ClassStats bugs='0' size='21' interface='false' sourceFile='StripedBlockUtil.java' class='org.apache.hadoop.hdfs.util.StripedBlockUtil$StripingChunkReadResult'></ClassStats><ClassStats bugs='0' size='15' interface='false' sourceFile='StripedBlockUtil.java' class='org.apache.hadoop.hdfs.util.StripedBlockUtil$VerticalRange'></ClassStats><ClassStats bugs='2' size='176' priority_3='2' interface='false' sourceFile='TestByteArrayManager.java' class='org.apache.hadoop.hdfs.util.TestByteArrayManager'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='TestByteArrayManager.java' class='org.apache.hadoop.hdfs.util.TestByteArrayManager$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='TestByteArrayManager.java' class='org.apache.hadoop.hdfs.util.TestByteArrayManager$2'></ClassStats><ClassStats bugs='0' size='28' interface='false' sourceFile='TestByteArrayManager.java' class='org.apache.hadoop.hdfs.util.TestByteArrayManager$3'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='TestByteArrayManager.java' class='org.apache.hadoop.hdfs.util.TestByteArrayManager$4'></ClassStats><ClassStats bugs='0' size='23' interface='false' sourceFile='TestByteArrayManager.java' class='org.apache.hadoop.hdfs.util.TestByteArrayManager$Allocator'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='TestByteArrayManager.java' class='org.apache.hadoop.hdfs.util.TestByteArrayManager$Allocator$1'></ClassStats><ClassStats bugs='0' size='17' interface='false' sourceFile='TestByteArrayManager.java' class='org.apache.hadoop.hdfs.util.TestByteArrayManager$AllocatorThread'></ClassStats><ClassStats bugs='0' size='18' interface='false' sourceFile='TestByteArrayManager.java' class='org.apache.hadoop.hdfs.util.TestByteArrayManager$NewByteArrayWithLimit'></ClassStats><ClassStats bugs='0' size='23' interface='false' sourceFile='TestByteArrayManager.java' class='org.apache.hadoop.hdfs.util.TestByteArrayManager$Recycler'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='TestByteArrayManager.java' class='org.apache.hadoop.hdfs.util.TestByteArrayManager$Recycler$1'></ClassStats><ClassStats bugs='2' size='82' priority_3='2' interface='false' sourceFile='TestByteArrayManager.java' class='org.apache.hadoop.hdfs.util.TestByteArrayManager$Runner'></ClassStats><ClassStats bugs='0' size='14' interface='false' sourceFile='TestByteArrayManager.java' class='org.apache.hadoop.hdfs.util.TestByteArrayManager$Runner$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='TestByteArrayManager.java' class='org.apache.hadoop.hdfs.util.TestByteArrayManager$Runner$2'></ClassStats><ClassStats bugs='6' size='227' priority_1='6' interface='false' sourceFile='TestECPolicyLoader.java' class='org.apache.hadoop.hdfs.util.TestECPolicyLoader'></ClassStats></PackageStats><PackageStats package='org.apache.hadoop.hdfs.web' priority_1='2' total_bugs='30' priority_2='13' priority_3='15' total_size='2827' total_types='73'><ClassStats bugs='0' size='121' interface='false' sourceFile='ByteRangeInputStream.java' class='org.apache.hadoop.hdfs.web.ByteRangeInputStream'></ClassStats><ClassStats bugs='0' size='4' interface='false' sourceFile='ByteRangeInputStream.java' class='org.apache.hadoop.hdfs.web.ByteRangeInputStream$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='ByteRangeInputStream.java' class='org.apache.hadoop.hdfs.web.ByteRangeInputStream$InputStreamAndFileLength'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='ByteRangeInputStream.java' class='org.apache.hadoop.hdfs.web.ByteRangeInputStream$StreamStatus'></ClassStats><ClassStats bugs='1' size='12' priority_3='1' interface='false' sourceFile='ByteRangeInputStream.java' class='org.apache.hadoop.hdfs.web.ByteRangeInputStream$URLOpener'></ClassStats><ClassStats bugs='7' size='469' priority_3='7' interface='false' sourceFile='JsonUtilClient.java' class='org.apache.hadoop.hdfs.web.JsonUtilClient'></ClassStats><ClassStats bugs='0' size='4' interface='false' sourceFile='JsonUtilClient.java' class='org.apache.hadoop.hdfs.web.JsonUtilClient$1'></ClassStats><ClassStats bugs='1' size='5' priority_3='1' interface='false' sourceFile='KerberosUgiAuthenticator.java' class='org.apache.hadoop.hdfs.web.KerberosUgiAuthenticator'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='KerberosUgiAuthenticator.java' class='org.apache.hadoop.hdfs.web.KerberosUgiAuthenticator$1'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='SWebHdfsFileSystem.java' class='org.apache.hadoop.hdfs.web.SWebHdfsFileSystem'></ClassStats><ClassStats bugs='2' size='159' priority_1='1' priority_3='1' interface='false' sourceFile='TestByteRangeInputStream.java' class='org.apache.hadoop.hdfs.web.TestByteRangeInputStream'></ClassStats><ClassStats bugs='1' size='8' priority_2='1' interface='false' sourceFile='TestByteRangeInputStream.java' class='org.apache.hadoop.hdfs.web.TestByteRangeInputStream$ByteRangeInputStreamImpl'></ClassStats><ClassStats bugs='0' size='21' interface='false' sourceFile='TestOffsetUrlInputStream.java' class='org.apache.hadoop.hdfs.web.TestOffsetUrlInputStream'></ClassStats><ClassStats bugs='4' size='103' priority_2='4' interface='false' sourceFile='TestTokenAspect.java' class='org.apache.hadoop.hdfs.web.TestTokenAspect'></ClassStats><ClassStats bugs='0' size='1' interface='false' sourceFile='TestTokenAspect.java' class='org.apache.hadoop.hdfs.web.TestTokenAspect$1'></ClassStats><ClassStats bugs='0' size='58' interface='false' sourceFile='TestTokenAspect.java' class='org.apache.hadoop.hdfs.web.TestTokenAspect$DummyFs'></ClassStats><ClassStats bugs='1' size='20' priority_3='1' interface='false' sourceFile='TestURLConnectionFactory.java' class='org.apache.hadoop.hdfs.web.TestURLConnectionFactory'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='TestURLConnectionFactory.java' class='org.apache.hadoop.hdfs.web.TestURLConnectionFactory$1'></ClassStats><ClassStats bugs='0' size='85' interface='false' sourceFile='TestWebHDFSOAuth2.java' class='org.apache.hadoop.hdfs.web.TestWebHDFSOAuth2'></ClassStats><ClassStats bugs='9' size='104' priority_2='8' priority_3='1' interface='false' sourceFile='TestWebHdfsContentLength.java' class='org.apache.hadoop.hdfs.web.TestWebHdfsContentLength'></ClassStats><ClassStats bugs='1' size='21' priority_1='1' interface='false' sourceFile='TestWebHdfsContentLength.java' class='org.apache.hadoop.hdfs.web.TestWebHdfsContentLength$1'></ClassStats><ClassStats bugs='0' size='46' interface='false' sourceFile='TokenAspect.java' class='org.apache.hadoop.hdfs.web.TokenAspect'></ClassStats><ClassStats bugs='0' size='4' interface='false' sourceFile='TokenAspect.java' class='org.apache.hadoop.hdfs.web.TokenAspect$DTSelecorByKind'></ClassStats><ClassStats bugs='0' size='3' interface='true' sourceFile='TokenAspect.java' class='org.apache.hadoop.hdfs.web.TokenAspect$TokenManagementDelegator'></ClassStats><ClassStats bugs='0' size='27' interface='false' sourceFile='TokenAspect.java' class='org.apache.hadoop.hdfs.web.TokenAspect$TokenManager'></ClassStats><ClassStats bugs='0' size='67' interface='false' sourceFile='URLConnectionFactory.java' class='org.apache.hadoop.hdfs.web.URLConnectionFactory'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='URLConnectionFactory.java' class='org.apache.hadoop.hdfs.web.URLConnectionFactory$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='URLConnectionFactory.java' class='org.apache.hadoop.hdfs.web.URLConnectionFactory$2'></ClassStats><ClassStats bugs='0' size='14' interface='false' sourceFile='URLConnectionFactory.java' class='org.apache.hadoop.hdfs.web.URLConnectionFactory$3'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='WebHdfsConstants.java' class='org.apache.hadoop.hdfs.web.WebHdfsConstants'></ClassStats><ClassStats bugs='0' size='17' interface='false' sourceFile='WebHdfsConstants.java' class='org.apache.hadoop.hdfs.web.WebHdfsConstants$PathType'></ClassStats><ClassStats bugs='3' size='715' priority_3='3' interface='false' sourceFile='WebHdfsFileSystem.java' class='org.apache.hadoop.hdfs.web.WebHdfsFileSystem'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='WebHdfsFileSystem.java' class='org.apache.hadoop.hdfs.web.WebHdfsFileSystem$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='WebHdfsFileSystem.java' class='org.apache.hadoop.hdfs.web.WebHdfsFileSystem$10'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='WebHdfsFileSystem.java' class='org.apache.hadoop.hdfs.web.WebHdfsFileSystem$11'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='WebHdfsFileSystem.java' class='org.apache.hadoop.hdfs.web.WebHdfsFileSystem$12'></ClassStats><ClassStats bugs='0' size='14' interface='false' sourceFile='WebHdfsFileSystem.java' class='org.apache.hadoop.hdfs.web.WebHdfsFileSystem$13'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='WebHdfsFileSystem.java' class='org.apache.hadoop.hdfs.web.WebHdfsFileSystem$14'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='WebHdfsFileSystem.java' class='org.apache.hadoop.hdfs.web.WebHdfsFileSystem$15'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='WebHdfsFileSystem.java' class='org.apache.hadoop.hdfs.web.WebHdfsFileSystem$16'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='WebHdfsFileSystem.java' class='org.apache.hadoop.hdfs.web.WebHdfsFileSystem$17'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='WebHdfsFileSystem.java' class='org.apache.hadoop.hdfs.web.WebHdfsFileSystem$18'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='WebHdfsFileSystem.java' class='org.apache.hadoop.hdfs.web.WebHdfsFileSystem$19'></ClassStats><ClassStats bugs='0' size='4' interface='false' sourceFile='WebHdfsFileSystem.java' class='org.apache.hadoop.hdfs.web.WebHdfsFileSystem$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='WebHdfsFileSystem.java' class='org.apache.hadoop.hdfs.web.WebHdfsFileSystem$20'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='WebHdfsFileSystem.java' class='org.apache.hadoop.hdfs.web.WebHdfsFileSystem$21'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='WebHdfsFileSystem.java' class='org.apache.hadoop.hdfs.web.WebHdfsFileSystem$22'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='WebHdfsFileSystem.java' class='org.apache.hadoop.hdfs.web.WebHdfsFileSystem$23'></ClassStats><ClassStats bugs='0' size='4' interface='false' sourceFile='WebHdfsFileSystem.java' class='org.apache.hadoop.hdfs.web.WebHdfsFileSystem$24'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='WebHdfsFileSystem.java' class='org.apache.hadoop.hdfs.web.WebHdfsFileSystem$3'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='WebHdfsFileSystem.java' class='org.apache.hadoop.hdfs.web.WebHdfsFileSystem$4'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='WebHdfsFileSystem.java' class='org.apache.hadoop.hdfs.web.WebHdfsFileSystem$5'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='WebHdfsFileSystem.java' class='org.apache.hadoop.hdfs.web.WebHdfsFileSystem$6'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='WebHdfsFileSystem.java' class='org.apache.hadoop.hdfs.web.WebHdfsFileSystem$7'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='WebHdfsFileSystem.java' class='org.apache.hadoop.hdfs.web.WebHdfsFileSystem$8'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='WebHdfsFileSystem.java' class='org.apache.hadoop.hdfs.web.WebHdfsFileSystem$9'></ClassStats><ClassStats bugs='0' size='26' interface='false' sourceFile='WebHdfsFileSystem.java' class='org.apache.hadoop.hdfs.web.WebHdfsFileSystem$AbstractFsPathRunner'></ClassStats><ClassStats bugs='0' size='120' interface='false' sourceFile='WebHdfsFileSystem.java' class='org.apache.hadoop.hdfs.web.WebHdfsFileSystem$AbstractRunner'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='WebHdfsFileSystem.java' class='org.apache.hadoop.hdfs.web.WebHdfsFileSystem$AbstractRunner$1'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='WebHdfsFileSystem.java' class='org.apache.hadoop.hdfs.web.WebHdfsFileSystem$FsPathBooleanRunner'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='WebHdfsFileSystem.java' class='org.apache.hadoop.hdfs.web.WebHdfsFileSystem$FsPathConnectionRunner'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='WebHdfsFileSystem.java' class='org.apache.hadoop.hdfs.web.WebHdfsFileSystem$FsPathOutputStreamRunner'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='WebHdfsFileSystem.java' class='org.apache.hadoop.hdfs.web.WebHdfsFileSystem$FsPathOutputStreamRunner$1'></ClassStats><ClassStats bugs='0' size='25' interface='false' sourceFile='WebHdfsFileSystem.java' class='org.apache.hadoop.hdfs.web.WebHdfsFileSystem$FsPathResponseRunner'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='WebHdfsFileSystem.java' class='org.apache.hadoop.hdfs.web.WebHdfsFileSystem$FsPathRunner'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='WebHdfsFileSystem.java' class='org.apache.hadoop.hdfs.web.WebHdfsFileSystem$OffsetUrlInputStream'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='WebHdfsFileSystem.java' class='org.apache.hadoop.hdfs.web.WebHdfsFileSystem$OffsetUrlOpener'></ClassStats><ClassStats bugs='0' size='154' interface='false' sourceFile='WebHdfsFileSystem.java' class='org.apache.hadoop.hdfs.web.WebHdfsFileSystem$ReadRunner'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='WebHdfsFileSystem.java' class='org.apache.hadoop.hdfs.web.WebHdfsFileSystem$ReadRunner$1'></ClassStats><ClassStats bugs='0' size='15' interface='false' sourceFile='WebHdfsFileSystem.java' class='org.apache.hadoop.hdfs.web.WebHdfsFileSystem$RunnerState'></ClassStats><ClassStats bugs='0' size='14' interface='false' sourceFile='WebHdfsFileSystem.java' class='org.apache.hadoop.hdfs.web.WebHdfsFileSystem$URLRunner'></ClassStats><ClassStats bugs='0' size='16' interface='false' sourceFile='WebHdfsFileSystem.java' class='org.apache.hadoop.hdfs.web.WebHdfsFileSystem$UnresolvedUrlOpener'></ClassStats><ClassStats bugs='0' size='42' interface='false' sourceFile='WebHdfsFileSystem.java' class='org.apache.hadoop.hdfs.web.WebHdfsFileSystem$WebHdfsInputStream'></ClassStats></PackageStats><PackageStats package='org.apache.hadoop.hdfs.web.oauth2' total_bugs='2' priority_3='2' total_size='348' total_types='12'><ClassStats bugs='0' size='10' interface='false' sourceFile='AccessTokenProvider.java' class='org.apache.hadoop.hdfs.web.oauth2.AccessTokenProvider'></ClassStats><ClassStats bugs='0' size='28' interface='false' sourceFile='AccessTokenTimer.java' class='org.apache.hadoop.hdfs.web.oauth2.AccessTokenTimer'></ClassStats><ClassStats bugs='0' size='16' interface='false' sourceFile='ConfCredentialBasedAccessTokenProvider.java' class='org.apache.hadoop.hdfs.web.oauth2.ConfCredentialBasedAccessTokenProvider'></ClassStats><ClassStats bugs='1' size='56' priority_3='1' interface='false' sourceFile='ConfRefreshTokenBasedAccessTokenProvider.java' class='org.apache.hadoop.hdfs.web.oauth2.ConfRefreshTokenBasedAccessTokenProvider'></ClassStats><ClassStats bugs='1' size='53' priority_3='1' interface='false' sourceFile='CredentialBasedAccessTokenProvider.java' class='org.apache.hadoop.hdfs.web.oauth2.CredentialBasedAccessTokenProvider'></ClassStats><ClassStats bugs='0' size='23' interface='false' sourceFile='OAuth2ConnectionConfigurator.java' class='org.apache.hadoop.hdfs.web.oauth2.OAuth2ConnectionConfigurator'></ClassStats><ClassStats bugs='0' size='16' interface='false' sourceFile='OAuth2Constants.java' class='org.apache.hadoop.hdfs.web.oauth2.OAuth2Constants'></ClassStats><ClassStats bugs='0' size='23' interface='false' sourceFile='TestAccessTokenTimer.java' class='org.apache.hadoop.hdfs.web.oauth2.TestAccessTokenTimer'></ClassStats><ClassStats bugs='0' size='52' interface='false' sourceFile='TestClientCredentialTimeBasedTokenRefresher.java' class='org.apache.hadoop.hdfs.web.oauth2.TestClientCredentialTimeBasedTokenRefresher'></ClassStats><ClassStats bugs='0' size='50' interface='false' sourceFile='TestRefreshTokenTimeBasedTokenRefresher.java' class='org.apache.hadoop.hdfs.web.oauth2.TestRefreshTokenTimeBasedTokenRefresher'></ClassStats><ClassStats bugs='0' size='20' interface='false' sourceFile='Utils.java' class='org.apache.hadoop.hdfs.web.oauth2.Utils'></ClassStats><ClassStats bugs='0' size='1' interface='true' sourceFile='package-info.java' class='org.apache.hadoop.hdfs.web.oauth2.package-info'></ClassStats></PackageStats><PackageStats package='org.apache.hadoop.hdfs.web.resources' total_bugs='0' total_size='1241' total_types='65'><ClassStats bugs='0' size='17' interface='false' sourceFile='AccessTimeParam.java' class='org.apache.hadoop.hdfs.web.resources.AccessTimeParam'></ClassStats><ClassStats bugs='0' size='45' interface='false' sourceFile='AclPermissionParam.java' class='org.apache.hadoop.hdfs.web.resources.AclPermissionParam'></ClassStats><ClassStats bugs='0' size='20' interface='false' sourceFile='BlockSizeParam.java' class='org.apache.hadoop.hdfs.web.resources.BlockSizeParam'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='BooleanParam.java' class='org.apache.hadoop.hdfs.web.resources.BooleanParam'></ClassStats><ClassStats bugs='0' size='14' interface='false' sourceFile='BooleanParam.java' class='org.apache.hadoop.hdfs.web.resources.BooleanParam$Domain'></ClassStats><ClassStats bugs='0' size='20' interface='false' sourceFile='BufferSizeParam.java' class='org.apache.hadoop.hdfs.web.resources.BufferSizeParam'></ClassStats><ClassStats bugs='0' size='25' interface='false' sourceFile='ConcatSourcesParam.java' class='org.apache.hadoop.hdfs.web.resources.ConcatSourcesParam'></ClassStats><ClassStats bugs='0' size='17' interface='false' sourceFile='CreateFlagParam.java' class='org.apache.hadoop.hdfs.web.resources.CreateFlagParam'></ClassStats><ClassStats bugs='0' size='16' interface='false' sourceFile='CreateParentParam.java' class='org.apache.hadoop.hdfs.web.resources.CreateParentParam'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='DelegationParam.java' class='org.apache.hadoop.hdfs.web.resources.DelegationParam'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='DeleteOpParam.java' class='org.apache.hadoop.hdfs.web.resources.DeleteOpParam'></ClassStats><ClassStats bugs='0' size='29' interface='false' sourceFile='DeleteOpParam.java' class='org.apache.hadoop.hdfs.web.resources.DeleteOpParam$Op'></ClassStats><ClassStats bugs='0' size='19' interface='false' sourceFile='DestinationParam.java' class='org.apache.hadoop.hdfs.web.resources.DestinationParam'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='DoAsParam.java' class='org.apache.hadoop.hdfs.web.resources.DoAsParam'></ClassStats><ClassStats bugs='0' size='4' interface='false' sourceFile='EnumParam.java' class='org.apache.hadoop.hdfs.web.resources.EnumParam'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='EnumParam.java' class='org.apache.hadoop.hdfs.web.resources.EnumParam$Domain'></ClassStats><ClassStats bugs='0' size='21' interface='false' sourceFile='EnumSetParam.java' class='org.apache.hadoop.hdfs.web.resources.EnumSetParam'></ClassStats><ClassStats bugs='0' size='20' interface='false' sourceFile='EnumSetParam.java' class='org.apache.hadoop.hdfs.web.resources.EnumSetParam$Domain'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='ExcludeDatanodesParam.java' class='org.apache.hadoop.hdfs.web.resources.ExcludeDatanodesParam'></ClassStats><ClassStats bugs='0' size='19' interface='false' sourceFile='FsActionParam.java' class='org.apache.hadoop.hdfs.web.resources.FsActionParam'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='GetOpParam.java' class='org.apache.hadoop.hdfs.web.resources.GetOpParam'></ClassStats><ClassStats bugs='0' size='70' interface='false' sourceFile='GetOpParam.java' class='org.apache.hadoop.hdfs.web.resources.GetOpParam$Op'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='GroupParam.java' class='org.apache.hadoop.hdfs.web.resources.GroupParam'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='HttpOpParam.java' class='org.apache.hadoop.hdfs.web.resources.HttpOpParam'></ClassStats><ClassStats bugs='0' size='7' interface='true' sourceFile='HttpOpParam.java' class='org.apache.hadoop.hdfs.web.resources.HttpOpParam$Op'></ClassStats><ClassStats bugs='0' size='36' interface='false' sourceFile='HttpOpParam.java' class='org.apache.hadoop.hdfs.web.resources.HttpOpParam$TemporaryRedirectOp'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='HttpOpParam.java' class='org.apache.hadoop.hdfs.web.resources.HttpOpParam$Type'></ClassStats><ClassStats bugs='0' size='19' interface='false' sourceFile='IntegerParam.java' class='org.apache.hadoop.hdfs.web.resources.IntegerParam'></ClassStats><ClassStats bugs='0' size='19' interface='false' sourceFile='IntegerParam.java' class='org.apache.hadoop.hdfs.web.resources.IntegerParam$Domain'></ClassStats><ClassStats bugs='0' size='20' interface='false' sourceFile='LengthParam.java' class='org.apache.hadoop.hdfs.web.resources.LengthParam'></ClassStats><ClassStats bugs='0' size='19' interface='false' sourceFile='LongParam.java' class='org.apache.hadoop.hdfs.web.resources.LongParam'></ClassStats><ClassStats bugs='0' size='19' interface='false' sourceFile='LongParam.java' class='org.apache.hadoop.hdfs.web.resources.LongParam$Domain'></ClassStats><ClassStats bugs='0' size='17' interface='false' sourceFile='ModificationTimeParam.java' class='org.apache.hadoop.hdfs.web.resources.ModificationTimeParam'></ClassStats><ClassStats bugs='0' size='17' interface='false' sourceFile='NewLengthParam.java' class='org.apache.hadoop.hdfs.web.resources.NewLengthParam'></ClassStats><ClassStats bugs='0' size='16' interface='false' sourceFile='NoRedirectParam.java' class='org.apache.hadoop.hdfs.web.resources.NoRedirectParam'></ClassStats><ClassStats bugs='0' size='20' interface='false' sourceFile='OffsetParam.java' class='org.apache.hadoop.hdfs.web.resources.OffsetParam'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='OldSnapshotNameParam.java' class='org.apache.hadoop.hdfs.web.resources.OldSnapshotNameParam'></ClassStats><ClassStats bugs='0' size='16' interface='false' sourceFile='OverwriteParam.java' class='org.apache.hadoop.hdfs.web.resources.OverwriteParam'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='OwnerParam.java' class='org.apache.hadoop.hdfs.web.resources.OwnerParam'></ClassStats><ClassStats bugs='0' size='31' interface='false' sourceFile='Param.java' class='org.apache.hadoop.hdfs.web.resources.Param'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='Param.java' class='org.apache.hadoop.hdfs.web.resources.Param$1'></ClassStats><ClassStats bugs='0' size='15' interface='false' sourceFile='Param.java' class='org.apache.hadoop.hdfs.web.resources.Param$Domain'></ClassStats><ClassStats bugs='0' size='35' interface='false' sourceFile='PermissionParam.java' class='org.apache.hadoop.hdfs.web.resources.PermissionParam'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='PostOpParam.java' class='org.apache.hadoop.hdfs.web.resources.PostOpParam'></ClassStats><ClassStats bugs='0' size='35' interface='false' sourceFile='PostOpParam.java' class='org.apache.hadoop.hdfs.web.resources.PostOpParam$Op'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='PutOpParam.java' class='org.apache.hadoop.hdfs.web.resources.PutOpParam'></ClassStats><ClassStats bugs='0' size='76' interface='false' sourceFile='PutOpParam.java' class='org.apache.hadoop.hdfs.web.resources.PutOpParam$Op'></ClassStats><ClassStats bugs='0' size='16' interface='false' sourceFile='RecursiveParam.java' class='org.apache.hadoop.hdfs.web.resources.RecursiveParam'></ClassStats><ClassStats bugs='0' size='17' interface='false' sourceFile='RenameOptionSetParam.java' class='org.apache.hadoop.hdfs.web.resources.RenameOptionSetParam'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='RenewerParam.java' class='org.apache.hadoop.hdfs.web.resources.RenewerParam'></ClassStats><ClassStats bugs='0' size='19' interface='false' sourceFile='ReplicationParam.java' class='org.apache.hadoop.hdfs.web.resources.ReplicationParam'></ClassStats><ClassStats bugs='0' size='19' interface='false' sourceFile='ShortParam.java' class='org.apache.hadoop.hdfs.web.resources.ShortParam'></ClassStats><ClassStats bugs='0' size='19' interface='false' sourceFile='ShortParam.java' class='org.apache.hadoop.hdfs.web.resources.ShortParam$Domain'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='SnapshotNameParam.java' class='org.apache.hadoop.hdfs.web.resources.SnapshotNameParam'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='StartAfterParam.java' class='org.apache.hadoop.hdfs.web.resources.StartAfterParam'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='StoragePolicyParam.java' class='org.apache.hadoop.hdfs.web.resources.StoragePolicyParam'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='StringParam.java' class='org.apache.hadoop.hdfs.web.resources.StringParam'></ClassStats><ClassStats bugs='0' size='16' interface='false' sourceFile='StringParam.java' class='org.apache.hadoop.hdfs.web.resources.StringParam$Domain'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='TokenArgumentParam.java' class='org.apache.hadoop.hdfs.web.resources.TokenArgumentParam'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='UnmaskedPermissionParam.java' class='org.apache.hadoop.hdfs.web.resources.UnmaskedPermissionParam'></ClassStats><ClassStats bugs='0' size='34' interface='false' sourceFile='UserParam.java' class='org.apache.hadoop.hdfs.web.resources.UserParam'></ClassStats><ClassStats bugs='0' size='18' interface='false' sourceFile='XAttrEncodingParam.java' class='org.apache.hadoop.hdfs.web.resources.XAttrEncodingParam'></ClassStats><ClassStats bugs='0' size='15' interface='false' sourceFile='XAttrNameParam.java' class='org.apache.hadoop.hdfs.web.resources.XAttrNameParam'></ClassStats><ClassStats bugs='0' size='19' interface='false' sourceFile='XAttrSetFlagParam.java' class='org.apache.hadoop.hdfs.web.resources.XAttrSetFlagParam'></ClassStats><ClassStats bugs='0' size='16' interface='false' sourceFile='XAttrValueParam.java' class='org.apache.hadoop.hdfs.web.resources.XAttrValueParam'></ClassStats></PackageStats><FindBugsProfile><ClassProfile avgMicrosecondsPerInvocation='62' totalMilliseconds='2837' name='edu.umd.cs.findbugs.classfile.engine.bcel.IsNullValueDataflowFactory' maxMicrosecondsPerInvocation='16896' standardDeviationMicrosecondsPerInvocation='238' invocations='45229'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='82' totalMilliseconds='2802' name='edu.umd.cs.findbugs.ba.npe.NullDerefAndRedundantComparisonFinder' maxMicrosecondsPerInvocation='160935' standardDeviationMicrosecondsPerInvocation='1000' invocations='33838'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='70' totalMilliseconds='2595' name='edu.umd.cs.findbugs.classfile.engine.bcel.UnconditionalValueDerefDataflowFactory' maxMicrosecondsPerInvocation='281316' standardDeviationMicrosecondsPerInvocation='1731' invocations='36883'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='52' totalMilliseconds='2479' name='edu.umd.cs.findbugs.classfile.engine.bcel.TypeDataflowFactory' maxMicrosecondsPerInvocation='158723' standardDeviationMicrosecondsPerInvocation='757' invocations='47027'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='41' totalMilliseconds='2019' name='edu.umd.cs.findbugs.classfile.engine.bcel.ValueNumberDataflowFactory' maxMicrosecondsPerInvocation='21947' standardDeviationMicrosecondsPerInvocation='286' invocations='48597'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='364' totalMilliseconds='2013' name='edu.umd.cs.findbugs.classfile.engine.ClassDataAnalysisEngine' maxMicrosecondsPerInvocation='1827' standardDeviationMicrosecondsPerInvocation='301' invocations='5521'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='48' totalMilliseconds='1744' name='edu.umd.cs.findbugs.detect.FindRefComparison$SpecialTypeAnalysis' maxMicrosecondsPerInvocation='229409' standardDeviationMicrosecondsPerInvocation='1229' invocations='35801'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='91' totalMilliseconds='1715' name='edu.umd.cs.findbugs.ba.obl.ObligationAnalysis' maxMicrosecondsPerInvocation='20342' standardDeviationMicrosecondsPerInvocation='285' invocations='18767'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='32' totalMilliseconds='1430' name='edu.umd.cs.findbugs.classfile.engine.bcel.CFGFactory' maxMicrosecondsPerInvocation='31157' standardDeviationMicrosecondsPerInvocation='185' invocations='44236'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='222' totalMilliseconds='1169' name='edu.umd.cs.findbugs.classfile.engine.ClassInfoAnalysisEngine' maxMicrosecondsPerInvocation='180201' standardDeviationMicrosecondsPerInvocation='2775' invocations='5256'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='1' totalMilliseconds='1165' name='edu.umd.cs.findbugs.ba.npe.TypeQualifierNullnessAnnotationDatabase' maxMicrosecondsPerInvocation='12736' standardDeviationMicrosecondsPerInvocation='19' invocations='670401'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='350' totalMilliseconds='1050' name='edu.umd.cs.findbugs.detect.FieldItemSummary' maxMicrosecondsPerInvocation='36717' standardDeviationMicrosecondsPerInvocation='950' invocations='2994'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='320' totalMilliseconds='959' name='edu.umd.cs.findbugs.detect.FindNoSideEffectMethods' maxMicrosecondsPerInvocation='14433' standardDeviationMicrosecondsPerInvocation='700' invocations='2994'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='448' totalMilliseconds='946' name='edu.umd.cs.findbugs.detect.FindOpenStream' maxMicrosecondsPerInvocation='164159' standardDeviationMicrosecondsPerInvocation='3859' invocations='2112'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='17' totalMilliseconds='826' name='edu.umd.cs.findbugs.OpcodeStack$JumpInfoFactory' maxMicrosecondsPerInvocation='15779' standardDeviationMicrosecondsPerInvocation='133' invocations='46513'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='2' totalMilliseconds='637' name='edu.umd.cs.findbugs.DetectorToDetector2Adapter' maxMicrosecondsPerInvocation='444' standardDeviationMicrosecondsPerInvocation='1' invocations='253974'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='283' totalMilliseconds='597' name='edu.umd.cs.findbugs.detect.FindBadCast2' maxMicrosecondsPerInvocation='33251' standardDeviationMicrosecondsPerInvocation='1380' invocations='2112'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='279' totalMilliseconds='589' name='edu.umd.cs.findbugs.detect.FindInconsistentSync2' maxMicrosecondsPerInvocation='11700' standardDeviationMicrosecondsPerInvocation='604' invocations='2112'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='13' totalMilliseconds='584' name='edu.umd.cs.findbugs.classfile.engine.bcel.ConstantDataflowFactory' maxMicrosecondsPerInvocation='10493' standardDeviationMicrosecondsPerInvocation='99' invocations='44236'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='273' totalMilliseconds='577' name='edu.umd.cs.findbugs.detect.LoadOfKnownNullValue' maxMicrosecondsPerInvocation='13912' standardDeviationMicrosecondsPerInvocation='560' invocations='2112'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='271' totalMilliseconds='572' name='edu.umd.cs.findbugs.detect.SynchronizingOnContentsOfFieldToProtectField' maxMicrosecondsPerInvocation='344168' standardDeviationMicrosecondsPerInvocation='7490' invocations='2112'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='11' totalMilliseconds='535' name='edu.umd.cs.findbugs.classfile.engine.bcel.MethodGenFactory' maxMicrosecondsPerInvocation='123867' standardDeviationMicrosecondsPerInvocation='573' invocations='46827'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='249' totalMilliseconds='527' name='edu.umd.cs.findbugs.detect.UnreadFields' maxMicrosecondsPerInvocation='21168' standardDeviationMicrosecondsPerInvocation='723' invocations='2112'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='13' totalMilliseconds='468' name='edu.umd.cs.findbugs.detect.FindNullDeref$CheckCallSitesAndReturnInstructions' maxMicrosecondsPerInvocation='9958' standardDeviationMicrosecondsPerInvocation='87' invocations='33838'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='220' totalMilliseconds='465' name='edu.umd.cs.findbugs.detect.SwitchFallthrough' maxMicrosecondsPerInvocation='211450' standardDeviationMicrosecondsPerInvocation='4603' invocations='2112'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='217' totalMilliseconds='459' name='edu.umd.cs.findbugs.detect.FindNullDeref' maxMicrosecondsPerInvocation='12658' standardDeviationMicrosecondsPerInvocation='487' invocations='2112'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='207' totalMilliseconds='438' name='edu.umd.cs.findbugs.detect.DumbMethods' maxMicrosecondsPerInvocation='11834' standardDeviationMicrosecondsPerInvocation='450' invocations='2112'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='202' totalMilliseconds='427' name='edu.umd.cs.findbugs.detect.InfiniteLoop' maxMicrosecondsPerInvocation='176463' standardDeviationMicrosecondsPerInvocation='3847' invocations='2112'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='190' totalMilliseconds='402' name='edu.umd.cs.findbugs.detect.FindRefComparison' maxMicrosecondsPerInvocation='7752' standardDeviationMicrosecondsPerInvocation='359' invocations='2112'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='188' totalMilliseconds='398' name='edu.umd.cs.findbugs.detect.MethodReturnCheck' maxMicrosecondsPerInvocation='9103' standardDeviationMicrosecondsPerInvocation='368' invocations='2112'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='184' totalMilliseconds='389' name='edu.umd.cs.findbugs.detect.FindUselessObjects' maxMicrosecondsPerInvocation='166772' standardDeviationMicrosecondsPerInvocation='3636' invocations='2112'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='158' totalMilliseconds='333' name='edu.umd.cs.findbugs.detect.NoteNonnullReturnValues' maxMicrosecondsPerInvocation='8251' standardDeviationMicrosecondsPerInvocation='277' invocations='2112'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='149' totalMilliseconds='316' name='edu.umd.cs.findbugs.detect.FindUseOfNonSerializableValue' maxMicrosecondsPerInvocation='11695' standardDeviationMicrosecondsPerInvocation='320' invocations='2112'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='148' totalMilliseconds='314' name='edu.umd.cs.findbugs.detect.RuntimeExceptionCapture' maxMicrosecondsPerInvocation='8853' standardDeviationMicrosecondsPerInvocation='332' invocations='2112'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='145' totalMilliseconds='307' name='edu.umd.cs.findbugs.detect.SerializableIdiom' maxMicrosecondsPerInvocation='10479' standardDeviationMicrosecondsPerInvocation='408' invocations='2112'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='145' totalMilliseconds='306' name='edu.umd.cs.findbugs.detect.FindSelfComparison' maxMicrosecondsPerInvocation='17545' standardDeviationMicrosecondsPerInvocation='525' invocations='2112'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='142' totalMilliseconds='301' name='edu.umd.cs.findbugs.detect.IncompatMask' maxMicrosecondsPerInvocation='18688' standardDeviationMicrosecondsPerInvocation='529' invocations='2112'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='141' totalMilliseconds='299' name='edu.umd.cs.findbugs.detect.FindHEmismatch' maxMicrosecondsPerInvocation='15705' standardDeviationMicrosecondsPerInvocation='482' invocations='2112'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='9' totalMilliseconds='290' name='edu.umd.cs.findbugs.classfile.engine.bcel.LiveLocalStoreDataflowFactory' maxMicrosecondsPerInvocation='14425' standardDeviationMicrosecondsPerInvocation='104' invocations='29286'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='135' totalMilliseconds='285' name='edu.umd.cs.findbugs.detect.FindDeadLocalStores' maxMicrosecondsPerInvocation='11091' standardDeviationMicrosecondsPerInvocation='395' invocations='2112'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='135' totalMilliseconds='285' name='edu.umd.cs.findbugs.detect.CrossSiteScripting' maxMicrosecondsPerInvocation='13171' standardDeviationMicrosecondsPerInvocation='551' invocations='2112'></ClassProfile></FindBugsProfile></FindBugsSummary><ClassFeatures></ClassFeatures><History></History></BugCollection>