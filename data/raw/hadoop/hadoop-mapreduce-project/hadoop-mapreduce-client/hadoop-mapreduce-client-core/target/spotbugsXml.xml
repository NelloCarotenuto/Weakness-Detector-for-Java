
<BugCollection sequence='0' release='' analysisTimestamp='1568197637913' version='3.1.12' timestamp='1568191385000'><Project projectName='Apache Hadoop MapReduce Core'><Jar>./hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/classes</Jar><AuxClasspathEntry>.m2/repository/org/apache/hadoop/hadoop-yarn-client/3.1.1/hadoop-yarn-client-3.1.1.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/log4j/log4j/1.2.17/log4j-1.2.17.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/org/apache/hadoop/hadoop-yarn-api/3.1.1/hadoop-yarn-api-3.1.1.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/org/apache/hadoop/hadoop-yarn-common/3.1.1/hadoop-yarn-common-3.1.1.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/org/apache/hadoop/hadoop-auth/3.1.1/hadoop-auth-3.1.1.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/com/nimbusds/nimbus-jose-jwt/4.41.1/nimbus-jose-jwt-4.41.1.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/com/github/stephenc/jcip/jcip-annotations/1.0-1/jcip-annotations-1.0-1.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/net/minidev/json-smart/2.3/json-smart-2.3.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/net/minidev/accessors-smart/1.2/accessors-smart-1.2.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/org/ow2/asm/asm/5.0.4/asm-5.0.4.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/org/apache/curator/curator-framework/2.12.0/curator-framework-2.12.0.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/javax/xml/bind/jaxb-api/2.2.11/jaxb-api-2.2.11.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/org/apache/commons/commons-compress/1.4.1/commons-compress-1.4.1.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/org/tukaani/xz/1.0/xz-1.0.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/javax/servlet/javax.servlet-api/3.1.0/javax.servlet-api-3.1.0.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/org/eclipse/jetty/jetty-util/9.3.19.v20170502/jetty-util-9.3.19.v20170502.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/com/sun/jersey/jersey-core/1.19/jersey-core-1.19.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/javax/ws/rs/jsr311-api/1.1.1/jsr311-api-1.1.1.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/com/sun/jersey/jersey-client/1.19/jersey-client-1.19.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/commons-io/commons-io/2.5/commons-io-2.5.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/com/google/inject/guice/4.0/guice-4.0.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/javax/inject/javax.inject/1/javax.inject-1.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/aopalliance/aopalliance/1.0/aopalliance-1.0.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/com/sun/jersey/jersey-server/1.19/jersey-server-1.19.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/com/sun/jersey/jersey-json/1.19/jersey-json-1.19.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/org/codehaus/jettison/jettison/1.1/jettison-1.1.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/com/sun/xml/bind/jaxb-impl/2.2.3-1/jaxb-impl-2.2.3-1.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/org/codehaus/jackson/jackson-jaxrs/1.9.13/jackson-jaxrs-1.9.13.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/org/codehaus/jackson/jackson-xc/1.9.13/jackson-xc-1.9.13.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/com/sun/jersey/contribs/jersey-guice/1.19/jersey-guice-1.19.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/com/fasterxml/jackson/core/jackson-core/2.7.8/jackson-core-2.7.8.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/com/fasterxml/jackson/module/jackson-module-jaxb-annotations/2.7.8/jackson-module-jaxb-annotations-2.7.8.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/com/fasterxml/jackson/jaxrs/jackson-jaxrs-json-provider/2.7.8/jackson-jaxrs-json-provider-2.7.8.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/com/fasterxml/jackson/jaxrs/jackson-jaxrs-base/2.7.8/jackson-jaxrs-base-2.7.8.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/org/apache/hadoop/hadoop-hdfs-client/3.1.1/hadoop-hdfs-client-3.1.1.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/com/squareup/okhttp/okhttp/2.7.5/okhttp-2.7.5.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/com/squareup/okio/okio/1.6.0/okio-1.6.0.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/com/fasterxml/jackson/core/jackson-annotations/2.7.8/jackson-annotations-2.7.8.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/org/eclipse/jetty/jetty-server/9.3.19.v20170502/jetty-server-9.3.19.v20170502.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/org/eclipse/jetty/jetty-http/9.3.19.v20170502/jetty-http-9.3.19.v20170502.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/org/eclipse/jetty/jetty-io/9.3.19.v20170502/jetty-io-9.3.19.v20170502.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/org/apache/htrace/htrace-core4/4.1.0-incubating/htrace-core4-4.1.0-incubating.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/com/fasterxml/jackson/core/jackson-databind/2.7.8/jackson-databind-2.7.8.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/org/apache/avro/avro/1.7.7/avro-1.7.7.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/org/codehaus/jackson/jackson-core-asl/1.9.13/jackson-core-asl-1.9.13.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/com/thoughtworks/paranamer/paranamer/2.3/paranamer-2.3.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/org/xerial/snappy/snappy-java/1.0.5/snappy-java-1.0.5.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/org/apache/hadoop/hadoop-common/3.1.1/hadoop-common-3.1.1.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/org/apache/commons/commons-math3/3.1.1/commons-math3-3.1.1.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/org/apache/httpcomponents/httpclient/4.5.2/httpclient-4.5.2.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/org/apache/httpcomponents/httpcore/4.4.4/httpcore-4.4.4.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/commons-net/commons-net/3.6/commons-net-3.6.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/org/eclipse/jetty/jetty-servlet/9.3.19.v20170502/jetty-servlet-9.3.19.v20170502.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/org/eclipse/jetty/jetty-security/9.3.19.v20170502/jetty-security-9.3.19.v20170502.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/org/eclipse/jetty/jetty-webapp/9.3.19.v20170502/jetty-webapp-9.3.19.v20170502.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/org/eclipse/jetty/jetty-xml/9.3.19.v20170502/jetty-xml-9.3.19.v20170502.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/javax/servlet/jsp/jsp-api/2.1/jsp-api-2.1.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/com/sun/jersey/jersey-servlet/1.19/jersey-servlet-1.19.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/commons-beanutils/commons-beanutils/1.9.3/commons-beanutils-1.9.3.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/org/apache/commons/commons-configuration2/2.1.1/commons-configuration2-2.1.1.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/org/apache/commons/commons-lang3/3.4/commons-lang3-3.4.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/com/google/re2j/re2j/1.1/re2j-1.1.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/com/google/code/gson/gson/2.2.4/gson-2.2.4.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/com/jcraft/jsch/0.1.54/jsch-0.1.54.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/org/apache/curator/curator-client/2.12.0/curator-client-2.12.0.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/org/apache/curator/curator-recipes/2.12.0/curator-recipes-2.12.0.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/com/google/code/findbugs/jsr305/3.0.0/jsr305-3.0.0.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/org/apache/zookeeper/zookeeper/3.4.9/zookeeper-3.4.9.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/org/apache/kerby/kerb-simplekdc/1.0.1/kerb-simplekdc-1.0.1.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/org/apache/kerby/kerb-client/1.0.1/kerb-client-1.0.1.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/org/apache/kerby/kerby-config/1.0.1/kerby-config-1.0.1.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/org/apache/kerby/kerb-core/1.0.1/kerb-core-1.0.1.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/org/apache/kerby/kerby-pkix/1.0.1/kerby-pkix-1.0.1.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/org/apache/kerby/kerby-asn1/1.0.1/kerby-asn1-1.0.1.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/org/apache/kerby/kerby-util/1.0.1/kerby-util-1.0.1.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/org/apache/kerby/kerb-common/1.0.1/kerb-common-1.0.1.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/org/apache/kerby/kerb-crypto/1.0.1/kerb-crypto-1.0.1.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/org/apache/kerby/kerb-util/1.0.1/kerb-util-1.0.1.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/org/apache/kerby/token-provider/1.0.1/token-provider-1.0.1.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/org/apache/kerby/kerb-admin/1.0.1/kerb-admin-1.0.1.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/org/apache/kerby/kerb-server/1.0.1/kerb-server-1.0.1.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/org/apache/kerby/kerb-identity/1.0.1/kerb-identity-1.0.1.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/org/apache/kerby/kerby-xdr/1.0.1/kerby-xdr-1.0.1.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/org/codehaus/woodstox/stax2-api/3.1.4/stax2-api-3.1.4.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/com/fasterxml/woodstox/woodstox-core/5.0.3/woodstox-core-5.0.3.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/org/slf4j/slf4j-api/1.7.25/slf4j-api-1.7.25.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/org/slf4j/slf4j-log4j12/1.7.25/slf4j-log4j12-1.7.25.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/org/apache/hadoop/hadoop-annotations/3.1.1/hadoop-annotations-3.1.1.jar</AuxClasspathEntry><AuxClasspathEntry>/usr/lib/jvm/java-8-openjdk-amd64/jre/../lib/tools.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/com/google/inject/extensions/guice-servlet/4.0/guice-servlet-4.0.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/io/netty/netty/3.10.5.Final/netty-3.10.5.Final.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/commons-logging/commons-logging/1.1.3/commons-logging-1.1.3.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/com/google/guava/guava/11.0.2/guava-11.0.2.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/commons-codec/commons-codec/1.11/commons-codec-1.11.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/commons-cli/commons-cli/1.2/commons-cli-1.2.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/commons-lang/commons-lang/2.6/commons-lang-2.6.jar</AuxClasspathEntry><AuxClasspathEntry>.m2/repository/commons-collections/commons-collections/3.2.2/commons-collections-3.2.2.jar</AuxClasspathEntry><SrcDir>./hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java</SrcDir><WrkDir>./hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target</WrkDir></Project><BugInstance instanceOccurrenceNum='0' instanceHash='16cc7a6aecc0a0b2d7dd031cd924e8e' rank='14' abbrev='Nm' category='BAD_PRACTICE' priority='1' type='NM_SAME_SIMPLE_NAME_AS_SUPERCLASS' instanceOccurrenceMax='0'><ShortMessage>Class names shouldn't shadow simple name of superclass</ShortMessage><LongMessage>The class name org.apache.hadoop.filecache.DistributedCache shadows the simple name of the superclass org.apache.hadoop.mapreduce.filecache.DistributedCache</LongMessage><Class classname='org.apache.hadoop.filecache.DistributedCache' primary='true'><SourceLine classname='org.apache.hadoop.filecache.DistributedCache' start='135' end='330' sourcepath='org/apache/hadoop/filecache/DistributedCache.java' sourcefile='DistributedCache.java'><Message>At DistributedCache.java:[lines 135-330]</Message></SourceLine><Message>In class org.apache.hadoop.filecache.DistributedCache</Message></Class><Class classname='org.apache.hadoop.mapreduce.filecache.DistributedCache'><SourceLine classname='org.apache.hadoop.mapreduce.filecache.DistributedCache' start='135' end='547' sourcepath='org/apache/hadoop/mapreduce/filecache/DistributedCache.java' sourcefile='DistributedCache.java'><Message>At DistributedCache.java:[lines 135-547]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.filecache.DistributedCache</Message></Class><SourceLine synthetic='true' classname='org.apache.hadoop.filecache.DistributedCache' start='135' end='330' sourcepath='org/apache/hadoop/filecache/DistributedCache.java' sourcefile='DistributedCache.java'><Message>At DistributedCache.java:[lines 135-330]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='12b548f06053907bb691265369a0887d' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from org.apache.hadoop.mapreduce.TaskAttemptID to org.apache.hadoop.mapred.TaskAttemptID in org.apache.hadoop.mapred.BackupStore$MemoryCache.createInMemorySegment()</LongMessage><Class classname='org.apache.hadoop.mapred.BackupStore$MemoryCache' primary='true'><SourceLine classname='org.apache.hadoop.mapred.BackupStore$MemoryCache' start='379' end='515' sourcepath='org/apache/hadoop/mapred/BackupStore.java' sourcefile='BackupStore.java'><Message>At BackupStore.java:[lines 379-515]</Message></SourceLine><Message>In class org.apache.hadoop.mapred.BackupStore$MemoryCache</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapred.BackupStore$MemoryCache' signature='()V' name='createInMemorySegment' primary='true'><SourceLine endBytecode='87' classname='org.apache.hadoop.mapred.BackupStore$MemoryCache' start='491' end='515' sourcepath='org/apache/hadoop/mapred/BackupStore.java' sourcefile='BackupStore.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapred.BackupStore$MemoryCache.createInMemorySegment()</Message></Method><Type role='TYPE_FOUND' descriptor='Lorg/apache/hadoop/mapreduce/TaskAttemptID;'><SourceLine classname='org.apache.hadoop.mapreduce.TaskAttemptID' start='48' end='201' sourcepath='org/apache/hadoop/mapreduce/TaskAttemptID.java' sourcefile='TaskAttemptID.java'><Message>At TaskAttemptID.java:[lines 48-201]</Message></SourceLine><Message>Actual type org.apache.hadoop.mapreduce.TaskAttemptID</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/mapred/TaskAttemptID;'><SourceLine classname='org.apache.hadoop.mapred.TaskAttemptID' start='48' end='193' sourcepath='org/apache/hadoop/mapred/TaskAttemptID.java' sourcefile='TaskAttemptID.java'><Message>At TaskAttemptID.java:[lines 48-193]</Message></SourceLine><Message>Expected org.apache.hadoop.mapred.TaskAttemptID</Message></Type><Field isStatic='false' role='FIELD_VALUE_OF' classname='org.apache.hadoop.mapred.BackupStore' signature='Lorg/apache/hadoop/mapreduce/TaskAttemptID;' name='tid' primary='true'><SourceLine classname='org.apache.hadoop.mapred.BackupStore' sourcepath='org/apache/hadoop/mapred/BackupStore.java' sourcefile='BackupStore.java'><Message>In BackupStore.java</Message></SourceLine><Message>Value loaded from field org.apache.hadoop.mapred.BackupStore.tid</Message></Field><SourceLine endBytecode='102' classname='org.apache.hadoop.mapred.BackupStore$MemoryCache' start='509' end='509' sourcepath='org/apache/hadoop/mapred/BackupStore.java' sourcefile='BackupStore.java' startBytecode='102' primary='true'><Message>At BackupStore.java:[line 509]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='e4ba4f70234b7b72f218b56435528eaf' rank='20' abbrev='UwF' category='STYLE' priority='3' type='UWF_FIELD_NOT_INITIALIZED_IN_CONSTRUCTOR' instanceOccurrenceMax='0'><ShortMessage>Field not initialized in constructor but dereferenced without null check</ShortMessage><LongMessage>BasicTypeSorterBase.comparator not initialized in constructor and dereferenced in org.apache.hadoop.mapred.MergeSorter.compare(IntWritable, IntWritable)</LongMessage><Class classname='org.apache.hadoop.mapred.BasicTypeSorterBase' primary='true'><SourceLine classname='org.apache.hadoop.mapred.BasicTypeSorterBase' start='35' end='147' sourcepath='org/apache/hadoop/mapred/BasicTypeSorterBase.java' sourcefile='BasicTypeSorterBase.java'><Message>At BasicTypeSorterBase.java:[lines 35-147]</Message></SourceLine><Message>In class org.apache.hadoop.mapred.BasicTypeSorterBase</Message></Class><Field isStatic='false' classname='org.apache.hadoop.mapred.BasicTypeSorterBase' signature='Lorg/apache/hadoop/io/RawComparator;' name='comparator' primary='true'><SourceLine classname='org.apache.hadoop.mapred.BasicTypeSorterBase' sourcepath='org/apache/hadoop/mapred/BasicTypeSorterBase.java' sourcefile='BasicTypeSorterBase.java'><Message>In BasicTypeSorterBase.java</Message></SourceLine><Message>Field org.apache.hadoop.mapred.BasicTypeSorterBase.comparator</Message></Field><Method isStatic='false' classname='org.apache.hadoop.mapred.MergeSorter' signature='(Lorg/apache/hadoop/io/IntWritable;Lorg/apache/hadoop/io/IntWritable;)I' name='compare' primary='true'><SourceLine endBytecode='200' classname='org.apache.hadoop.mapred.MergeSorter' start='61' end='67' sourcepath='org/apache/hadoop/mapred/MergeSorter.java' sourcefile='MergeSorter.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapred.MergeSorter.compare(IntWritable, IntWritable)</Message></Method><SourceLine endBytecode='91' classname='org.apache.hadoop.mapred.MergeSorter' start='67' end='67' sourcepath='org/apache/hadoop/mapred/MergeSorter.java' sourcefile='MergeSorter.java' startBytecode='91' primary='true'><Message>At MergeSorter.java:[line 67]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='f586a41c8ee6d5e7ef8189a5925b5337' rank='20' abbrev='UwF' category='STYLE' priority='3' type='UWF_FIELD_NOT_INITIALIZED_IN_CONSTRUCTOR' instanceOccurrenceMax='0'><ShortMessage>Field not initialized in constructor but dereferenced without null check</ShortMessage><LongMessage>BasicTypeSorterBase.keyValBuffer not initialized in constructor and dereferenced in org.apache.hadoop.mapred.MergeSorter.compare(IntWritable, IntWritable)</LongMessage><Class classname='org.apache.hadoop.mapred.BasicTypeSorterBase' primary='true'><SourceLine classname='org.apache.hadoop.mapred.BasicTypeSorterBase' start='35' end='147' sourcepath='org/apache/hadoop/mapred/BasicTypeSorterBase.java' sourcefile='BasicTypeSorterBase.java'><Message>At BasicTypeSorterBase.java:[lines 35-147]</Message></SourceLine><Message>In class org.apache.hadoop.mapred.BasicTypeSorterBase</Message></Class><Field isStatic='false' classname='org.apache.hadoop.mapred.BasicTypeSorterBase' signature='Lorg/apache/hadoop/io/OutputBuffer;' name='keyValBuffer' primary='true'><SourceLine classname='org.apache.hadoop.mapred.BasicTypeSorterBase' sourcepath='org/apache/hadoop/mapred/BasicTypeSorterBase.java' sourcefile='BasicTypeSorterBase.java'><Message>In BasicTypeSorterBase.java</Message></SourceLine><Message>Field org.apache.hadoop.mapred.BasicTypeSorterBase.keyValBuffer</Message></Field><Method isStatic='false' classname='org.apache.hadoop.mapred.MergeSorter' signature='(Lorg/apache/hadoop/io/IntWritable;Lorg/apache/hadoop/io/IntWritable;)I' name='compare' primary='true'><SourceLine endBytecode='200' classname='org.apache.hadoop.mapred.MergeSorter' start='61' end='67' sourcepath='org/apache/hadoop/mapred/MergeSorter.java' sourcefile='MergeSorter.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapred.MergeSorter.compare(IntWritable, IntWritable)</Message></Method><SourceLine endBytecode='45' classname='org.apache.hadoop.mapred.MergeSorter' start='67' end='67' sourcepath='org/apache/hadoop/mapred/MergeSorter.java' sourcefile='MergeSorter.java' startBytecode='45' primary='true'><Message>At MergeSorter.java:[line 67]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='d3eaebe827253a06462b09a8aac05941' rank='20' abbrev='UwF' category='STYLE' priority='3' type='UWF_FIELD_NOT_INITIALIZED_IN_CONSTRUCTOR' instanceOccurrenceMax='0'><ShortMessage>Field not initialized in constructor but dereferenced without null check</ShortMessage><LongMessage>BasicTypeSorterBase.reporter not initialized in constructor and dereferenced in org.apache.hadoop.mapred.MergeSorter.compare(IntWritable, IntWritable)</LongMessage><Class classname='org.apache.hadoop.mapred.BasicTypeSorterBase' primary='true'><SourceLine classname='org.apache.hadoop.mapred.BasicTypeSorterBase' start='35' end='147' sourcepath='org/apache/hadoop/mapred/BasicTypeSorterBase.java' sourcefile='BasicTypeSorterBase.java'><Message>At BasicTypeSorterBase.java:[lines 35-147]</Message></SourceLine><Message>In class org.apache.hadoop.mapred.BasicTypeSorterBase</Message></Class><Field isStatic='false' classname='org.apache.hadoop.mapred.BasicTypeSorterBase' signature='Lorg/apache/hadoop/util/Progressable;' name='reporter' primary='true'><SourceLine classname='org.apache.hadoop.mapred.BasicTypeSorterBase' sourcepath='org/apache/hadoop/mapred/BasicTypeSorterBase.java' sourcefile='BasicTypeSorterBase.java'><Message>In BasicTypeSorterBase.java</Message></SourceLine><Message>Field org.apache.hadoop.mapred.BasicTypeSorterBase.reporter</Message></Field><Method isStatic='false' classname='org.apache.hadoop.mapred.MergeSorter' signature='(Lorg/apache/hadoop/io/IntWritable;Lorg/apache/hadoop/io/IntWritable;)I' name='compare' primary='true'><SourceLine endBytecode='200' classname='org.apache.hadoop.mapred.MergeSorter' start='61' end='67' sourcepath='org/apache/hadoop/mapred/MergeSorter.java' sourcefile='MergeSorter.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapred.MergeSorter.compare(IntWritable, IntWritable)</Message></Method><SourceLine endBytecode='32' classname='org.apache.hadoop.mapred.MergeSorter' start='65' end='65' sourcepath='org/apache/hadoop/mapred/MergeSorter.java' sourcefile='MergeSorter.java' startBytecode='32' primary='true'><Message>At MergeSorter.java:[line 65]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='8d3d49b6a3dbfd58caad7bf3394d5982' rank='19' abbrev='Nm' category='BAD_PRACTICE' priority='3' type='NM_CONFUSING' instanceOccurrenceMax='0'><ShortMessage>Confusing method names</ShortMessage><LongMessage>Confusing to have methods org.apache.hadoop.mapred.ClusterStatus$BlackListInfo.getBlackListReport() and org.apache.hadoop.mapreduce.TaskTrackerInfo.getBlacklistReport()</LongMessage><Class classname='org.apache.hadoop.mapred.ClusterStatus$BlackListInfo' primary='true'><SourceLine classname='org.apache.hadoop.mapred.ClusterStatus$BlackListInfo' start='84' end='206' sourcepath='org/apache/hadoop/mapred/ClusterStatus.java' sourcefile='ClusterStatus.java'><Message>At ClusterStatus.java:[lines 84-206]</Message></SourceLine><Message>In class org.apache.hadoop.mapred.ClusterStatus$BlackListInfo</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapred.ClusterStatus$BlackListInfo' signature='()Ljava/lang/String;' name='getBlackListReport' primary='true'><SourceLine endBytecode='46' classname='org.apache.hadoop.mapred.ClusterStatus$BlackListInfo' start='130' end='130' sourcepath='org/apache/hadoop/mapred/ClusterStatus.java' sourcefile='ClusterStatus.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapred.ClusterStatus$BlackListInfo.getBlackListReport()</Message></Method><Class classname='org.apache.hadoop.mapreduce.TaskTrackerInfo'><SourceLine classname='org.apache.hadoop.mapreduce.TaskTrackerInfo' start='36' end='106' sourcepath='org/apache/hadoop/mapreduce/TaskTrackerInfo.java' sourcefile='TaskTrackerInfo.java'><Message>At TaskTrackerInfo.java:[lines 36-106]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.TaskTrackerInfo</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapreduce.TaskTrackerInfo' signature='()Ljava/lang/String;' name='getBlacklistReport'><SourceLine endBytecode='46' classname='org.apache.hadoop.mapreduce.TaskTrackerInfo' start='89' end='89' sourcepath='org/apache/hadoop/mapreduce/TaskTrackerInfo.java' sourcefile='TaskTrackerInfo.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapreduce.TaskTrackerInfo.getBlacklistReport()</Message></Method><SourceLine synthetic='true' endBytecode='46' classname='org.apache.hadoop.mapred.ClusterStatus$BlackListInfo' start='130' end='130' sourcepath='org/apache/hadoop/mapred/ClusterStatus.java' sourcefile='ClusterStatus.java' startBytecode='0'><Message>At ClusterStatus.java:[line 130]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='5c392306911c74227c42f61f11fa8dad' rank='20' abbrev='UwF' category='STYLE' priority='3' type='UWF_FIELD_NOT_INITIALIZED_IN_CONSTRUCTOR' instanceOccurrenceMax='0'><ShortMessage>Field not initialized in constructor but dereferenced without null check</ShortMessage><LongMessage>ClusterStatus$BlackListInfo.blackListReport not initialized in constructor and dereferenced in org.apache.hadoop.mapred.ClusterStatus$BlackListInfo.toString()</LongMessage><Class classname='org.apache.hadoop.mapred.ClusterStatus$BlackListInfo' primary='true'><SourceLine classname='org.apache.hadoop.mapred.ClusterStatus$BlackListInfo' start='84' end='206' sourcepath='org/apache/hadoop/mapred/ClusterStatus.java' sourcefile='ClusterStatus.java'><Message>At ClusterStatus.java:[lines 84-206]</Message></SourceLine><Message>In class org.apache.hadoop.mapred.ClusterStatus$BlackListInfo</Message></Class><Field isStatic='false' classname='org.apache.hadoop.mapred.ClusterStatus$BlackListInfo' signature='Ljava/lang/String;' name='blackListReport' primary='true'><SourceLine classname='org.apache.hadoop.mapred.ClusterStatus$BlackListInfo' sourcepath='org/apache/hadoop/mapred/ClusterStatus.java' sourcefile='ClusterStatus.java'><Message>In ClusterStatus.java</Message></SourceLine><Message>Field org.apache.hadoop.mapred.ClusterStatus$BlackListInfo.blackListReport</Message></Field><Method isStatic='false' classname='org.apache.hadoop.mapred.ClusterStatus$BlackListInfo' signature='()Ljava/lang/String;' name='toString' primary='true'><SourceLine endBytecode='136' classname='org.apache.hadoop.mapred.ClusterStatus$BlackListInfo' start='166' end='172' sourcepath='org/apache/hadoop/mapred/ClusterStatus.java' sourcefile='ClusterStatus.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapred.ClusterStatus$BlackListInfo.toString()</Message></Method><SourceLine endBytecode='49' classname='org.apache.hadoop.mapred.ClusterStatus$BlackListInfo' start='171' end='171' sourcepath='org/apache/hadoop/mapred/ClusterStatus.java' sourcefile='ClusterStatus.java' startBytecode='49' primary='true'><Message>At ClusterStatus.java:[line 171]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='9038004e9963ad8dfcbe3a6ac4f798' rank='20' abbrev='SIC' category='PERFORMANCE' priority='3' type='SIC_INNER_SHOULD_BE_STATIC_ANON' instanceOccurrenceMax='0'><ShortMessage>Could be refactored into a named static inner class</ShortMessage><LongMessage>The class org.apache.hadoop.mapred.Counters$GroupFactory$1 could be refactored into a named _static_ inner class</LongMessage><Class role='CLASS_ANONYMOUS' classname='org.apache.hadoop.mapred.Counters$GroupFactory$1'><SourceLine classname='org.apache.hadoop.mapred.Counters$GroupFactory$1' start='492' end='494' sourcepath='org/apache/hadoop/mapred/Counters.java' sourcefile='Counters.java'><Message>At Counters.java:[lines 492-494]</Message></SourceLine><Message>Anonymous class org.apache.hadoop.mapred.Counters$GroupFactory$1</Message></Class><Class classname='org.apache.hadoop.mapred.Counters$GroupFactory' primary='true'><SourceLine classname='org.apache.hadoop.mapred.Counters$GroupFactory' start='487' end='507' sourcepath='org/apache/hadoop/mapred/Counters.java' sourcefile='Counters.java'><Message>At Counters.java:[lines 487-507]</Message></SourceLine><Message>In class org.apache.hadoop.mapred.Counters$GroupFactory</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapred.Counters$GroupFactory' signature='(Ljava/lang/Class;)Lorg/apache/hadoop/mapreduce/counters/CounterGroupFactory$FrameworkGroupFactory;' name='newFrameworkGroupFactory' primary='true'><SourceLine endBytecode='79' classname='org.apache.hadoop.mapred.Counters$GroupFactory' start='492' end='492' sourcepath='org/apache/hadoop/mapred/Counters.java' sourcefile='Counters.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapred.Counters$GroupFactory.newFrameworkGroupFactory(Class)</Message></Method><SourceLine endBytecode='6' classname='org.apache.hadoop.mapred.Counters$GroupFactory' start='492' end='492' sourcepath='org/apache/hadoop/mapred/Counters.java' sourcefile='Counters.java' startBytecode='6' primary='true'><Message>At Counters.java:[line 492]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='e91af46f389a11ab5bccbfcfde7de3ef' rank='6' abbrev='Nm' category='CORRECTNESS' priority='2' type='NM_WRONG_PACKAGE' instanceOccurrenceMax='0'><ShortMessage>Method doesn't override method in superclass due to wrong package for parameter</ShortMessage><LongMessage>org.apache.hadoop.mapred.FileOutputCommitter.commitJob(JobContext) doesn't override method in superclass because parameter type org.apache.hadoop.mapred.JobContext doesn't match superclass parameter type org.apache.hadoop.mapreduce.JobContext</LongMessage><Class classname='org.apache.hadoop.mapred.FileOutputCommitter' primary='true'><SourceLine classname='org.apache.hadoop.mapred.FileOutputCommitter' start='35' end='206' sourcepath='org/apache/hadoop/mapred/FileOutputCommitter.java' sourcefile='FileOutputCommitter.java'><Message>At FileOutputCommitter.java:[lines 35-206]</Message></SourceLine><Message>In class org.apache.hadoop.mapred.FileOutputCommitter</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapred.FileOutputCommitter' signature='(Lorg/apache/hadoop/mapred/JobContext;)V' name='commitJob' primary='true'><SourceLine endBytecode='65' classname='org.apache.hadoop.mapred.FileOutputCommitter' start='136' end='137' sourcepath='org/apache/hadoop/mapred/FileOutputCommitter.java' sourcefile='FileOutputCommitter.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapred.FileOutputCommitter.commitJob(JobContext)</Message></Method><Class role='CLASS_SUPERCLASS' classname='org.apache.hadoop.mapred.OutputCommitter'><SourceLine classname='org.apache.hadoop.mapred.OutputCommitter' start='70' end='378' sourcepath='org/apache/hadoop/mapred/OutputCommitter.java' sourcefile='OutputCommitter.java'><Message>At OutputCommitter.java:[lines 70-378]</Message></SourceLine><Message>superclass is org.apache.hadoop.mapred.OutputCommitter</Message></Class><Method isStatic='false' role='METHOD_DID_YOU_MEAN_TO_OVERRIDE' classname='org.apache.hadoop.mapred.OutputCommitter' signature='(Lorg/apache/hadoop/mapreduce/JobContext;)V' name='commitJob'><SourceLine endBytecode='64' classname='org.apache.hadoop.mapred.OutputCommitter' start='291' end='292' sourcepath='org/apache/hadoop/mapred/OutputCommitter.java' sourcefile='OutputCommitter.java' startBytecode='0'></SourceLine><Message>Did you intend to override org.apache.hadoop.mapred.OutputCommitter.commitJob(JobContext)</Message></Method><Type role='TYPE_FOUND' descriptor='Lorg/apache/hadoop/mapred/JobContext;'><SourceLine classname='org.apache.hadoop.mapred.JobContext' sourcepath='org/apache/hadoop/mapred/JobContext.java' sourcefile='JobContext.java'><Message>In JobContext.java</Message></SourceLine><Message>Actual type org.apache.hadoop.mapred.JobContext</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/mapreduce/JobContext;'><SourceLine classname='org.apache.hadoop.mapreduce.JobContext' sourcepath='org/apache/hadoop/mapreduce/JobContext.java' sourcefile='JobContext.java'><Message>In JobContext.java</Message></SourceLine><Message>Expected org.apache.hadoop.mapreduce.JobContext</Message></Type><SourceLine synthetic='true' endBytecode='65' classname='org.apache.hadoop.mapred.FileOutputCommitter' start='136' end='137' sourcepath='org/apache/hadoop/mapred/FileOutputCommitter.java' sourcefile='FileOutputCommitter.java' startBytecode='0'><Message>At FileOutputCommitter.java:[lines 136-137]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='6cf9d02fbcbcefc9a39a650acf8a9c49' rank='6' abbrev='Nm' category='CORRECTNESS' priority='2' type='NM_WRONG_PACKAGE' instanceOccurrenceMax='0'><ShortMessage>Method doesn't override method in superclass due to wrong package for parameter</ShortMessage><LongMessage>org.apache.hadoop.mapred.FileOutputCommitter.isCommitJobRepeatable(JobContext) doesn't override method in superclass because parameter type org.apache.hadoop.mapred.JobContext doesn't match superclass parameter type org.apache.hadoop.mapreduce.JobContext</LongMessage><Class classname='org.apache.hadoop.mapred.FileOutputCommitter' primary='true'><SourceLine classname='org.apache.hadoop.mapred.FileOutputCommitter' start='35' end='206' sourcepath='org/apache/hadoop/mapred/FileOutputCommitter.java' sourcefile='FileOutputCommitter.java'><Message>At FileOutputCommitter.java:[lines 35-206]</Message></SourceLine><Message>In class org.apache.hadoop.mapred.FileOutputCommitter</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapred.FileOutputCommitter' signature='(Lorg/apache/hadoop/mapred/JobContext;)Z' name='isCommitJobRepeatable' primary='true'><SourceLine endBytecode='61' classname='org.apache.hadoop.mapred.FileOutputCommitter' start='194' end='194' sourcepath='org/apache/hadoop/mapred/FileOutputCommitter.java' sourcefile='FileOutputCommitter.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapred.FileOutputCommitter.isCommitJobRepeatable(JobContext)</Message></Method><Class role='CLASS_SUPERCLASS' classname='org.apache.hadoop.mapred.OutputCommitter'><SourceLine classname='org.apache.hadoop.mapred.OutputCommitter' start='70' end='378' sourcepath='org/apache/hadoop/mapred/OutputCommitter.java' sourcefile='OutputCommitter.java'><Message>At OutputCommitter.java:[lines 70-378]</Message></SourceLine><Message>superclass is org.apache.hadoop.mapred.OutputCommitter</Message></Class><Method isStatic='false' role='METHOD_DID_YOU_MEAN_TO_OVERRIDE' classname='org.apache.hadoop.mapred.OutputCommitter' signature='(Lorg/apache/hadoop/mapreduce/JobContext;)Z' name='isCommitJobRepeatable'><SourceLine endBytecode='60' classname='org.apache.hadoop.mapred.OutputCommitter' start='236' end='236' sourcepath='org/apache/hadoop/mapred/OutputCommitter.java' sourcefile='OutputCommitter.java' startBytecode='0'></SourceLine><Message>Did you intend to override org.apache.hadoop.mapred.OutputCommitter.isCommitJobRepeatable(JobContext)</Message></Method><Type role='TYPE_FOUND' descriptor='Lorg/apache/hadoop/mapred/JobContext;'><SourceLine classname='org.apache.hadoop.mapred.JobContext' sourcepath='org/apache/hadoop/mapred/JobContext.java' sourcefile='JobContext.java'><Message>In JobContext.java</Message></SourceLine><Message>Actual type org.apache.hadoop.mapred.JobContext</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/mapreduce/JobContext;'><SourceLine classname='org.apache.hadoop.mapreduce.JobContext' sourcepath='org/apache/hadoop/mapreduce/JobContext.java' sourcefile='JobContext.java'><Message>In JobContext.java</Message></SourceLine><Message>Expected org.apache.hadoop.mapreduce.JobContext</Message></Type><SourceLine synthetic='true' endBytecode='61' classname='org.apache.hadoop.mapred.FileOutputCommitter' start='194' end='194' sourcepath='org/apache/hadoop/mapred/FileOutputCommitter.java' sourcefile='FileOutputCommitter.java' startBytecode='0'><Message>At FileOutputCommitter.java:[line 194]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='7ea71fc3befff9c6699dfff0578871f7' rank='6' abbrev='Nm' category='CORRECTNESS' priority='2' type='NM_WRONG_PACKAGE' instanceOccurrenceMax='0'><ShortMessage>Method doesn't override method in superclass due to wrong package for parameter</ShortMessage><LongMessage>org.apache.hadoop.mapred.FileOutputCommitter.isRecoverySupported(JobContext) doesn't override method in superclass because parameter type org.apache.hadoop.mapred.JobContext doesn't match superclass parameter type org.apache.hadoop.mapreduce.JobContext</LongMessage><Class classname='org.apache.hadoop.mapred.FileOutputCommitter' primary='true'><SourceLine classname='org.apache.hadoop.mapred.FileOutputCommitter' start='35' end='206' sourcepath='org/apache/hadoop/mapred/FileOutputCommitter.java' sourcefile='FileOutputCommitter.java'><Message>At FileOutputCommitter.java:[lines 35-206]</Message></SourceLine><Message>In class org.apache.hadoop.mapred.FileOutputCommitter</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapred.FileOutputCommitter' signature='(Lorg/apache/hadoop/mapred/JobContext;)Z' name='isRecoverySupported' primary='true'><SourceLine endBytecode='61' classname='org.apache.hadoop.mapred.FileOutputCommitter' start='199' end='199' sourcepath='org/apache/hadoop/mapred/FileOutputCommitter.java' sourcefile='FileOutputCommitter.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapred.FileOutputCommitter.isRecoverySupported(JobContext)</Message></Method><Class role='CLASS_SUPERCLASS' classname='org.apache.hadoop.mapred.OutputCommitter'><SourceLine classname='org.apache.hadoop.mapred.OutputCommitter' start='70' end='378' sourcepath='org/apache/hadoop/mapred/OutputCommitter.java' sourcefile='OutputCommitter.java'><Message>At OutputCommitter.java:[lines 70-378]</Message></SourceLine><Message>superclass is org.apache.hadoop.mapred.OutputCommitter</Message></Class><Method isStatic='false' role='METHOD_DID_YOU_MEAN_TO_OVERRIDE' classname='org.apache.hadoop.mapred.OutputCommitter' signature='(Lorg/apache/hadoop/mapreduce/JobContext;)Z' name='isRecoverySupported'><SourceLine endBytecode='60' classname='org.apache.hadoop.mapred.OutputCommitter' start='378' end='378' sourcepath='org/apache/hadoop/mapred/OutputCommitter.java' sourcefile='OutputCommitter.java' startBytecode='0'></SourceLine><Message>Did you intend to override org.apache.hadoop.mapred.OutputCommitter.isRecoverySupported(JobContext)</Message></Method><Type role='TYPE_FOUND' descriptor='Lorg/apache/hadoop/mapred/JobContext;'><SourceLine classname='org.apache.hadoop.mapred.JobContext' sourcepath='org/apache/hadoop/mapred/JobContext.java' sourcefile='JobContext.java'><Message>In JobContext.java</Message></SourceLine><Message>Actual type org.apache.hadoop.mapred.JobContext</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/mapreduce/JobContext;'><SourceLine classname='org.apache.hadoop.mapreduce.JobContext' sourcepath='org/apache/hadoop/mapreduce/JobContext.java' sourcefile='JobContext.java'><Message>In JobContext.java</Message></SourceLine><Message>Expected org.apache.hadoop.mapreduce.JobContext</Message></Type><SourceLine synthetic='true' endBytecode='61' classname='org.apache.hadoop.mapred.FileOutputCommitter' start='199' end='199' sourcepath='org/apache/hadoop/mapred/FileOutputCommitter.java' sourcefile='FileOutputCommitter.java' startBytecode='0'><Message>At FileOutputCommitter.java:[line 199]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='6d55aea64cdb81b7a504d2d23d9a804b' rank='6' abbrev='Nm' category='CORRECTNESS' priority='2' type='NM_WRONG_PACKAGE' instanceOccurrenceMax='0'><ShortMessage>Method doesn't override method in superclass due to wrong package for parameter</ShortMessage><LongMessage>org.apache.hadoop.mapred.FileOutputCommitter.recoverTask(TaskAttemptContext) doesn't override method in superclass because parameter type org.apache.hadoop.mapred.TaskAttemptContext doesn't match superclass parameter type org.apache.hadoop.mapreduce.TaskAttemptContext</LongMessage><Class classname='org.apache.hadoop.mapred.FileOutputCommitter' primary='true'><SourceLine classname='org.apache.hadoop.mapred.FileOutputCommitter' start='35' end='206' sourcepath='org/apache/hadoop/mapred/FileOutputCommitter.java' sourcefile='FileOutputCommitter.java'><Message>At FileOutputCommitter.java:[lines 35-206]</Message></SourceLine><Message>In class org.apache.hadoop.mapred.FileOutputCommitter</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapred.FileOutputCommitter' signature='(Lorg/apache/hadoop/mapred/TaskAttemptContext;)V' name='recoverTask' primary='true'><SourceLine endBytecode='65' classname='org.apache.hadoop.mapred.FileOutputCommitter' start='205' end='206' sourcepath='org/apache/hadoop/mapred/FileOutputCommitter.java' sourcefile='FileOutputCommitter.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapred.FileOutputCommitter.recoverTask(TaskAttemptContext)</Message></Method><Class role='CLASS_SUPERCLASS' classname='org.apache.hadoop.mapred.OutputCommitter'><SourceLine classname='org.apache.hadoop.mapred.OutputCommitter' start='70' end='378' sourcepath='org/apache/hadoop/mapred/OutputCommitter.java' sourcefile='OutputCommitter.java'><Message>At OutputCommitter.java:[lines 70-378]</Message></SourceLine><Message>superclass is org.apache.hadoop.mapred.OutputCommitter</Message></Class><Method isStatic='false' role='METHOD_DID_YOU_MEAN_TO_OVERRIDE' classname='org.apache.hadoop.mapred.OutputCommitter' signature='(Lorg/apache/hadoop/mapreduce/TaskAttemptContext;)V' name='recoverTask'><SourceLine endBytecode='64' classname='org.apache.hadoop.mapred.OutputCommitter' start='367' end='368' sourcepath='org/apache/hadoop/mapred/OutputCommitter.java' sourcefile='OutputCommitter.java' startBytecode='0'></SourceLine><Message>Did you intend to override org.apache.hadoop.mapred.OutputCommitter.recoverTask(TaskAttemptContext)</Message></Method><Type role='TYPE_FOUND' descriptor='Lorg/apache/hadoop/mapred/TaskAttemptContext;'><SourceLine classname='org.apache.hadoop.mapred.TaskAttemptContext' start='25' end='25' sourcepath='org/apache/hadoop/mapred/TaskAttemptContext.java' sourcefile='TaskAttemptContext.java'><Message>At TaskAttemptContext.java:[line 25]</Message></SourceLine><Message>Actual type org.apache.hadoop.mapred.TaskAttemptContext</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/mapreduce/TaskAttemptContext;'><SourceLine classname='org.apache.hadoop.mapreduce.TaskAttemptContext' sourcepath='org/apache/hadoop/mapreduce/TaskAttemptContext.java' sourcefile='TaskAttemptContext.java'><Message>In TaskAttemptContext.java</Message></SourceLine><Message>Expected org.apache.hadoop.mapreduce.TaskAttemptContext</Message></Type><SourceLine synthetic='true' endBytecode='65' classname='org.apache.hadoop.mapred.FileOutputCommitter' start='205' end='206' sourcepath='org/apache/hadoop/mapred/FileOutputCommitter.java' sourcefile='FileOutputCommitter.java' startBytecode='0'><Message>At FileOutputCommitter.java:[lines 205-206]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='ebaa08916e4565b350c701788961a890' rank='9' abbrev='Nm' category='CORRECTNESS' priority='3' type='NM_WRONG_PACKAGE' instanceOccurrenceMax='0'><ShortMessage>Method doesn't override method in superclass due to wrong package for parameter</ShortMessage><LongMessage>org.apache.hadoop.mapred.FileOutputCommitter.cleanupJob(JobContext) doesn't override method in superclass because parameter type org.apache.hadoop.mapred.JobContext doesn't match superclass parameter type org.apache.hadoop.mapreduce.JobContext</LongMessage><Class classname='org.apache.hadoop.mapred.FileOutputCommitter' primary='true'><SourceLine classname='org.apache.hadoop.mapred.FileOutputCommitter' start='35' end='206' sourcepath='org/apache/hadoop/mapred/FileOutputCommitter.java' sourcefile='FileOutputCommitter.java'><Message>At FileOutputCommitter.java:[lines 35-206]</Message></SourceLine><Message>In class org.apache.hadoop.mapred.FileOutputCommitter</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapred.FileOutputCommitter' signature='(Lorg/apache/hadoop/mapred/JobContext;)V' name='cleanupJob' primary='true'><SourceLine endBytecode='65' classname='org.apache.hadoop.mapred.FileOutputCommitter' start='142' end='143' sourcepath='org/apache/hadoop/mapred/FileOutputCommitter.java' sourcefile='FileOutputCommitter.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapred.FileOutputCommitter.cleanupJob(JobContext)</Message></Method><Class role='CLASS_SUPERCLASS' classname='org.apache.hadoop.mapred.OutputCommitter'><SourceLine classname='org.apache.hadoop.mapred.OutputCommitter' start='70' end='378' sourcepath='org/apache/hadoop/mapred/OutputCommitter.java' sourcefile='OutputCommitter.java'><Message>At OutputCommitter.java:[lines 70-378]</Message></SourceLine><Message>superclass is org.apache.hadoop.mapred.OutputCommitter</Message></Class><Method isStatic='false' role='METHOD_DID_YOU_MEAN_TO_OVERRIDE' classname='org.apache.hadoop.mapred.OutputCommitter' signature='(Lorg/apache/hadoop/mapreduce/JobContext;)V' name='cleanupJob'><SourceLine endBytecode='64' classname='org.apache.hadoop.mapred.OutputCommitter' start='280' end='281' sourcepath='org/apache/hadoop/mapred/OutputCommitter.java' sourcefile='OutputCommitter.java' startBytecode='0'></SourceLine><Message>Did you intend to override org.apache.hadoop.mapred.OutputCommitter.cleanupJob(JobContext)</Message></Method><Type role='TYPE_FOUND' descriptor='Lorg/apache/hadoop/mapred/JobContext;'><SourceLine classname='org.apache.hadoop.mapred.JobContext' sourcepath='org/apache/hadoop/mapred/JobContext.java' sourcefile='JobContext.java'><Message>In JobContext.java</Message></SourceLine><Message>Actual type org.apache.hadoop.mapred.JobContext</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/mapreduce/JobContext;'><SourceLine classname='org.apache.hadoop.mapreduce.JobContext' sourcepath='org/apache/hadoop/mapreduce/JobContext.java' sourcefile='JobContext.java'><Message>In JobContext.java</Message></SourceLine><Message>Expected org.apache.hadoop.mapreduce.JobContext</Message></Type><SourceLine synthetic='true' endBytecode='65' classname='org.apache.hadoop.mapred.FileOutputCommitter' start='142' end='143' sourcepath='org/apache/hadoop/mapred/FileOutputCommitter.java' sourcefile='FileOutputCommitter.java' startBytecode='0'><Message>At FileOutputCommitter.java:[lines 142-143]</Message></SourceLine><Property name='edu.umd.cs.findbugs.detect.Naming$NamingProperty.CONFUSING_METHOD_IS_DEPRECATED' value='true'></Property></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='e5ef6202a293a9bb1278469393bc10da' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from org.apache.hadoop.mapred.InputSplit to org.apache.hadoop.mapred.FileSplit in org.apache.hadoop.mapred.FixedLengthInputFormat.getRecordReader(InputSplit, JobConf, Reporter)</LongMessage><Class classname='org.apache.hadoop.mapred.FixedLengthInputFormat' primary='true'><SourceLine classname='org.apache.hadoop.mapred.FixedLengthInputFormat' start='45' end='94' sourcepath='org/apache/hadoop/mapred/FixedLengthInputFormat.java' sourcefile='FixedLengthInputFormat.java'><Message>At FixedLengthInputFormat.java:[lines 45-94]</Message></SourceLine><Message>In class org.apache.hadoop.mapred.FixedLengthInputFormat</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapred.FixedLengthInputFormat' signature='(Lorg/apache/hadoop/mapred/InputSplit;Lorg/apache/hadoop/mapred/JobConf;Lorg/apache/hadoop/mapred/Reporter;)Lorg/apache/hadoop/mapred/RecordReader;' name='getRecordReader' primary='true'><SourceLine endBytecode='30' classname='org.apache.hadoop.mapred.FixedLengthInputFormat' start='81' end='87' sourcepath='org/apache/hadoop/mapred/FixedLengthInputFormat.java' sourcefile='FixedLengthInputFormat.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapred.FixedLengthInputFormat.getRecordReader(InputSplit, JobConf, Reporter)</Message></Method><Type role='TYPE_FOUND' descriptor='Lorg/apache/hadoop/mapred/InputSplit;'><SourceLine classname='org.apache.hadoop.mapred.InputSplit' sourcepath='org/apache/hadoop/mapred/InputSplit.java' sourcefile='InputSplit.java'><Message>In InputSplit.java</Message></SourceLine><Message>Actual type org.apache.hadoop.mapred.InputSplit</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/mapred/FileSplit;'><SourceLine classname='org.apache.hadoop.mapred.FileSplit' start='39' end='113' sourcepath='org/apache/hadoop/mapred/FileSplit.java' sourcefile='FileSplit.java'><Message>At FileSplit.java:[lines 39-113]</Message></SourceLine><Message>Expected org.apache.hadoop.mapred.FileSplit</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='59' name='genericSplit' register='1'><Message>Value loaded from genericSplit</Message></LocalVariable><SourceLine endBytecode='60' classname='org.apache.hadoop.mapred.FixedLengthInputFormat' start='87' end='87' sourcepath='org/apache/hadoop/mapred/FixedLengthInputFormat.java' sourcefile='FixedLengthInputFormat.java' startBytecode='60' primary='true'><Message>At FixedLengthInputFormat.java:[line 87]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='cbdfd315dfcbd7c43af4ec92befa890b' rank='14' abbrev='Nm' category='BAD_PRACTICE' priority='1' type='NM_SAME_SIMPLE_NAME_AS_SUPERCLASS' instanceOccurrenceMax='0'><ShortMessage>Class names shouldn't shadow simple name of superclass</ShortMessage><LongMessage>The class name org.apache.hadoop.mapred.ID shadows the simple name of the superclass org.apache.hadoop.mapreduce.ID</LongMessage><Class classname='org.apache.hadoop.mapred.ID' primary='true'><SourceLine classname='org.apache.hadoop.mapred.ID' start='39' end='43' sourcepath='org/apache/hadoop/mapred/ID.java' sourcefile='ID.java'><Message>At ID.java:[lines 39-43]</Message></SourceLine><Message>In class org.apache.hadoop.mapred.ID</Message></Class><Class classname='org.apache.hadoop.mapreduce.ID'><SourceLine classname='org.apache.hadoop.mapreduce.ID' start='38' end='92' sourcepath='org/apache/hadoop/mapreduce/ID.java' sourcefile='ID.java'><Message>At ID.java:[lines 38-92]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.ID</Message></Class><SourceLine synthetic='true' classname='org.apache.hadoop.mapred.ID' start='39' end='43' sourcepath='org/apache/hadoop/mapred/ID.java' sourcefile='ID.java'><Message>At ID.java:[lines 39-43]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='39a7db8c52378927f48c64a326f62f4a' cweid='374' rank='18' abbrev='EI' category='MALICIOUS_CODE' priority='2' type='EI_EXPOSE_REP' instanceOccurrenceMax='0'><ShortMessage>May expose internal representation by returning reference to mutable object</ShortMessage><LongMessage>org.apache.hadoop.mapred.IFileInputStream.getChecksum() may expose internal representation by returning IFileInputStream.csum</LongMessage><Class classname='org.apache.hadoop.mapred.IFileInputStream' primary='true'><SourceLine classname='org.apache.hadoop.mapred.IFileInputStream' start='52' end='254' sourcepath='org/apache/hadoop/mapred/IFileInputStream.java' sourcefile='IFileInputStream.java'><Message>At IFileInputStream.java:[lines 52-254]</Message></SourceLine><Message>In class org.apache.hadoop.mapred.IFileInputStream</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapred.IFileInputStream' signature='()[B' name='getChecksum' primary='true'><SourceLine endBytecode='46' classname='org.apache.hadoop.mapred.IFileInputStream' start='249' end='249' sourcepath='org/apache/hadoop/mapred/IFileInputStream.java' sourcefile='IFileInputStream.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapred.IFileInputStream.getChecksum()</Message></Method><Field isStatic='false' classname='org.apache.hadoop.mapred.IFileInputStream' signature='[B' name='csum' primary='true'><SourceLine classname='org.apache.hadoop.mapred.IFileInputStream' sourcepath='org/apache/hadoop/mapred/IFileInputStream.java' sourcefile='IFileInputStream.java'><Message>In IFileInputStream.java</Message></SourceLine><Message>Field org.apache.hadoop.mapred.IFileInputStream.csum</Message></Field><SourceLine endBytecode='4' classname='org.apache.hadoop.mapred.IFileInputStream' start='249' end='249' sourcepath='org/apache/hadoop/mapred/IFileInputStream.java' sourcefile='IFileInputStream.java' startBytecode='4' primary='true'><Message>At IFileInputStream.java:[line 249]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='fa9ab912503d358768e9016b07c5b2ec' rank='19' abbrev='Nm' category='BAD_PRACTICE' priority='3' type='NM_CONFUSING' instanceOccurrenceMax='0'><ShortMessage>Confusing method names</ShortMessage><LongMessage>Confusing to have methods org.apache.hadoop.mapred.JVMId.getJobId() and org.apache.hadoop.mapred.JobProfile.getJobID()</LongMessage><Class classname='org.apache.hadoop.mapred.JVMId' primary='true'><SourceLine classname='org.apache.hadoop.mapred.JVMId' start='32' end='171' sourcepath='org/apache/hadoop/mapred/JVMId.java' sourcefile='JVMId.java'><Message>At JVMId.java:[lines 32-171]</Message></SourceLine><Message>In class org.apache.hadoop.mapred.JVMId</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapred.JVMId' signature='()Lorg/apache/hadoop/mapred/JobID;' name='getJobId' primary='true'><SourceLine endBytecode='46' classname='org.apache.hadoop.mapred.JVMId' start='56' end='56' sourcepath='org/apache/hadoop/mapred/JVMId.java' sourcefile='JVMId.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapred.JVMId.getJobId()</Message></Method><Class classname='org.apache.hadoop.mapred.JobProfile'><SourceLine classname='org.apache.hadoop.mapred.JobProfile' start='43' end='185' sourcepath='org/apache/hadoop/mapred/JobProfile.java' sourcefile='JobProfile.java'><Message>At JobProfile.java:[lines 43-185]</Message></SourceLine><Message>In class org.apache.hadoop.mapred.JobProfile</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapred.JobProfile' signature='()Lorg/apache/hadoop/mapred/JobID;' name='getJobID'><SourceLine endBytecode='46' classname='org.apache.hadoop.mapred.JobProfile' start='122' end='122' sourcepath='org/apache/hadoop/mapred/JobProfile.java' sourcefile='JobProfile.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapred.JobProfile.getJobID()</Message></Method><SourceLine synthetic='true' endBytecode='46' classname='org.apache.hadoop.mapred.JVMId' start='56' end='56' sourcepath='org/apache/hadoop/mapred/JVMId.java' sourcefile='JVMId.java' startBytecode='0'><Message>At JVMId.java:[line 56]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='f52331d9d46578a370da17cd6b9cc345' rank='19' abbrev='Nm' category='BAD_PRACTICE' priority='3' type='NM_CONFUSING' instanceOccurrenceMax='0'><ShortMessage>Confusing method names</ShortMessage><LongMessage>Confusing to have methods org.apache.hadoop.mapred.JobACLsManager.areACLsEnabled() and org.apache.hadoop.mapred.QueueManager.areAclsEnabled()</LongMessage><Class classname='org.apache.hadoop.mapred.JobACLsManager' primary='true'><SourceLine classname='org.apache.hadoop.mapred.JobACLsManager' start='36' end='124' sourcepath='org/apache/hadoop/mapred/JobACLsManager.java' sourcefile='JobACLsManager.java'><Message>At JobACLsManager.java:[lines 36-124]</Message></SourceLine><Message>In class org.apache.hadoop.mapred.JobACLsManager</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapred.JobACLsManager' signature='()Z' name='areACLsEnabled' primary='true'><SourceLine endBytecode='52' classname='org.apache.hadoop.mapred.JobACLsManager' start='46' end='46' sourcepath='org/apache/hadoop/mapred/JobACLsManager.java' sourcefile='JobACLsManager.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapred.JobACLsManager.areACLsEnabled()</Message></Method><Class classname='org.apache.hadoop.mapred.QueueManager'><SourceLine classname='org.apache.hadoop.mapred.QueueManager' start='82' end='613' sourcepath='org/apache/hadoop/mapred/QueueManager.java' sourcefile='QueueManager.java'><Message>At QueueManager.java:[lines 82-613]</Message></SourceLine><Message>In class org.apache.hadoop.mapred.QueueManager</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapred.QueueManager' signature='()Z' name='areAclsEnabled'><SourceLine endBytecode='46' classname='org.apache.hadoop.mapred.QueueManager' start='498' end='498' sourcepath='org/apache/hadoop/mapred/QueueManager.java' sourcefile='QueueManager.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapred.QueueManager.areAclsEnabled()</Message></Method><SourceLine synthetic='true' endBytecode='52' classname='org.apache.hadoop.mapred.JobACLsManager' start='46' end='46' sourcepath='org/apache/hadoop/mapred/JobACLsManager.java' sourcefile='JobACLsManager.java' startBytecode='0'><Message>At JobACLsManager.java:[line 46]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='6f34ed064aba84f4fafb7e9a4032afc6' cweid='391' rank='19' abbrev='DE' category='BAD_PRACTICE' priority='3' type='DE_MIGHT_IGNORE' instanceOccurrenceMax='0'><ShortMessage>Method might ignore exception</ShortMessage><LongMessage>org.apache.hadoop.mapred.JobClient.getJob(JobID) might ignore java.lang.Exception</LongMessage><Class classname='org.apache.hadoop.mapred.JobClient' primary='true'><SourceLine classname='org.apache.hadoop.mapred.JobClient' start='140' end='1279' sourcepath='org/apache/hadoop/mapred/JobClient.java' sourcefile='JobClient.java'><Message>At JobClient.java:[lines 140-1279]</Message></SourceLine><Message>In class org.apache.hadoop.mapred.JobClient</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapred.JobClient' signature='(Lorg/apache/hadoop/mapred/JobID;)Lorg/apache/hadoop/mapred/RunningJob;' name='getJob' primary='true'><SourceLine endBytecode='177' classname='org.apache.hadoop.mapred.JobClient' start='634' end='645' sourcepath='org/apache/hadoop/mapred/JobClient.java' sourcefile='JobClient.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapred.JobClient.getJob(JobID)</Message></Method><Class role='CLASS_EXCEPTION' classname='java.lang.Exception'><SourceLine classname='java.lang.Exception' start='54' end='123' sourcepath='java/lang/Exception.java' sourcefile='Exception.java'><Message>At Exception.java:[lines 54-123]</Message></SourceLine><Message>Exception class java.lang.Exception</Message></Class><SourceLine endBytecode='24' classname='org.apache.hadoop.mapred.JobClient' start='638' end='638' sourcepath='org/apache/hadoop/mapred/JobClient.java' sourcefile='JobClient.java' startBytecode='24' primary='true'><Message>At JobClient.java:[line 638]</Message></SourceLine><SourceLine endBytecode='24' classname='org.apache.hadoop.mapred.JobClient' start='638' end='638' sourcepath='org/apache/hadoop/mapred/JobClient.java' sourcefile='JobClient.java' startBytecode='24' primary='true'><Message>At JobClient.java:[line 638]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='15c0a88c2125dc334bc290a79787e25e' rank='20' abbrev='PZLA' category='STYLE' priority='3' type='PZLA_PREFER_ZERO_LENGTH_ARRAYS' instanceOccurrenceMax='0'><ShortMessage>Consider returning a zero length array rather than null</ShortMessage><LongMessage>Should org.apache.hadoop.mapred.JobClient.getJobsFromQueue(String) return a zero length array rather than null?</LongMessage><Class classname='org.apache.hadoop.mapred.JobClient' primary='true'><SourceLine classname='org.apache.hadoop.mapred.JobClient' start='140' end='1279' sourcepath='org/apache/hadoop/mapred/JobClient.java' sourcefile='JobClient.java'><Message>At JobClient.java:[lines 140-1279]</Message></SourceLine><Message>In class org.apache.hadoop.mapred.JobClient</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapred.JobClient' signature='(Ljava/lang/String;)[Lorg/apache/hadoop/mapred/JobStatus;' name='getJobsFromQueue' primary='true'><SourceLine endBytecode='283' classname='org.apache.hadoop.mapred.JobClient' start='1160' end='1177' sourcepath='org/apache/hadoop/mapred/JobClient.java' sourcefile='JobClient.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapred.JobClient.getJobsFromQueue(String)</Message></Method><SourceLine endBytecode='25' classname='org.apache.hadoop.mapred.JobClient' start='1167' end='1167' sourcepath='org/apache/hadoop/mapred/JobClient.java' sourcefile='JobClient.java' startBytecode='25' primary='true'><Message>At JobClient.java:[line 1167]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='a3307a36050ef963309aa9641c278c60' cweid='476' rank='20' abbrev='RCN' category='STYLE' priority='3' type='RCN_REDUNDANT_NULLCHECK_OF_NONNULL_VALUE' instanceOccurrenceMax='0'><ShortMessage>Redundant nullcheck of value known to be non-null</ShortMessage><LongMessage>Redundant nullcheck of status, which is known to be non-null in org.apache.hadoop.mapred.JobClient.getJobInner(JobID)</LongMessage><Class classname='org.apache.hadoop.mapred.JobClient' primary='true'><SourceLine classname='org.apache.hadoop.mapred.JobClient' start='140' end='1279' sourcepath='org/apache/hadoop/mapred/JobClient.java' sourcefile='JobClient.java'><Message>At JobClient.java:[lines 140-1279]</Message></SourceLine><Message>In class org.apache.hadoop.mapred.JobClient</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapred.JobClient' signature='(Lorg/apache/hadoop/mapred/JobID;)Lorg/apache/hadoop/mapred/RunningJob;' name='getJobInner' primary='true'><SourceLine endBytecode='205' classname='org.apache.hadoop.mapred.JobClient' start='610' end='621' sourcepath='org/apache/hadoop/mapred/JobClient.java' sourcefile='JobClient.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapred.JobClient.getJobInner(JobID)</Message></Method><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='18' name='status' register='3'><Message>Value loaded from status</Message></LocalVariable><Method isStatic='true' role='METHOD_RETURN_VALUE_OF' classname='org.apache.hadoop.mapred.JobStatus' signature='(Lorg/apache/hadoop/mapreduce/JobStatus;)Lorg/apache/hadoop/mapred/JobStatus;' name='downgrade'><SourceLine endBytecode='197' classname='org.apache.hadoop.mapred.JobStatus' start='344' end='354' sourcepath='org/apache/hadoop/mapred/JobStatus.java' sourcefile='JobStatus.java' startBytecode='0'></SourceLine><Message>Return value of org.apache.hadoop.mapred.JobStatus.downgrade(JobStatus) of type org.apache.hadoop.mapred.JobStatus</Message></Method><SourceLine role='SOURCE_REDUNDANT_NULL_CHECK' endBytecode='19' classname='org.apache.hadoop.mapred.JobClient' start='613' end='613' sourcepath='org/apache/hadoop/mapred/JobClient.java' sourcefile='JobClient.java' startBytecode='19' primary='true'><Message>Redundant null check at JobClient.java:[line 613]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='65491840277232615ff049cd87e49e44' rank='20' abbrev='SIC' category='PERFORMANCE' priority='3' type='SIC_INNER_SHOULD_BE_STATIC_ANON' instanceOccurrenceMax='0'><ShortMessage>Could be refactored into a named static inner class</ShortMessage><LongMessage>The class org.apache.hadoop.mapred.JobClient$1 could be refactored into a named _static_ inner class</LongMessage><Class role='CLASS_ANONYMOUS' classname='org.apache.hadoop.mapred.JobClient$1'><SourceLine classname='org.apache.hadoop.mapred.JobClient$1' start='571' end='577' sourcepath='org/apache/hadoop/mapred/JobClient.java' sourcefile='JobClient.java'><Message>At JobClient.java:[lines 571-577]</Message></SourceLine><Message>Anonymous class org.apache.hadoop.mapred.JobClient$1</Message></Class><Class classname='org.apache.hadoop.mapred.JobClient' primary='true'><SourceLine classname='org.apache.hadoop.mapred.JobClient' start='140' end='1279' sourcepath='org/apache/hadoop/mapred/JobClient.java' sourcefile='JobClient.java'><Message>At JobClient.java:[lines 140-1279]</Message></SourceLine><Message>In class org.apache.hadoop.mapred.JobClient</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapred.JobClient' signature='(Lorg/apache/hadoop/mapred/JobConf;)Lorg/apache/hadoop/mapred/RunningJob;' name='submitJobInternal' primary='true'><SourceLine endBytecode='234' classname='org.apache.hadoop.mapred.JobClient' start='569' end='594' sourcepath='org/apache/hadoop/mapred/JobClient.java' sourcefile='JobClient.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapred.JobClient.submitJobInternal(JobConf)</Message></Method><SourceLine endBytecode='24' classname='org.apache.hadoop.mapred.JobClient' start='571' end='571' sourcepath='org/apache/hadoop/mapred/JobClient.java' sourcefile='JobClient.java' startBytecode='24' primary='true'><Message>At JobClient.java:[line 571]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='58a18318040b8ba6dc166ec5e2d572ec' rank='19' abbrev='Nm' category='BAD_PRACTICE' priority='3' type='NM_CONFUSING' instanceOccurrenceMax='0'><ShortMessage>Confusing method names</ShortMessage><LongMessage>Confusing to have methods org.apache.hadoop.mapred.JobClient$NetworkedJob.getJobID() and org.apache.hadoop.mapred.JobProfile.getJobId()</LongMessage><Class classname='org.apache.hadoop.mapred.JobClient$NetworkedJob' primary='true'><SourceLine classname='org.apache.hadoop.mapred.JobClient$NetworkedJob' start='171' end='429' sourcepath='org/apache/hadoop/mapred/JobClient.java' sourcefile='JobClient.java'><Message>At JobClient.java:[lines 171-429]</Message></SourceLine><Message>In class org.apache.hadoop.mapred.JobClient$NetworkedJob</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapred.JobClient$NetworkedJob' signature='()Ljava/lang/String;' name='getJobID' primary='true'><SourceLine endBytecode='49' classname='org.apache.hadoop.mapred.JobClient$NetworkedJob' start='208' end='208' sourcepath='org/apache/hadoop/mapred/JobClient.java' sourcefile='JobClient.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapred.JobClient$NetworkedJob.getJobID()</Message></Method><Class classname='org.apache.hadoop.mapred.JobProfile'><SourceLine classname='org.apache.hadoop.mapred.JobProfile' start='43' end='185' sourcepath='org/apache/hadoop/mapred/JobProfile.java' sourcefile='JobProfile.java'><Message>At JobProfile.java:[lines 43-185]</Message></SourceLine><Message>In class org.apache.hadoop.mapred.JobProfile</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapred.JobProfile' signature='()Ljava/lang/String;' name='getJobId'><SourceLine endBytecode='49' classname='org.apache.hadoop.mapred.JobProfile' start='130' end='130' sourcepath='org/apache/hadoop/mapred/JobProfile.java' sourcefile='JobProfile.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapred.JobProfile.getJobId()</Message></Method><SourceLine synthetic='true' endBytecode='49' classname='org.apache.hadoop.mapred.JobClient$NetworkedJob' start='208' end='208' sourcepath='org/apache/hadoop/mapred/JobClient.java' sourcefile='JobClient.java' startBytecode='0'><Message>At JobClient.java:[line 208]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='7f940222c46b4511336b7b3424a78b90' rank='19' abbrev='Nm' category='BAD_PRACTICE' priority='3' type='NM_CONFUSING' instanceOccurrenceMax='0'><ShortMessage>Confusing method names</ShortMessage><LongMessage>Confusing to have methods org.apache.hadoop.mapred.JobClient$NetworkedJob.getJobName() and org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser$JobInfo.getJobname()</LongMessage><Class classname='org.apache.hadoop.mapred.JobClient$NetworkedJob' primary='true'><SourceLine classname='org.apache.hadoop.mapred.JobClient$NetworkedJob' start='171' end='429' sourcepath='org/apache/hadoop/mapred/JobClient.java' sourcefile='JobClient.java'><Message>At JobClient.java:[lines 171-429]</Message></SourceLine><Message>In class org.apache.hadoop.mapred.JobClient$NetworkedJob</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapred.JobClient$NetworkedJob' signature='()Ljava/lang/String;' name='getJobName' primary='true'><SourceLine endBytecode='49' classname='org.apache.hadoop.mapred.JobClient$NetworkedJob' start='215' end='215' sourcepath='org/apache/hadoop/mapred/JobClient.java' sourcefile='JobClient.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapred.JobClient$NetworkedJob.getJobName()</Message></Method><Class classname='org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser$JobInfo'><SourceLine classname='org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser$JobInfo' start='453' end='581' sourcepath='org/apache/hadoop/mapreduce/jobhistory/JobHistoryParser.java' sourcefile='JobHistoryParser.java'><Message>At JobHistoryParser.java:[lines 453-581]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser$JobInfo</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser$JobInfo' signature='()Ljava/lang/String;' name='getJobname'><SourceLine endBytecode='46' classname='org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser$JobInfo' start='537' end='537' sourcepath='org/apache/hadoop/mapreduce/jobhistory/JobHistoryParser.java' sourcefile='JobHistoryParser.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser$JobInfo.getJobname()</Message></Method><SourceLine synthetic='true' endBytecode='49' classname='org.apache.hadoop.mapred.JobClient$NetworkedJob' start='215' end='215' sourcepath='org/apache/hadoop/mapred/JobClient.java' sourcefile='JobClient.java' startBytecode='0'><Message>At JobClient.java:[line 215]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='21170af8c07b69154ae88ae91a44e8f1' rank='19' abbrev='Nm' category='BAD_PRACTICE' priority='3' type='NM_CONFUSING' instanceOccurrenceMax='0'><ShortMessage>Confusing method names</ShortMessage><LongMessage>Confusing to have methods org.apache.hadoop.mapred.JobClient$NetworkedJob.getTrackingURL() and org.apache.hadoop.mapreduce.JobStatus.getTrackingUrl()</LongMessage><Class classname='org.apache.hadoop.mapred.JobClient$NetworkedJob' primary='true'><SourceLine classname='org.apache.hadoop.mapred.JobClient$NetworkedJob' start='171' end='429' sourcepath='org/apache/hadoop/mapred/JobClient.java' sourcefile='JobClient.java'><Message>At JobClient.java:[lines 171-429]</Message></SourceLine><Message>In class org.apache.hadoop.mapred.JobClient$NetworkedJob</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapred.JobClient$NetworkedJob' signature='()Ljava/lang/String;' name='getTrackingURL' primary='true'><SourceLine endBytecode='49' classname='org.apache.hadoop.mapred.JobClient$NetworkedJob' start='229' end='229' sourcepath='org/apache/hadoop/mapred/JobClient.java' sourcefile='JobClient.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapred.JobClient$NetworkedJob.getTrackingURL()</Message></Method><Class classname='org.apache.hadoop.mapreduce.JobStatus'><SourceLine classname='org.apache.hadoop.mapreduce.JobStatus' start='45' end='656' sourcepath='org/apache/hadoop/mapreduce/JobStatus.java' sourcefile='JobStatus.java'><Message>At JobStatus.java:[lines 45-656]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.JobStatus</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapreduce.JobStatus' signature='()Ljava/lang/String;' name='getTrackingUrl'><SourceLine endBytecode='46' classname='org.apache.hadoop.mapreduce.JobStatus' start='527' end='527' sourcepath='org/apache/hadoop/mapreduce/JobStatus.java' sourcefile='JobStatus.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapreduce.JobStatus.getTrackingUrl()</Message></Method><SourceLine synthetic='true' endBytecode='49' classname='org.apache.hadoop.mapred.JobClient$NetworkedJob' start='229' end='229' sourcepath='org/apache/hadoop/mapred/JobClient.java' sourcefile='JobClient.java' startBytecode='0'><Message>At JobClient.java:[line 229]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='9cedf131f2789f202e8817f4de3ae2f8' cweid='563' rank='20' abbrev='DLS' category='STYLE' priority='3' type='DLS_DEAD_LOCAL_STORE' instanceOccurrenceMax='0'><ShortMessage>Dead store to local variable</ShortMessage><LongMessage>Dead store to priority in org.apache.hadoop.mapred.JobConf.getJobPriority()</LongMessage><Class classname='org.apache.hadoop.mapred.JobConf' primary='true'><SourceLine classname='org.apache.hadoop.mapred.JobConf' start='118' end='2224' sourcepath='org/apache/hadoop/mapred/JobConf.java' sourcefile='JobConf.java'><Message>At JobConf.java:[lines 118-2224]</Message></SourceLine><Message>In class org.apache.hadoop.mapred.JobConf</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapred.JobConf' signature='()Lorg/apache/hadoop/mapred/JobPriority;' name='getJobPriority' primary='true'><SourceLine endBytecode='21' classname='org.apache.hadoop.mapred.JobConf' start='1582' end='1593' sourcepath='org/apache/hadoop/mapred/JobConf.java' sourcefile='JobConf.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapred.JobConf.getJobPriority()</Message></Method><LocalVariable role='LOCAL_VARIABLE_NAMED' pc='19' name='priority' register='2'><Message>Local variable named priority</Message></LocalVariable><SourceLine endBytecode='18' classname='org.apache.hadoop.mapred.JobConf' start='1587' end='1587' sourcepath='org/apache/hadoop/mapred/JobConf.java' sourcefile='JobConf.java' startBytecode='18' primary='true'><Message>At JobConf.java:[line 1587]</Message></SourceLine><Property name='edu.umd.cs.findbugs.detect.DeadLocalStoreProperty.KILLED_BY_SUBSEQUENT_STORE' value='true'></Property><Property name='edu.umd.cs.findbugs.detect.DeadLocalStoreProperty.LOCAL_NAME' value='priority'></Property></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='f81c434c66fc4672c4f15981702bcafe' rank='16' abbrev='Nm' category='BAD_PRACTICE' priority='2' type='NM_SAME_SIMPLE_NAME_AS_INTERFACE' instanceOccurrenceMax='0'><ShortMessage>Class names shouldn't shadow simple name of implemented interface</ShortMessage><LongMessage>The class name org.apache.hadoop.mapred.JobContext shadows the simple name of implemented interface org.apache.hadoop.mapreduce.JobContext</LongMessage><Class classname='org.apache.hadoop.mapred.JobContext' primary='true'><SourceLine classname='org.apache.hadoop.mapred.JobContext' sourcepath='org/apache/hadoop/mapred/JobContext.java' sourcefile='JobContext.java'><Message>In JobContext.java</Message></SourceLine><Message>In class org.apache.hadoop.mapred.JobContext</Message></Class><Class classname='org.apache.hadoop.mapreduce.JobContext'><SourceLine classname='org.apache.hadoop.mapreduce.JobContext' sourcepath='org/apache/hadoop/mapreduce/JobContext.java' sourcefile='JobContext.java'><Message>In JobContext.java</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.JobContext</Message></Class><SourceLine synthetic='true' classname='org.apache.hadoop.mapred.JobContext' sourcepath='org/apache/hadoop/mapred/JobContext.java' sourcefile='JobContext.java'><Message>In JobContext.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='e642b84688b75df6041a53f917482525' rank='14' abbrev='Nm' category='BAD_PRACTICE' priority='1' type='NM_SAME_SIMPLE_NAME_AS_SUPERCLASS' instanceOccurrenceMax='0'><ShortMessage>Class names shouldn't shadow simple name of superclass</ShortMessage><LongMessage>The class name org.apache.hadoop.mapred.JobContextImpl shadows the simple name of the superclass org.apache.hadoop.mapreduce.task.JobContextImpl</LongMessage><Class classname='org.apache.hadoop.mapred.JobContextImpl' primary='true'><SourceLine classname='org.apache.hadoop.mapred.JobContextImpl' start='35' end='59' sourcepath='org/apache/hadoop/mapred/JobContextImpl.java' sourcefile='JobContextImpl.java'><Message>At JobContextImpl.java:[lines 35-59]</Message></SourceLine><Message>In class org.apache.hadoop.mapred.JobContextImpl</Message></Class><Class classname='org.apache.hadoop.mapreduce.task.JobContextImpl'><SourceLine classname='org.apache.hadoop.mapreduce.task.JobContextImpl' start='63' end='461' sourcepath='org/apache/hadoop/mapreduce/task/JobContextImpl.java' sourcefile='JobContextImpl.java'><Message>At JobContextImpl.java:[lines 63-461]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.task.JobContextImpl</Message></Class><SourceLine synthetic='true' classname='org.apache.hadoop.mapred.JobContextImpl' start='35' end='59' sourcepath='org/apache/hadoop/mapred/JobContextImpl.java' sourcefile='JobContextImpl.java'><Message>At JobContextImpl.java:[lines 35-59]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='caf824b297dcd46faae8318bfbfb3054' rank='14' abbrev='Nm' category='BAD_PRACTICE' priority='1' type='NM_SAME_SIMPLE_NAME_AS_SUPERCLASS' instanceOccurrenceMax='0'><ShortMessage>Class names shouldn't shadow simple name of superclass</ShortMessage><LongMessage>The class name org.apache.hadoop.mapred.JobID shadows the simple name of the superclass org.apache.hadoop.mapreduce.JobID</LongMessage><Class classname='org.apache.hadoop.mapred.JobID' primary='true'><SourceLine classname='org.apache.hadoop.mapred.JobID' start='53' end='118' sourcepath='org/apache/hadoop/mapred/JobID.java' sourcefile='JobID.java'><Message>At JobID.java:[lines 53-118]</Message></SourceLine><Message>In class org.apache.hadoop.mapred.JobID</Message></Class><Class classname='org.apache.hadoop.mapreduce.JobID'><SourceLine classname='org.apache.hadoop.mapreduce.JobID' start='47' end='156' sourcepath='org/apache/hadoop/mapreduce/JobID.java' sourcefile='JobID.java'><Message>At JobID.java:[lines 47-156]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.JobID</Message></Class><SourceLine synthetic='true' classname='org.apache.hadoop.mapred.JobID' start='53' end='118' sourcepath='org/apache/hadoop/mapred/JobID.java' sourcefile='JobID.java'><Message>At JobID.java:[lines 53-118]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='6e3b7b7834db2a07282c3702ae77c6f8' rank='19' abbrev='Nm' category='BAD_PRACTICE' priority='3' type='NM_CONFUSING' instanceOccurrenceMax='0'><ShortMessage>Confusing method names</ShortMessage><LongMessage>Confusing to have methods org.apache.hadoop.mapred.JobInfo.getJobID() and org.apache.hadoop.mapreduce.jobhistory.JobFinishedEvent.getJobid()</LongMessage><Class classname='org.apache.hadoop.mapred.JobInfo' primary='true'><SourceLine classname='org.apache.hadoop.mapred.JobInfo' start='39' end='82' sourcepath='org/apache/hadoop/mapred/JobInfo.java' sourcefile='JobInfo.java'><Message>At JobInfo.java:[lines 39-82]</Message></SourceLine><Message>In class org.apache.hadoop.mapred.JobInfo</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapred.JobInfo' signature='()Lorg/apache/hadoop/mapreduce/JobID;' name='getJobID' primary='true'><SourceLine endBytecode='46' classname='org.apache.hadoop.mapred.JobInfo' start='53' end='53' sourcepath='org/apache/hadoop/mapred/JobInfo.java' sourcefile='JobInfo.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapred.JobInfo.getJobID()</Message></Method><Class classname='org.apache.hadoop.mapreduce.jobhistory.JobFinishedEvent'><SourceLine classname='org.apache.hadoop.mapreduce.jobhistory.JobFinishedEvent' start='41' end='186' sourcepath='org/apache/hadoop/mapreduce/jobhistory/JobFinishedEvent.java' sourcefile='JobFinishedEvent.java'><Message>At JobFinishedEvent.java:[lines 41-186]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.jobhistory.JobFinishedEvent</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapreduce.jobhistory.JobFinishedEvent' signature='()Lorg/apache/hadoop/mapreduce/JobID;' name='getJobid'><SourceLine endBytecode='46' classname='org.apache.hadoop.mapreduce.jobhistory.JobFinishedEvent' start='130' end='130' sourcepath='org/apache/hadoop/mapreduce/jobhistory/JobFinishedEvent.java' sourcefile='JobFinishedEvent.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapreduce.jobhistory.JobFinishedEvent.getJobid()</Message></Method><SourceLine synthetic='true' endBytecode='46' classname='org.apache.hadoop.mapred.JobInfo' start='53' end='53' sourcepath='org/apache/hadoop/mapred/JobInfo.java' sourcefile='JobInfo.java' startBytecode='0'><Message>At JobInfo.java:[line 53]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='5cba916153537e3b608a2702ac62ea87' cweid='476' rank='20' abbrev='RCN' category='STYLE' priority='3' type='RCN_REDUNDANT_NULLCHECK_OF_NONNULL_VALUE' instanceOccurrenceMax='0'><ShortMessage>Redundant nullcheck of value known to be non-null</ShortMessage><LongMessage>Redundant nullcheck of org.apache.hadoop.mapred.JobQueueInfo.getChildren(), which is known to be non-null in org.apache.hadoop.mapred.JobQueueClient.displayQueueInfo(String, boolean)</LongMessage><Class classname='org.apache.hadoop.mapred.JobQueueClient' primary='true'><SourceLine classname='org.apache.hadoop.mapred.JobQueueClient' start='49' end='242' sourcepath='org/apache/hadoop/mapred/JobQueueClient.java' sourcefile='JobQueueClient.java'><Message>At JobQueueClient.java:[lines 49-242]</Message></SourceLine><Message>In class org.apache.hadoop.mapred.JobQueueClient</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapred.JobQueueClient' signature='(Ljava/lang/String;Z)V' name='displayQueueInfo' primary='true'><SourceLine endBytecode='268' classname='org.apache.hadoop.mapred.JobQueueClient' start='183' end='198' sourcepath='org/apache/hadoop/mapred/JobQueueClient.java' sourcefile='JobQueueClient.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapred.JobQueueClient.displayQueueInfo(String, boolean)</Message></Method><Method isStatic='false' role='METHOD_RETURN_VALUE_OF' classname='org.apache.hadoop.mapred.JobQueueInfo' signature='()Ljava/util/List;' name='getChildren'><SourceLine endBytecode='168' classname='org.apache.hadoop.mapred.JobQueueInfo' start='112' end='116' sourcepath='org/apache/hadoop/mapred/JobQueueInfo.java' sourcefile='JobQueueInfo.java' startBytecode='0'></SourceLine><Message>Return value of org.apache.hadoop.mapred.JobQueueInfo.getChildren() of type java.util.List</Message></Method><SourceLine role='SOURCE_REDUNDANT_NULL_CHECK' endBytecode='77' classname='org.apache.hadoop.mapred.JobQueueClient' start='191' end='191' sourcepath='org/apache/hadoop/mapred/JobQueueClient.java' sourcefile='JobQueueClient.java' startBytecode='77' primary='true'><Message>Redundant null check at JobQueueClient.java:[line 191]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='a21af87125fb85f246db3608269c11d9' cweid='476' rank='20' abbrev='RCN' category='STYLE' priority='3' type='RCN_REDUNDANT_NULLCHECK_OF_NONNULL_VALUE' instanceOccurrenceMax='0'><ShortMessage>Redundant nullcheck of value known to be non-null</ShortMessage><LongMessage>Redundant nullcheck of org.apache.hadoop.mapred.JobQueueInfo.getChildren(), which is known to be non-null in org.apache.hadoop.mapred.JobQueueClient.expandQueueList(JobQueueInfo[])</LongMessage><Class classname='org.apache.hadoop.mapred.JobQueueClient' primary='true'><SourceLine classname='org.apache.hadoop.mapred.JobQueueClient' start='49' end='242' sourcepath='org/apache/hadoop/mapred/JobQueueClient.java' sourcefile='JobQueueClient.java'><Message>At JobQueueClient.java:[lines 49-242]</Message></SourceLine><Message>In class org.apache.hadoop.mapred.JobQueueClient</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapred.JobQueueClient' signature='([Lorg/apache/hadoop/mapred/JobQueueInfo;)Ljava/util/List;' name='expandQueueList' primary='true'><SourceLine endBytecode='251' classname='org.apache.hadoop.mapred.JobQueueClient' start='162' end='171' sourcepath='org/apache/hadoop/mapred/JobQueueClient.java' sourcefile='JobQueueClient.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapred.JobQueueClient.expandQueueList(JobQueueInfo[])</Message></Method><Method isStatic='false' role='METHOD_RETURN_VALUE_OF' classname='org.apache.hadoop.mapred.JobQueueInfo' signature='()Ljava/util/List;' name='getChildren'><SourceLine endBytecode='168' classname='org.apache.hadoop.mapred.JobQueueInfo' start='112' end='116' sourcepath='org/apache/hadoop/mapred/JobQueueInfo.java' sourcefile='JobQueueInfo.java' startBytecode='0'></SourceLine><Message>Return value of org.apache.hadoop.mapred.JobQueueInfo.getChildren() of type java.util.List</Message></Method><SourceLine role='SOURCE_REDUNDANT_NULL_CHECK' endBytecode='44' classname='org.apache.hadoop.mapred.JobQueueClient' start='165' end='165' sourcepath='org/apache/hadoop/mapred/JobQueueClient.java' sourcefile='JobQueueClient.java' startBytecode='44' primary='true'><Message>Redundant null check at JobQueueClient.java:[line 165]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='db8f1b8d6b90873fcde3f3c394677c6e' cweid='476' rank='20' abbrev='RCN' category='STYLE' priority='3' type='RCN_REDUNDANT_NULLCHECK_OF_NONNULL_VALUE' instanceOccurrenceMax='0'><ShortMessage>Redundant nullcheck of value known to be non-null</ShortMessage><LongMessage>Redundant nullcheck of childQueues, which is known to be non-null in org.apache.hadoop.mapred.JobQueueClient.printJobQueueInfo(JobQueueInfo, Writer, String)</LongMessage><Class classname='org.apache.hadoop.mapred.JobQueueClient' primary='true'><SourceLine classname='org.apache.hadoop.mapred.JobQueueClient' start='49' end='242' sourcepath='org/apache/hadoop/mapred/JobQueueClient.java' sourcefile='JobQueueClient.java'><Message>At JobQueueClient.java:[lines 49-242]</Message></SourceLine><Message>In class org.apache.hadoop.mapred.JobQueueClient</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapred.JobQueueClient' signature='(Lorg/apache/hadoop/mapred/JobQueueInfo;Ljava/io/Writer;Ljava/lang/String;)V' name='printJobQueueInfo' primary='true'><SourceLine endBytecode='447' classname='org.apache.hadoop.mapred.JobQueueClient' start='126' end='145' sourcepath='org/apache/hadoop/mapred/JobQueueClient.java' sourcefile='JobQueueClient.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapred.JobQueueClient.printJobQueueInfo(JobQueueInfo, Writer, String)</Message></Method><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='162' name='childQueues' register='4'><Message>Value loaded from childQueues</Message></LocalVariable><Method isStatic='false' role='METHOD_RETURN_VALUE_OF' classname='org.apache.hadoop.mapred.JobQueueInfo' signature='()Ljava/util/List;' name='getChildren'><SourceLine endBytecode='168' classname='org.apache.hadoop.mapred.JobQueueInfo' start='112' end='116' sourcepath='org/apache/hadoop/mapred/JobQueueInfo.java' sourcefile='JobQueueInfo.java' startBytecode='0'></SourceLine><Message>Return value of org.apache.hadoop.mapred.JobQueueInfo.getChildren() of type java.util.List</Message></Method><SourceLine role='SOURCE_REDUNDANT_NULL_CHECK' endBytecode='164' classname='org.apache.hadoop.mapred.JobQueueClient' start='139' end='139' sourcepath='org/apache/hadoop/mapred/JobQueueClient.java' sourcefile='JobQueueClient.java' startBytecode='164' primary='true'><Message>Redundant null check at JobQueueClient.java:[line 139]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='7f4f7d3388761d0c0a198b76cd34a87c' rank='14' abbrev='Nm' category='BAD_PRACTICE' priority='1' type='NM_SAME_SIMPLE_NAME_AS_SUPERCLASS' instanceOccurrenceMax='0'><ShortMessage>Class names shouldn't shadow simple name of superclass</ShortMessage><LongMessage>The class name org.apache.hadoop.mapred.JobStatus shadows the simple name of the superclass org.apache.hadoop.mapreduce.JobStatus</LongMessage><Class classname='org.apache.hadoop.mapred.JobStatus' primary='true'><SourceLine classname='org.apache.hadoop.mapred.JobStatus' start='33' end='529' sourcepath='org/apache/hadoop/mapred/JobStatus.java' sourcefile='JobStatus.java'><Message>At JobStatus.java:[lines 33-529]</Message></SourceLine><Message>In class org.apache.hadoop.mapred.JobStatus</Message></Class><Class classname='org.apache.hadoop.mapreduce.JobStatus'><SourceLine classname='org.apache.hadoop.mapreduce.JobStatus' start='45' end='656' sourcepath='org/apache/hadoop/mapreduce/JobStatus.java' sourcefile='JobStatus.java'><Message>At JobStatus.java:[lines 45-656]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.JobStatus</Message></Class><SourceLine synthetic='true' classname='org.apache.hadoop.mapred.JobStatus' start='33' end='529' sourcepath='org/apache/hadoop/mapred/JobStatus.java' sourcefile='JobStatus.java'><Message>At JobStatus.java:[lines 33-529]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='847d39067533f2a2185ee37123d08642' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from org.apache.hadoop.mapred.InputSplit to org.apache.hadoop.mapred.FileSplit in org.apache.hadoop.mapred.KeyValueTextInputFormat.getRecordReader(InputSplit, JobConf, Reporter)</LongMessage><Class classname='org.apache.hadoop.mapred.KeyValueTextInputFormat' primary='true'><SourceLine classname='org.apache.hadoop.mapred.KeyValueTextInputFormat' start='40' end='63' sourcepath='org/apache/hadoop/mapred/KeyValueTextInputFormat.java' sourcefile='KeyValueTextInputFormat.java'><Message>At KeyValueTextInputFormat.java:[lines 40-63]</Message></SourceLine><Message>In class org.apache.hadoop.mapred.KeyValueTextInputFormat</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapred.KeyValueTextInputFormat' signature='(Lorg/apache/hadoop/mapred/InputSplit;Lorg/apache/hadoop/mapred/JobConf;Lorg/apache/hadoop/mapred/Reporter;)Lorg/apache/hadoop/mapred/RecordReader;' name='getRecordReader' primary='true'><SourceLine endBytecode='10' classname='org.apache.hadoop.mapred.KeyValueTextInputFormat' start='62' end='63' sourcepath='org/apache/hadoop/mapred/KeyValueTextInputFormat.java' sourcefile='KeyValueTextInputFormat.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapred.KeyValueTextInputFormat.getRecordReader(InputSplit, JobConf, Reporter)</Message></Method><Type role='TYPE_FOUND' descriptor='Lorg/apache/hadoop/mapred/InputSplit;'><SourceLine classname='org.apache.hadoop.mapred.InputSplit' sourcepath='org/apache/hadoop/mapred/InputSplit.java' sourcefile='InputSplit.java'><Message>In InputSplit.java</Message></SourceLine><Message>Actual type org.apache.hadoop.mapred.InputSplit</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/mapred/FileSplit;'><SourceLine classname='org.apache.hadoop.mapred.FileSplit' start='39' end='113' sourcepath='org/apache/hadoop/mapred/FileSplit.java' sourcefile='FileSplit.java'><Message>At FileSplit.java:[lines 39-113]</Message></SourceLine><Message>Expected org.apache.hadoop.mapred.FileSplit</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='15' name='genericSplit' register='1'><Message>Value loaded from genericSplit</Message></LocalVariable><SourceLine endBytecode='16' classname='org.apache.hadoop.mapred.KeyValueTextInputFormat' start='63' end='63' sourcepath='org/apache/hadoop/mapred/KeyValueTextInputFormat.java' sourcefile='KeyValueTextInputFormat.java' startBytecode='16' primary='true'><Message>At KeyValueTextInputFormat.java:[line 63]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='ba15a594c3e60fd935fb4086eb17dc3d' cweid='374' rank='18' abbrev='EI2' category='MALICIOUS_CODE' priority='2' type='EI_EXPOSE_REP2' instanceOccurrenceMax='0'><ShortMessage>May expose internal representation by incorporating reference to mutable object</ShortMessage><LongMessage>new org.apache.hadoop.mapred.LocatedFileStatusFetcher(Configuration, Path[], boolean, PathFilter, boolean) may expose internal representation by storing an externally mutable object into LocatedFileStatusFetcher.inputDirs</LongMessage><Class classname='org.apache.hadoop.mapred.LocatedFileStatusFetcher' primary='true'><SourceLine classname='org.apache.hadoop.mapred.LocatedFileStatusFetcher' start='56' end='197' sourcepath='org/apache/hadoop/mapred/LocatedFileStatusFetcher.java' sourcefile='LocatedFileStatusFetcher.java'><Message>At LocatedFileStatusFetcher.java:[lines 56-197]</Message></SourceLine><Message>In class org.apache.hadoop.mapred.LocatedFileStatusFetcher</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapred.LocatedFileStatusFetcher' signature='(Lorg/apache/hadoop/conf/Configuration;[Lorg/apache/hadoop/fs/Path;ZLorg/apache/hadoop/fs/PathFilter;Z)V' name='&lt;init&gt;' primary='true'><SourceLine endBytecode='339' classname='org.apache.hadoop.mapred.LocatedFileStatusFetcher' start='92' end='106' sourcepath='org/apache/hadoop/mapred/LocatedFileStatusFetcher.java' sourcefile='LocatedFileStatusFetcher.java' startBytecode='0'></SourceLine><Message>In method new org.apache.hadoop.mapred.LocatedFileStatusFetcher(Configuration, Path[], boolean, PathFilter, boolean)</Message></Method><Field isStatic='false' classname='org.apache.hadoop.mapred.LocatedFileStatusFetcher' signature='[Lorg/apache/hadoop/fs/Path;' name='inputDirs' primary='true'><SourceLine classname='org.apache.hadoop.mapred.LocatedFileStatusFetcher' sourcepath='org/apache/hadoop/mapred/LocatedFileStatusFetcher.java' sourcefile='LocatedFileStatusFetcher.java'><Message>In LocatedFileStatusFetcher.java</Message></SourceLine><Message>Field org.apache.hadoop.mapred.LocatedFileStatusFetcher.inputDirs</Message></Field><LocalVariable role='LOCAL_VARIABLE_NAMED' pc='141' name='dirs' register='2'><Message>Local variable named dirs</Message></LocalVariable><SourceLine endBytecode='141' classname='org.apache.hadoop.mapred.LocatedFileStatusFetcher' start='102' end='102' sourcepath='org/apache/hadoop/mapred/LocatedFileStatusFetcher.java' sourcefile='LocatedFileStatusFetcher.java' startBytecode='141' primary='true'><Message>At LocatedFileStatusFetcher.java:[line 102]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='dbc53f46853ef7e8919ae40eaf45e806' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST_OF_RETURN_VALUE' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast of return value from method</ShortMessage><LongMessage>Unchecked/unconfirmed cast from org.apache.hadoop.conf.Configuration to org.apache.hadoop.mapred.JobConf of return value in org.apache.hadoop.mapred.MROutputFiles.removeAll()</LongMessage><Class classname='org.apache.hadoop.mapred.MROutputFiles' primary='true'><SourceLine classname='org.apache.hadoop.mapred.MROutputFiles' start='42' end='224' sourcepath='org/apache/hadoop/mapred/MROutputFiles.java' sourcefile='MROutputFiles.java'><Message>At MROutputFiles.java:[lines 42-224]</Message></SourceLine><Message>In class org.apache.hadoop.mapred.MROutputFiles</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapred.MROutputFiles' signature='()V' name='removeAll' primary='true'><SourceLine endBytecode='5' classname='org.apache.hadoop.mapred.MROutputFiles' start='215' end='216' sourcepath='org/apache/hadoop/mapred/MROutputFiles.java' sourcefile='MROutputFiles.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapred.MROutputFiles.removeAll()</Message></Method><Type role='TYPE_FOUND' descriptor='Lorg/apache/hadoop/conf/Configuration;'><SourceLine classname='org.apache.hadoop.conf.Configuration' start='223' end='3860' sourcepath='org/apache/hadoop/conf/Configuration.java' sourcefile='Configuration.java'><Message>At Configuration.java:[lines 223-3860]</Message></SourceLine><Message>Actual type org.apache.hadoop.conf.Configuration</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/mapred/JobConf;'><SourceLine classname='org.apache.hadoop.mapred.JobConf' start='118' end='2224' sourcepath='org/apache/hadoop/mapred/JobConf.java' sourcefile='JobConf.java'><Message>At JobConf.java:[lines 118-2224]</Message></SourceLine><Message>Expected org.apache.hadoop.mapred.JobConf</Message></Type><SourceLine endBytecode='4' classname='org.apache.hadoop.mapred.MROutputFiles' start='215' end='215' sourcepath='org/apache/hadoop/mapred/MROutputFiles.java' sourcefile='MROutputFiles.java' startBytecode='4' primary='true'><Message>At MROutputFiles.java:[line 215]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='1eee7631244c1356aabb653ab2417a3' rank='20' abbrev='SIC' category='PERFORMANCE' priority='3' type='SIC_INNER_SHOULD_BE_STATIC_ANON' instanceOccurrenceMax='0'><ShortMessage>Could be refactored into a named static inner class</ShortMessage><LongMessage>The class org.apache.hadoop.mapred.MapFileOutputFormat$1 could be refactored into a named _static_ inner class</LongMessage><Class role='CLASS_ANONYMOUS' classname='org.apache.hadoop.mapred.MapFileOutputFormat$1'><SourceLine classname='org.apache.hadoop.mapred.MapFileOutputFormat$1' start='72' end='80' sourcepath='org/apache/hadoop/mapred/MapFileOutputFormat.java' sourcefile='MapFileOutputFormat.java'><Message>At MapFileOutputFormat.java:[lines 72-80]</Message></SourceLine><Message>Anonymous class org.apache.hadoop.mapred.MapFileOutputFormat$1</Message></Class><Class classname='org.apache.hadoop.mapred.MapFileOutputFormat' primary='true'><SourceLine classname='org.apache.hadoop.mapred.MapFileOutputFormat' start='42' end='105' sourcepath='org/apache/hadoop/mapred/MapFileOutputFormat.java' sourcefile='MapFileOutputFormat.java'><Message>At MapFileOutputFormat.java:[lines 42-105]</Message></SourceLine><Message>In class org.apache.hadoop.mapred.MapFileOutputFormat</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapred.MapFileOutputFormat' signature='(Lorg/apache/hadoop/fs/FileSystem;Lorg/apache/hadoop/mapred/JobConf;Ljava/lang/String;Lorg/apache/hadoop/util/Progressable;)Lorg/apache/hadoop/mapred/RecordWriter;' name='getRecordWriter' primary='true'><SourceLine endBytecode='356' classname='org.apache.hadoop.mapred.MapFileOutputFormat' start='49' end='72' sourcepath='org/apache/hadoop/mapred/MapFileOutputFormat.java' sourcefile='MapFileOutputFormat.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapred.MapFileOutputFormat.getRecordWriter(FileSystem, JobConf, String, Progressable)</Message></Method><SourceLine endBytecode='103' classname='org.apache.hadoop.mapred.MapFileOutputFormat' start='72' end='72' sourcepath='org/apache/hadoop/mapred/MapFileOutputFormat.java' sourcefile='MapFileOutputFormat.java' startBytecode='103' primary='true'><Message>At MapFileOutputFormat.java:[line 72]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='53fa0c44be331d1743f9164db8b18686' cweid='192' rank='20' abbrev='ICAST' category='STYLE' priority='3' type='ICAST_INTEGER_MULTIPLY_CAST_TO_LONG' instanceOccurrenceMax='0'><ShortMessage>Result of integer multiplication cast to long</ShortMessage><LongMessage>Result of integer multiplication cast to long in org.apache.hadoop.mapred.MapTask$MapOutputBuffer.mergeParts()</LongMessage><Class classname='org.apache.hadoop.mapred.MapTask$MapOutputBuffer' primary='true'><SourceLine classname='org.apache.hadoop.mapred.MapTask$MapOutputBuffer' start='886' end='2018' sourcepath='org/apache/hadoop/mapred/MapTask.java' sourcefile='MapTask.java'><Message>At MapTask.java:[lines 886-2018]</Message></SourceLine><Message>In class org.apache.hadoop.mapred.MapTask$MapOutputBuffer</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapred.MapTask$MapOutputBuffer' signature='()V' name='mergeParts' primary='true'><SourceLine endBytecode='2227' classname='org.apache.hadoop.mapred.MapTask$MapOutputBuffer' start='1847' end='1995' sourcepath='org/apache/hadoop/mapred/MapTask.java' sourcefile='MapTask.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapred.MapTask$MapOutputBuffer.mergeParts()</Message></Method><SourceLine endBytecode='234' classname='org.apache.hadoop.mapred.MapTask$MapOutputBuffer' start='1878' end='1878' sourcepath='org/apache/hadoop/mapred/MapTask.java' sourcefile='MapTask.java' startBytecode='234' primary='true'><Message>At MapTask.java:[line 1878]</Message></SourceLine><SourceLine role='SOURCE_LINE_ANOTHER_INSTANCE' endBytecode='244' classname='org.apache.hadoop.mapred.MapTask$MapOutputBuffer' start='1879' end='1879' sourcepath='org/apache/hadoop/mapred/MapTask.java' sourcefile='MapTask.java' startBytecode='244'><Message>Another occurrence at MapTask.java:[line 1879]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='c8a8666043ec9a4d6bee135264bc3616' cweid='192' rank='20' abbrev='ICAST' category='STYLE' priority='3' type='ICAST_INTEGER_MULTIPLY_CAST_TO_LONG' instanceOccurrenceMax='0'><ShortMessage>Result of integer multiplication cast to long</ShortMessage><LongMessage>Result of integer multiplication cast to long in org.apache.hadoop.mapred.MapTask$MapOutputBuffer.sortAndSpill()</LongMessage><Class classname='org.apache.hadoop.mapred.MapTask$MapOutputBuffer' primary='true'><SourceLine classname='org.apache.hadoop.mapred.MapTask$MapOutputBuffer' start='886' end='2018' sourcepath='org/apache/hadoop/mapred/MapTask.java' sourcefile='MapTask.java'><Message>At MapTask.java:[lines 886-2018]</Message></SourceLine><Message>In class org.apache.hadoop.mapred.MapTask$MapOutputBuffer</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapred.MapTask$MapOutputBuffer' signature='()V' name='sortAndSpill' primary='true'><SourceLine endBytecode='1600' classname='org.apache.hadoop.mapred.MapTask$MapOutputBuffer' start='1609' end='1704' sourcepath='org/apache/hadoop/mapred/MapTask.java' sourcefile='MapTask.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapred.MapTask$MapOutputBuffer.sortAndSpill()</Message></Method><SourceLine endBytecode='569' classname='org.apache.hadoop.mapred.MapTask$MapOutputBuffer' start='1687' end='1687' sourcepath='org/apache/hadoop/mapred/MapTask.java' sourcefile='MapTask.java' startBytecode='569' primary='true'><Message>At MapTask.java:[line 1687]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='d407d2c124605ae87db9c3332af89152' cweid='192' rank='20' abbrev='ICAST' category='STYLE' priority='3' type='ICAST_INTEGER_MULTIPLY_CAST_TO_LONG' instanceOccurrenceMax='0'><ShortMessage>Result of integer multiplication cast to long</ShortMessage><LongMessage>Result of integer multiplication cast to long in org.apache.hadoop.mapred.MapTask$MapOutputBuffer.spillSingleRecord(Object, Object, int)</LongMessage><Class classname='org.apache.hadoop.mapred.MapTask$MapOutputBuffer' primary='true'><SourceLine classname='org.apache.hadoop.mapred.MapTask$MapOutputBuffer' start='886' end='2018' sourcepath='org/apache/hadoop/mapred/MapTask.java' sourcefile='MapTask.java'><Message>At MapTask.java:[lines 886-2018]</Message></SourceLine><Message>In class org.apache.hadoop.mapred.MapTask$MapOutputBuffer</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapred.MapTask$MapOutputBuffer' signature='(Ljava/lang/Object;Ljava/lang/Object;I)V' name='spillSingleRecord' primary='true'><SourceLine endBytecode='1028' classname='org.apache.hadoop.mapred.MapTask$MapOutputBuffer' start='1713' end='1777' sourcepath='org/apache/hadoop/mapred/MapTask.java' sourcefile='MapTask.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapred.MapTask$MapOutputBuffer.spillSingleRecord(Object, Object, int)</Message></Method><SourceLine endBytecode='299' classname='org.apache.hadoop.mapred.MapTask$MapOutputBuffer' start='1761' end='1761' sourcepath='org/apache/hadoop/mapred/MapTask.java' sourcefile='MapTask.java' startBytecode='299' primary='true'><Message>At MapTask.java:[line 1761]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='1d2d6ad852e2a3c73c212044ff01dcec' cweid='366' rank='17' abbrev='IS' category='MT_CORRECTNESS' priority='2' type='IS2_INCONSISTENT_SYNC' instanceOccurrenceMax='0'><ShortMessage>Inconsistent synchronization</ShortMessage><LongMessage>Inconsistent synchronization of org.apache.hadoop.mapred.MapTask$MapOutputBuffer.kvindex; locked 60% of time</LongMessage><Class classname='org.apache.hadoop.mapred.MapTask$MapOutputBuffer' primary='true'><SourceLine classname='org.apache.hadoop.mapred.MapTask$MapOutputBuffer' start='886' end='2018' sourcepath='org/apache/hadoop/mapred/MapTask.java' sourcefile='MapTask.java'><Message>At MapTask.java:[lines 886-2018]</Message></SourceLine><Message>In class org.apache.hadoop.mapred.MapTask$MapOutputBuffer</Message></Class><Field isStatic='false' classname='org.apache.hadoop.mapred.MapTask$MapOutputBuffer' signature='I' name='kvindex' primary='true'><SourceLine classname='org.apache.hadoop.mapred.MapTask$MapOutputBuffer' sourcepath='org/apache/hadoop/mapred/MapTask.java' sourcefile='MapTask.java'><Message>In MapTask.java</Message></SourceLine><Message>Field org.apache.hadoop.mapred.MapTask$MapOutputBuffer.kvindex</Message></Field><Int role='INT_SYNC_PERCENT' value='60'><Message>Synchronized 60% of the time</Message></Int><SourceLine role='SOURCE_LINE_UNSYNC_ACCESS' endBytecode='105' classname='org.apache.hadoop.mapred.MapTask$MapOutputBuffer' start='1236' end='1236' sourcepath='org/apache/hadoop/mapred/MapTask.java' sourcefile='MapTask.java' startBytecode='105' primary='true'><Message>Unsynchronized access at MapTask.java:[line 1236]</Message></SourceLine><SourceLine role='SOURCE_LINE_UNSYNC_ACCESS' endBytecode='117' classname='org.apache.hadoop.mapred.MapTask$MapOutputBuffer' start='1236' end='1236' sourcepath='org/apache/hadoop/mapred/MapTask.java' sourcefile='MapTask.java' startBytecode='117'><Message>Unsynchronized access at MapTask.java:[line 1236]</Message></SourceLine><SourceLine role='SOURCE_LINE_UNSYNC_ACCESS' endBytecode='102' classname='org.apache.hadoop.mapred.MapTask$MapOutputBuffer' start='1495' end='1495' sourcepath='org/apache/hadoop/mapred/MapTask.java' sourcefile='MapTask.java' startBytecode='102'><Message>Unsynchronized access at MapTask.java:[line 1495]</Message></SourceLine><SourceLine role='SOURCE_LINE_UNSYNC_ACCESS' endBytecode='114' classname='org.apache.hadoop.mapred.MapTask$MapOutputBuffer' start='1496' end='1496' sourcepath='org/apache/hadoop/mapred/MapTask.java' sourcefile='MapTask.java' startBytecode='114'><Message>Unsynchronized access at MapTask.java:[line 1496]</Message></SourceLine><SourceLine role='SOURCE_LINE_UNSYNC_ACCESS' endBytecode='48' classname='org.apache.hadoop.mapred.MapTask$MapOutputBuffer$Buffer' start='1390' end='1390' sourcepath='org/apache/hadoop/mapred/MapTask.java' sourcefile='MapTask.java' startBytecode='48'><Message>Unsynchronized access at MapTask.java:[line 1390]</Message></SourceLine><SourceLine role='SOURCE_LINE_UNSYNC_ACCESS' endBytecode='264' classname='org.apache.hadoop.mapred.MapTask$MapOutputBuffer$Buffer' start='1423' end='1423' sourcepath='org/apache/hadoop/mapred/MapTask.java' sourcefile='MapTask.java' startBytecode='264'><Message>Unsynchronized access at MapTask.java:[line 1423]</Message></SourceLine><SourceLine role='SOURCE_LINE_UNSYNC_ACCESS' endBytecode='376' classname='org.apache.hadoop.mapred.MapTask$MapOutputBuffer$Buffer' start='1437' end='1437' sourcepath='org/apache/hadoop/mapred/MapTask.java' sourcefile='MapTask.java' startBytecode='376'><Message>Unsynchronized access at MapTask.java:[line 1437]</Message></SourceLine><SourceLine role='SOURCE_LINE_UNSYNC_ACCESS' endBytecode='35' classname='org.apache.hadoop.mapred.MapTask$MapOutputBuffer$BlockingBuffer' start='1339' end='1339' sourcepath='org/apache/hadoop/mapred/MapTask.java' sourcefile='MapTask.java' startBytecode='35'><Message>Unsynchronized access at MapTask.java:[line 1339]</Message></SourceLine><SourceLine role='SOURCE_LINE_SYNC_ACCESS' endBytecode='305' classname='org.apache.hadoop.mapred.MapTask$MapOutputBuffer' start='1007' end='1007' sourcepath='org/apache/hadoop/mapred/MapTask.java' sourcefile='MapTask.java' startBytecode='305'><Message>Synchronized access at MapTask.java:[line 1007]</Message></SourceLine><SourceLine role='SOURCE_LINE_SYNC_ACCESS' endBytecode='23' classname='org.apache.hadoop.mapred.MapTask$MapOutputBuffer' start='1592' end='1592' sourcepath='org/apache/hadoop/mapred/MapTask.java' sourcefile='MapTask.java' startBytecode='23'><Message>Synchronized access at MapTask.java:[line 1592]</Message></SourceLine><SourceLine role='SOURCE_LINE_SYNC_ACCESS' endBytecode='36' classname='org.apache.hadoop.mapred.MapTask$MapOutputBuffer' start='1217' end='1217' sourcepath='org/apache/hadoop/mapred/MapTask.java' sourcefile='MapTask.java' startBytecode='36'><Message>Synchronized access at MapTask.java:[line 1217]</Message></SourceLine><SourceLine role='SOURCE_LINE_SYNC_ACCESS' endBytecode='64' classname='org.apache.hadoop.mapred.MapTask$MapOutputBuffer' start='1219' end='1219' sourcepath='org/apache/hadoop/mapred/MapTask.java' sourcefile='MapTask.java' startBytecode='64'><Message>Synchronized access at MapTask.java:[line 1219]</Message></SourceLine><SourceLine role='SOURCE_LINE_SYNC_ACCESS' endBytecode='76' classname='org.apache.hadoop.mapred.MapTask$MapOutputBuffer' start='1219' end='1219' sourcepath='org/apache/hadoop/mapred/MapTask.java' sourcefile='MapTask.java' startBytecode='76'><Message>Synchronized access at MapTask.java:[line 1219]</Message></SourceLine><SourceLine role='SOURCE_LINE_SYNC_ACCESS' endBytecode='216' classname='org.apache.hadoop.mapred.MapTask$MapOutputBuffer' start='1108' end='1108' sourcepath='org/apache/hadoop/mapred/MapTask.java' sourcefile='MapTask.java' startBytecode='216'><Message>Synchronized access at MapTask.java:[line 1108]</Message></SourceLine><SourceLine role='SOURCE_LINE_SYNC_ACCESS' endBytecode='595' classname='org.apache.hadoop.mapred.MapTask$MapOutputBuffer' start='1189' end='1189' sourcepath='org/apache/hadoop/mapred/MapTask.java' sourcefile='MapTask.java' startBytecode='595'><Message>Synchronized access at MapTask.java:[line 1189]</Message></SourceLine><SourceLine role='SOURCE_LINE_SYNC_ACCESS' endBytecode='327' classname='org.apache.hadoop.mapred.MapTask$MapOutputBuffer' start='1123' end='1123' sourcepath='org/apache/hadoop/mapred/MapTask.java' sourcefile='MapTask.java' startBytecode='327'><Message>Synchronized access at MapTask.java:[line 1123]</Message></SourceLine><SourceLine role='SOURCE_LINE_SYNC_ACCESS' endBytecode='610' classname='org.apache.hadoop.mapred.MapTask$MapOutputBuffer' start='1190' end='1190' sourcepath='org/apache/hadoop/mapred/MapTask.java' sourcefile='MapTask.java' startBytecode='610'><Message>Synchronized access at MapTask.java:[line 1190]</Message></SourceLine><SourceLine role='SOURCE_LINE_SYNC_ACCESS' endBytecode='626' classname='org.apache.hadoop.mapred.MapTask$MapOutputBuffer' start='1191' end='1191' sourcepath='org/apache/hadoop/mapred/MapTask.java' sourcefile='MapTask.java' startBytecode='626'><Message>Synchronized access at MapTask.java:[line 1191]</Message></SourceLine><SourceLine role='SOURCE_LINE_SYNC_ACCESS' endBytecode='642' classname='org.apache.hadoop.mapred.MapTask$MapOutputBuffer' start='1192' end='1192' sourcepath='org/apache/hadoop/mapred/MapTask.java' sourcefile='MapTask.java' startBytecode='642'><Message>Synchronized access at MapTask.java:[line 1192]</Message></SourceLine><SourceLine role='SOURCE_LINE_SYNC_ACCESS' endBytecode='661' classname='org.apache.hadoop.mapred.MapTask$MapOutputBuffer' start='1194' end='1194' sourcepath='org/apache/hadoop/mapred/MapTask.java' sourcefile='MapTask.java' startBytecode='661'><Message>Synchronized access at MapTask.java:[line 1194]</Message></SourceLine><SourceLine role='SOURCE_LINE_SYNC_ACCESS' endBytecode='682' classname='org.apache.hadoop.mapred.MapTask$MapOutputBuffer' start='1194' end='1194' sourcepath='org/apache/hadoop/mapred/MapTask.java' sourcefile='MapTask.java' startBytecode='682'><Message>Synchronized access at MapTask.java:[line 1194]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='befd1ba663f960db7219e920587b8343' cweid='374' rank='18' abbrev='EI2' category='MALICIOUS_CODE' priority='2' type='EI_EXPOSE_REP2' instanceOccurrenceMax='0'><ShortMessage>May expose internal representation by incorporating reference to mutable object</ShortMessage><LongMessage>org.apache.hadoop.mapred.MapTask$MapOutputBuffer$InMemValBytes.reset(byte[], int, int) may expose internal representation by storing an externally mutable object into MapTask$MapOutputBuffer$InMemValBytes.buffer</LongMessage><Class classname='org.apache.hadoop.mapred.MapTask$MapOutputBuffer$InMemValBytes' primary='true'><SourceLine classname='org.apache.hadoop.mapred.MapTask$MapOutputBuffer$InMemValBytes' start='1794' end='1813' sourcepath='org/apache/hadoop/mapred/MapTask.java' sourcefile='MapTask.java'><Message>At MapTask.java:[lines 1794-1813]</Message></SourceLine><Message>In class org.apache.hadoop.mapred.MapTask$MapOutputBuffer$InMemValBytes</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapred.MapTask$MapOutputBuffer$InMemValBytes' signature='([BII)V' name='reset' primary='true'><SourceLine endBytecode='248' classname='org.apache.hadoop.mapred.MapTask$MapOutputBuffer$InMemValBytes' start='1800' end='1813' sourcepath='org/apache/hadoop/mapred/MapTask.java' sourcefile='MapTask.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapred.MapTask$MapOutputBuffer$InMemValBytes.reset(byte[], int, int)</Message></Method><Field isStatic='false' classname='org.apache.hadoop.mapred.MapTask$MapOutputBuffer$InMemValBytes' signature='[B' name='buffer' primary='true'><SourceLine classname='org.apache.hadoop.mapred.MapTask$MapOutputBuffer$InMemValBytes' sourcepath='org/apache/hadoop/mapred/MapTask.java' sourcefile='MapTask.java'><Message>In MapTask.java</Message></SourceLine><Message>Field org.apache.hadoop.mapred.MapTask$MapOutputBuffer$InMemValBytes.buffer</Message></Field><LocalVariable role='LOCAL_VARIABLE_NAMED' pc='2' name='buffer' register='1'><Message>Local variable named buffer</Message></LocalVariable><SourceLine endBytecode='2' classname='org.apache.hadoop.mapred.MapTask$MapOutputBuffer$InMemValBytes' start='1800' end='1800' sourcepath='org/apache/hadoop/mapred/MapTask.java' sourcefile='MapTask.java' startBytecode='2' primary='true'><Message>At MapTask.java:[line 1800]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='2fc12551cc15a9d0777d59d75f307109' rank='20' abbrev='SIC' category='PERFORMANCE' priority='3' type='SIC_INNER_SHOULD_BE_STATIC_NEEDS_THIS' instanceOccurrenceMax='0'><ShortMessage>Could be refactored into a static inner class</ShortMessage><LongMessage>The class org.apache.hadoop.mapred.MapTask$NewDirectOutputCollector could be refactored into a _static_ inner class</LongMessage><Class classname='org.apache.hadoop.mapred.MapTask$NewDirectOutputCollector' primary='true'><SourceLine classname='org.apache.hadoop.mapred.MapTask$NewDirectOutputCollector' start='644' end='694' sourcepath='org/apache/hadoop/mapred/MapTask.java' sourcefile='MapTask.java'><Message>At MapTask.java:[lines 644-694]</Message></SourceLine><Message>In class org.apache.hadoop.mapred.MapTask$NewDirectOutputCollector</Message></Class><SourceLine synthetic='true' classname='org.apache.hadoop.mapred.MapTask$NewDirectOutputCollector' start='644' end='694' sourcepath='org/apache/hadoop/mapred/MapTask.java' sourcefile='MapTask.java'><Message>At MapTask.java:[lines 644-694]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='a2f3aebfd49adc6d0707c8c4cce4547' rank='20' abbrev='SIC' category='PERFORMANCE' priority='3' type='SIC_INNER_SHOULD_BE_STATIC_NEEDS_THIS' instanceOccurrenceMax='0'><ShortMessage>Could be refactored into a static inner class</ShortMessage><LongMessage>The class org.apache.hadoop.mapred.MapTask$NewOutputCollector could be refactored into a _static_ inner class</LongMessage><Class classname='org.apache.hadoop.mapred.MapTask$NewOutputCollector' primary='true'><SourceLine classname='org.apache.hadoop.mapred.MapTask$NewOutputCollector' start='698' end='740' sourcepath='org/apache/hadoop/mapred/MapTask.java' sourcefile='MapTask.java'><Message>At MapTask.java:[lines 698-740]</Message></SourceLine><Message>In class org.apache.hadoop.mapred.MapTask$NewOutputCollector</Message></Class><SourceLine synthetic='true' classname='org.apache.hadoop.mapred.MapTask$NewOutputCollector' start='698' end='740' sourcepath='org/apache/hadoop/mapred/MapTask.java' sourcefile='MapTask.java'><Message>At MapTask.java:[lines 698-740]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='4763dfc5cc7108e4f992d831709d8c83' cweid='374' rank='18' abbrev='EI' category='MALICIOUS_CODE' priority='2' type='EI_EXPOSE_REP' instanceOccurrenceMax='0'><ShortMessage>May expose internal representation by returning reference to mutable object</ShortMessage><LongMessage>org.apache.hadoop.mapred.MapTaskCompletionEventsUpdate.getMapTaskCompletionEvents() may expose internal representation by returning MapTaskCompletionEventsUpdate.events</LongMessage><Class classname='org.apache.hadoop.mapred.MapTaskCompletionEventsUpdate' primary='true'><SourceLine classname='org.apache.hadoop.mapred.MapTaskCompletionEventsUpdate' start='39' end='70' sourcepath='org/apache/hadoop/mapred/MapTaskCompletionEventsUpdate.java' sourcefile='MapTaskCompletionEventsUpdate.java'><Message>At MapTaskCompletionEventsUpdate.java:[lines 39-70]</Message></SourceLine><Message>In class org.apache.hadoop.mapred.MapTaskCompletionEventsUpdate</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapred.MapTaskCompletionEventsUpdate' signature='()[Lorg/apache/hadoop/mapred/TaskCompletionEvent;' name='getMapTaskCompletionEvents' primary='true'><SourceLine endBytecode='46' classname='org.apache.hadoop.mapred.MapTaskCompletionEventsUpdate' start='52' end='52' sourcepath='org/apache/hadoop/mapred/MapTaskCompletionEventsUpdate.java' sourcefile='MapTaskCompletionEventsUpdate.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapred.MapTaskCompletionEventsUpdate.getMapTaskCompletionEvents()</Message></Method><Field isStatic='false' classname='org.apache.hadoop.mapred.MapTaskCompletionEventsUpdate' signature='[Lorg/apache/hadoop/mapred/TaskCompletionEvent;' name='events' primary='true'><SourceLine classname='org.apache.hadoop.mapred.MapTaskCompletionEventsUpdate' sourcepath='org/apache/hadoop/mapred/MapTaskCompletionEventsUpdate.java' sourcefile='MapTaskCompletionEventsUpdate.java'><Message>In MapTaskCompletionEventsUpdate.java</Message></SourceLine><Message>Field org.apache.hadoop.mapred.MapTaskCompletionEventsUpdate.events</Message></Field><SourceLine endBytecode='4' classname='org.apache.hadoop.mapred.MapTaskCompletionEventsUpdate' start='52' end='52' sourcepath='org/apache/hadoop/mapred/MapTaskCompletionEventsUpdate.java' sourcefile='MapTaskCompletionEventsUpdate.java' startBytecode='4' primary='true'><Message>At MapTaskCompletionEventsUpdate.java:[line 52]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='257a84ceb6fefc232a758fafd6171488' cweid='374' rank='18' abbrev='EI2' category='MALICIOUS_CODE' priority='2' type='EI_EXPOSE_REP2' instanceOccurrenceMax='0'><ShortMessage>May expose internal representation by incorporating reference to mutable object</ShortMessage><LongMessage>new org.apache.hadoop.mapred.MapTaskCompletionEventsUpdate(TaskCompletionEvent[], boolean) may expose internal representation by storing an externally mutable object into MapTaskCompletionEventsUpdate.events</LongMessage><Class classname='org.apache.hadoop.mapred.MapTaskCompletionEventsUpdate' primary='true'><SourceLine classname='org.apache.hadoop.mapred.MapTaskCompletionEventsUpdate' start='39' end='70' sourcepath='org/apache/hadoop/mapred/MapTaskCompletionEventsUpdate.java' sourcefile='MapTaskCompletionEventsUpdate.java'><Message>At MapTaskCompletionEventsUpdate.java:[lines 39-70]</Message></SourceLine><Message>In class org.apache.hadoop.mapred.MapTaskCompletionEventsUpdate</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapred.MapTaskCompletionEventsUpdate' signature='([Lorg/apache/hadoop/mapred/TaskCompletionEvent;Z)V' name='&lt;init&gt;' primary='true'><SourceLine endBytecode='88' classname='org.apache.hadoop.mapred.MapTaskCompletionEventsUpdate' start='42' end='45' sourcepath='org/apache/hadoop/mapred/MapTaskCompletionEventsUpdate.java' sourcefile='MapTaskCompletionEventsUpdate.java' startBytecode='0'></SourceLine><Message>In method new org.apache.hadoop.mapred.MapTaskCompletionEventsUpdate(TaskCompletionEvent[], boolean)</Message></Method><Field isStatic='false' classname='org.apache.hadoop.mapred.MapTaskCompletionEventsUpdate' signature='[Lorg/apache/hadoop/mapred/TaskCompletionEvent;' name='events' primary='true'><SourceLine classname='org.apache.hadoop.mapred.MapTaskCompletionEventsUpdate' sourcepath='org/apache/hadoop/mapred/MapTaskCompletionEventsUpdate.java' sourcefile='MapTaskCompletionEventsUpdate.java'><Message>In MapTaskCompletionEventsUpdate.java</Message></SourceLine><Message>Field org.apache.hadoop.mapred.MapTaskCompletionEventsUpdate.events</Message></Field><LocalVariable role='LOCAL_VARIABLE_NAMED' pc='6' name='events' register='1'><Message>Local variable named events</Message></LocalVariable><SourceLine endBytecode='6' classname='org.apache.hadoop.mapred.MapTaskCompletionEventsUpdate' start='43' end='43' sourcepath='org/apache/hadoop/mapred/MapTaskCompletionEventsUpdate.java' sourcefile='MapTaskCompletionEventsUpdate.java' startBytecode='6' primary='true'><Message>At MapTaskCompletionEventsUpdate.java:[line 43]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='9bfe29e88ff662805ee2b6ceb19019de' rank='19' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_COMPARATOR_SHOULD_BE_SERIALIZABLE' instanceOccurrenceMax='0'><ShortMessage>Comparator doesn't implement Serializable</ShortMessage><LongMessage>org.apache.hadoop.mapred.MergeSorter implements Comparator but not Serializable</LongMessage><Class classname='org.apache.hadoop.mapred.MergeSorter' primary='true'><SourceLine classname='org.apache.hadoop.mapred.MergeSorter' start='35' end='77' sourcepath='org/apache/hadoop/mapred/MergeSorter.java' sourcefile='MergeSorter.java'><Message>At MergeSorter.java:[lines 35-77]</Message></SourceLine><Message>In class org.apache.hadoop.mapred.MergeSorter</Message></Class><SourceLine synthetic='true' classname='org.apache.hadoop.mapred.MergeSorter' start='35' end='77' sourcepath='org/apache/hadoop/mapred/MergeSorter.java' sourcefile='MergeSorter.java'><Message>At MergeSorter.java:[lines 35-77]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='a521109ae5bc85c59235f0048ebedf33' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from org.apache.hadoop.mapreduce.JobContext to org.apache.hadoop.mapred.JobContext in org.apache.hadoop.mapred.OutputCommitter.abortJob(JobContext, JobStatus$State)</LongMessage><Class classname='org.apache.hadoop.mapred.OutputCommitter' primary='true'><SourceLine classname='org.apache.hadoop.mapred.OutputCommitter' start='70' end='378' sourcepath='org/apache/hadoop/mapred/OutputCommitter.java' sourcefile='OutputCommitter.java'><Message>At OutputCommitter.java:[lines 70-378]</Message></SourceLine><Message>In class org.apache.hadoop.mapred.OutputCommitter</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapred.OutputCommitter' signature='(Lorg/apache/hadoop/mapreduce/JobContext;Lorg/apache/hadoop/mapreduce/JobStatus$State;)V' name='abortJob' primary='true'><SourceLine endBytecode='27' classname='org.apache.hadoop.mapred.OutputCommitter' start='303' end='308' sourcepath='org/apache/hadoop/mapred/OutputCommitter.java' sourcefile='OutputCommitter.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapred.OutputCommitter.abortJob(JobContext, JobStatus$State)</Message></Method><Type role='TYPE_FOUND' descriptor='Lorg/apache/hadoop/mapreduce/JobContext;'><SourceLine classname='org.apache.hadoop.mapreduce.JobContext' sourcepath='org/apache/hadoop/mapreduce/JobContext.java' sourcefile='JobContext.java'><Message>In JobContext.java</Message></SourceLine><Message>Actual type org.apache.hadoop.mapreduce.JobContext</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/mapred/JobContext;'><SourceLine classname='org.apache.hadoop.mapred.JobContext' sourcepath='org/apache/hadoop/mapred/JobContext.java' sourcefile='JobContext.java'><Message>In JobContext.java</Message></SourceLine><Message>Expected org.apache.hadoop.mapred.JobContext</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='50' name='context' register='1'><Message>Value loaded from context</Message></LocalVariable><SourceLine endBytecode='51' classname='org.apache.hadoop.mapred.OutputCommitter' start='307' end='307' sourcepath='org/apache/hadoop/mapred/OutputCommitter.java' sourcefile='OutputCommitter.java' startBytecode='51' primary='true'><Message>At OutputCommitter.java:[line 307]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='e1c2239217d1cdf76a8bb1533be850de' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from org.apache.hadoop.mapreduce.TaskAttemptContext to org.apache.hadoop.mapred.TaskAttemptContext in org.apache.hadoop.mapred.OutputCommitter.abortTask(TaskAttemptContext)</LongMessage><Class classname='org.apache.hadoop.mapred.OutputCommitter' primary='true'><SourceLine classname='org.apache.hadoop.mapred.OutputCommitter' start='70' end='378' sourcepath='org/apache/hadoop/mapred/OutputCommitter.java' sourcefile='OutputCommitter.java'><Message>At OutputCommitter.java:[lines 70-378]</Message></SourceLine><Message>In class org.apache.hadoop.mapred.OutputCommitter</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapred.OutputCommitter' signature='(Lorg/apache/hadoop/mapreduce/TaskAttemptContext;)V' name='abortTask' primary='true'><SourceLine endBytecode='4' classname='org.apache.hadoop.mapred.OutputCommitter' start='355' end='356' sourcepath='org/apache/hadoop/mapred/OutputCommitter.java' sourcefile='OutputCommitter.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapred.OutputCommitter.abortTask(TaskAttemptContext)</Message></Method><Type role='TYPE_FOUND' descriptor='Lorg/apache/hadoop/mapreduce/TaskAttemptContext;'><SourceLine classname='org.apache.hadoop.mapreduce.TaskAttemptContext' sourcepath='org/apache/hadoop/mapreduce/TaskAttemptContext.java' sourcefile='TaskAttemptContext.java'><Message>In TaskAttemptContext.java</Message></SourceLine><Message>Actual type org.apache.hadoop.mapreduce.TaskAttemptContext</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/mapred/TaskAttemptContext;'><SourceLine classname='org.apache.hadoop.mapred.TaskAttemptContext' start='25' end='25' sourcepath='org/apache/hadoop/mapred/TaskAttemptContext.java' sourcefile='TaskAttemptContext.java'><Message>At TaskAttemptContext.java:[line 25]</Message></SourceLine><Message>Expected org.apache.hadoop.mapred.TaskAttemptContext</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='1' name='taskContext' register='1'><Message>Value loaded from taskContext</Message></LocalVariable><SourceLine endBytecode='2' classname='org.apache.hadoop.mapred.OutputCommitter' start='355' end='355' sourcepath='org/apache/hadoop/mapred/OutputCommitter.java' sourcefile='OutputCommitter.java' startBytecode='2' primary='true'><Message>At OutputCommitter.java:[line 355]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='aacf73da79bd7b2baca59328363d0778' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from org.apache.hadoop.mapreduce.JobContext to org.apache.hadoop.mapred.JobContext in org.apache.hadoop.mapred.OutputCommitter.cleanupJob(JobContext)</LongMessage><Class classname='org.apache.hadoop.mapred.OutputCommitter' primary='true'><SourceLine classname='org.apache.hadoop.mapred.OutputCommitter' start='70' end='378' sourcepath='org/apache/hadoop/mapred/OutputCommitter.java' sourcefile='OutputCommitter.java'><Message>At OutputCommitter.java:[lines 70-378]</Message></SourceLine><Message>In class org.apache.hadoop.mapred.OutputCommitter</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapred.OutputCommitter' signature='(Lorg/apache/hadoop/mapreduce/JobContext;)V' name='cleanupJob' primary='true'><SourceLine endBytecode='4' classname='org.apache.hadoop.mapred.OutputCommitter' start='280' end='281' sourcepath='org/apache/hadoop/mapred/OutputCommitter.java' sourcefile='OutputCommitter.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapred.OutputCommitter.cleanupJob(JobContext)</Message></Method><Type role='TYPE_FOUND' descriptor='Lorg/apache/hadoop/mapreduce/JobContext;'><SourceLine classname='org.apache.hadoop.mapreduce.JobContext' sourcepath='org/apache/hadoop/mapreduce/JobContext.java' sourcefile='JobContext.java'><Message>In JobContext.java</Message></SourceLine><Message>Actual type org.apache.hadoop.mapreduce.JobContext</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/mapred/JobContext;'><SourceLine classname='org.apache.hadoop.mapred.JobContext' sourcepath='org/apache/hadoop/mapred/JobContext.java' sourcefile='JobContext.java'><Message>In JobContext.java</Message></SourceLine><Message>Expected org.apache.hadoop.mapred.JobContext</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='1' name='context' register='1'><Message>Value loaded from context</Message></LocalVariable><SourceLine endBytecode='2' classname='org.apache.hadoop.mapred.OutputCommitter' start='280' end='280' sourcepath='org/apache/hadoop/mapred/OutputCommitter.java' sourcefile='OutputCommitter.java' startBytecode='2' primary='true'><Message>At OutputCommitter.java:[line 280]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='b7e4762e06da488dce5a83f5571a2d28' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from org.apache.hadoop.mapreduce.JobContext to org.apache.hadoop.mapred.JobContext in org.apache.hadoop.mapred.OutputCommitter.commitJob(JobContext)</LongMessage><Class classname='org.apache.hadoop.mapred.OutputCommitter' primary='true'><SourceLine classname='org.apache.hadoop.mapred.OutputCommitter' start='70' end='378' sourcepath='org/apache/hadoop/mapred/OutputCommitter.java' sourcefile='OutputCommitter.java'><Message>At OutputCommitter.java:[lines 70-378]</Message></SourceLine><Message>In class org.apache.hadoop.mapred.OutputCommitter</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapred.OutputCommitter' signature='(Lorg/apache/hadoop/mapreduce/JobContext;)V' name='commitJob' primary='true'><SourceLine endBytecode='4' classname='org.apache.hadoop.mapred.OutputCommitter' start='291' end='292' sourcepath='org/apache/hadoop/mapred/OutputCommitter.java' sourcefile='OutputCommitter.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapred.OutputCommitter.commitJob(JobContext)</Message></Method><Type role='TYPE_FOUND' descriptor='Lorg/apache/hadoop/mapreduce/JobContext;'><SourceLine classname='org.apache.hadoop.mapreduce.JobContext' sourcepath='org/apache/hadoop/mapreduce/JobContext.java' sourcefile='JobContext.java'><Message>In JobContext.java</Message></SourceLine><Message>Actual type org.apache.hadoop.mapreduce.JobContext</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/mapred/JobContext;'><SourceLine classname='org.apache.hadoop.mapred.JobContext' sourcepath='org/apache/hadoop/mapred/JobContext.java' sourcefile='JobContext.java'><Message>In JobContext.java</Message></SourceLine><Message>Expected org.apache.hadoop.mapred.JobContext</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='1' name='context' register='1'><Message>Value loaded from context</Message></LocalVariable><SourceLine endBytecode='2' classname='org.apache.hadoop.mapred.OutputCommitter' start='291' end='291' sourcepath='org/apache/hadoop/mapred/OutputCommitter.java' sourcefile='OutputCommitter.java' startBytecode='2' primary='true'><Message>At OutputCommitter.java:[line 291]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='9dcdac2ea7f7af2fe0b8c42c04ace0e6' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from org.apache.hadoop.mapreduce.TaskAttemptContext to org.apache.hadoop.mapred.TaskAttemptContext in org.apache.hadoop.mapred.OutputCommitter.commitTask(TaskAttemptContext)</LongMessage><Class classname='org.apache.hadoop.mapred.OutputCommitter' primary='true'><SourceLine classname='org.apache.hadoop.mapred.OutputCommitter' start='70' end='378' sourcepath='org/apache/hadoop/mapred/OutputCommitter.java' sourcefile='OutputCommitter.java'><Message>At OutputCommitter.java:[lines 70-378]</Message></SourceLine><Message>In class org.apache.hadoop.mapred.OutputCommitter</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapred.OutputCommitter' signature='(Lorg/apache/hadoop/mapreduce/TaskAttemptContext;)V' name='commitTask' primary='true'><SourceLine endBytecode='4' classname='org.apache.hadoop.mapred.OutputCommitter' start='343' end='344' sourcepath='org/apache/hadoop/mapred/OutputCommitter.java' sourcefile='OutputCommitter.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapred.OutputCommitter.commitTask(TaskAttemptContext)</Message></Method><Type role='TYPE_FOUND' descriptor='Lorg/apache/hadoop/mapreduce/TaskAttemptContext;'><SourceLine classname='org.apache.hadoop.mapreduce.TaskAttemptContext' sourcepath='org/apache/hadoop/mapreduce/TaskAttemptContext.java' sourcefile='TaskAttemptContext.java'><Message>In TaskAttemptContext.java</Message></SourceLine><Message>Actual type org.apache.hadoop.mapreduce.TaskAttemptContext</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/mapred/TaskAttemptContext;'><SourceLine classname='org.apache.hadoop.mapred.TaskAttemptContext' start='25' end='25' sourcepath='org/apache/hadoop/mapred/TaskAttemptContext.java' sourcefile='TaskAttemptContext.java'><Message>At TaskAttemptContext.java:[line 25]</Message></SourceLine><Message>Expected org.apache.hadoop.mapred.TaskAttemptContext</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='1' name='taskContext' register='1'><Message>Value loaded from taskContext</Message></LocalVariable><SourceLine endBytecode='2' classname='org.apache.hadoop.mapred.OutputCommitter' start='343' end='343' sourcepath='org/apache/hadoop/mapred/OutputCommitter.java' sourcefile='OutputCommitter.java' startBytecode='2' primary='true'><Message>At OutputCommitter.java:[line 343]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='2ed240d105ad1f355e5e4f9e697df713' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from org.apache.hadoop.mapreduce.JobContext to org.apache.hadoop.mapred.JobContext in org.apache.hadoop.mapred.OutputCommitter.isCommitJobRepeatable(JobContext)</LongMessage><Class classname='org.apache.hadoop.mapred.OutputCommitter' primary='true'><SourceLine classname='org.apache.hadoop.mapred.OutputCommitter' start='70' end='378' sourcepath='org/apache/hadoop/mapred/OutputCommitter.java' sourcefile='OutputCommitter.java'><Message>At OutputCommitter.java:[lines 70-378]</Message></SourceLine><Message>In class org.apache.hadoop.mapred.OutputCommitter</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapred.OutputCommitter' signature='(Lorg/apache/hadoop/mapreduce/JobContext;)Z' name='isCommitJobRepeatable' primary='true'><SourceLine endBytecode='4' classname='org.apache.hadoop.mapred.OutputCommitter' start='236' end='236' sourcepath='org/apache/hadoop/mapred/OutputCommitter.java' sourcefile='OutputCommitter.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapred.OutputCommitter.isCommitJobRepeatable(JobContext)</Message></Method><Type role='TYPE_FOUND' descriptor='Lorg/apache/hadoop/mapreduce/JobContext;'><SourceLine classname='org.apache.hadoop.mapreduce.JobContext' sourcepath='org/apache/hadoop/mapreduce/JobContext.java' sourcefile='JobContext.java'><Message>In JobContext.java</Message></SourceLine><Message>Actual type org.apache.hadoop.mapreduce.JobContext</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/mapred/JobContext;'><SourceLine classname='org.apache.hadoop.mapred.JobContext' sourcepath='org/apache/hadoop/mapred/JobContext.java' sourcefile='JobContext.java'><Message>In JobContext.java</Message></SourceLine><Message>Expected org.apache.hadoop.mapred.JobContext</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='1' name='jobContext' register='1'><Message>Value loaded from jobContext</Message></LocalVariable><SourceLine endBytecode='2' classname='org.apache.hadoop.mapred.OutputCommitter' start='236' end='236' sourcepath='org/apache/hadoop/mapred/OutputCommitter.java' sourcefile='OutputCommitter.java' startBytecode='2' primary='true'><Message>At OutputCommitter.java:[line 236]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='9d4aac2e85e93d44303893a9d8a5fc13' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from org.apache.hadoop.mapreduce.JobContext to org.apache.hadoop.mapred.JobContext in org.apache.hadoop.mapred.OutputCommitter.isRecoverySupported(JobContext)</LongMessage><Class classname='org.apache.hadoop.mapred.OutputCommitter' primary='true'><SourceLine classname='org.apache.hadoop.mapred.OutputCommitter' start='70' end='378' sourcepath='org/apache/hadoop/mapred/OutputCommitter.java' sourcefile='OutputCommitter.java'><Message>At OutputCommitter.java:[lines 70-378]</Message></SourceLine><Message>In class org.apache.hadoop.mapred.OutputCommitter</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapred.OutputCommitter' signature='(Lorg/apache/hadoop/mapreduce/JobContext;)Z' name='isRecoverySupported' primary='true'><SourceLine endBytecode='4' classname='org.apache.hadoop.mapred.OutputCommitter' start='378' end='378' sourcepath='org/apache/hadoop/mapred/OutputCommitter.java' sourcefile='OutputCommitter.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapred.OutputCommitter.isRecoverySupported(JobContext)</Message></Method><Type role='TYPE_FOUND' descriptor='Lorg/apache/hadoop/mapreduce/JobContext;'><SourceLine classname='org.apache.hadoop.mapreduce.JobContext' sourcepath='org/apache/hadoop/mapreduce/JobContext.java' sourcefile='JobContext.java'><Message>In JobContext.java</Message></SourceLine><Message>Actual type org.apache.hadoop.mapreduce.JobContext</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/mapred/JobContext;'><SourceLine classname='org.apache.hadoop.mapred.JobContext' sourcepath='org/apache/hadoop/mapred/JobContext.java' sourcefile='JobContext.java'><Message>In JobContext.java</Message></SourceLine><Message>Expected org.apache.hadoop.mapred.JobContext</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='1' name='context' register='1'><Message>Value loaded from context</Message></LocalVariable><SourceLine endBytecode='2' classname='org.apache.hadoop.mapred.OutputCommitter' start='378' end='378' sourcepath='org/apache/hadoop/mapred/OutputCommitter.java' sourcefile='OutputCommitter.java' startBytecode='2' primary='true'><Message>At OutputCommitter.java:[line 378]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='77dc3cadfb0f53c6084784f45001e375' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from org.apache.hadoop.mapreduce.TaskAttemptContext to org.apache.hadoop.mapred.TaskAttemptContext in org.apache.hadoop.mapred.OutputCommitter.needsTaskCommit(TaskAttemptContext)</LongMessage><Class classname='org.apache.hadoop.mapred.OutputCommitter' primary='true'><SourceLine classname='org.apache.hadoop.mapred.OutputCommitter' start='70' end='378' sourcepath='org/apache/hadoop/mapred/OutputCommitter.java' sourcefile='OutputCommitter.java'><Message>At OutputCommitter.java:[lines 70-378]</Message></SourceLine><Message>In class org.apache.hadoop.mapred.OutputCommitter</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapred.OutputCommitter' signature='(Lorg/apache/hadoop/mapreduce/TaskAttemptContext;)Z' name='needsTaskCommit' primary='true'><SourceLine endBytecode='4' classname='org.apache.hadoop.mapred.OutputCommitter' start='331' end='331' sourcepath='org/apache/hadoop/mapred/OutputCommitter.java' sourcefile='OutputCommitter.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapred.OutputCommitter.needsTaskCommit(TaskAttemptContext)</Message></Method><Type role='TYPE_FOUND' descriptor='Lorg/apache/hadoop/mapreduce/TaskAttemptContext;'><SourceLine classname='org.apache.hadoop.mapreduce.TaskAttemptContext' sourcepath='org/apache/hadoop/mapreduce/TaskAttemptContext.java' sourcefile='TaskAttemptContext.java'><Message>In TaskAttemptContext.java</Message></SourceLine><Message>Actual type org.apache.hadoop.mapreduce.TaskAttemptContext</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/mapred/TaskAttemptContext;'><SourceLine classname='org.apache.hadoop.mapred.TaskAttemptContext' start='25' end='25' sourcepath='org/apache/hadoop/mapred/TaskAttemptContext.java' sourcefile='TaskAttemptContext.java'><Message>At TaskAttemptContext.java:[line 25]</Message></SourceLine><Message>Expected org.apache.hadoop.mapred.TaskAttemptContext</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='1' name='taskContext' register='1'><Message>Value loaded from taskContext</Message></LocalVariable><SourceLine endBytecode='2' classname='org.apache.hadoop.mapred.OutputCommitter' start='331' end='331' sourcepath='org/apache/hadoop/mapred/OutputCommitter.java' sourcefile='OutputCommitter.java' startBytecode='2' primary='true'><Message>At OutputCommitter.java:[line 331]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='91812a8205ba44ccf2b248ab56340080' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from org.apache.hadoop.mapreduce.TaskAttemptContext to org.apache.hadoop.mapred.TaskAttemptContext in org.apache.hadoop.mapred.OutputCommitter.recoverTask(TaskAttemptContext)</LongMessage><Class classname='org.apache.hadoop.mapred.OutputCommitter' primary='true'><SourceLine classname='org.apache.hadoop.mapred.OutputCommitter' start='70' end='378' sourcepath='org/apache/hadoop/mapred/OutputCommitter.java' sourcefile='OutputCommitter.java'><Message>At OutputCommitter.java:[lines 70-378]</Message></SourceLine><Message>In class org.apache.hadoop.mapred.OutputCommitter</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapred.OutputCommitter' signature='(Lorg/apache/hadoop/mapreduce/TaskAttemptContext;)V' name='recoverTask' primary='true'><SourceLine endBytecode='4' classname='org.apache.hadoop.mapred.OutputCommitter' start='367' end='368' sourcepath='org/apache/hadoop/mapred/OutputCommitter.java' sourcefile='OutputCommitter.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapred.OutputCommitter.recoverTask(TaskAttemptContext)</Message></Method><Type role='TYPE_FOUND' descriptor='Lorg/apache/hadoop/mapreduce/TaskAttemptContext;'><SourceLine classname='org.apache.hadoop.mapreduce.TaskAttemptContext' sourcepath='org/apache/hadoop/mapreduce/TaskAttemptContext.java' sourcefile='TaskAttemptContext.java'><Message>In TaskAttemptContext.java</Message></SourceLine><Message>Actual type org.apache.hadoop.mapreduce.TaskAttemptContext</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/mapred/TaskAttemptContext;'><SourceLine classname='org.apache.hadoop.mapred.TaskAttemptContext' start='25' end='25' sourcepath='org/apache/hadoop/mapred/TaskAttemptContext.java' sourcefile='TaskAttemptContext.java'><Message>At TaskAttemptContext.java:[line 25]</Message></SourceLine><Message>Expected org.apache.hadoop.mapred.TaskAttemptContext</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='1' name='taskContext' register='1'><Message>Value loaded from taskContext</Message></LocalVariable><SourceLine endBytecode='2' classname='org.apache.hadoop.mapred.OutputCommitter' start='367' end='367' sourcepath='org/apache/hadoop/mapred/OutputCommitter.java' sourcefile='OutputCommitter.java' startBytecode='2' primary='true'><Message>At OutputCommitter.java:[line 367]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='cf99bae963587f2d97012773ba341d9b' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from org.apache.hadoop.mapreduce.JobContext to org.apache.hadoop.mapred.JobContext in org.apache.hadoop.mapred.OutputCommitter.setupJob(JobContext)</LongMessage><Class classname='org.apache.hadoop.mapred.OutputCommitter' primary='true'><SourceLine classname='org.apache.hadoop.mapred.OutputCommitter' start='70' end='378' sourcepath='org/apache/hadoop/mapred/OutputCommitter.java' sourcefile='OutputCommitter.java'><Message>At OutputCommitter.java:[lines 70-378]</Message></SourceLine><Message>In class org.apache.hadoop.mapred.OutputCommitter</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapred.OutputCommitter' signature='(Lorg/apache/hadoop/mapreduce/JobContext;)V' name='setupJob' primary='true'><SourceLine endBytecode='4' classname='org.apache.hadoop.mapred.OutputCommitter' start='265' end='266' sourcepath='org/apache/hadoop/mapred/OutputCommitter.java' sourcefile='OutputCommitter.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapred.OutputCommitter.setupJob(JobContext)</Message></Method><Type role='TYPE_FOUND' descriptor='Lorg/apache/hadoop/mapreduce/JobContext;'><SourceLine classname='org.apache.hadoop.mapreduce.JobContext' sourcepath='org/apache/hadoop/mapreduce/JobContext.java' sourcefile='JobContext.java'><Message>In JobContext.java</Message></SourceLine><Message>Actual type org.apache.hadoop.mapreduce.JobContext</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/mapred/JobContext;'><SourceLine classname='org.apache.hadoop.mapred.JobContext' sourcepath='org/apache/hadoop/mapred/JobContext.java' sourcefile='JobContext.java'><Message>In JobContext.java</Message></SourceLine><Message>Expected org.apache.hadoop.mapred.JobContext</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='1' name='jobContext' register='1'><Message>Value loaded from jobContext</Message></LocalVariable><SourceLine endBytecode='2' classname='org.apache.hadoop.mapred.OutputCommitter' start='265' end='265' sourcepath='org/apache/hadoop/mapred/OutputCommitter.java' sourcefile='OutputCommitter.java' startBytecode='2' primary='true'><Message>At OutputCommitter.java:[line 265]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='90c16a93f6fda84f7a4fee62e0207ae4' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from org.apache.hadoop.mapreduce.TaskAttemptContext to org.apache.hadoop.mapred.TaskAttemptContext in org.apache.hadoop.mapred.OutputCommitter.setupTask(TaskAttemptContext)</LongMessage><Class classname='org.apache.hadoop.mapred.OutputCommitter' primary='true'><SourceLine classname='org.apache.hadoop.mapred.OutputCommitter' start='70' end='378' sourcepath='org/apache/hadoop/mapred/OutputCommitter.java' sourcefile='OutputCommitter.java'><Message>At OutputCommitter.java:[lines 70-378]</Message></SourceLine><Message>In class org.apache.hadoop.mapred.OutputCommitter</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapred.OutputCommitter' signature='(Lorg/apache/hadoop/mapreduce/TaskAttemptContext;)V' name='setupTask' primary='true'><SourceLine endBytecode='4' classname='org.apache.hadoop.mapred.OutputCommitter' start='319' end='320' sourcepath='org/apache/hadoop/mapred/OutputCommitter.java' sourcefile='OutputCommitter.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapred.OutputCommitter.setupTask(TaskAttemptContext)</Message></Method><Type role='TYPE_FOUND' descriptor='Lorg/apache/hadoop/mapreduce/TaskAttemptContext;'><SourceLine classname='org.apache.hadoop.mapreduce.TaskAttemptContext' sourcepath='org/apache/hadoop/mapreduce/TaskAttemptContext.java' sourcefile='TaskAttemptContext.java'><Message>In TaskAttemptContext.java</Message></SourceLine><Message>Actual type org.apache.hadoop.mapreduce.TaskAttemptContext</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/mapred/TaskAttemptContext;'><SourceLine classname='org.apache.hadoop.mapred.TaskAttemptContext' start='25' end='25' sourcepath='org/apache/hadoop/mapred/TaskAttemptContext.java' sourcefile='TaskAttemptContext.java'><Message>At TaskAttemptContext.java:[line 25]</Message></SourceLine><Message>Expected org.apache.hadoop.mapred.TaskAttemptContext</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='1' name='taskContext' register='1'><Message>Value loaded from taskContext</Message></LocalVariable><SourceLine endBytecode='2' classname='org.apache.hadoop.mapred.OutputCommitter' start='319' end='319' sourcepath='org/apache/hadoop/mapred/OutputCommitter.java' sourcefile='OutputCommitter.java' startBytecode='2' primary='true'><Message>At OutputCommitter.java:[line 319]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='5de90f0fa004ddfa2a221090c16f1b5f' rank='14' abbrev='Nm' category='BAD_PRACTICE' priority='1' type='NM_SAME_SIMPLE_NAME_AS_SUPERCLASS' instanceOccurrenceMax='0'><ShortMessage>Class names shouldn't shadow simple name of superclass</ShortMessage><LongMessage>The class name org.apache.hadoop.mapred.OutputCommitter shadows the simple name of the superclass org.apache.hadoop.mapreduce.OutputCommitter</LongMessage><Class classname='org.apache.hadoop.mapred.OutputCommitter' primary='true'><SourceLine classname='org.apache.hadoop.mapred.OutputCommitter' start='70' end='378' sourcepath='org/apache/hadoop/mapred/OutputCommitter.java' sourcefile='OutputCommitter.java'><Message>At OutputCommitter.java:[lines 70-378]</Message></SourceLine><Message>In class org.apache.hadoop.mapred.OutputCommitter</Message></Class><Class classname='org.apache.hadoop.mapreduce.OutputCommitter'><SourceLine classname='org.apache.hadoop.mapreduce.OutputCommitter' start='69' end='254' sourcepath='org/apache/hadoop/mapreduce/OutputCommitter.java' sourcefile='OutputCommitter.java'><Message>At OutputCommitter.java:[lines 69-254]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.OutputCommitter</Message></Class><SourceLine synthetic='true' classname='org.apache.hadoop.mapred.OutputCommitter' start='70' end='378' sourcepath='org/apache/hadoop/mapred/OutputCommitter.java' sourcefile='OutputCommitter.java'><Message>At OutputCommitter.java:[lines 70-378]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='117119e654f00f4f2c4856f1149c82cd' rank='16' abbrev='Nm' category='BAD_PRACTICE' priority='2' type='NM_WRONG_PACKAGE_INTENTIONAL' instanceOccurrenceMax='0'><ShortMessage>Method doesn't override method in superclass due to wrong package for parameter</ShortMessage><LongMessage>org.apache.hadoop.mapred.OutputCommitter.commitJob(JobContext) doesn't override method in superclass because parameter type org.apache.hadoop.mapred.JobContext doesn't match superclass parameter type org.apache.hadoop.mapreduce.JobContext</LongMessage><Class classname='org.apache.hadoop.mapred.OutputCommitter' primary='true'><SourceLine classname='org.apache.hadoop.mapred.OutputCommitter' start='70' end='378' sourcepath='org/apache/hadoop/mapred/OutputCommitter.java' sourcefile='OutputCommitter.java'><Message>At OutputCommitter.java:[lines 70-378]</Message></SourceLine><Message>In class org.apache.hadoop.mapred.OutputCommitter</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapred.OutputCommitter' signature='(Lorg/apache/hadoop/mapred/JobContext;)V' name='commitJob' primary='true'><SourceLine endBytecode='61' classname='org.apache.hadoop.mapred.OutputCommitter' start='106' end='107' sourcepath='org/apache/hadoop/mapred/OutputCommitter.java' sourcefile='OutputCommitter.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapred.OutputCommitter.commitJob(JobContext)</Message></Method><Class role='CLASS_SUPERCLASS' classname='org.apache.hadoop.mapreduce.OutputCommitter'><SourceLine classname='org.apache.hadoop.mapreduce.OutputCommitter' start='69' end='254' sourcepath='org/apache/hadoop/mapreduce/OutputCommitter.java' sourcefile='OutputCommitter.java'><Message>At OutputCommitter.java:[lines 69-254]</Message></SourceLine><Message>superclass is org.apache.hadoop.mapreduce.OutputCommitter</Message></Class><Method isStatic='false' role='METHOD_DID_YOU_MEAN_TO_OVERRIDE' classname='org.apache.hadoop.mapreduce.OutputCommitter' signature='(Lorg/apache/hadoop/mapreduce/JobContext;)V' name='commitJob'><SourceLine endBytecode='61' classname='org.apache.hadoop.mapreduce.OutputCommitter' start='104' end='105' sourcepath='org/apache/hadoop/mapreduce/OutputCommitter.java' sourcefile='OutputCommitter.java' startBytecode='0'></SourceLine><Message>Did you intend to override org.apache.hadoop.mapreduce.OutputCommitter.commitJob(JobContext)</Message></Method><Type role='TYPE_FOUND' descriptor='Lorg/apache/hadoop/mapred/JobContext;'><SourceLine classname='org.apache.hadoop.mapred.JobContext' sourcepath='org/apache/hadoop/mapred/JobContext.java' sourcefile='JobContext.java'><Message>In JobContext.java</Message></SourceLine><Message>Actual type org.apache.hadoop.mapred.JobContext</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/mapreduce/JobContext;'><SourceLine classname='org.apache.hadoop.mapreduce.JobContext' sourcepath='org/apache/hadoop/mapreduce/JobContext.java' sourcefile='JobContext.java'><Message>In JobContext.java</Message></SourceLine><Message>Expected org.apache.hadoop.mapreduce.JobContext</Message></Type><Method isStatic='false' role='METHOD_OVERRIDDEN' classname='org.apache.hadoop.mapred.OutputCommitter' signature='(Lorg/apache/hadoop/mapreduce/JobContext;)V' name='commitJob'><SourceLine endBytecode='64' classname='org.apache.hadoop.mapred.OutputCommitter' start='291' end='292' sourcepath='org/apache/hadoop/mapred/OutputCommitter.java' sourcefile='OutputCommitter.java' startBytecode='0'></SourceLine><Message>Overrides org.apache.hadoop.mapred.OutputCommitter.commitJob(JobContext)</Message></Method><SourceLine synthetic='true' endBytecode='61' classname='org.apache.hadoop.mapred.OutputCommitter' start='106' end='107' sourcepath='org/apache/hadoop/mapred/OutputCommitter.java' sourcefile='OutputCommitter.java' startBytecode='0'><Message>At OutputCommitter.java:[lines 106-107]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='52ef760a6afe642cf821d7ecef285e08' rank='16' abbrev='Nm' category='BAD_PRACTICE' priority='2' type='NM_WRONG_PACKAGE_INTENTIONAL' instanceOccurrenceMax='0'><ShortMessage>Method doesn't override method in superclass due to wrong package for parameter</ShortMessage><LongMessage>org.apache.hadoop.mapred.OutputCommitter.isCommitJobRepeatable(JobContext) doesn't override method in superclass because parameter type org.apache.hadoop.mapred.JobContext doesn't match superclass parameter type org.apache.hadoop.mapreduce.JobContext</LongMessage><Class classname='org.apache.hadoop.mapred.OutputCommitter' primary='true'><SourceLine classname='org.apache.hadoop.mapred.OutputCommitter' start='70' end='378' sourcepath='org/apache/hadoop/mapred/OutputCommitter.java' sourcefile='OutputCommitter.java'><Message>At OutputCommitter.java:[lines 70-378]</Message></SourceLine><Message>In class org.apache.hadoop.mapred.OutputCommitter</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapred.OutputCommitter' signature='(Lorg/apache/hadoop/mapred/JobContext;)Z' name='isCommitJobRepeatable' primary='true'><SourceLine endBytecode='53' classname='org.apache.hadoop.mapred.OutputCommitter' start='230' end='230' sourcepath='org/apache/hadoop/mapred/OutputCommitter.java' sourcefile='OutputCommitter.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapred.OutputCommitter.isCommitJobRepeatable(JobContext)</Message></Method><Class role='CLASS_SUPERCLASS' classname='org.apache.hadoop.mapreduce.OutputCommitter'><SourceLine classname='org.apache.hadoop.mapreduce.OutputCommitter' start='69' end='254' sourcepath='org/apache/hadoop/mapreduce/OutputCommitter.java' sourcefile='OutputCommitter.java'><Message>At OutputCommitter.java:[lines 69-254]</Message></SourceLine><Message>superclass is org.apache.hadoop.mapreduce.OutputCommitter</Message></Class><Method isStatic='false' role='METHOD_DID_YOU_MEAN_TO_OVERRIDE' classname='org.apache.hadoop.mapreduce.OutputCommitter' signature='(Lorg/apache/hadoop/mapreduce/JobContext;)Z' name='isCommitJobRepeatable'><SourceLine endBytecode='53' classname='org.apache.hadoop.mapreduce.OutputCommitter' start='215' end='215' sourcepath='org/apache/hadoop/mapreduce/OutputCommitter.java' sourcefile='OutputCommitter.java' startBytecode='0'></SourceLine><Message>Did you intend to override org.apache.hadoop.mapreduce.OutputCommitter.isCommitJobRepeatable(JobContext)</Message></Method><Type role='TYPE_FOUND' descriptor='Lorg/apache/hadoop/mapred/JobContext;'><SourceLine classname='org.apache.hadoop.mapred.JobContext' sourcepath='org/apache/hadoop/mapred/JobContext.java' sourcefile='JobContext.java'><Message>In JobContext.java</Message></SourceLine><Message>Actual type org.apache.hadoop.mapred.JobContext</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/mapreduce/JobContext;'><SourceLine classname='org.apache.hadoop.mapreduce.JobContext' sourcepath='org/apache/hadoop/mapreduce/JobContext.java' sourcefile='JobContext.java'><Message>In JobContext.java</Message></SourceLine><Message>Expected org.apache.hadoop.mapreduce.JobContext</Message></Type><Method isStatic='false' role='METHOD_OVERRIDDEN' classname='org.apache.hadoop.mapred.OutputCommitter' signature='(Lorg/apache/hadoop/mapreduce/JobContext;)Z' name='isCommitJobRepeatable'><SourceLine endBytecode='60' classname='org.apache.hadoop.mapred.OutputCommitter' start='236' end='236' sourcepath='org/apache/hadoop/mapred/OutputCommitter.java' sourcefile='OutputCommitter.java' startBytecode='0'></SourceLine><Message>Overrides org.apache.hadoop.mapred.OutputCommitter.isCommitJobRepeatable(JobContext)</Message></Method><SourceLine synthetic='true' endBytecode='53' classname='org.apache.hadoop.mapred.OutputCommitter' start='230' end='230' sourcepath='org/apache/hadoop/mapred/OutputCommitter.java' sourcefile='OutputCommitter.java' startBytecode='0'><Message>At OutputCommitter.java:[line 230]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='c942ccdbf0ea2db1c28f481e00c58e65' rank='16' abbrev='Nm' category='BAD_PRACTICE' priority='2' type='NM_WRONG_PACKAGE_INTENTIONAL' instanceOccurrenceMax='0'><ShortMessage>Method doesn't override method in superclass due to wrong package for parameter</ShortMessage><LongMessage>org.apache.hadoop.mapred.OutputCommitter.isRecoverySupported(JobContext) doesn't override method in superclass because parameter type org.apache.hadoop.mapred.JobContext doesn't match superclass parameter type org.apache.hadoop.mapreduce.JobContext</LongMessage><Class classname='org.apache.hadoop.mapred.OutputCommitter' primary='true'><SourceLine classname='org.apache.hadoop.mapred.OutputCommitter' start='70' end='378' sourcepath='org/apache/hadoop/mapred/OutputCommitter.java' sourcefile='OutputCommitter.java'><Message>At OutputCommitter.java:[lines 70-378]</Message></SourceLine><Message>In class org.apache.hadoop.mapred.OutputCommitter</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapred.OutputCommitter' signature='(Lorg/apache/hadoop/mapred/JobContext;)Z' name='isRecoverySupported' primary='true'><SourceLine endBytecode='56' classname='org.apache.hadoop.mapred.OutputCommitter' start='204' end='204' sourcepath='org/apache/hadoop/mapred/OutputCommitter.java' sourcefile='OutputCommitter.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapred.OutputCommitter.isRecoverySupported(JobContext)</Message></Method><Class role='CLASS_SUPERCLASS' classname='org.apache.hadoop.mapreduce.OutputCommitter'><SourceLine classname='org.apache.hadoop.mapreduce.OutputCommitter' start='69' end='254' sourcepath='org/apache/hadoop/mapreduce/OutputCommitter.java' sourcefile='OutputCommitter.java'><Message>At OutputCommitter.java:[lines 69-254]</Message></SourceLine><Message>superclass is org.apache.hadoop.mapreduce.OutputCommitter</Message></Class><Method isStatic='false' role='METHOD_DID_YOU_MEAN_TO_OVERRIDE' classname='org.apache.hadoop.mapreduce.OutputCommitter' signature='(Lorg/apache/hadoop/mapreduce/JobContext;)Z' name='isRecoverySupported'><SourceLine endBytecode='56' classname='org.apache.hadoop.mapreduce.OutputCommitter' start='232' end='232' sourcepath='org/apache/hadoop/mapreduce/OutputCommitter.java' sourcefile='OutputCommitter.java' startBytecode='0'></SourceLine><Message>Did you intend to override org.apache.hadoop.mapreduce.OutputCommitter.isRecoverySupported(JobContext)</Message></Method><Type role='TYPE_FOUND' descriptor='Lorg/apache/hadoop/mapred/JobContext;'><SourceLine classname='org.apache.hadoop.mapred.JobContext' sourcepath='org/apache/hadoop/mapred/JobContext.java' sourcefile='JobContext.java'><Message>In JobContext.java</Message></SourceLine><Message>Actual type org.apache.hadoop.mapred.JobContext</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/mapreduce/JobContext;'><SourceLine classname='org.apache.hadoop.mapreduce.JobContext' sourcepath='org/apache/hadoop/mapreduce/JobContext.java' sourcefile='JobContext.java'><Message>In JobContext.java</Message></SourceLine><Message>Expected org.apache.hadoop.mapreduce.JobContext</Message></Type><Method isStatic='false' role='METHOD_OVERRIDDEN' classname='org.apache.hadoop.mapred.OutputCommitter' signature='(Lorg/apache/hadoop/mapreduce/JobContext;)Z' name='isRecoverySupported'><SourceLine endBytecode='60' classname='org.apache.hadoop.mapred.OutputCommitter' start='378' end='378' sourcepath='org/apache/hadoop/mapred/OutputCommitter.java' sourcefile='OutputCommitter.java' startBytecode='0'></SourceLine><Message>Overrides org.apache.hadoop.mapred.OutputCommitter.isRecoverySupported(JobContext)</Message></Method><SourceLine synthetic='true' endBytecode='56' classname='org.apache.hadoop.mapred.OutputCommitter' start='204' end='204' sourcepath='org/apache/hadoop/mapred/OutputCommitter.java' sourcefile='OutputCommitter.java' startBytecode='0'><Message>At OutputCommitter.java:[line 204]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='54c95f1f44fefa5dd488434f21bf7535' rank='16' abbrev='Nm' category='BAD_PRACTICE' priority='2' type='NM_WRONG_PACKAGE_INTENTIONAL' instanceOccurrenceMax='0'><ShortMessage>Method doesn't override method in superclass due to wrong package for parameter</ShortMessage><LongMessage>org.apache.hadoop.mapred.OutputCommitter.recoverTask(TaskAttemptContext) doesn't override method in superclass because parameter type org.apache.hadoop.mapred.TaskAttemptContext doesn't match superclass parameter type org.apache.hadoop.mapreduce.TaskAttemptContext</LongMessage><Class classname='org.apache.hadoop.mapred.OutputCommitter' primary='true'><SourceLine classname='org.apache.hadoop.mapred.OutputCommitter' start='70' end='378' sourcepath='org/apache/hadoop/mapred/OutputCommitter.java' sourcefile='OutputCommitter.java'><Message>At OutputCommitter.java:[lines 70-378]</Message></SourceLine><Message>In class org.apache.hadoop.mapred.OutputCommitter</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapred.OutputCommitter' signature='(Lorg/apache/hadoop/mapred/TaskAttemptContext;)V' name='recoverTask' primary='true'><SourceLine endBytecode='52' classname='org.apache.hadoop.mapred.OutputCommitter' start='255' end='255' sourcepath='org/apache/hadoop/mapred/OutputCommitter.java' sourcefile='OutputCommitter.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapred.OutputCommitter.recoverTask(TaskAttemptContext)</Message></Method><Class role='CLASS_SUPERCLASS' classname='org.apache.hadoop.mapreduce.OutputCommitter'><SourceLine classname='org.apache.hadoop.mapreduce.OutputCommitter' start='69' end='254' sourcepath='org/apache/hadoop/mapreduce/OutputCommitter.java' sourcefile='OutputCommitter.java'><Message>At OutputCommitter.java:[lines 69-254]</Message></SourceLine><Message>superclass is org.apache.hadoop.mapreduce.OutputCommitter</Message></Class><Method isStatic='false' role='METHOD_DID_YOU_MEAN_TO_OVERRIDE' classname='org.apache.hadoop.mapreduce.OutputCommitter' signature='(Lorg/apache/hadoop/mapreduce/TaskAttemptContext;)V' name='recoverTask'><SourceLine endBytecode='52' classname='org.apache.hadoop.mapreduce.OutputCommitter' start='254' end='254' sourcepath='org/apache/hadoop/mapreduce/OutputCommitter.java' sourcefile='OutputCommitter.java' startBytecode='0'></SourceLine><Message>Did you intend to override org.apache.hadoop.mapreduce.OutputCommitter.recoverTask(TaskAttemptContext)</Message></Method><Type role='TYPE_FOUND' descriptor='Lorg/apache/hadoop/mapred/TaskAttemptContext;'><SourceLine classname='org.apache.hadoop.mapred.TaskAttemptContext' start='25' end='25' sourcepath='org/apache/hadoop/mapred/TaskAttemptContext.java' sourcefile='TaskAttemptContext.java'><Message>At TaskAttemptContext.java:[line 25]</Message></SourceLine><Message>Actual type org.apache.hadoop.mapred.TaskAttemptContext</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/mapreduce/TaskAttemptContext;'><SourceLine classname='org.apache.hadoop.mapreduce.TaskAttemptContext' sourcepath='org/apache/hadoop/mapreduce/TaskAttemptContext.java' sourcefile='TaskAttemptContext.java'><Message>In TaskAttemptContext.java</Message></SourceLine><Message>Expected org.apache.hadoop.mapreduce.TaskAttemptContext</Message></Type><Method isStatic='false' role='METHOD_OVERRIDDEN' classname='org.apache.hadoop.mapred.OutputCommitter' signature='(Lorg/apache/hadoop/mapreduce/TaskAttemptContext;)V' name='recoverTask'><SourceLine endBytecode='64' classname='org.apache.hadoop.mapred.OutputCommitter' start='367' end='368' sourcepath='org/apache/hadoop/mapred/OutputCommitter.java' sourcefile='OutputCommitter.java' startBytecode='0'></SourceLine><Message>Overrides org.apache.hadoop.mapred.OutputCommitter.recoverTask(TaskAttemptContext)</Message></Method><SourceLine synthetic='true' endBytecode='52' classname='org.apache.hadoop.mapred.OutputCommitter' start='255' end='255' sourcepath='org/apache/hadoop/mapred/OutputCommitter.java' sourcefile='OutputCommitter.java' startBytecode='0'><Message>At OutputCommitter.java:[line 255]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='dd33bc95b16b448ee55807c0ad799b75' rank='19' abbrev='Nm' category='BAD_PRACTICE' priority='3' type='NM_WRONG_PACKAGE_INTENTIONAL' instanceOccurrenceMax='0'><ShortMessage>Method doesn't override method in superclass due to wrong package for parameter</ShortMessage><LongMessage>org.apache.hadoop.mapred.OutputCommitter.cleanupJob(JobContext) doesn't override method in superclass because parameter type org.apache.hadoop.mapred.JobContext doesn't match superclass parameter type org.apache.hadoop.mapreduce.JobContext</LongMessage><Class classname='org.apache.hadoop.mapred.OutputCommitter' primary='true'><SourceLine classname='org.apache.hadoop.mapred.OutputCommitter' start='70' end='378' sourcepath='org/apache/hadoop/mapred/OutputCommitter.java' sourcefile='OutputCommitter.java'><Message>At OutputCommitter.java:[lines 70-378]</Message></SourceLine><Message>In class org.apache.hadoop.mapred.OutputCommitter</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapred.OutputCommitter' signature='(Lorg/apache/hadoop/mapred/JobContext;)V' name='cleanupJob' primary='true'><SourceLine endBytecode='52' classname='org.apache.hadoop.mapred.OutputCommitter' start='93' end='93' sourcepath='org/apache/hadoop/mapred/OutputCommitter.java' sourcefile='OutputCommitter.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapred.OutputCommitter.cleanupJob(JobContext)</Message></Method><Class role='CLASS_SUPERCLASS' classname='org.apache.hadoop.mapreduce.OutputCommitter'><SourceLine classname='org.apache.hadoop.mapreduce.OutputCommitter' start='69' end='254' sourcepath='org/apache/hadoop/mapreduce/OutputCommitter.java' sourcefile='OutputCommitter.java'><Message>At OutputCommitter.java:[lines 69-254]</Message></SourceLine><Message>superclass is org.apache.hadoop.mapreduce.OutputCommitter</Message></Class><Method isStatic='false' role='METHOD_DID_YOU_MEAN_TO_OVERRIDE' classname='org.apache.hadoop.mapreduce.OutputCommitter' signature='(Lorg/apache/hadoop/mapreduce/JobContext;)V' name='cleanupJob'><SourceLine endBytecode='52' classname='org.apache.hadoop.mapreduce.OutputCommitter' start='91' end='91' sourcepath='org/apache/hadoop/mapreduce/OutputCommitter.java' sourcefile='OutputCommitter.java' startBytecode='0'></SourceLine><Message>Did you intend to override org.apache.hadoop.mapreduce.OutputCommitter.cleanupJob(JobContext)</Message></Method><Type role='TYPE_FOUND' descriptor='Lorg/apache/hadoop/mapred/JobContext;'><SourceLine classname='org.apache.hadoop.mapred.JobContext' sourcepath='org/apache/hadoop/mapred/JobContext.java' sourcefile='JobContext.java'><Message>In JobContext.java</Message></SourceLine><Message>Actual type org.apache.hadoop.mapred.JobContext</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/mapreduce/JobContext;'><SourceLine classname='org.apache.hadoop.mapreduce.JobContext' sourcepath='org/apache/hadoop/mapreduce/JobContext.java' sourcefile='JobContext.java'><Message>In JobContext.java</Message></SourceLine><Message>Expected org.apache.hadoop.mapreduce.JobContext</Message></Type><Method isStatic='false' role='METHOD_OVERRIDDEN' classname='org.apache.hadoop.mapred.OutputCommitter' signature='(Lorg/apache/hadoop/mapreduce/JobContext;)V' name='cleanupJob'><SourceLine endBytecode='64' classname='org.apache.hadoop.mapred.OutputCommitter' start='280' end='281' sourcepath='org/apache/hadoop/mapred/OutputCommitter.java' sourcefile='OutputCommitter.java' startBytecode='0'></SourceLine><Message>Overrides org.apache.hadoop.mapred.OutputCommitter.cleanupJob(JobContext)</Message></Method><SourceLine synthetic='true' endBytecode='52' classname='org.apache.hadoop.mapred.OutputCommitter' start='93' end='93' sourcepath='org/apache/hadoop/mapred/OutputCommitter.java' sourcefile='OutputCommitter.java' startBytecode='0'><Message>At OutputCommitter.java:[line 93]</Message></SourceLine><Property name='edu.umd.cs.findbugs.detect.Naming$NamingProperty.CONFUSING_METHOD_IS_DEPRECATED' value='true'></Property></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='3a898b40c2c45718a955c5ac65701c3c' rank='14' abbrev='Nm' category='BAD_PRACTICE' priority='1' type='NM_SAME_SIMPLE_NAME_AS_SUPERCLASS' instanceOccurrenceMax='0'><ShortMessage>Class names shouldn't shadow simple name of superclass</ShortMessage><LongMessage>The class name org.apache.hadoop.mapred.QueueAclsInfo shadows the simple name of the superclass org.apache.hadoop.mapreduce.QueueAclsInfo</LongMessage><Class classname='org.apache.hadoop.mapred.QueueAclsInfo' primary='true'><SourceLine classname='org.apache.hadoop.mapred.QueueAclsInfo' start='31' end='48' sourcepath='org/apache/hadoop/mapred/QueueAclsInfo.java' sourcefile='QueueAclsInfo.java'><Message>At QueueAclsInfo.java:[lines 31-48]</Message></SourceLine><Message>In class org.apache.hadoop.mapred.QueueAclsInfo</Message></Class><Class classname='org.apache.hadoop.mapreduce.QueueAclsInfo'><SourceLine classname='org.apache.hadoop.mapreduce.QueueAclsInfo' start='46' end='94' sourcepath='org/apache/hadoop/mapreduce/QueueAclsInfo.java' sourcefile='QueueAclsInfo.java'><Message>At QueueAclsInfo.java:[lines 46-94]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.QueueAclsInfo</Message></Class><SourceLine synthetic='true' classname='org.apache.hadoop.mapred.QueueAclsInfo' start='31' end='48' sourcepath='org/apache/hadoop/mapred/QueueAclsInfo.java' sourcefile='QueueAclsInfo.java'><Message>At QueueAclsInfo.java:[lines 31-48]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='2cb4370c94be5c1cde2c417591cd6848' cweid='476' rank='20' abbrev='RCN' category='STYLE' priority='3' type='RCN_REDUNDANT_NULLCHECK_OF_NONNULL_VALUE' instanceOccurrenceMax='0'><ShortMessage>Redundant nullcheck of value known to be non-null</ShortMessage><LongMessage>Redundant nullcheck of children, which is known to be non-null in org.apache.hadoop.mapred.QueueConfigurationParser.getQueueElement(Document, JobQueueInfo)</LongMessage><Class classname='org.apache.hadoop.mapred.QueueConfigurationParser' primary='true'><SourceLine classname='org.apache.hadoop.mapred.QueueConfigurationParser' start='62' end='468' sourcepath='org/apache/hadoop/mapred/QueueConfigurationParser.java' sourcefile='QueueConfigurationParser.java'><Message>At QueueConfigurationParser.java:[lines 62-468]</Message></SourceLine><Message>In class org.apache.hadoop.mapred.QueueConfigurationParser</Message></Class><Method isStatic='true' classname='org.apache.hadoop.mapred.QueueConfigurationParser' signature='(Lorg/w3c/dom/Document;Lorg/apache/hadoop/mapred/JobQueueInfo;)Lorg/w3c/dom/Element;' name='getQueueElement' primary='true'><SourceLine endBytecode='629' classname='org.apache.hadoop.mapred.QueueConfigurationParser' start='430' end='468' sourcepath='org/apache/hadoop/mapred/QueueConfigurationParser.java' sourcefile='QueueConfigurationParser.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapred.QueueConfigurationParser.getQueueElement(Document, JobQueueInfo)</Message></Method><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='222' name='children' register='7'><Message>Value loaded from children</Message></LocalVariable><Method isStatic='false' role='METHOD_RETURN_VALUE_OF' classname='org.apache.hadoop.mapred.JobQueueInfo' signature='()Ljava/util/List;' name='getChildren'><SourceLine endBytecode='168' classname='org.apache.hadoop.mapred.JobQueueInfo' start='112' end='116' sourcepath='org/apache/hadoop/mapred/JobQueueInfo.java' sourcefile='JobQueueInfo.java' startBytecode='0'></SourceLine><Message>Return value of org.apache.hadoop.mapred.JobQueueInfo.getChildren() of type java.util.List</Message></Method><SourceLine role='SOURCE_REDUNDANT_NULL_CHECK' endBytecode='224' classname='org.apache.hadoop.mapred.QueueConfigurationParser' start='462' end='462' sourcepath='org/apache/hadoop/mapred/QueueConfigurationParser.java' sourcefile='QueueConfigurationParser.java' startBytecode='224' primary='true'><Message>Redundant null check at QueueConfigurationParser.java:[line 462]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='6a176bf2e4184fc5259a98defcaebd72' rank='20' abbrev='SIC' category='PERFORMANCE' priority='3' type='SIC_INNER_SHOULD_BE_STATIC_ANON' instanceOccurrenceMax='0'><ShortMessage>Could be refactored into a named static inner class</ShortMessage><LongMessage>The class org.apache.hadoop.mapred.ReduceTask$2 could be refactored into a named _static_ inner class</LongMessage><Class role='CLASS_ANONYMOUS' classname='org.apache.hadoop.mapred.ReduceTask$2'><SourceLine classname='org.apache.hadoop.mapred.ReduceTask$2' start='114' end='124' sourcepath='org/apache/hadoop/mapred/ReduceTask.java' sourcefile='ReduceTask.java'><Message>At ReduceTask.java:[lines 114-124]</Message></SourceLine><Message>Anonymous class org.apache.hadoop.mapred.ReduceTask$2</Message></Class><Class classname='org.apache.hadoop.mapred.ReduceTask' primary='true'><SourceLine classname='org.apache.hadoop.mapred.ReduceTask' start='63' end='643' sourcepath='org/apache/hadoop/mapred/ReduceTask.java' sourcefile='ReduceTask.java'><Message>At ReduceTask.java:[lines 63-643]</Message></SourceLine><Message>In class org.apache.hadoop.mapred.ReduceTask</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapred.ReduceTask' signature='(Ljava/lang/String;Lorg/apache/hadoop/mapred/TaskAttemptID;III)V' name='&lt;init&gt;' primary='true'><SourceLine endBytecode='374' classname='org.apache.hadoop.mapred.ReduceTask' start='138' end='140' sourcepath='org/apache/hadoop/mapred/ReduceTask.java' sourcefile='ReduceTask.java' startBytecode='0'></SourceLine><Message>In method new org.apache.hadoop.mapred.ReduceTask(String, TaskAttemptID, int, int, int)</Message></Method><SourceLine endBytecode='167' classname='org.apache.hadoop.mapred.ReduceTask' start='113' end='113' sourcepath='org/apache/hadoop/mapred/ReduceTask.java' sourcefile='ReduceTask.java' startBytecode='167' primary='true'><Message>At ReduceTask.java:[line 113]</Message></SourceLine><Field isStatic='false' classname='org.apache.hadoop.mapred.ReduceTask' signature='Ljava/util/Comparator;' name='mapOutputFileComparator' primary='true'><SourceLine classname='org.apache.hadoop.mapred.ReduceTask' sourcepath='org/apache/hadoop/mapred/ReduceTask.java' sourcefile='ReduceTask.java'><Message>In ReduceTask.java</Message></SourceLine><Message>Field org.apache.hadoop.mapred.ReduceTask.mapOutputFileComparator</Message></Field></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='61c011af7573fbdfd104ac86f46ccd3b' rank='20' abbrev='SIC' category='PERFORMANCE' priority='3' type='SIC_INNER_SHOULD_BE_STATIC_ANON' instanceOccurrenceMax='0'><ShortMessage>Could be refactored into a named static inner class</ShortMessage><LongMessage>The class org.apache.hadoop.mapred.ReduceTask$3 could be refactored into a named _static_ inner class</LongMessage><Class role='CLASS_ANONYMOUS' classname='org.apache.hadoop.mapred.ReduceTask$3'><SourceLine classname='org.apache.hadoop.mapred.ReduceTask$3' start='420' end='426' sourcepath='org/apache/hadoop/mapred/ReduceTask.java' sourcefile='ReduceTask.java'><Message>At ReduceTask.java:[lines 420-426]</Message></SourceLine><Message>Anonymous class org.apache.hadoop.mapred.ReduceTask$3</Message></Class><Class classname='org.apache.hadoop.mapred.ReduceTask' primary='true'><SourceLine classname='org.apache.hadoop.mapred.ReduceTask' start='63' end='643' sourcepath='org/apache/hadoop/mapred/ReduceTask.java' sourcefile='ReduceTask.java'><Message>At ReduceTask.java:[lines 63-643]</Message></SourceLine><Message>In class org.apache.hadoop.mapred.ReduceTask</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapred.ReduceTask' signature='(Lorg/apache/hadoop/mapred/JobConf;Lorg/apache/hadoop/mapred/TaskUmbilicalProtocol;Lorg/apache/hadoop/mapred/Task$TaskReporter;Lorg/apache/hadoop/mapred/RawKeyValueIterator;Lorg/apache/hadoop/io/RawComparator;Ljava/lang/Class;Ljava/lang/Class;)V' name='runOldReducer' primary='true'><SourceLine endBytecode='779' classname='org.apache.hadoop.mapred.ReduceTask' start='410' end='463' sourcepath='org/apache/hadoop/mapred/ReduceTask.java' sourcefile='ReduceTask.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapred.ReduceTask.runOldReducer(JobConf, TaskUmbilicalProtocol, Task$TaskReporter, RawKeyValueIterator, RawComparator, Class, Class)</Message></Method><SourceLine endBytecode='48' classname='org.apache.hadoop.mapred.ReduceTask' start='419' end='419' sourcepath='org/apache/hadoop/mapred/ReduceTask.java' sourcefile='ReduceTask.java' startBytecode='48' primary='true'><Message>At ReduceTask.java:[line 419]</Message></SourceLine><LocalVariable role='LOCAL_VARIABLE_NAMED' pc='53' name='collector' register='12'><Message>Local variable named collector</Message></LocalVariable></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='7579cdc0ac25860178a81a6d3883a0bd' rank='20' abbrev='SIC' category='PERFORMANCE' priority='3' type='SIC_INNER_SHOULD_BE_STATIC_ANON' instanceOccurrenceMax='0'><ShortMessage>Could be refactored into a named static inner class</ShortMessage><LongMessage>The class org.apache.hadoop.mapred.ReduceTask$4 could be refactored into a named _static_ inner class</LongMessage><Class role='CLASS_ANONYMOUS' classname='org.apache.hadoop.mapred.ReduceTask$4'><SourceLine classname='org.apache.hadoop.mapred.ReduceTask$4' start='588' end='604' sourcepath='org/apache/hadoop/mapred/ReduceTask.java' sourcefile='ReduceTask.java'><Message>At ReduceTask.java:[lines 588-604]</Message></SourceLine><Message>Anonymous class org.apache.hadoop.mapred.ReduceTask$4</Message></Class><Class classname='org.apache.hadoop.mapred.ReduceTask' primary='true'><SourceLine classname='org.apache.hadoop.mapred.ReduceTask' start='63' end='643' sourcepath='org/apache/hadoop/mapred/ReduceTask.java' sourcefile='ReduceTask.java'><Message>At ReduceTask.java:[lines 63-643]</Message></SourceLine><Message>In class org.apache.hadoop.mapred.ReduceTask</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapred.ReduceTask' signature='(Lorg/apache/hadoop/mapred/JobConf;Lorg/apache/hadoop/mapred/TaskUmbilicalProtocol;Lorg/apache/hadoop/mapred/Task$TaskReporter;Lorg/apache/hadoop/mapred/RawKeyValueIterator;Lorg/apache/hadoop/io/RawComparator;Ljava/lang/Class;Ljava/lang/Class;)V' name='runNewReducer' primary='true'><SourceLine endBytecode='498' classname='org.apache.hadoop.mapred.ReduceTask' start='587' end='632' sourcepath='org/apache/hadoop/mapred/ReduceTask.java' sourcefile='ReduceTask.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapred.ReduceTask.runNewReducer(JobConf, TaskUmbilicalProtocol, Task$TaskReporter, RawKeyValueIterator, RawComparator, Class, Class)</Message></Method><SourceLine endBytecode='12' classname='org.apache.hadoop.mapred.ReduceTask' start='588' end='588' sourcepath='org/apache/hadoop/mapred/ReduceTask.java' sourcefile='ReduceTask.java' startBytecode='12' primary='true'><Message>At ReduceTask.java:[line 588]</Message></SourceLine><LocalVariable role='LOCAL_VARIABLE_NAMED' pc='15' name='rIter' register='4'><Message>Local variable named rIter</Message></LocalVariable></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='a90579d68d4c6f9b5ce68c69d001a2b0' rank='20' abbrev='UPM' category='PERFORMANCE' priority='3' type='UPM_UNCALLED_PRIVATE_METHOD' instanceOccurrenceMax='0'><ShortMessage>Private method is never called</ShortMessage><LongMessage>Private method org.apache.hadoop.mapred.ReduceTask.getMapFiles(FileSystem) is never called</LongMessage><Class classname='org.apache.hadoop.mapred.ReduceTask' primary='true'><SourceLine classname='org.apache.hadoop.mapred.ReduceTask' start='63' end='643' sourcepath='org/apache/hadoop/mapred/ReduceTask.java' sourcefile='ReduceTask.java'><Message>At ReduceTask.java:[lines 63-643]</Message></SourceLine><Message>In class org.apache.hadoop.mapred.ReduceTask</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapred.ReduceTask' signature='(Lorg/apache/hadoop/fs/FileSystem;)[Lorg/apache/hadoop/fs/Path;' name='getMapFiles' primary='true'><SourceLine endBytecode='176' classname='org.apache.hadoop.mapred.ReduceTask' start='196' end='200' sourcepath='org/apache/hadoop/mapred/ReduceTask.java' sourcefile='ReduceTask.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapred.ReduceTask.getMapFiles(FileSystem)</Message></Method><SourceLine synthetic='true' endBytecode='176' classname='org.apache.hadoop.mapred.ReduceTask' start='196' end='200' sourcepath='org/apache/hadoop/mapred/ReduceTask.java' sourcefile='ReduceTask.java' startBytecode='0'><Message>At ReduceTask.java:[lines 196-200]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='31d0530a5b4c143079dbe1de1e7d17d1' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from org.apache.hadoop.mapred.InputSplit to org.apache.hadoop.mapred.FileSplit in org.apache.hadoop.mapred.SequenceFileAsBinaryInputFormat.getRecordReader(InputSplit, JobConf, Reporter)</LongMessage><Class classname='org.apache.hadoop.mapred.SequenceFileAsBinaryInputFormat' primary='true'><SourceLine classname='org.apache.hadoop.mapred.SequenceFileAsBinaryInputFormat' start='41' end='47' sourcepath='org/apache/hadoop/mapred/SequenceFileAsBinaryInputFormat.java' sourcefile='SequenceFileAsBinaryInputFormat.java'><Message>At SequenceFileAsBinaryInputFormat.java:[lines 41-47]</Message></SourceLine><Message>In class org.apache.hadoop.mapred.SequenceFileAsBinaryInputFormat</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapred.SequenceFileAsBinaryInputFormat' signature='(Lorg/apache/hadoop/mapred/InputSplit;Lorg/apache/hadoop/mapred/JobConf;Lorg/apache/hadoop/mapred/Reporter;)Lorg/apache/hadoop/mapred/RecordReader;' name='getRecordReader' primary='true'><SourceLine endBytecode='6' classname='org.apache.hadoop.mapred.SequenceFileAsBinaryInputFormat' start='47' end='47' sourcepath='org/apache/hadoop/mapred/SequenceFileAsBinaryInputFormat.java' sourcefile='SequenceFileAsBinaryInputFormat.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapred.SequenceFileAsBinaryInputFormat.getRecordReader(InputSplit, JobConf, Reporter)</Message></Method><Type role='TYPE_FOUND' descriptor='Lorg/apache/hadoop/mapred/InputSplit;'><SourceLine classname='org.apache.hadoop.mapred.InputSplit' sourcepath='org/apache/hadoop/mapred/InputSplit.java' sourcefile='InputSplit.java'><Message>In InputSplit.java</Message></SourceLine><Message>Actual type org.apache.hadoop.mapred.InputSplit</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/mapred/FileSplit;'><SourceLine classname='org.apache.hadoop.mapred.FileSplit' start='39' end='113' sourcepath='org/apache/hadoop/mapred/FileSplit.java' sourcefile='FileSplit.java'><Message>At FileSplit.java:[lines 39-113]</Message></SourceLine><Message>Expected org.apache.hadoop.mapred.FileSplit</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='5' name='split' register='1'><Message>Value loaded from split</Message></LocalVariable><SourceLine endBytecode='6' classname='org.apache.hadoop.mapred.SequenceFileAsBinaryInputFormat' start='47' end='47' sourcepath='org/apache/hadoop/mapred/SequenceFileAsBinaryInputFormat.java' sourcefile='SequenceFileAsBinaryInputFormat.java' startBytecode='6' primary='true'><Message>At SequenceFileAsBinaryInputFormat.java:[line 47]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='b1be981bceb066e69970b2c691d85c8b' rank='20' abbrev='SIC' category='PERFORMANCE' priority='3' type='SIC_INNER_SHOULD_BE_STATIC_ANON' instanceOccurrenceMax='0'><ShortMessage>Could be refactored into a named static inner class</ShortMessage><LongMessage>The class org.apache.hadoop.mapred.SequenceFileAsBinaryOutputFormat$1 could be refactored into a named _static_ inner class</LongMessage><Class role='CLASS_ANONYMOUS' classname='org.apache.hadoop.mapred.SequenceFileAsBinaryOutputFormat$1'><SourceLine classname='org.apache.hadoop.mapred.SequenceFileAsBinaryOutputFormat$1' start='138' end='152' sourcepath='org/apache/hadoop/mapred/SequenceFileAsBinaryOutputFormat.java' sourcefile='SequenceFileAsBinaryOutputFormat.java'><Message>At SequenceFileAsBinaryOutputFormat.java:[lines 138-152]</Message></SourceLine><Message>Anonymous class org.apache.hadoop.mapred.SequenceFileAsBinaryOutputFormat$1</Message></Class><Class classname='org.apache.hadoop.mapred.SequenceFileAsBinaryOutputFormat' primary='true'><SourceLine classname='org.apache.hadoop.mapred.SequenceFileAsBinaryOutputFormat' start='42' end='168' sourcepath='org/apache/hadoop/mapred/SequenceFileAsBinaryOutputFormat.java' sourcefile='SequenceFileAsBinaryOutputFormat.java'><Message>At SequenceFileAsBinaryOutputFormat.java:[lines 42-168]</Message></SourceLine><Message>In class org.apache.hadoop.mapred.SequenceFileAsBinaryOutputFormat</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapred.SequenceFileAsBinaryOutputFormat' signature='(Lorg/apache/hadoop/fs/FileSystem;Lorg/apache/hadoop/mapred/JobConf;Ljava/lang/String;Lorg/apache/hadoop/util/Progressable;)Lorg/apache/hadoop/mapred/RecordWriter;' name='getRecordWriter' primary='true'><SourceLine endBytecode='339' classname='org.apache.hadoop.mapred.SequenceFileAsBinaryOutputFormat' start='116' end='138' sourcepath='org/apache/hadoop/mapred/SequenceFileAsBinaryOutputFormat.java' sourcefile='SequenceFileAsBinaryOutputFormat.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapred.SequenceFileAsBinaryOutputFormat.getRecordWriter(FileSystem, JobConf, String, Progressable)</Message></Method><SourceLine endBytecode='86' classname='org.apache.hadoop.mapred.SequenceFileAsBinaryOutputFormat' start='138' end='138' sourcepath='org/apache/hadoop/mapred/SequenceFileAsBinaryOutputFormat.java' sourcefile='SequenceFileAsBinaryOutputFormat.java' startBytecode='86' primary='true'><Message>At SequenceFileAsBinaryOutputFormat.java:[line 138]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='1462204681954aeb3abb47ff700356ef' rank='14' abbrev='Nm' category='BAD_PRACTICE' priority='1' type='NM_SAME_SIMPLE_NAME_AS_SUPERCLASS' instanceOccurrenceMax='0'><ShortMessage>Class names shouldn't shadow simple name of superclass</ShortMessage><LongMessage>The class name org.apache.hadoop.mapred.SequenceFileAsBinaryOutputFormat$WritableValueBytes shadows the simple name of the superclass org.apache.hadoop.mapreduce.lib.output.SequenceFileAsBinaryOutputFormat$WritableValueBytes</LongMessage><Class classname='org.apache.hadoop.mapred.SequenceFileAsBinaryOutputFormat$WritableValueBytes' primary='true'><SourceLine classname='org.apache.hadoop.mapred.SequenceFileAsBinaryOutputFormat$WritableValueBytes' start='51' end='56' sourcepath='org/apache/hadoop/mapred/SequenceFileAsBinaryOutputFormat.java' sourcefile='SequenceFileAsBinaryOutputFormat.java'><Message>At SequenceFileAsBinaryOutputFormat.java:[lines 51-56]</Message></SourceLine><Message>In class org.apache.hadoop.mapred.SequenceFileAsBinaryOutputFormat$WritableValueBytes</Message></Class><Class classname='org.apache.hadoop.mapreduce.lib.output.SequenceFileAsBinaryOutputFormat$WritableValueBytes'><SourceLine classname='org.apache.hadoop.mapreduce.lib.output.SequenceFileAsBinaryOutputFormat$WritableValueBytes' start='54' end='78' sourcepath='org/apache/hadoop/mapreduce/lib/output/SequenceFileAsBinaryOutputFormat.java' sourcefile='SequenceFileAsBinaryOutputFormat.java'><Message>At SequenceFileAsBinaryOutputFormat.java:[lines 54-78]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.lib.output.SequenceFileAsBinaryOutputFormat$WritableValueBytes</Message></Class><SourceLine synthetic='true' classname='org.apache.hadoop.mapred.SequenceFileAsBinaryOutputFormat$WritableValueBytes' start='51' end='56' sourcepath='org/apache/hadoop/mapred/SequenceFileAsBinaryOutputFormat.java' sourcefile='SequenceFileAsBinaryOutputFormat.java'><Message>At SequenceFileAsBinaryOutputFormat.java:[lines 51-56]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='68403f433cc7e0fbdc82d26ed8743f27' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from org.apache.hadoop.mapred.InputSplit to org.apache.hadoop.mapred.FileSplit in org.apache.hadoop.mapred.SequenceFileAsTextInputFormat.getRecordReader(InputSplit, JobConf, Reporter)</LongMessage><Class classname='org.apache.hadoop.mapred.SequenceFileAsTextInputFormat' primary='true'><SourceLine classname='org.apache.hadoop.mapred.SequenceFileAsTextInputFormat' start='39' end='49' sourcepath='org/apache/hadoop/mapred/SequenceFileAsTextInputFormat.java' sourcefile='SequenceFileAsTextInputFormat.java'><Message>At SequenceFileAsTextInputFormat.java:[lines 39-49]</Message></SourceLine><Message>In class org.apache.hadoop.mapred.SequenceFileAsTextInputFormat</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapred.SequenceFileAsTextInputFormat' signature='(Lorg/apache/hadoop/mapred/InputSplit;Lorg/apache/hadoop/mapred/JobConf;Lorg/apache/hadoop/mapred/Reporter;)Lorg/apache/hadoop/mapred/RecordReader;' name='getRecordReader' primary='true'><SourceLine endBytecode='10' classname='org.apache.hadoop.mapred.SequenceFileAsTextInputFormat' start='47' end='49' sourcepath='org/apache/hadoop/mapred/SequenceFileAsTextInputFormat.java' sourcefile='SequenceFileAsTextInputFormat.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapred.SequenceFileAsTextInputFormat.getRecordReader(InputSplit, JobConf, Reporter)</Message></Method><Type role='TYPE_FOUND' descriptor='Lorg/apache/hadoop/mapred/InputSplit;'><SourceLine classname='org.apache.hadoop.mapred.InputSplit' sourcepath='org/apache/hadoop/mapred/InputSplit.java' sourcefile='InputSplit.java'><Message>In InputSplit.java</Message></SourceLine><Message>Actual type org.apache.hadoop.mapred.InputSplit</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/mapred/FileSplit;'><SourceLine classname='org.apache.hadoop.mapred.FileSplit' start='39' end='113' sourcepath='org/apache/hadoop/mapred/FileSplit.java' sourcefile='FileSplit.java'><Message>At FileSplit.java:[lines 39-113]</Message></SourceLine><Message>Expected org.apache.hadoop.mapred.FileSplit</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='15' name='split' register='1'><Message>Value loaded from split</Message></LocalVariable><SourceLine endBytecode='16' classname='org.apache.hadoop.mapred.SequenceFileAsTextInputFormat' start='49' end='49' sourcepath='org/apache/hadoop/mapred/SequenceFileAsTextInputFormat.java' sourcefile='SequenceFileAsTextInputFormat.java' startBytecode='16' primary='true'><Message>At SequenceFileAsTextInputFormat.java:[line 49]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='3c086b999cbc97402944476b7a823567' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from org.apache.hadoop.mapred.InputSplit to org.apache.hadoop.mapred.FileSplit in org.apache.hadoop.mapred.SequenceFileInputFilter.getRecordReader(InputSplit, JobConf, Reporter)</LongMessage><Class classname='org.apache.hadoop.mapred.SequenceFileInputFilter' primary='true'><SourceLine classname='org.apache.hadoop.mapred.SequenceFileInputFilter' start='41' end='67' sourcepath='org/apache/hadoop/mapred/SequenceFileInputFilter.java' sourcefile='SequenceFileInputFilter.java'><Message>At SequenceFileInputFilter.java:[lines 41-67]</Message></SourceLine><Message>In class org.apache.hadoop.mapred.SequenceFileInputFilter</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapred.SequenceFileInputFilter' signature='(Lorg/apache/hadoop/mapred/InputSplit;Lorg/apache/hadoop/mapred/JobConf;Lorg/apache/hadoop/mapred/Reporter;)Lorg/apache/hadoop/mapred/RecordReader;' name='getRecordReader' primary='true'><SourceLine endBytecode='10' classname='org.apache.hadoop.mapred.SequenceFileInputFilter' start='54' end='56' sourcepath='org/apache/hadoop/mapred/SequenceFileInputFilter.java' sourcefile='SequenceFileInputFilter.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapred.SequenceFileInputFilter.getRecordReader(InputSplit, JobConf, Reporter)</Message></Method><Type role='TYPE_FOUND' descriptor='Lorg/apache/hadoop/mapred/InputSplit;'><SourceLine classname='org.apache.hadoop.mapred.InputSplit' sourcepath='org/apache/hadoop/mapred/InputSplit.java' sourcefile='InputSplit.java'><Message>In InputSplit.java</Message></SourceLine><Message>Actual type org.apache.hadoop.mapred.InputSplit</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/mapred/FileSplit;'><SourceLine classname='org.apache.hadoop.mapred.FileSplit' start='39' end='113' sourcepath='org/apache/hadoop/mapred/FileSplit.java' sourcefile='FileSplit.java'><Message>At FileSplit.java:[lines 39-113]</Message></SourceLine><Message>Expected org.apache.hadoop.mapred.FileSplit</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='15' name='split' register='1'><Message>Value loaded from split</Message></LocalVariable><SourceLine endBytecode='16' classname='org.apache.hadoop.mapred.SequenceFileInputFilter' start='56' end='56' sourcepath='org/apache/hadoop/mapred/SequenceFileInputFilter.java' sourcefile='SequenceFileInputFilter.java' startBytecode='16' primary='true'><Message>At SequenceFileInputFilter.java:[line 56]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='bdb424b9d4b27223a673b09ac6def13' rank='16' abbrev='Nm' category='BAD_PRACTICE' priority='2' type='NM_SAME_SIMPLE_NAME_AS_INTERFACE' instanceOccurrenceMax='0'><ShortMessage>Class names shouldn't shadow simple name of implemented interface</ShortMessage><LongMessage>The class name org.apache.hadoop.mapred.SequenceFileInputFilter$Filter shadows the simple name of implemented interface org.apache.hadoop.mapreduce.lib.input.SequenceFileInputFilter$Filter</LongMessage><Class classname='org.apache.hadoop.mapred.SequenceFileInputFilter$Filter' primary='true'><SourceLine classname='org.apache.hadoop.mapred.SequenceFileInputFilter$Filter' sourcepath='org/apache/hadoop/mapred/SequenceFileInputFilter.java' sourcefile='SequenceFileInputFilter.java'><Message>In SequenceFileInputFilter.java</Message></SourceLine><Message>In class org.apache.hadoop.mapred.SequenceFileInputFilter$Filter</Message></Class><Class classname='org.apache.hadoop.mapreduce.lib.input.SequenceFileInputFilter$Filter'><SourceLine classname='org.apache.hadoop.mapreduce.lib.input.SequenceFileInputFilter$Filter' sourcepath='org/apache/hadoop/mapreduce/lib/input/SequenceFileInputFilter.java' sourcefile='SequenceFileInputFilter.java'><Message>In SequenceFileInputFilter.java</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.lib.input.SequenceFileInputFilter$Filter</Message></Class><SourceLine synthetic='true' classname='org.apache.hadoop.mapred.SequenceFileInputFilter$Filter' sourcepath='org/apache/hadoop/mapred/SequenceFileInputFilter.java' sourcefile='SequenceFileInputFilter.java'><Message>In SequenceFileInputFilter.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='433bff8ad684ccf4bd52e9782cf6dac5' rank='14' abbrev='Nm' category='BAD_PRACTICE' priority='1' type='NM_SAME_SIMPLE_NAME_AS_SUPERCLASS' instanceOccurrenceMax='0'><ShortMessage>Class names shouldn't shadow simple name of superclass</ShortMessage><LongMessage>The class name org.apache.hadoop.mapred.SequenceFileInputFilter$FilterBase shadows the simple name of the superclass org.apache.hadoop.mapreduce.lib.input.SequenceFileInputFilter$FilterBase</LongMessage><Class classname='org.apache.hadoop.mapred.SequenceFileInputFilter$FilterBase' primary='true'><SourceLine classname='org.apache.hadoop.mapred.SequenceFileInputFilter$FilterBase' start='80' end='80' sourcepath='org/apache/hadoop/mapred/SequenceFileInputFilter.java' sourcefile='SequenceFileInputFilter.java'><Message>At SequenceFileInputFilter.java:[line 80]</Message></SourceLine><Message>In class org.apache.hadoop.mapred.SequenceFileInputFilter$FilterBase</Message></Class><Class classname='org.apache.hadoop.mapreduce.lib.input.SequenceFileInputFilter$FilterBase'><SourceLine classname='org.apache.hadoop.mapreduce.lib.input.SequenceFileInputFilter$FilterBase' start='101' end='105' sourcepath='org/apache/hadoop/mapreduce/lib/input/SequenceFileInputFilter.java' sourcefile='SequenceFileInputFilter.java'><Message>At SequenceFileInputFilter.java:[lines 101-105]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.lib.input.SequenceFileInputFilter$FilterBase</Message></Class><SourceLine synthetic='true' classname='org.apache.hadoop.mapred.SequenceFileInputFilter$FilterBase' start='80' end='80' sourcepath='org/apache/hadoop/mapred/SequenceFileInputFilter.java' sourcefile='SequenceFileInputFilter.java'><Message>At SequenceFileInputFilter.java:[line 80]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='86f89dde13c8c07cc16ef3f98a6030c' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from org.apache.hadoop.mapred.InputSplit to org.apache.hadoop.mapred.FileSplit in org.apache.hadoop.mapred.SequenceFileInputFormat.getRecordReader(InputSplit, JobConf, Reporter)</LongMessage><Class classname='org.apache.hadoop.mapred.SequenceFileInputFormat' primary='true'><SourceLine classname='org.apache.hadoop.mapred.SequenceFileInputFormat' start='39' end='64' sourcepath='org/apache/hadoop/mapred/SequenceFileInputFormat.java' sourcefile='SequenceFileInputFormat.java'><Message>At SequenceFileInputFormat.java:[lines 39-64]</Message></SourceLine><Message>In class org.apache.hadoop.mapred.SequenceFileInputFormat</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapred.SequenceFileInputFormat' signature='(Lorg/apache/hadoop/mapred/InputSplit;Lorg/apache/hadoop/mapred/JobConf;Lorg/apache/hadoop/mapred/Reporter;)Lorg/apache/hadoop/mapred/RecordReader;' name='getRecordReader' primary='true'><SourceLine endBytecode='10' classname='org.apache.hadoop.mapred.SequenceFileInputFormat' start='62' end='64' sourcepath='org/apache/hadoop/mapred/SequenceFileInputFormat.java' sourcefile='SequenceFileInputFormat.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapred.SequenceFileInputFormat.getRecordReader(InputSplit, JobConf, Reporter)</Message></Method><Type role='TYPE_FOUND' descriptor='Lorg/apache/hadoop/mapred/InputSplit;'><SourceLine classname='org.apache.hadoop.mapred.InputSplit' sourcepath='org/apache/hadoop/mapred/InputSplit.java' sourcefile='InputSplit.java'><Message>In InputSplit.java</Message></SourceLine><Message>Actual type org.apache.hadoop.mapred.InputSplit</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/mapred/FileSplit;'><SourceLine classname='org.apache.hadoop.mapred.FileSplit' start='39' end='113' sourcepath='org/apache/hadoop/mapred/FileSplit.java' sourcefile='FileSplit.java'><Message>At FileSplit.java:[lines 39-113]</Message></SourceLine><Message>Expected org.apache.hadoop.mapred.FileSplit</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='15' name='split' register='1'><Message>Value loaded from split</Message></LocalVariable><SourceLine endBytecode='16' classname='org.apache.hadoop.mapred.SequenceFileInputFormat' start='64' end='64' sourcepath='org/apache/hadoop/mapred/SequenceFileInputFormat.java' sourcefile='SequenceFileInputFormat.java' startBytecode='16' primary='true'><Message>At SequenceFileInputFormat.java:[line 64]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='5f988dd661aae58c39406b9d57281ae4' cweid='192' rank='20' abbrev='ICAST' category='STYLE' priority='3' type='ICAST_INTEGER_MULTIPLY_CAST_TO_LONG' instanceOccurrenceMax='0'><ShortMessage>Result of integer multiplication cast to long</ShortMessage><LongMessage>Result of integer multiplication cast to long in org.apache.hadoop.mapred.StatisticsCollector.start()</LongMessage><Class classname='org.apache.hadoop.mapred.StatisticsCollector' primary='true'><SourceLine classname='org.apache.hadoop.mapred.StatisticsCollector' start='38' end='140' sourcepath='org/apache/hadoop/mapred/StatisticsCollector.java' sourcefile='StatisticsCollector.java'><Message>At StatisticsCollector.java:[lines 38-140]</Message></SourceLine><Message>In class org.apache.hadoop.mapred.StatisticsCollector</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapred.StatisticsCollector' signature='()V' name='start' primary='true'><SourceLine endBytecode='159' classname='org.apache.hadoop.mapred.StatisticsCollector' start='74' end='86' sourcepath='org/apache/hadoop/mapred/StatisticsCollector.java' sourcefile='StatisticsCollector.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapred.StatisticsCollector.start()</Message></Method><SourceLine endBytecode='36' classname='org.apache.hadoop.mapred.StatisticsCollector' start='83' end='83' sourcepath='org/apache/hadoop/mapred/StatisticsCollector.java' sourcefile='StatisticsCollector.java' startBytecode='36' primary='true'><Message>At StatisticsCollector.java:[line 83]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='e697a9856679ed367ee71adb2f533063' rank='20' abbrev='UrF' category='PERFORMANCE' priority='3' type='URF_UNREAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Unread field</ShortMessage><LongMessage>Unread field: org.apache.hadoop.mapred.StatisticsCollector$Stat.name</LongMessage><Class classname='org.apache.hadoop.mapred.StatisticsCollector$Stat' primary='true'><SourceLine classname='org.apache.hadoop.mapred.StatisticsCollector$Stat' start='182' end='202' sourcepath='org/apache/hadoop/mapred/StatisticsCollector.java' sourcefile='StatisticsCollector.java'><Message>At StatisticsCollector.java:[lines 182-202]</Message></SourceLine><Message>In class org.apache.hadoop.mapred.StatisticsCollector$Stat</Message></Class><Field isStatic='false' classname='org.apache.hadoop.mapred.StatisticsCollector$Stat' signature='Ljava/lang/String;' name='name' primary='true'><SourceLine classname='org.apache.hadoop.mapred.StatisticsCollector$Stat' sourcepath='org/apache/hadoop/mapred/StatisticsCollector.java' sourcefile='StatisticsCollector.java'><Message>In StatisticsCollector.java</Message></SourceLine><Message>Field org.apache.hadoop.mapred.StatisticsCollector$Stat.name</Message></Field><SourceLine endBytecode='6' classname='org.apache.hadoop.mapred.StatisticsCollector$Stat' start='187' end='187' sourcepath='org/apache/hadoop/mapred/StatisticsCollector.java' sourcefile='StatisticsCollector.java' startBytecode='6' primary='true'><Message>At StatisticsCollector.java:[line 187]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='854673954eab77dea095ec06e300db60' cweid='382' rank='16' abbrev='Dm' category='BAD_PRACTICE' priority='2' type='DM_EXIT' instanceOccurrenceMax='0'><ShortMessage>Method invokes System.exit(...)</ShortMessage><LongMessage>org.apache.hadoop.mapred.Task.commit(TaskUmbilicalProtocol, Task$TaskReporter, OutputCommitter) invokes System.exit(...), which shuts down the entire virtual machine</LongMessage><Class classname='org.apache.hadoop.mapred.Task' primary='true'><SourceLine classname='org.apache.hadoop.mapred.Task' start='83' end='1910' sourcepath='org/apache/hadoop/mapred/Task.java' sourcefile='Task.java'><Message>At Task.java:[lines 83-1910]</Message></SourceLine><Message>In class org.apache.hadoop.mapred.Task</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapred.Task' signature='(Lorg/apache/hadoop/mapred/TaskUmbilicalProtocol;Lorg/apache/hadoop/mapred/Task$TaskReporter;Lorg/apache/hadoop/mapreduce/OutputCommitter;)V' name='commit' primary='true'><SourceLine endBytecode='432' classname='org.apache.hadoop.mapred.Task' start='1384' end='1417' sourcepath='org/apache/hadoop/mapred/Task.java' sourcefile='Task.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapred.Task.commit(TaskUmbilicalProtocol, Task$TaskReporter, OutputCommitter)</Message></Method><SourceLine endBytecode='90' classname='org.apache.hadoop.mapred.Task' start='1402' end='1402' sourcepath='org/apache/hadoop/mapred/Task.java' sourcefile='Task.java' startBytecode='90' primary='true'><Message>At Task.java:[line 1402]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='9da5212b9c6413bdbf948f3fd2c2e941' cweid='382' rank='16' abbrev='Dm' category='BAD_PRACTICE' priority='2' type='DM_EXIT' instanceOccurrenceMax='0'><ShortMessage>Method invokes System.exit(...)</ShortMessage><LongMessage>org.apache.hadoop.mapred.Task.done(TaskUmbilicalProtocol, Task$TaskReporter) invokes System.exit(...), which shuts down the entire virtual machine</LongMessage><Class classname='org.apache.hadoop.mapred.Task' primary='true'><SourceLine classname='org.apache.hadoop.mapred.Task' start='83' end='1910' sourcepath='org/apache/hadoop/mapred/Task.java' sourcefile='Task.java'><Message>At Task.java:[lines 83-1910]</Message></SourceLine><Message>In class org.apache.hadoop.mapred.Task</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapred.Task' signature='(Lorg/apache/hadoop/mapred/TaskUmbilicalProtocol;Lorg/apache/hadoop/mapred/Task$TaskReporter;)V' name='done' primary='true'><SourceLine endBytecode='525' classname='org.apache.hadoop.mapred.Task' start='1223' end='1276' sourcepath='org/apache/hadoop/mapred/Task.java' sourcefile='Task.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapred.Task.done(TaskUmbilicalProtocol, Task$TaskReporter)</Message></Method><SourceLine endBytecode='175' classname='org.apache.hadoop.mapred.Task' start='1249' end='1249' sourcepath='org/apache/hadoop/mapred/Task.java' sourcefile='Task.java' startBytecode='175' primary='true'><Message>At Task.java:[line 1249]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='32925ec5fb2e0e443b5c79850b0322b7' cweid='382' rank='16' abbrev='Dm' category='BAD_PRACTICE' priority='2' type='DM_EXIT' instanceOccurrenceMax='0'><ShortMessage>Method invokes System.exit(...)</ShortMessage><LongMessage>org.apache.hadoop.mapred.Task.reportFatalError(TaskAttemptID, Throwable, String, boolean) invokes System.exit(...), which shuts down the entire virtual machine</LongMessage><Class classname='org.apache.hadoop.mapred.Task' primary='true'><SourceLine classname='org.apache.hadoop.mapred.Task' start='83' end='1910' sourcepath='org/apache/hadoop/mapred/Task.java' sourcefile='Task.java'><Message>At Task.java:[lines 83-1910]</Message></SourceLine><Message>In class org.apache.hadoop.mapred.Task</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapred.Task' signature='(Lorg/apache/hadoop/mapred/TaskAttemptID;Ljava/lang/Throwable;Ljava/lang/String;Z)V' name='reportFatalError' primary='true'><SourceLine endBytecode='296' classname='org.apache.hadoop.mapred.Task' start='360' end='376' sourcepath='org/apache/hadoop/mapred/Task.java' sourcefile='Task.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapred.Task.reportFatalError(TaskAttemptID, Throwable, String, boolean)</Message></Method><SourceLine endBytecode='76' classname='org.apache.hadoop.mapred.Task' start='374' end='374' sourcepath='org/apache/hadoop/mapred/Task.java' sourcefile='Task.java' startBytecode='76' primary='true'><Message>At Task.java:[line 374]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='c3d26ccfede5313fdf9ff4e7ba5a96a1' cweid='374' rank='18' abbrev='EI' category='MALICIOUS_CODE' priority='2' type='EI_EXPOSE_REP' instanceOccurrenceMax='0'><ShortMessage>May expose internal representation by returning reference to mutable object</ShortMessage><LongMessage>org.apache.hadoop.mapred.Task.getEncryptedSpillKey() may expose internal representation by returning Task.encryptedSpillKey</LongMessage><Class classname='org.apache.hadoop.mapred.Task' primary='true'><SourceLine classname='org.apache.hadoop.mapred.Task' start='83' end='1910' sourcepath='org/apache/hadoop/mapred/Task.java' sourcefile='Task.java'><Message>At Task.java:[lines 83-1910]</Message></SourceLine><Message>In class org.apache.hadoop.mapred.Task</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapred.Task' signature='()[B' name='getEncryptedSpillKey' primary='true'><SourceLine endBytecode='46' classname='org.apache.hadoop.mapred.Task' start='281' end='281' sourcepath='org/apache/hadoop/mapred/Task.java' sourcefile='Task.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapred.Task.getEncryptedSpillKey()</Message></Method><Field isStatic='false' classname='org.apache.hadoop.mapred.Task' signature='[B' name='encryptedSpillKey' primary='true'><SourceLine classname='org.apache.hadoop.mapred.Task' sourcepath='org/apache/hadoop/mapred/Task.java' sourcefile='Task.java'><Message>In Task.java</Message></SourceLine><Message>Field org.apache.hadoop.mapred.Task.encryptedSpillKey</Message></Field><SourceLine endBytecode='4' classname='org.apache.hadoop.mapred.Task' start='281' end='281' sourcepath='org/apache/hadoop/mapred/Task.java' sourcefile='Task.java' startBytecode='4' primary='true'><Message>At Task.java:[line 281]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='8461dfaa8584af5fcd15f09c22c5d670' cweid='374' rank='18' abbrev='EI2' category='MALICIOUS_CODE' priority='2' type='EI_EXPOSE_REP2' instanceOccurrenceMax='0'><ShortMessage>May expose internal representation by incorporating reference to mutable object</ShortMessage><LongMessage>org.apache.hadoop.mapred.Task.setEncryptedSpillKey(byte[]) may expose internal representation by storing an externally mutable object into Task.encryptedSpillKey</LongMessage><Class classname='org.apache.hadoop.mapred.Task' primary='true'><SourceLine classname='org.apache.hadoop.mapred.Task' start='83' end='1910' sourcepath='org/apache/hadoop/mapred/Task.java' sourcefile='Task.java'><Message>At Task.java:[lines 83-1910]</Message></SourceLine><Message>In class org.apache.hadoop.mapred.Task</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapred.Task' signature='([B)V' name='setEncryptedSpillKey' primary='true'><SourceLine endBytecode='78' classname='org.apache.hadoop.mapred.Task' start='289' end='292' sourcepath='org/apache/hadoop/mapred/Task.java' sourcefile='Task.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapred.Task.setEncryptedSpillKey(byte[])</Message></Method><Field isStatic='false' classname='org.apache.hadoop.mapred.Task' signature='[B' name='encryptedSpillKey' primary='true'><SourceLine classname='org.apache.hadoop.mapred.Task' sourcepath='org/apache/hadoop/mapred/Task.java' sourcefile='Task.java'><Message>In Task.java</Message></SourceLine><Message>Field org.apache.hadoop.mapred.Task.encryptedSpillKey</Message></Field><LocalVariable role='LOCAL_VARIABLE_NAMED' pc='6' name='encryptedSpillKey' register='1'><Message>Local variable named encryptedSpillKey</Message></LocalVariable><SourceLine endBytecode='6' classname='org.apache.hadoop.mapred.Task' start='290' end='290' sourcepath='org/apache/hadoop/mapred/Task.java' sourcefile='Task.java' startBytecode='6' primary='true'><Message>At Task.java:[line 290]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='7e65c8e702576f6851a09e041402be99' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.mapred.Task.MERGED_OUTPUT_PREFIX isn't final but should be</LongMessage><Class classname='org.apache.hadoop.mapred.Task' primary='true'><SourceLine classname='org.apache.hadoop.mapred.Task' start='83' end='1910' sourcepath='org/apache/hadoop/mapred/Task.java' sourcefile='Task.java'><Message>At Task.java:[lines 83-1910]</Message></SourceLine><Message>In class org.apache.hadoop.mapred.Task</Message></Class><Field isStatic='true' classname='org.apache.hadoop.mapred.Task' signature='Ljava/lang/String;' name='MERGED_OUTPUT_PREFIX' primary='true'><SourceLine classname='org.apache.hadoop.mapred.Task' sourcepath='org/apache/hadoop/mapred/Task.java' sourcefile='Task.java'><Message>In Task.java</Message></SourceLine><Message>Field org.apache.hadoop.mapred.Task.MERGED_OUTPUT_PREFIX</Message></Field><SourceLine endBytecode='11' classname='org.apache.hadoop.mapred.Task' start='87' end='87' sourcepath='org/apache/hadoop/mapred/Task.java' sourcefile='Task.java' startBytecode='11' primary='true'><Message>At Task.java:[line 87]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='bdd397c4a697a0acf8920253ffa3e76c' rank='20' abbrev='UwF' category='STYLE' priority='3' type='UWF_FIELD_NOT_INITIALIZED_IN_CONSTRUCTOR' instanceOccurrenceMax='0'><ShortMessage>Field not initialized in constructor but dereferenced without null check</ShortMessage><LongMessage>Task$CombineOutputCollector.writer not initialized in constructor and dereferenced in org.apache.hadoop.mapred.Task$CombineOutputCollector.collect(Object, Object)</LongMessage><Class classname='org.apache.hadoop.mapred.Task$CombineOutputCollector' primary='true'><SourceLine classname='org.apache.hadoop.mapred.Task$CombineOutputCollector' start='1549' end='1566' sourcepath='org/apache/hadoop/mapred/Task.java' sourcefile='Task.java'><Message>At Task.java:[lines 1549-1566]</Message></SourceLine><Message>In class org.apache.hadoop.mapred.Task$CombineOutputCollector</Message></Class><Field isStatic='false' classname='org.apache.hadoop.mapred.Task$CombineOutputCollector' signature='Lorg/apache/hadoop/mapred/IFile$Writer;' name='writer' primary='true'><SourceLine classname='org.apache.hadoop.mapred.Task$CombineOutputCollector' sourcepath='org/apache/hadoop/mapred/Task.java' sourcefile='Task.java'><Message>In Task.java</Message></SourceLine><Message>Field org.apache.hadoop.mapred.Task$CombineOutputCollector.writer</Message></Field><Method isStatic='false' classname='org.apache.hadoop.mapred.Task$CombineOutputCollector' signature='(Ljava/lang/Object;Ljava/lang/Object;)V' name='collect' primary='true'><SourceLine endBytecode='168' classname='org.apache.hadoop.mapred.Task$CombineOutputCollector' start='1561' end='1566' sourcepath='org/apache/hadoop/mapred/Task.java' sourcefile='Task.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapred.Task$CombineOutputCollector.collect(Object, Object)</Message></Method><SourceLine endBytecode='14' classname='org.apache.hadoop.mapred.Task$CombineOutputCollector' start='1562' end='1562' sourcepath='org/apache/hadoop/mapred/Task.java' sourcefile='Task.java' startBytecode='14' primary='true'><Message>At Task.java:[line 1562]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='bee17da3dbabaaa7f5c7e8f355258e3b' cweid='382' rank='16' abbrev='Dm' category='BAD_PRACTICE' priority='2' type='DM_EXIT' instanceOccurrenceMax='0'><ShortMessage>Method invokes System.exit(...)</ShortMessage><LongMessage>org.apache.hadoop.mapred.Task$TaskReporter.run() invokes System.exit(...), which shuts down the entire virtual machine</LongMessage><Class classname='org.apache.hadoop.mapred.Task$TaskReporter' primary='true'><SourceLine classname='org.apache.hadoop.mapred.Task$TaskReporter' start='646' end='992' sourcepath='org/apache/hadoop/mapred/Task.java' sourcefile='Task.java'><Message>At Task.java:[lines 646-992]</Message></SourceLine><Message>In class org.apache.hadoop.mapred.Task$TaskReporter</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapred.Task$TaskReporter' signature='()V' name='run' primary='true'><SourceLine endBytecode='1416' classname='org.apache.hadoop.mapred.Task$TaskReporter' start='851' end='945' sourcepath='org/apache/hadoop/mapred/Task.java' sourcefile='Task.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapred.Task$TaskReporter.run()</Message></Method><SourceLine endBytecode='318' classname='org.apache.hadoop.mapred.Task$TaskReporter' start='903' end='903' sourcepath='org/apache/hadoop/mapred/Task.java' sourcefile='Task.java' startBytecode='318' primary='true'><Message>At Task.java:[line 903]</Message></SourceLine><SourceLine role='SOURCE_LINE_ANOTHER_INSTANCE' endBytecode='683' classname='org.apache.hadoop.mapred.Task$TaskReporter' start='939' end='939' sourcepath='org/apache/hadoop/mapred/Task.java' sourcefile='Task.java' startBytecode='683'><Message>Another occurrence at Task.java:[line 939]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='54555a9a145605037ad515896648c0e' rank='17' abbrev='No' category='MT_CORRECTNESS' priority='3' type='NO_NOTIFY_NOT_NOTIFYALL' instanceOccurrenceMax='0'><ShortMessage>Using notify() rather than notifyAll()</ShortMessage><LongMessage>Using notify rather than notifyAll in org.apache.hadoop.mapred.Task$TaskReporter.resetDoneFlag()</LongMessage><Class classname='org.apache.hadoop.mapred.Task$TaskReporter' primary='true'><SourceLine classname='org.apache.hadoop.mapred.Task$TaskReporter' start='646' end='992' sourcepath='org/apache/hadoop/mapred/Task.java' sourcefile='Task.java'><Message>At Task.java:[lines 646-992]</Message></SourceLine><Message>In class org.apache.hadoop.mapred.Task$TaskReporter</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapred.Task$TaskReporter' signature='()V' name='resetDoneFlag' primary='true'><SourceLine endBytecode='130' classname='org.apache.hadoop.mapred.Task$TaskReporter' start='947' end='951' sourcepath='org/apache/hadoop/mapred/Task.java' sourcefile='Task.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapred.Task$TaskReporter.resetDoneFlag()</Message></Method><SourceLine endBytecode='16' classname='org.apache.hadoop.mapred.Task$TaskReporter' start='949' end='949' sourcepath='org/apache/hadoop/mapred/Task.java' sourcefile='Task.java' startBytecode='16' primary='true'><Message>At Task.java:[line 949]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='1d5e73d9353041df57f849f17814bf22' rank='17' abbrev='No' category='MT_CORRECTNESS' priority='3' type='NO_NOTIFY_NOT_NOTIFYALL' instanceOccurrenceMax='0'><ShortMessage>Using notify() rather than notifyAll()</ShortMessage><LongMessage>Using notify rather than notifyAll in org.apache.hadoop.mapred.Task$TaskReporter.stopCommunicationThread()</LongMessage><Class classname='org.apache.hadoop.mapred.Task$TaskReporter' primary='true'><SourceLine classname='org.apache.hadoop.mapred.Task$TaskReporter' start='646' end='992' sourcepath='org/apache/hadoop/mapred/Task.java' sourcefile='Task.java'><Message>At Task.java:[lines 646-992]</Message></SourceLine><Message>In class org.apache.hadoop.mapred.Task$TaskReporter</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapred.Task$TaskReporter' signature='()V' name='stopCommunicationThread' primary='true'><SourceLine endBytecode='235' classname='org.apache.hadoop.mapred.Task$TaskReporter' start='976' end='992' sourcepath='org/apache/hadoop/mapred/Task.java' sourcefile='Task.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapred.Task$TaskReporter.stopCommunicationThread()</Message></Method><SourceLine endBytecode='18' classname='org.apache.hadoop.mapred.Task$TaskReporter' start='981' end='981' sourcepath='org/apache/hadoop/mapred/Task.java' sourcefile='Task.java' startBytecode='18' primary='true'><Message>At Task.java:[line 981]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='d7cac22b4355d4d0931b0d51d18622ba' rank='19' abbrev='Se' category='BAD_PRACTICE' priority='3' type='SE_BAD_FIELD' instanceOccurrenceMax='0'><ShortMessage>Non-transient non-serializable instance field in serializable class</ShortMessage><LongMessage>Class org.apache.hadoop.mapred.Task$TaskReporter$TaskLimitException defines non-transient non-serializable instance field this$1</LongMessage><Class classname='org.apache.hadoop.mapred.Task$TaskReporter$TaskLimitException' primary='true'><SourceLine classname='org.apache.hadoop.mapred.Task$TaskReporter$TaskLimitException' start='750' end='752' sourcepath='org/apache/hadoop/mapred/Task.java' sourcefile='Task.java'><Message>At Task.java:[lines 750-752]</Message></SourceLine><Message>In class org.apache.hadoop.mapred.Task$TaskReporter$TaskLimitException</Message></Class><Field isStatic='false' classname='org.apache.hadoop.mapred.Task$TaskReporter$TaskLimitException' signature='Lorg/apache/hadoop/mapred/Task$TaskReporter;' name='this$1' primary='true'><SourceLine classname='org.apache.hadoop.mapred.Task$TaskReporter$TaskLimitException' sourcepath='org/apache/hadoop/mapred/Task.java' sourcefile='Task.java'><Message>In Task.java</Message></SourceLine><Message>Field org.apache.hadoop.mapred.Task$TaskReporter$TaskLimitException.this$1</Message></Field><Type role='TYPE_FOUND' descriptor='Lorg/apache/hadoop/mapred/Task$TaskReporter;'><SourceLine classname='org.apache.hadoop.mapred.Task$TaskReporter' start='646' end='992' sourcepath='org/apache/hadoop/mapred/Task.java' sourcefile='Task.java'><Message>At Task.java:[lines 646-992]</Message></SourceLine><Message>Actual type org.apache.hadoop.mapred.Task$TaskReporter</Message></Type><SourceLine synthetic='true' classname='org.apache.hadoop.mapred.Task$TaskReporter$TaskLimitException' sourcepath='org/apache/hadoop/mapred/Task.java' sourcefile='Task.java'><Message>In Task.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='d5126ed60c91e2953e2798f6d340ccb' rank='16' abbrev='Nm' category='BAD_PRACTICE' priority='2' type='NM_SAME_SIMPLE_NAME_AS_INTERFACE' instanceOccurrenceMax='0'><ShortMessage>Class names shouldn't shadow simple name of implemented interface</ShortMessage><LongMessage>The class name org.apache.hadoop.mapred.TaskAttemptContext shadows the simple name of implemented interface org.apache.hadoop.mapreduce.TaskAttemptContext</LongMessage><Class classname='org.apache.hadoop.mapred.TaskAttemptContext' primary='true'><SourceLine classname='org.apache.hadoop.mapred.TaskAttemptContext' start='25' end='25' sourcepath='org/apache/hadoop/mapred/TaskAttemptContext.java' sourcefile='TaskAttemptContext.java'><Message>At TaskAttemptContext.java:[line 25]</Message></SourceLine><Message>In class org.apache.hadoop.mapred.TaskAttemptContext</Message></Class><Class classname='org.apache.hadoop.mapreduce.TaskAttemptContext'><SourceLine classname='org.apache.hadoop.mapreduce.TaskAttemptContext' sourcepath='org/apache/hadoop/mapreduce/TaskAttemptContext.java' sourcefile='TaskAttemptContext.java'><Message>In TaskAttemptContext.java</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.TaskAttemptContext</Message></Class><SourceLine synthetic='true' classname='org.apache.hadoop.mapred.TaskAttemptContext' start='25' end='25' sourcepath='org/apache/hadoop/mapred/TaskAttemptContext.java' sourcefile='TaskAttemptContext.java'><Message>At TaskAttemptContext.java:[line 25]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='9d50576d7248d5a2ef79e6f9563ad191' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST_OF_RETURN_VALUE' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast of return value from method</ShortMessage><LongMessage>Unchecked/unconfirmed cast from org.apache.hadoop.conf.Configuration to org.apache.hadoop.mapred.JobConf of return value in org.apache.hadoop.mapred.TaskAttemptContextImpl.getJobConf()</LongMessage><Class classname='org.apache.hadoop.mapred.TaskAttemptContextImpl' primary='true'><SourceLine classname='org.apache.hadoop.mapred.TaskAttemptContextImpl' start='26' end='90' sourcepath='org/apache/hadoop/mapred/TaskAttemptContextImpl.java' sourcefile='TaskAttemptContextImpl.java'><Message>At TaskAttemptContextImpl.java:[lines 26-90]</Message></SourceLine><Message>In class org.apache.hadoop.mapred.TaskAttemptContextImpl</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapred.TaskAttemptContextImpl' signature='()Lorg/apache/hadoop/mapred/JobConf;' name='getJobConf' primary='true'><SourceLine endBytecode='3' classname='org.apache.hadoop.mapred.TaskAttemptContextImpl' start='57' end='57' sourcepath='org/apache/hadoop/mapred/TaskAttemptContextImpl.java' sourcefile='TaskAttemptContextImpl.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapred.TaskAttemptContextImpl.getJobConf()</Message></Method><Type role='TYPE_FOUND' descriptor='Lorg/apache/hadoop/conf/Configuration;'><SourceLine classname='org.apache.hadoop.conf.Configuration' start='223' end='3860' sourcepath='org/apache/hadoop/conf/Configuration.java' sourcefile='Configuration.java'><Message>At Configuration.java:[lines 223-3860]</Message></SourceLine><Message>Actual type org.apache.hadoop.conf.Configuration</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/mapred/JobConf;'><SourceLine classname='org.apache.hadoop.mapred.JobConf' start='118' end='2224' sourcepath='org/apache/hadoop/mapred/JobConf.java' sourcefile='JobConf.java'><Message>At JobConf.java:[lines 118-2224]</Message></SourceLine><Message>Expected org.apache.hadoop.mapred.JobConf</Message></Type><SourceLine endBytecode='4' classname='org.apache.hadoop.mapred.TaskAttemptContextImpl' start='57' end='57' sourcepath='org/apache/hadoop/mapred/TaskAttemptContextImpl.java' sourcefile='TaskAttemptContextImpl.java' startBytecode='4' primary='true'><Message>At TaskAttemptContextImpl.java:[line 57]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='cdd44ba9e58111f64e8f83d1e81b1711' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST_OF_RETURN_VALUE' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast of return value from method</ShortMessage><LongMessage>Unchecked/unconfirmed cast from org.apache.hadoop.mapreduce.TaskAttemptID to org.apache.hadoop.mapred.TaskAttemptID of return value in org.apache.hadoop.mapred.TaskAttemptContextImpl.getTaskAttemptID()</LongMessage><Class classname='org.apache.hadoop.mapred.TaskAttemptContextImpl' primary='true'><SourceLine classname='org.apache.hadoop.mapred.TaskAttemptContextImpl' start='26' end='90' sourcepath='org/apache/hadoop/mapred/TaskAttemptContextImpl.java' sourcefile='TaskAttemptContextImpl.java'><Message>At TaskAttemptContextImpl.java:[lines 26-90]</Message></SourceLine><Message>In class org.apache.hadoop.mapred.TaskAttemptContextImpl</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapred.TaskAttemptContextImpl' signature='()Lorg/apache/hadoop/mapred/TaskAttemptID;' name='getTaskAttemptID' primary='true'><SourceLine endBytecode='3' classname='org.apache.hadoop.mapred.TaskAttemptContextImpl' start='49' end='49' sourcepath='org/apache/hadoop/mapred/TaskAttemptContextImpl.java' sourcefile='TaskAttemptContextImpl.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapred.TaskAttemptContextImpl.getTaskAttemptID()</Message></Method><Type role='TYPE_FOUND' descriptor='Lorg/apache/hadoop/mapreduce/TaskAttemptID;'><SourceLine classname='org.apache.hadoop.mapreduce.TaskAttemptID' start='48' end='201' sourcepath='org/apache/hadoop/mapreduce/TaskAttemptID.java' sourcefile='TaskAttemptID.java'><Message>At TaskAttemptID.java:[lines 48-201]</Message></SourceLine><Message>Actual type org.apache.hadoop.mapreduce.TaskAttemptID</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/mapred/TaskAttemptID;'><SourceLine classname='org.apache.hadoop.mapred.TaskAttemptID' start='48' end='193' sourcepath='org/apache/hadoop/mapred/TaskAttemptID.java' sourcefile='TaskAttemptID.java'><Message>At TaskAttemptID.java:[lines 48-193]</Message></SourceLine><Message>Expected org.apache.hadoop.mapred.TaskAttemptID</Message></Type><SourceLine endBytecode='4' classname='org.apache.hadoop.mapred.TaskAttemptContextImpl' start='49' end='49' sourcepath='org/apache/hadoop/mapred/TaskAttemptContextImpl.java' sourcefile='TaskAttemptContextImpl.java' startBytecode='4' primary='true'><Message>At TaskAttemptContextImpl.java:[line 49]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='8d7ccf5cfee76a55c945874414ba0a30' rank='19' abbrev='Nm' category='BAD_PRACTICE' priority='3' type='NM_CONFUSING' instanceOccurrenceMax='1'><ShortMessage>Confusing method names</ShortMessage><LongMessage>Confusing to have methods org.apache.hadoop.mapred.TaskAttemptContextImpl.getTaskAttemptID() and org.apache.hadoop.mapred.TaskCompletionEvent.getTaskAttemptId()</LongMessage><Class classname='org.apache.hadoop.mapred.TaskAttemptContextImpl' primary='true'><SourceLine classname='org.apache.hadoop.mapred.TaskAttemptContextImpl' start='26' end='90' sourcepath='org/apache/hadoop/mapred/TaskAttemptContextImpl.java' sourcefile='TaskAttemptContextImpl.java'><Message>At TaskAttemptContextImpl.java:[lines 26-90]</Message></SourceLine><Message>In class org.apache.hadoop.mapred.TaskAttemptContextImpl</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapred.TaskAttemptContextImpl' signature='()Lorg/apache/hadoop/mapred/TaskAttemptID;' name='getTaskAttemptID' primary='true'><SourceLine endBytecode='49' classname='org.apache.hadoop.mapred.TaskAttemptContextImpl' start='49' end='49' sourcepath='org/apache/hadoop/mapred/TaskAttemptContextImpl.java' sourcefile='TaskAttemptContextImpl.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapred.TaskAttemptContextImpl.getTaskAttemptID()</Message></Method><Class classname='org.apache.hadoop.mapred.TaskCompletionEvent'><SourceLine classname='org.apache.hadoop.mapred.TaskCompletionEvent' start='29' end='193' sourcepath='org/apache/hadoop/mapred/TaskCompletionEvent.java' sourcefile='TaskCompletionEvent.java'><Message>At TaskCompletionEvent.java:[lines 29-193]</Message></SourceLine><Message>In class org.apache.hadoop.mapred.TaskCompletionEvent</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapred.TaskCompletionEvent' signature='()Lorg/apache/hadoop/mapred/TaskAttemptID;' name='getTaskAttemptId'><SourceLine endBytecode='49' classname='org.apache.hadoop.mapred.TaskCompletionEvent' start='119' end='119' sourcepath='org/apache/hadoop/mapred/TaskCompletionEvent.java' sourcefile='TaskCompletionEvent.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapred.TaskCompletionEvent.getTaskAttemptId()</Message></Method><SourceLine synthetic='true' endBytecode='49' classname='org.apache.hadoop.mapred.TaskAttemptContextImpl' start='49' end='49' sourcepath='org/apache/hadoop/mapred/TaskAttemptContextImpl.java' sourcefile='TaskAttemptContextImpl.java' startBytecode='0'><Message>At TaskAttemptContextImpl.java:[line 49]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='1' instanceHash='8d7ccf5cfee76a55c945874414ba0a30' rank='19' abbrev='Nm' category='BAD_PRACTICE' priority='3' type='NM_CONFUSING' instanceOccurrenceMax='1'><ShortMessage>Confusing method names</ShortMessage><LongMessage>Confusing to have methods org.apache.hadoop.mapred.TaskAttemptContextImpl.getTaskAttemptID() and org.apache.hadoop.mapred.TaskCompletionEvent.getTaskAttemptId()</LongMessage><Class classname='org.apache.hadoop.mapred.TaskAttemptContextImpl' primary='true'><SourceLine classname='org.apache.hadoop.mapred.TaskAttemptContextImpl' start='26' end='90' sourcepath='org/apache/hadoop/mapred/TaskAttemptContextImpl.java' sourcefile='TaskAttemptContextImpl.java'><Message>At TaskAttemptContextImpl.java:[lines 26-90]</Message></SourceLine><Message>In class org.apache.hadoop.mapred.TaskAttemptContextImpl</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapred.TaskAttemptContextImpl' signature='()Lorg/apache/hadoop/mapreduce/TaskAttemptID;' name='getTaskAttemptID' primary='true'><SourceLine endBytecode='46' classname='org.apache.hadoop.mapred.TaskAttemptContextImpl' start='26' end='26' sourcepath='org/apache/hadoop/mapred/TaskAttemptContextImpl.java' sourcefile='TaskAttemptContextImpl.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapred.TaskAttemptContextImpl.getTaskAttemptID()</Message></Method><Class classname='org.apache.hadoop.mapred.TaskCompletionEvent'><SourceLine classname='org.apache.hadoop.mapred.TaskCompletionEvent' start='29' end='193' sourcepath='org/apache/hadoop/mapred/TaskCompletionEvent.java' sourcefile='TaskCompletionEvent.java'><Message>At TaskCompletionEvent.java:[lines 29-193]</Message></SourceLine><Message>In class org.apache.hadoop.mapred.TaskCompletionEvent</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapred.TaskCompletionEvent' signature='()Lorg/apache/hadoop/mapreduce/TaskAttemptID;' name='getTaskAttemptId'><SourceLine endBytecode='46' classname='org.apache.hadoop.mapred.TaskCompletionEvent' start='29' end='29' sourcepath='org/apache/hadoop/mapred/TaskCompletionEvent.java' sourcefile='TaskCompletionEvent.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapred.TaskCompletionEvent.getTaskAttemptId()</Message></Method><SourceLine synthetic='true' endBytecode='46' classname='org.apache.hadoop.mapred.TaskAttemptContextImpl' start='26' end='26' sourcepath='org/apache/hadoop/mapred/TaskAttemptContextImpl.java' sourcefile='TaskAttemptContextImpl.java' startBytecode='0'><Message>At TaskAttemptContextImpl.java:[line 26]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='41710e65ef3b53a547b38b63f53db38f' rank='14' abbrev='Nm' category='BAD_PRACTICE' priority='1' type='NM_SAME_SIMPLE_NAME_AS_SUPERCLASS' instanceOccurrenceMax='0'><ShortMessage>Class names shouldn't shadow simple name of superclass</ShortMessage><LongMessage>The class name org.apache.hadoop.mapred.TaskAttemptContextImpl shadows the simple name of the superclass org.apache.hadoop.mapreduce.task.TaskAttemptContextImpl</LongMessage><Class classname='org.apache.hadoop.mapred.TaskAttemptContextImpl' primary='true'><SourceLine classname='org.apache.hadoop.mapred.TaskAttemptContextImpl' start='26' end='90' sourcepath='org/apache/hadoop/mapred/TaskAttemptContextImpl.java' sourcefile='TaskAttemptContextImpl.java'><Message>At TaskAttemptContextImpl.java:[lines 26-90]</Message></SourceLine><Message>In class org.apache.hadoop.mapred.TaskAttemptContextImpl</Message></Class><Class classname='org.apache.hadoop.mapreduce.task.TaskAttemptContextImpl'><SourceLine classname='org.apache.hadoop.mapreduce.task.TaskAttemptContextImpl' start='39' end='130' sourcepath='org/apache/hadoop/mapreduce/task/TaskAttemptContextImpl.java' sourcefile='TaskAttemptContextImpl.java'><Message>At TaskAttemptContextImpl.java:[lines 39-130]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.task.TaskAttemptContextImpl</Message></Class><SourceLine synthetic='true' classname='org.apache.hadoop.mapred.TaskAttemptContextImpl' start='26' end='90' sourcepath='org/apache/hadoop/mapred/TaskAttemptContextImpl.java' sourcefile='TaskAttemptContextImpl.java'><Message>At TaskAttemptContextImpl.java:[lines 26-90]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='e4bb68471a09d840932bfa911480f19a' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST_OF_RETURN_VALUE' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast of return value from method</ShortMessage><LongMessage>Unchecked/unconfirmed cast from org.apache.hadoop.mapreduce.JobID to org.apache.hadoop.mapred.JobID of return value in org.apache.hadoop.mapred.TaskAttemptID.getJobID()</LongMessage><Class classname='org.apache.hadoop.mapred.TaskAttemptID' primary='true'><SourceLine classname='org.apache.hadoop.mapred.TaskAttemptID' start='48' end='193' sourcepath='org/apache/hadoop/mapred/TaskAttemptID.java' sourcefile='TaskAttemptID.java'><Message>At TaskAttemptID.java:[lines 48-193]</Message></SourceLine><Message>In class org.apache.hadoop.mapred.TaskAttemptID</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapred.TaskAttemptID' signature='()Lorg/apache/hadoop/mapred/JobID;' name='getJobID' primary='true'><SourceLine endBytecode='3' classname='org.apache.hadoop.mapred.TaskAttemptID' start='113' end='113' sourcepath='org/apache/hadoop/mapred/TaskAttemptID.java' sourcefile='TaskAttemptID.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapred.TaskAttemptID.getJobID()</Message></Method><Type role='TYPE_FOUND' descriptor='Lorg/apache/hadoop/mapreduce/JobID;'><SourceLine classname='org.apache.hadoop.mapreduce.JobID' start='47' end='156' sourcepath='org/apache/hadoop/mapreduce/JobID.java' sourcefile='JobID.java'><Message>At JobID.java:[lines 47-156]</Message></SourceLine><Message>Actual type org.apache.hadoop.mapreduce.JobID</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/mapred/JobID;'><SourceLine classname='org.apache.hadoop.mapred.JobID' start='53' end='118' sourcepath='org/apache/hadoop/mapred/JobID.java' sourcefile='JobID.java'><Message>At JobID.java:[lines 53-118]</Message></SourceLine><Message>Expected org.apache.hadoop.mapred.JobID</Message></Type><SourceLine endBytecode='4' classname='org.apache.hadoop.mapred.TaskAttemptID' start='113' end='113' sourcepath='org/apache/hadoop/mapred/TaskAttemptID.java' sourcefile='TaskAttemptID.java' startBytecode='4' primary='true'><Message>At TaskAttemptID.java:[line 113]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='dd3421aff2b62a66dc5afea6cb28dac9' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST_OF_RETURN_VALUE' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast of return value from method</ShortMessage><LongMessage>Unchecked/unconfirmed cast from org.apache.hadoop.mapreduce.TaskID to org.apache.hadoop.mapred.TaskID of return value in org.apache.hadoop.mapred.TaskAttemptID.getTaskID()</LongMessage><Class classname='org.apache.hadoop.mapred.TaskAttemptID' primary='true'><SourceLine classname='org.apache.hadoop.mapred.TaskAttemptID' start='48' end='193' sourcepath='org/apache/hadoop/mapred/TaskAttemptID.java' sourcefile='TaskAttemptID.java'><Message>At TaskAttemptID.java:[lines 48-193]</Message></SourceLine><Message>In class org.apache.hadoop.mapred.TaskAttemptID</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapred.TaskAttemptID' signature='()Lorg/apache/hadoop/mapred/TaskID;' name='getTaskID' primary='true'><SourceLine endBytecode='3' classname='org.apache.hadoop.mapred.TaskAttemptID' start='109' end='109' sourcepath='org/apache/hadoop/mapred/TaskAttemptID.java' sourcefile='TaskAttemptID.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapred.TaskAttemptID.getTaskID()</Message></Method><Type role='TYPE_FOUND' descriptor='Lorg/apache/hadoop/mapreduce/TaskID;'><SourceLine classname='org.apache.hadoop.mapreduce.TaskID' start='58' end='281' sourcepath='org/apache/hadoop/mapreduce/TaskID.java' sourcefile='TaskID.java'><Message>At TaskID.java:[lines 58-281]</Message></SourceLine><Message>Actual type org.apache.hadoop.mapreduce.TaskID</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/mapred/TaskID;'><SourceLine classname='org.apache.hadoop.mapred.TaskID' start='50' end='195' sourcepath='org/apache/hadoop/mapred/TaskID.java' sourcefile='TaskID.java'><Message>At TaskID.java:[lines 50-195]</Message></SourceLine><Message>Expected org.apache.hadoop.mapred.TaskID</Message></Type><SourceLine endBytecode='4' classname='org.apache.hadoop.mapred.TaskAttemptID' start='109' end='109' sourcepath='org/apache/hadoop/mapred/TaskAttemptID.java' sourcefile='TaskAttemptID.java' startBytecode='4' primary='true'><Message>At TaskAttemptID.java:[line 109]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='1de53f18359f72daa8215461b23fec4b' rank='19' abbrev='Nm' category='BAD_PRACTICE' priority='3' type='NM_CONFUSING' instanceOccurrenceMax='0'><ShortMessage>Confusing method names</ShortMessage><LongMessage>Confusing to have methods org.apache.hadoop.mapred.TaskAttemptID.getTaskID() and org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser$TaskInfo.getTaskId()</LongMessage><Class classname='org.apache.hadoop.mapred.TaskAttemptID' primary='true'><SourceLine classname='org.apache.hadoop.mapred.TaskAttemptID' start='48' end='193' sourcepath='org/apache/hadoop/mapred/TaskAttemptID.java' sourcefile='TaskAttemptID.java'><Message>At TaskAttemptID.java:[lines 48-193]</Message></SourceLine><Message>In class org.apache.hadoop.mapred.TaskAttemptID</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapred.TaskAttemptID' signature='()Lorg/apache/hadoop/mapreduce/TaskID;' name='getTaskID' primary='true'><SourceLine endBytecode='46' classname='org.apache.hadoop.mapred.TaskAttemptID' start='48' end='48' sourcepath='org/apache/hadoop/mapred/TaskAttemptID.java' sourcefile='TaskAttemptID.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapred.TaskAttemptID.getTaskID()</Message></Method><Class classname='org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser$TaskInfo'><SourceLine classname='org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser$TaskInfo' start='600' end='646' sourcepath='org/apache/hadoop/mapreduce/jobhistory/JobHistoryParser.java' sourcefile='JobHistoryParser.java'><Message>At JobHistoryParser.java:[lines 600-646]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser$TaskInfo</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser$TaskInfo' signature='()Lorg/apache/hadoop/mapreduce/TaskID;' name='getTaskId'><SourceLine endBytecode='46' classname='org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser$TaskInfo' start='621' end='621' sourcepath='org/apache/hadoop/mapreduce/jobhistory/JobHistoryParser.java' sourcefile='JobHistoryParser.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser$TaskInfo.getTaskId()</Message></Method><SourceLine synthetic='true' endBytecode='46' classname='org.apache.hadoop.mapred.TaskAttemptID' start='48' end='48' sourcepath='org/apache/hadoop/mapred/TaskAttemptID.java' sourcefile='TaskAttemptID.java' startBytecode='0'><Message>At TaskAttemptID.java:[line 48]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='649358042921c7cfa88e1363ae0e47d2' rank='14' abbrev='Nm' category='BAD_PRACTICE' priority='1' type='NM_SAME_SIMPLE_NAME_AS_SUPERCLASS' instanceOccurrenceMax='0'><ShortMessage>Class names shouldn't shadow simple name of superclass</ShortMessage><LongMessage>The class name org.apache.hadoop.mapred.TaskAttemptID shadows the simple name of the superclass org.apache.hadoop.mapreduce.TaskAttemptID</LongMessage><Class classname='org.apache.hadoop.mapred.TaskAttemptID' primary='true'><SourceLine classname='org.apache.hadoop.mapred.TaskAttemptID' start='48' end='193' sourcepath='org/apache/hadoop/mapred/TaskAttemptID.java' sourcefile='TaskAttemptID.java'><Message>At TaskAttemptID.java:[lines 48-193]</Message></SourceLine><Message>In class org.apache.hadoop.mapred.TaskAttemptID</Message></Class><Class classname='org.apache.hadoop.mapreduce.TaskAttemptID'><SourceLine classname='org.apache.hadoop.mapreduce.TaskAttemptID' start='48' end='201' sourcepath='org/apache/hadoop/mapreduce/TaskAttemptID.java' sourcefile='TaskAttemptID.java'><Message>At TaskAttemptID.java:[lines 48-201]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.TaskAttemptID</Message></Class><SourceLine synthetic='true' classname='org.apache.hadoop.mapred.TaskAttemptID' start='48' end='193' sourcepath='org/apache/hadoop/mapred/TaskAttemptID.java' sourcefile='TaskAttemptID.java'><Message>At TaskAttemptID.java:[lines 48-193]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='ce4420ee3c774394d306a9601d70c096' rank='14' abbrev='Nm' category='BAD_PRACTICE' priority='1' type='NM_SAME_SIMPLE_NAME_AS_SUPERCLASS' instanceOccurrenceMax='0'><ShortMessage>Class names shouldn't shadow simple name of superclass</ShortMessage><LongMessage>The class name org.apache.hadoop.mapred.TaskCompletionEvent shadows the simple name of the superclass org.apache.hadoop.mapreduce.TaskCompletionEvent</LongMessage><Class classname='org.apache.hadoop.mapred.TaskCompletionEvent' primary='true'><SourceLine classname='org.apache.hadoop.mapred.TaskCompletionEvent' start='29' end='193' sourcepath='org/apache/hadoop/mapred/TaskCompletionEvent.java' sourcefile='TaskCompletionEvent.java'><Message>At TaskCompletionEvent.java:[lines 29-193]</Message></SourceLine><Message>In class org.apache.hadoop.mapred.TaskCompletionEvent</Message></Class><Class classname='org.apache.hadoop.mapreduce.TaskCompletionEvent'><SourceLine classname='org.apache.hadoop.mapreduce.TaskCompletionEvent' start='76' end='249' sourcepath='org/apache/hadoop/mapreduce/TaskCompletionEvent.java' sourcefile='TaskCompletionEvent.java'><Message>At TaskCompletionEvent.java:[lines 76-249]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.TaskCompletionEvent</Message></Class><SourceLine synthetic='true' classname='org.apache.hadoop.mapred.TaskCompletionEvent' start='29' end='193' sourcepath='org/apache/hadoop/mapred/TaskCompletionEvent.java' sourcefile='TaskCompletionEvent.java'><Message>At TaskCompletionEvent.java:[lines 29-193]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='92962d56d0bfc18bfcd04651dbf70593' rank='4' abbrev='Nm' category='CORRECTNESS' priority='1' type='NM_WRONG_PACKAGE' instanceOccurrenceMax='0'><ShortMessage>Method doesn't override method in superclass due to wrong package for parameter</ShortMessage><LongMessage>org.apache.hadoop.mapred.TaskCompletionEvent.setTaskStatus(TaskCompletionEvent$Status) doesn't override method in superclass because parameter type org.apache.hadoop.mapred.TaskCompletionEvent$Status doesn't match superclass parameter type org.apache.hadoop.mapreduce.TaskCompletionEvent$Status</LongMessage><Class classname='org.apache.hadoop.mapred.TaskCompletionEvent' primary='true'><SourceLine classname='org.apache.hadoop.mapred.TaskCompletionEvent' start='29' end='193' sourcepath='org/apache/hadoop/mapred/TaskCompletionEvent.java' sourcefile='TaskCompletionEvent.java'><Message>At TaskCompletionEvent.java:[lines 29-193]</Message></SourceLine><Message>In class org.apache.hadoop.mapred.TaskCompletionEvent</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapred.TaskCompletionEvent' signature='(Lorg/apache/hadoop/mapred/TaskCompletionEvent$Status;)V' name='setTaskStatus' primary='true'><SourceLine endBytecode='75' classname='org.apache.hadoop.mapred.TaskCompletionEvent' start='164' end='166' sourcepath='org/apache/hadoop/mapred/TaskCompletionEvent.java' sourcefile='TaskCompletionEvent.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapred.TaskCompletionEvent.setTaskStatus(TaskCompletionEvent$Status)</Message></Method><Class role='CLASS_SUPERCLASS' classname='org.apache.hadoop.mapreduce.TaskCompletionEvent'><SourceLine classname='org.apache.hadoop.mapreduce.TaskCompletionEvent' start='76' end='249' sourcepath='org/apache/hadoop/mapreduce/TaskCompletionEvent.java' sourcefile='TaskCompletionEvent.java'><Message>At TaskCompletionEvent.java:[lines 76-249]</Message></SourceLine><Message>superclass is org.apache.hadoop.mapreduce.TaskCompletionEvent</Message></Class><Method isStatic='false' role='METHOD_DID_YOU_MEAN_TO_OVERRIDE' classname='org.apache.hadoop.mapreduce.TaskCompletionEvent' signature='(Lorg/apache/hadoop/mapreduce/TaskCompletionEvent$Status;)V' name='setTaskStatus'><SourceLine endBytecode='61' classname='org.apache.hadoop.mapreduce.TaskCompletionEvent' start='178' end='179' sourcepath='org/apache/hadoop/mapreduce/TaskCompletionEvent.java' sourcefile='TaskCompletionEvent.java' startBytecode='0'></SourceLine><Message>Did you intend to override org.apache.hadoop.mapreduce.TaskCompletionEvent.setTaskStatus(TaskCompletionEvent$Status)</Message></Method><Type role='TYPE_FOUND' descriptor='Lorg/apache/hadoop/mapred/TaskCompletionEvent$Status;'><SourceLine classname='org.apache.hadoop.mapred.TaskCompletionEvent$Status' start='33' end='64' sourcepath='org/apache/hadoop/mapred/TaskCompletionEvent.java' sourcefile='TaskCompletionEvent.java'><Message>At TaskCompletionEvent.java:[lines 33-64]</Message></SourceLine><Message>Actual type org.apache.hadoop.mapred.TaskCompletionEvent$Status</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/mapreduce/TaskCompletionEvent$Status;'><SourceLine classname='org.apache.hadoop.mapreduce.TaskCompletionEvent$Status' start='37' end='68' sourcepath='org/apache/hadoop/mapreduce/TaskCompletionEvent.java' sourcefile='TaskCompletionEvent.java'><Message>At TaskCompletionEvent.java:[lines 37-68]</Message></SourceLine><Message>Expected org.apache.hadoop.mapreduce.TaskCompletionEvent$Status</Message></Type><SourceLine synthetic='true' endBytecode='75' classname='org.apache.hadoop.mapred.TaskCompletionEvent' start='164' end='166' sourcepath='org/apache/hadoop/mapred/TaskCompletionEvent.java' sourcefile='TaskCompletionEvent.java' startBytecode='0'><Message>At TaskCompletionEvent.java:[lines 164-166]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='a88423a4491d2944097ec136545fe8b5' rank='6' abbrev='Nm' category='CORRECTNESS' priority='2' type='NM_WRONG_PACKAGE' instanceOccurrenceMax='0'><ShortMessage>Method doesn't override method in superclass due to wrong package for parameter</ShortMessage><LongMessage>org.apache.hadoop.mapred.TaskCompletionEvent.setTaskAttemptId(TaskAttemptID) doesn't override method in superclass because parameter type org.apache.hadoop.mapred.TaskAttemptID doesn't match superclass parameter type org.apache.hadoop.mapreduce.TaskAttemptID</LongMessage><Class classname='org.apache.hadoop.mapred.TaskCompletionEvent' primary='true'><SourceLine classname='org.apache.hadoop.mapred.TaskCompletionEvent' start='29' end='193' sourcepath='org/apache/hadoop/mapred/TaskCompletionEvent.java' sourcefile='TaskCompletionEvent.java'><Message>At TaskCompletionEvent.java:[lines 29-193]</Message></SourceLine><Message>In class org.apache.hadoop.mapred.TaskCompletionEvent</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapred.TaskCompletionEvent' signature='(Lorg/apache/hadoop/mapred/TaskAttemptID;)V' name='setTaskAttemptId' primary='true'><SourceLine endBytecode='61' classname='org.apache.hadoop.mapred.TaskCompletionEvent' start='155' end='156' sourcepath='org/apache/hadoop/mapred/TaskCompletionEvent.java' sourcefile='TaskCompletionEvent.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapred.TaskCompletionEvent.setTaskAttemptId(TaskAttemptID)</Message></Method><Class role='CLASS_SUPERCLASS' classname='org.apache.hadoop.mapreduce.TaskCompletionEvent'><SourceLine classname='org.apache.hadoop.mapreduce.TaskCompletionEvent' start='76' end='249' sourcepath='org/apache/hadoop/mapreduce/TaskCompletionEvent.java' sourcefile='TaskCompletionEvent.java'><Message>At TaskCompletionEvent.java:[lines 76-249]</Message></SourceLine><Message>superclass is org.apache.hadoop.mapreduce.TaskCompletionEvent</Message></Class><Method isStatic='false' role='METHOD_DID_YOU_MEAN_TO_OVERRIDE' classname='org.apache.hadoop.mapreduce.TaskCompletionEvent' signature='(Lorg/apache/hadoop/mapreduce/TaskAttemptID;)V' name='setTaskAttemptId'><SourceLine endBytecode='61' classname='org.apache.hadoop.mapreduce.TaskCompletionEvent' start='170' end='171' sourcepath='org/apache/hadoop/mapreduce/TaskCompletionEvent.java' sourcefile='TaskCompletionEvent.java' startBytecode='0'></SourceLine><Message>Did you intend to override org.apache.hadoop.mapreduce.TaskCompletionEvent.setTaskAttemptId(TaskAttemptID)</Message></Method><Type role='TYPE_FOUND' descriptor='Lorg/apache/hadoop/mapred/TaskAttemptID;'><SourceLine classname='org.apache.hadoop.mapred.TaskAttemptID' start='48' end='193' sourcepath='org/apache/hadoop/mapred/TaskAttemptID.java' sourcefile='TaskAttemptID.java'><Message>At TaskAttemptID.java:[lines 48-193]</Message></SourceLine><Message>Actual type org.apache.hadoop.mapred.TaskAttemptID</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/mapreduce/TaskAttemptID;'><SourceLine classname='org.apache.hadoop.mapreduce.TaskAttemptID' start='48' end='201' sourcepath='org/apache/hadoop/mapreduce/TaskAttemptID.java' sourcefile='TaskAttemptID.java'><Message>At TaskAttemptID.java:[lines 48-201]</Message></SourceLine><Message>Expected org.apache.hadoop.mapreduce.TaskAttemptID</Message></Type><SourceLine synthetic='true' endBytecode='61' classname='org.apache.hadoop.mapred.TaskCompletionEvent' start='155' end='156' sourcepath='org/apache/hadoop/mapred/TaskCompletionEvent.java' sourcefile='TaskCompletionEvent.java' startBytecode='0'><Message>At TaskCompletionEvent.java:[lines 155-156]</Message></SourceLine><Property name='edu.umd.cs.findbugs.detect.Naming$NamingProperty.CONFUSING_METHOD_IS_CALLED' value='true'></Property></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='2b17b1a5f5cdedaf2252dcbfbff0ce36' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST_OF_RETURN_VALUE' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast of return value from method</ShortMessage><LongMessage>Unchecked/unconfirmed cast from org.apache.hadoop.mapreduce.JobID to org.apache.hadoop.mapred.JobID of return value in org.apache.hadoop.mapred.TaskID.getJobID()</LongMessage><Class classname='org.apache.hadoop.mapred.TaskID' primary='true'><SourceLine classname='org.apache.hadoop.mapred.TaskID' start='50' end='195' sourcepath='org/apache/hadoop/mapred/TaskID.java' sourcefile='TaskID.java'><Message>At TaskID.java:[lines 50-195]</Message></SourceLine><Message>In class org.apache.hadoop.mapred.TaskID</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapred.TaskID' signature='()Lorg/apache/hadoop/mapred/JobID;' name='getJobID' primary='true'><SourceLine endBytecode='3' classname='org.apache.hadoop.mapred.TaskID' start='127' end='127' sourcepath='org/apache/hadoop/mapred/TaskID.java' sourcefile='TaskID.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapred.TaskID.getJobID()</Message></Method><Type role='TYPE_FOUND' descriptor='Lorg/apache/hadoop/mapreduce/JobID;'><SourceLine classname='org.apache.hadoop.mapreduce.JobID' start='47' end='156' sourcepath='org/apache/hadoop/mapreduce/JobID.java' sourcefile='JobID.java'><Message>At JobID.java:[lines 47-156]</Message></SourceLine><Message>Actual type org.apache.hadoop.mapreduce.JobID</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/mapred/JobID;'><SourceLine classname='org.apache.hadoop.mapred.JobID' start='53' end='118' sourcepath='org/apache/hadoop/mapred/JobID.java' sourcefile='JobID.java'><Message>At JobID.java:[lines 53-118]</Message></SourceLine><Message>Expected org.apache.hadoop.mapred.JobID</Message></Type><SourceLine endBytecode='4' classname='org.apache.hadoop.mapred.TaskID' start='127' end='127' sourcepath='org/apache/hadoop/mapred/TaskID.java' sourcefile='TaskID.java' startBytecode='4' primary='true'><Message>At TaskID.java:[line 127]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='87bbdf8a21d8276099800ec26f99dab3' rank='14' abbrev='Nm' category='BAD_PRACTICE' priority='1' type='NM_SAME_SIMPLE_NAME_AS_SUPERCLASS' instanceOccurrenceMax='0'><ShortMessage>Class names shouldn't shadow simple name of superclass</ShortMessage><LongMessage>The class name org.apache.hadoop.mapred.TaskID shadows the simple name of the superclass org.apache.hadoop.mapreduce.TaskID</LongMessage><Class classname='org.apache.hadoop.mapred.TaskID' primary='true'><SourceLine classname='org.apache.hadoop.mapred.TaskID' start='50' end='195' sourcepath='org/apache/hadoop/mapred/TaskID.java' sourcefile='TaskID.java'><Message>At TaskID.java:[lines 50-195]</Message></SourceLine><Message>In class org.apache.hadoop.mapred.TaskID</Message></Class><Class classname='org.apache.hadoop.mapreduce.TaskID'><SourceLine classname='org.apache.hadoop.mapreduce.TaskID' start='58' end='281' sourcepath='org/apache/hadoop/mapreduce/TaskID.java' sourcefile='TaskID.java'><Message>At TaskID.java:[lines 58-281]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.TaskID</Message></Class><SourceLine synthetic='true' classname='org.apache.hadoop.mapred.TaskID' start='50' end='195' sourcepath='org/apache/hadoop/mapred/TaskID.java' sourcefile='TaskID.java'><Message>At TaskID.java:[lines 50-195]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='cad6873276b266750231e961e1c5e806' cweid='192' rank='20' abbrev='ICAST' category='STYLE' priority='3' type='ICAST_INTEGER_MULTIPLY_CAST_TO_LONG' instanceOccurrenceMax='0'><ShortMessage>Result of integer multiplication cast to long</ShortMessage><LongMessage>Result of integer multiplication cast to long in org.apache.hadoop.mapred.TaskLogAppender.getTotalLogFileSize()</LongMessage><Class classname='org.apache.hadoop.mapred.TaskLogAppender' primary='true'><SourceLine classname='org.apache.hadoop.mapred.TaskLogAppender' start='35' end='151' sourcepath='org/apache/hadoop/mapred/TaskLogAppender.java' sourcefile='TaskLogAppender.java'><Message>At TaskLogAppender.java:[lines 35-151]</Message></SourceLine><Message>In class org.apache.hadoop.mapred.TaskLogAppender</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapred.TaskLogAppender' signature='()J' name='getTotalLogFileSize' primary='true'><SourceLine endBytecode='53' classname='org.apache.hadoop.mapred.TaskLogAppender' start='128' end='128' sourcepath='org/apache/hadoop/mapred/TaskLogAppender.java' sourcefile='TaskLogAppender.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapred.TaskLogAppender.getTotalLogFileSize()</Message></Method><SourceLine endBytecode='10' classname='org.apache.hadoop.mapred.TaskLogAppender' start='128' end='128' sourcepath='org/apache/hadoop/mapred/TaskLogAppender.java' sourcefile='TaskLogAppender.java' startBytecode='10' primary='true'><Message>At TaskLogAppender.java:[line 128]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='10afa81b68f27c09b7b94a85ed1dd0d9' rank='20' abbrev='UwF' category='STYLE' priority='3' type='UWF_FIELD_NOT_INITIALIZED_IN_CONSTRUCTOR' instanceOccurrenceMax='0'><ShortMessage>Field not initialized in constructor but dereferenced without null check</ShortMessage><LongMessage>TaskLogAppender.maxEvents not initialized in constructor and dereferenced in org.apache.hadoop.mapred.TaskLogAppender.activateOptions()</LongMessage><Class classname='org.apache.hadoop.mapred.TaskLogAppender' primary='true'><SourceLine classname='org.apache.hadoop.mapred.TaskLogAppender' start='35' end='151' sourcepath='org/apache/hadoop/mapred/TaskLogAppender.java' sourcefile='TaskLogAppender.java'><Message>At TaskLogAppender.java:[lines 35-151]</Message></SourceLine><Message>In class org.apache.hadoop.mapred.TaskLogAppender</Message></Class><Field isStatic='false' classname='org.apache.hadoop.mapred.TaskLogAppender' signature='Ljava/lang/Integer;' name='maxEvents' primary='true'><SourceLine classname='org.apache.hadoop.mapred.TaskLogAppender' sourcepath='org/apache/hadoop/mapred/TaskLogAppender.java' sourcefile='TaskLogAppender.java'><Message>In TaskLogAppender.java</Message></SourceLine><Message>Field org.apache.hadoop.mapred.TaskLogAppender.maxEvents</Message></Field><Method isStatic='false' classname='org.apache.hadoop.mapred.TaskLogAppender' signature='()V' name='activateOptions' primary='true'><SourceLine endBytecode='202' classname='org.apache.hadoop.mapred.TaskLogAppender' start='49' end='60' sourcepath='org/apache/hadoop/mapred/TaskLogAppender.java' sourcefile='TaskLogAppender.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapred.TaskLogAppender.activateOptions()</Message></Method><SourceLine endBytecode='12' classname='org.apache.hadoop.mapred.TaskLogAppender' start='52' end='52' sourcepath='org/apache/hadoop/mapred/TaskLogAppender.java' sourcefile='TaskLogAppender.java' startBytecode='12' primary='true'><Message>At TaskLogAppender.java:[line 52]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='6c35f2c5eb884c33b087236e58704f2' rank='20' abbrev='UwF' category='STYLE' priority='3' type='UWF_FIELD_NOT_INITIALIZED_IN_CONSTRUCTOR' instanceOccurrenceMax='0'><ShortMessage>Field not initialized in constructor but dereferenced without null check</ShortMessage><LongMessage>TaskLogAppender.maxEvents not initialized in constructor and dereferenced in org.apache.hadoop.mapred.TaskLogAppender.append(LoggingEvent)</LongMessage><Class classname='org.apache.hadoop.mapred.TaskLogAppender' primary='true'><SourceLine classname='org.apache.hadoop.mapred.TaskLogAppender' start='35' end='151' sourcepath='org/apache/hadoop/mapred/TaskLogAppender.java' sourcefile='TaskLogAppender.java'><Message>At TaskLogAppender.java:[lines 35-151]</Message></SourceLine><Message>In class org.apache.hadoop.mapred.TaskLogAppender</Message></Class><Field isStatic='false' classname='org.apache.hadoop.mapred.TaskLogAppender' signature='Ljava/lang/Integer;' name='maxEvents' primary='true'><SourceLine classname='org.apache.hadoop.mapred.TaskLogAppender' sourcepath='org/apache/hadoop/mapred/TaskLogAppender.java' sourcefile='TaskLogAppender.java'><Message>In TaskLogAppender.java</Message></SourceLine><Message>Field org.apache.hadoop.mapred.TaskLogAppender.maxEvents</Message></Field><Method isStatic='false' classname='org.apache.hadoop.mapred.TaskLogAppender' signature='(Lorg/apache/log4j/spi/LoggingEvent;)V' name='append' primary='true'><SourceLine endBytecode='188' classname='org.apache.hadoop.mapred.TaskLogAppender' start='84' end='94' sourcepath='org/apache/hadoop/mapred/TaskLogAppender.java' sourcefile='TaskLogAppender.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapred.TaskLogAppender.append(LoggingEvent)</Message></Method><SourceLine endBytecode='32' classname='org.apache.hadoop.mapred.TaskLogAppender' start='88' end='88' sourcepath='org/apache/hadoop/mapred/TaskLogAppender.java' sourcefile='TaskLogAppender.java' startBytecode='32' primary='true'><Message>At TaskLogAppender.java:[line 88]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='63c1034201b3375865ee356c0e5b099b' rank='20' abbrev='UwF' category='STYLE' priority='3' type='UWF_FIELD_NOT_INITIALIZED_IN_CONSTRUCTOR' instanceOccurrenceMax='0'><ShortMessage>Field not initialized in constructor but dereferenced without null check</ShortMessage><LongMessage>TaskLogAppender.maxEvents not initialized in constructor and dereferenced in org.apache.hadoop.mapred.TaskLogAppender.getTotalLogFileSize()</LongMessage><Class classname='org.apache.hadoop.mapred.TaskLogAppender' primary='true'><SourceLine classname='org.apache.hadoop.mapred.TaskLogAppender' start='35' end='151' sourcepath='org/apache/hadoop/mapred/TaskLogAppender.java' sourcefile='TaskLogAppender.java'><Message>At TaskLogAppender.java:[lines 35-151]</Message></SourceLine><Message>In class org.apache.hadoop.mapred.TaskLogAppender</Message></Class><Field isStatic='false' classname='org.apache.hadoop.mapred.TaskLogAppender' signature='Ljava/lang/Integer;' name='maxEvents' primary='true'><SourceLine classname='org.apache.hadoop.mapred.TaskLogAppender' sourcepath='org/apache/hadoop/mapred/TaskLogAppender.java' sourcefile='TaskLogAppender.java'><Message>In TaskLogAppender.java</Message></SourceLine><Message>Field org.apache.hadoop.mapred.TaskLogAppender.maxEvents</Message></Field><Method isStatic='false' classname='org.apache.hadoop.mapred.TaskLogAppender' signature='()J' name='getTotalLogFileSize' primary='true'><SourceLine endBytecode='53' classname='org.apache.hadoop.mapred.TaskLogAppender' start='128' end='128' sourcepath='org/apache/hadoop/mapred/TaskLogAppender.java' sourcefile='TaskLogAppender.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapred.TaskLogAppender.getTotalLogFileSize()</Message></Method><SourceLine endBytecode='4' classname='org.apache.hadoop.mapred.TaskLogAppender' start='128' end='128' sourcepath='org/apache/hadoop/mapred/TaskLogAppender.java' sourcefile='TaskLogAppender.java' startBytecode='4' primary='true'><Message>At TaskLogAppender.java:[line 128]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='a742703e0861643a59598aab91aa434d' rank='14' abbrev='Nm' category='BAD_PRACTICE' priority='1' type='NM_SAME_SIMPLE_NAME_AS_SUPERCLASS' instanceOccurrenceMax='0'><ShortMessage>Class names shouldn't shadow simple name of superclass</ShortMessage><LongMessage>The class name org.apache.hadoop.mapred.TaskReport shadows the simple name of the superclass org.apache.hadoop.mapreduce.TaskReport</LongMessage><Class classname='org.apache.hadoop.mapred.TaskReport' primary='true'><SourceLine classname='org.apache.hadoop.mapred.TaskReport' start='35' end='156' sourcepath='org/apache/hadoop/mapred/TaskReport.java' sourcefile='TaskReport.java'><Message>At TaskReport.java:[lines 35-156]</Message></SourceLine><Message>In class org.apache.hadoop.mapred.TaskReport</Message></Class><Class classname='org.apache.hadoop.mapreduce.TaskReport'><SourceLine classname='org.apache.hadoop.mapreduce.TaskReport' start='49' end='238' sourcepath='org/apache/hadoop/mapreduce/TaskReport.java' sourcefile='TaskReport.java'><Message>At TaskReport.java:[lines 49-238]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.TaskReport</Message></Class><SourceLine synthetic='true' classname='org.apache.hadoop.mapred.TaskReport' start='35' end='156' sourcepath='org/apache/hadoop/mapred/TaskReport.java' sourcefile='TaskReport.java'><Message>At TaskReport.java:[lines 35-156]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='e851fb682488f17cd75cdf9a6996b929' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from org.apache.hadoop.mapred.InputSplit to org.apache.hadoop.mapred.FileSplit in org.apache.hadoop.mapred.TextInputFormat.getRecordReader(InputSplit, JobConf, Reporter)</LongMessage><Class classname='org.apache.hadoop.mapred.TextInputFormat' primary='true'><SourceLine classname='org.apache.hadoop.mapred.TextInputFormat' start='39' end='67' sourcepath='org/apache/hadoop/mapred/TextInputFormat.java' sourcefile='TextInputFormat.java'><Message>At TextInputFormat.java:[lines 39-67]</Message></SourceLine><Message>In class org.apache.hadoop.mapred.TextInputFormat</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapred.TextInputFormat' signature='(Lorg/apache/hadoop/mapred/InputSplit;Lorg/apache/hadoop/mapred/JobConf;Lorg/apache/hadoop/mapred/Reporter;)Lorg/apache/hadoop/mapred/RecordReader;' name='getRecordReader' primary='true'><SourceLine endBytecode='24' classname='org.apache.hadoop.mapred.TextInputFormat' start='61' end='67' sourcepath='org/apache/hadoop/mapred/TextInputFormat.java' sourcefile='TextInputFormat.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapred.TextInputFormat.getRecordReader(InputSplit, JobConf, Reporter)</Message></Method><Type role='TYPE_FOUND' descriptor='Lorg/apache/hadoop/mapred/InputSplit;'><SourceLine classname='org.apache.hadoop.mapred.InputSplit' sourcepath='org/apache/hadoop/mapred/InputSplit.java' sourcefile='InputSplit.java'><Message>In InputSplit.java</Message></SourceLine><Message>Actual type org.apache.hadoop.mapred.InputSplit</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/mapred/FileSplit;'><SourceLine classname='org.apache.hadoop.mapred.FileSplit' start='39' end='113' sourcepath='org/apache/hadoop/mapred/FileSplit.java' sourcefile='FileSplit.java'><Message>At FileSplit.java:[lines 39-113]</Message></SourceLine><Message>Expected org.apache.hadoop.mapred.FileSplit</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='42' name='genericSplit' register='1'><Message>Value loaded from genericSplit</Message></LocalVariable><SourceLine endBytecode='43' classname='org.apache.hadoop.mapred.TextInputFormat' start='67' end='67' sourcepath='org/apache/hadoop/mapred/TextInputFormat.java' sourcefile='TextInputFormat.java' startBytecode='43' primary='true'><Message>At TextInputFormat.java:[line 67]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='439dba33b9d5de23398ddd7938caaac3' rank='14' abbrev='Nm' category='BAD_PRACTICE' priority='1' type='NM_SAME_SIMPLE_NAME_AS_SUPERCLASS' instanceOccurrenceMax='0'><ShortMessage>Class names shouldn't shadow simple name of superclass</ShortMessage><LongMessage>The class name org.apache.hadoop.mapred.jobcontrol.JobControl shadows the simple name of the superclass org.apache.hadoop.mapreduce.lib.jobcontrol.JobControl</LongMessage><Class classname='org.apache.hadoop.mapred.jobcontrol.JobControl' primary='true'><SourceLine classname='org.apache.hadoop.mapred.jobcontrol.JobControl' start='39' end='113' sourcepath='org/apache/hadoop/mapred/jobcontrol/JobControl.java' sourcefile='JobControl.java'><Message>At JobControl.java:[lines 39-113]</Message></SourceLine><Message>In class org.apache.hadoop.mapred.jobcontrol.JobControl</Message></Class><Class classname='org.apache.hadoop.mapreduce.lib.jobcontrol.JobControl'><SourceLine classname='org.apache.hadoop.mapreduce.lib.jobcontrol.JobControl' start='58' end='353' sourcepath='org/apache/hadoop/mapreduce/lib/jobcontrol/JobControl.java' sourcefile='JobControl.java'><Message>At JobControl.java:[lines 58-353]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.lib.jobcontrol.JobControl</Message></Class><SourceLine synthetic='true' classname='org.apache.hadoop.mapred.jobcontrol.JobControl' start='39' end='113' sourcepath='org/apache/hadoop/mapred/jobcontrol/JobControl.java' sourcefile='JobControl.java'><Message>At JobControl.java:[lines 39-113]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='65359a40dbcbb1d544ba83f059043cbd' rank='14' abbrev='Nm' category='BAD_PRACTICE' priority='1' type='NM_SAME_SIMPLE_NAME_AS_SUPERCLASS' instanceOccurrenceMax='0'><ShortMessage>Class names shouldn't shadow simple name of superclass</ShortMessage><LongMessage>The class name org.apache.hadoop.mapred.join.ArrayListBackedIterator shadows the simple name of the superclass org.apache.hadoop.mapreduce.lib.join.ArrayListBackedIterator</LongMessage><Class classname='org.apache.hadoop.mapred.join.ArrayListBackedIterator' primary='true'><SourceLine classname='org.apache.hadoop.mapred.join.ArrayListBackedIterator' start='39' end='44' sourcepath='org/apache/hadoop/mapred/join/ArrayListBackedIterator.java' sourcefile='ArrayListBackedIterator.java'><Message>At ArrayListBackedIterator.java:[lines 39-44]</Message></SourceLine><Message>In class org.apache.hadoop.mapred.join.ArrayListBackedIterator</Message></Class><Class classname='org.apache.hadoop.mapreduce.lib.join.ArrayListBackedIterator'><SourceLine classname='org.apache.hadoop.mapreduce.lib.join.ArrayListBackedIterator' start='44' end='94' sourcepath='org/apache/hadoop/mapreduce/lib/join/ArrayListBackedIterator.java' sourcefile='ArrayListBackedIterator.java'><Message>At ArrayListBackedIterator.java:[lines 44-94]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.lib.join.ArrayListBackedIterator</Message></Class><SourceLine synthetic='true' classname='org.apache.hadoop.mapred.join.ArrayListBackedIterator' start='39' end='44' sourcepath='org/apache/hadoop/mapred/join/ArrayListBackedIterator.java' sourcefile='ArrayListBackedIterator.java'><Message>At ArrayListBackedIterator.java:[lines 39-44]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='b23572e4aa7a86ac61931a607d5bd930' rank='20' abbrev='UwF' category='STYLE' priority='3' type='UWF_FIELD_NOT_INITIALIZED_IN_CONSTRUCTOR' instanceOccurrenceMax='0'><ShortMessage>Field not initialized in constructor but dereferenced without null check</ShortMessage><LongMessage>CompositeInputFormat.root not initialized in constructor and dereferenced in org.apache.hadoop.mapred.join.CompositeInputFormat.getRecordReader(InputSplit, JobConf, Reporter)</LongMessage><Class classname='org.apache.hadoop.mapred.join.CompositeInputFormat' primary='true'><SourceLine classname='org.apache.hadoop.mapred.join.CompositeInputFormat' start='50' end='182' sourcepath='org/apache/hadoop/mapred/join/CompositeInputFormat.java' sourcefile='CompositeInputFormat.java'><Message>At CompositeInputFormat.java:[lines 50-182]</Message></SourceLine><Message>In class org.apache.hadoop.mapred.join.CompositeInputFormat</Message></Class><Field isStatic='false' classname='org.apache.hadoop.mapred.join.CompositeInputFormat' signature='Lorg/apache/hadoop/mapred/join/Parser$Node;' name='root' primary='true'><SourceLine classname='org.apache.hadoop.mapred.join.CompositeInputFormat' sourcepath='org/apache/hadoop/mapred/join/CompositeInputFormat.java' sourcefile='CompositeInputFormat.java'><Message>In CompositeInputFormat.java</Message></SourceLine><Message>Field org.apache.hadoop.mapred.join.CompositeInputFormat.root</Message></Field><Method isStatic='false' classname='org.apache.hadoop.mapred.join.CompositeInputFormat' signature='(Lorg/apache/hadoop/mapred/InputSplit;Lorg/apache/hadoop/mapred/JobConf;Lorg/apache/hadoop/mapred/Reporter;)Lorg/apache/hadoop/mapred/join/ComposableRecordReader;' name='getRecordReader' primary='true'><SourceLine endBytecode='109' classname='org.apache.hadoop.mapred.join.CompositeInputFormat' start='133' end='134' sourcepath='org/apache/hadoop/mapred/join/CompositeInputFormat.java' sourcefile='CompositeInputFormat.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapred.join.CompositeInputFormat.getRecordReader(InputSplit, JobConf, Reporter)</Message></Method><SourceLine endBytecode='12' classname='org.apache.hadoop.mapred.join.CompositeInputFormat' start='134' end='134' sourcepath='org/apache/hadoop/mapred/join/CompositeInputFormat.java' sourcefile='CompositeInputFormat.java' startBytecode='12' primary='true'><Message>At CompositeInputFormat.java:[line 134]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='76bec0cf1f0a93d1459ca134de71d185' rank='20' abbrev='UwF' category='STYLE' priority='3' type='UWF_FIELD_NOT_INITIALIZED_IN_CONSTRUCTOR' instanceOccurrenceMax='0'><ShortMessage>Field not initialized in constructor but dereferenced without null check</ShortMessage><LongMessage>CompositeInputFormat.root not initialized in constructor and dereferenced in org.apache.hadoop.mapred.join.CompositeInputFormat.getSplits(JobConf, int)</LongMessage><Class classname='org.apache.hadoop.mapred.join.CompositeInputFormat' primary='true'><SourceLine classname='org.apache.hadoop.mapred.join.CompositeInputFormat' start='50' end='182' sourcepath='org/apache/hadoop/mapred/join/CompositeInputFormat.java' sourcefile='CompositeInputFormat.java'><Message>At CompositeInputFormat.java:[lines 50-182]</Message></SourceLine><Message>In class org.apache.hadoop.mapred.join.CompositeInputFormat</Message></Class><Field isStatic='false' classname='org.apache.hadoop.mapred.join.CompositeInputFormat' signature='Lorg/apache/hadoop/mapred/join/Parser$Node;' name='root' primary='true'><SourceLine classname='org.apache.hadoop.mapred.join.CompositeInputFormat' sourcepath='org/apache/hadoop/mapred/join/CompositeInputFormat.java' sourcefile='CompositeInputFormat.java'><Message>In CompositeInputFormat.java</Message></SourceLine><Message>Field org.apache.hadoop.mapred.join.CompositeInputFormat.root</Message></Field><Method isStatic='false' classname='org.apache.hadoop.mapred.join.CompositeInputFormat' signature='(Lorg/apache/hadoop/mapred/JobConf;I)[Lorg/apache/hadoop/mapred/InputSplit;' name='getSplits' primary='true'><SourceLine endBytecode='111' classname='org.apache.hadoop.mapred.join.CompositeInputFormat' start='119' end='121' sourcepath='org/apache/hadoop/mapred/join/CompositeInputFormat.java' sourcefile='CompositeInputFormat.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapred.join.CompositeInputFormat.getSplits(JobConf, int)</Message></Method><SourceLine endBytecode='20' classname='org.apache.hadoop.mapred.join.CompositeInputFormat' start='121' end='121' sourcepath='org/apache/hadoop/mapred/join/CompositeInputFormat.java' sourcefile='CompositeInputFormat.java' startBytecode='20' primary='true'><Message>At CompositeInputFormat.java:[line 121]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='4c6c6b24df24c06e6f2a933ee753df29' rank='19' abbrev='Eq' category='BAD_PRACTICE' priority='3' type='EQ_COMPARETO_USE_OBJECT_EQUALS' instanceOccurrenceMax='0'><ShortMessage>Class defines compareTo(...) and uses Object.equals()</ShortMessage><LongMessage>org.apache.hadoop.mapred.join.JoinRecordReader defines compareTo(Object) and uses Object.equals()</LongMessage><Class classname='org.apache.hadoop.mapred.join.JoinRecordReader' primary='true'><SourceLine classname='org.apache.hadoop.mapred.join.JoinRecordReader' start='35' end='80' sourcepath='org/apache/hadoop/mapred/join/JoinRecordReader.java' sourcefile='JoinRecordReader.java'><Message>At JoinRecordReader.java:[lines 35-80]</Message></SourceLine><Message>In class org.apache.hadoop.mapred.join.JoinRecordReader</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapred.join.JoinRecordReader' signature='(Ljava/lang/Object;)I' name='compareTo' primary='true'><SourceLine endBytecode='68' classname='org.apache.hadoop.mapred.join.JoinRecordReader' start='35' end='35' sourcepath='org/apache/hadoop/mapred/join/JoinRecordReader.java' sourcefile='JoinRecordReader.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapred.join.JoinRecordReader.compareTo(Object)</Message></Method><SourceLine synthetic='true' endBytecode='68' classname='org.apache.hadoop.mapred.join.JoinRecordReader' start='35' end='35' sourcepath='org/apache/hadoop/mapred/join/JoinRecordReader.java' sourcefile='JoinRecordReader.java' startBytecode='0'><Message>At JoinRecordReader.java:[line 35]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='501ae4f37885164102d9358eae30044e' rank='19' abbrev='Eq' category='BAD_PRACTICE' priority='3' type='EQ_COMPARETO_USE_OBJECT_EQUALS' instanceOccurrenceMax='0'><ShortMessage>Class defines compareTo(...) and uses Object.equals()</ShortMessage><LongMessage>org.apache.hadoop.mapred.join.MultiFilterRecordReader defines compareTo(Object) and uses Object.equals()</LongMessage><Class classname='org.apache.hadoop.mapred.join.MultiFilterRecordReader' primary='true'><SourceLine classname='org.apache.hadoop.mapred.join.MultiFilterRecordReader' start='38' end='115' sourcepath='org/apache/hadoop/mapred/join/MultiFilterRecordReader.java' sourcefile='MultiFilterRecordReader.java'><Message>At MultiFilterRecordReader.java:[lines 38-115]</Message></SourceLine><Message>In class org.apache.hadoop.mapred.join.MultiFilterRecordReader</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapred.join.MultiFilterRecordReader' signature='(Ljava/lang/Object;)I' name='compareTo' primary='true'><SourceLine endBytecode='68' classname='org.apache.hadoop.mapred.join.MultiFilterRecordReader' start='38' end='38' sourcepath='org/apache/hadoop/mapred/join/MultiFilterRecordReader.java' sourcefile='MultiFilterRecordReader.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapred.join.MultiFilterRecordReader.compareTo(Object)</Message></Method><SourceLine synthetic='true' endBytecode='68' classname='org.apache.hadoop.mapred.join.MultiFilterRecordReader' start='38' end='38' sourcepath='org/apache/hadoop/mapred/join/MultiFilterRecordReader.java' sourcefile='MultiFilterRecordReader.java' startBytecode='0'><Message>At MultiFilterRecordReader.java:[line 38]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='a46ea76ce6f66f8c9276ca9a41ffaeb2' cweid='218' rank='18' abbrev='MS' category='MALICIOUS_CODE' priority='2' type='MS_MUTABLE_COLLECTION_PKGPROTECT' instanceOccurrenceMax='0'><ShortMessage>Field is a mutable collection which should be package protected</ShortMessage><LongMessage>org.apache.hadoop.mapred.join.Parser$Node.rrCstrMap is a mutable collection which should be package protected</LongMessage><Class classname='org.apache.hadoop.mapred.join.Parser$Node' primary='true'><SourceLine classname='org.apache.hadoop.mapred.join.Parser$Node' start='195' end='252' sourcepath='org/apache/hadoop/mapred/join/Parser.java' sourcefile='Parser.java'><Message>At Parser.java:[lines 195-252]</Message></SourceLine><Message>In class org.apache.hadoop.mapred.join.Parser$Node</Message></Class><Field isStatic='true' classname='org.apache.hadoop.mapred.join.Parser$Node' signature='Ljava/util/Map;' name='rrCstrMap' primary='true'><SourceLine classname='org.apache.hadoop.mapred.join.Parser$Node' sourcepath='org/apache/hadoop/mapred/join/Parser.java' sourcefile='Parser.java'><Message>In Parser.java</Message></SourceLine><Message>Field org.apache.hadoop.mapred.join.Parser$Node.rrCstrMap</Message></Field><SourceLine endBytecode='29' classname='org.apache.hadoop.mapred.join.Parser$Node' start='213' end='213' sourcepath='org/apache/hadoop/mapred/join/Parser.java' sourcefile='Parser.java' startBytecode='29' primary='true'><Message>At Parser.java:[line 213]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='45b42a1e510e9850abd6c747bc0f7651' rank='16' abbrev='Nm' category='BAD_PRACTICE' priority='2' type='NM_SAME_SIMPLE_NAME_AS_INTERFACE' instanceOccurrenceMax='0'><ShortMessage>Class names shouldn't shadow simple name of implemented interface</ShortMessage><LongMessage>The class name org.apache.hadoop.mapred.join.ResetableIterator shadows the simple name of implemented interface org.apache.hadoop.mapreduce.lib.join.ResetableIterator</LongMessage><Class classname='org.apache.hadoop.mapred.join.ResetableIterator' primary='true'><SourceLine classname='org.apache.hadoop.mapred.join.ResetableIterator' sourcepath='org/apache/hadoop/mapred/join/ResetableIterator.java' sourcefile='ResetableIterator.java'><Message>In ResetableIterator.java</Message></SourceLine><Message>In class org.apache.hadoop.mapred.join.ResetableIterator</Message></Class><Class classname='org.apache.hadoop.mapreduce.lib.join.ResetableIterator'><SourceLine classname='org.apache.hadoop.mapreduce.lib.join.ResetableIterator' sourcepath='org/apache/hadoop/mapreduce/lib/join/ResetableIterator.java' sourcefile='ResetableIterator.java'><Message>In ResetableIterator.java</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.lib.join.ResetableIterator</Message></Class><SourceLine synthetic='true' classname='org.apache.hadoop.mapred.join.ResetableIterator' sourcepath='org/apache/hadoop/mapred/join/ResetableIterator.java' sourcefile='ResetableIterator.java'><Message>In ResetableIterator.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='5e0cb1d3735c04f0140826f6941f2088' rank='14' abbrev='Nm' category='BAD_PRACTICE' priority='1' type='NM_SAME_SIMPLE_NAME_AS_SUPERCLASS' instanceOccurrenceMax='0'><ShortMessage>Class names shouldn't shadow simple name of superclass</ShortMessage><LongMessage>The class name org.apache.hadoop.mapred.join.ResetableIterator$EMPTY shadows the simple name of the superclass org.apache.hadoop.mapreduce.lib.join.ResetableIterator$EMPTY</LongMessage><Class classname='org.apache.hadoop.mapred.join.ResetableIterator$EMPTY' primary='true'><SourceLine classname='org.apache.hadoop.mapred.join.ResetableIterator$EMPTY' start='34' end='34' sourcepath='org/apache/hadoop/mapred/join/ResetableIterator.java' sourcefile='ResetableIterator.java'><Message>At ResetableIterator.java:[line 34]</Message></SourceLine><Message>In class org.apache.hadoop.mapred.join.ResetableIterator$EMPTY</Message></Class><Class classname='org.apache.hadoop.mapreduce.lib.join.ResetableIterator$EMPTY'><SourceLine classname='org.apache.hadoop.mapreduce.lib.join.ResetableIterator$EMPTY' start='35' end='48' sourcepath='org/apache/hadoop/mapreduce/lib/join/ResetableIterator.java' sourcefile='ResetableIterator.java'><Message>At ResetableIterator.java:[lines 35-48]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.lib.join.ResetableIterator$EMPTY</Message></Class><SourceLine synthetic='true' classname='org.apache.hadoop.mapred.join.ResetableIterator$EMPTY' start='34' end='34' sourcepath='org/apache/hadoop/mapred/join/ResetableIterator.java' sourcefile='ResetableIterator.java'><Message>At ResetableIterator.java:[line 34]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='82a500324c2226ae1915f3696553dc45' rank='14' abbrev='Nm' category='BAD_PRACTICE' priority='1' type='NM_SAME_SIMPLE_NAME_AS_SUPERCLASS' instanceOccurrenceMax='0'><ShortMessage>Class names shouldn't shadow simple name of superclass</ShortMessage><LongMessage>The class name org.apache.hadoop.mapred.join.StreamBackedIterator shadows the simple name of the superclass org.apache.hadoop.mapreduce.lib.join.StreamBackedIterator</LongMessage><Class classname='org.apache.hadoop.mapred.join.StreamBackedIterator' primary='true'><SourceLine classname='org.apache.hadoop.mapred.join.StreamBackedIterator' start='30' end='30' sourcepath='org/apache/hadoop/mapred/join/StreamBackedIterator.java' sourcefile='StreamBackedIterator.java'><Message>At StreamBackedIterator.java:[line 30]</Message></SourceLine><Message>In class org.apache.hadoop.mapred.join.StreamBackedIterator</Message></Class><Class classname='org.apache.hadoop.mapreduce.lib.join.StreamBackedIterator'><SourceLine classname='org.apache.hadoop.mapreduce.lib.join.StreamBackedIterator' start='49' end='102' sourcepath='org/apache/hadoop/mapreduce/lib/join/StreamBackedIterator.java' sourcefile='StreamBackedIterator.java'><Message>At StreamBackedIterator.java:[lines 49-102]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.lib.join.StreamBackedIterator</Message></Class><SourceLine synthetic='true' classname='org.apache.hadoop.mapred.join.StreamBackedIterator' start='30' end='30' sourcepath='org/apache/hadoop/mapred/join/StreamBackedIterator.java' sourcefile='StreamBackedIterator.java'><Message>At StreamBackedIterator.java:[line 30]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='5e958a3538532e19375dff31ce21066b' rank='14' abbrev='Nm' category='BAD_PRACTICE' priority='1' type='NM_SAME_SIMPLE_NAME_AS_SUPERCLASS' instanceOccurrenceMax='0'><ShortMessage>Class names shouldn't shadow simple name of superclass</ShortMessage><LongMessage>The class name org.apache.hadoop.mapred.join.TupleWritable shadows the simple name of the superclass org.apache.hadoop.mapreduce.lib.join.TupleWritable</LongMessage><Class classname='org.apache.hadoop.mapred.join.TupleWritable' primary='true'><SourceLine classname='org.apache.hadoop.mapred.join.TupleWritable' start='46' end='78' sourcepath='org/apache/hadoop/mapred/join/TupleWritable.java' sourcefile='TupleWritable.java'><Message>At TupleWritable.java:[lines 46-78]</Message></SourceLine><Message>In class org.apache.hadoop.mapred.join.TupleWritable</Message></Class><Class classname='org.apache.hadoop.mapreduce.lib.join.TupleWritable'><SourceLine classname='org.apache.hadoop.mapreduce.lib.join.TupleWritable' start='47' end='297' sourcepath='org/apache/hadoop/mapreduce/lib/join/TupleWritable.java' sourcefile='TupleWritable.java'><Message>At TupleWritable.java:[lines 47-297]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.lib.join.TupleWritable</Message></Class><SourceLine synthetic='true' classname='org.apache.hadoop.mapred.join.TupleWritable' start='46' end='78' sourcepath='org/apache/hadoop/mapred/join/TupleWritable.java' sourcefile='TupleWritable.java'><Message>At TupleWritable.java:[lines 46-78]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='34192849e79866a7663436b00109f9ec' rank='14' abbrev='Nm' category='BAD_PRACTICE' priority='1' type='NM_SAME_SIMPLE_NAME_AS_SUPERCLASS' instanceOccurrenceMax='0'><ShortMessage>Class names shouldn't shadow simple name of superclass</ShortMessage><LongMessage>The class name org.apache.hadoop.mapred.lib.BinaryPartitioner shadows the simple name of the superclass org.apache.hadoop.mapreduce.lib.partition.BinaryPartitioner</LongMessage><Class classname='org.apache.hadoop.mapred.lib.BinaryPartitioner' primary='true'><SourceLine classname='org.apache.hadoop.mapred.lib.BinaryPartitioner' start='35' end='41' sourcepath='org/apache/hadoop/mapred/lib/BinaryPartitioner.java' sourcefile='BinaryPartitioner.java'><Message>At BinaryPartitioner.java:[lines 35-41]</Message></SourceLine><Message>In class org.apache.hadoop.mapred.lib.BinaryPartitioner</Message></Class><Class classname='org.apache.hadoop.mapreduce.lib.partition.BinaryPartitioner'><SourceLine classname='org.apache.hadoop.mapreduce.lib.partition.BinaryPartitioner' start='69' end='139' sourcepath='org/apache/hadoop/mapreduce/lib/partition/BinaryPartitioner.java' sourcefile='BinaryPartitioner.java'><Message>At BinaryPartitioner.java:[lines 69-139]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.lib.partition.BinaryPartitioner</Message></Class><SourceLine synthetic='true' classname='org.apache.hadoop.mapred.lib.BinaryPartitioner' start='35' end='41' sourcepath='org/apache/hadoop/mapred/lib/BinaryPartitioner.java' sourcefile='BinaryPartitioner.java'><Message>At BinaryPartitioner.java:[lines 35-41]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='d5f1a2f476cdf8458d6b21d900ce8feb' rank='14' abbrev='Nm' category='BAD_PRACTICE' priority='1' type='NM_SAME_SIMPLE_NAME_AS_SUPERCLASS' instanceOccurrenceMax='0'><ShortMessage>Class names shouldn't shadow simple name of superclass</ShortMessage><LongMessage>The class name org.apache.hadoop.mapred.lib.Chain shadows the simple name of the superclass org.apache.hadoop.mapreduce.lib.chain.Chain</LongMessage><Class classname='org.apache.hadoop.mapred.lib.Chain' primary='true'><SourceLine classname='org.apache.hadoop.mapred.lib.Chain' start='39' end='293' sourcepath='org/apache/hadoop/mapred/lib/Chain.java' sourcefile='Chain.java'><Message>At Chain.java:[lines 39-293]</Message></SourceLine><Message>In class org.apache.hadoop.mapred.lib.Chain</Message></Class><Class classname='org.apache.hadoop.mapreduce.lib.chain.Chain'><SourceLine classname='org.apache.hadoop.mapreduce.lib.chain.Chain' start='50' end='861' sourcepath='org/apache/hadoop/mapreduce/lib/chain/Chain.java' sourcefile='Chain.java'><Message>At Chain.java:[lines 50-861]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.lib.chain.Chain</Message></Class><SourceLine synthetic='true' classname='org.apache.hadoop.mapred.lib.Chain' start='39' end='293' sourcepath='org/apache/hadoop/mapred/lib/Chain.java' sourcefile='Chain.java'><Message>At Chain.java:[lines 39-293]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='14e0cf7a8266634df7f718f5e9cd347d' rank='20' abbrev='SIC' category='PERFORMANCE' priority='3' type='SIC_INNER_SHOULD_BE_STATIC_ANON' instanceOccurrenceMax='0'><ShortMessage>Could be refactored into a named static inner class</ShortMessage><LongMessage>The class org.apache.hadoop.mapred.lib.Chain$1 could be refactored into a named _static_ inner class</LongMessage><Class role='CLASS_ANONYMOUS' classname='org.apache.hadoop.mapred.lib.Chain$1'><SourceLine classname='org.apache.hadoop.mapred.lib.Chain$1' start='294' end='296' sourcepath='org/apache/hadoop/mapred/lib/Chain.java' sourcefile='Chain.java'><Message>At Chain.java:[lines 294-296]</Message></SourceLine><Message>Anonymous class org.apache.hadoop.mapred.lib.Chain$1</Message></Class><Class classname='org.apache.hadoop.mapred.lib.Chain' primary='true'><SourceLine classname='org.apache.hadoop.mapred.lib.Chain' start='39' end='293' sourcepath='org/apache/hadoop/mapred/lib/Chain.java' sourcefile='Chain.java'><Message>At Chain.java:[lines 39-293]</Message></SourceLine><Message>In class org.apache.hadoop.mapred.lib.Chain</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapred.lib.Chain' signature='(Z)V' name='&lt;init&gt;' primary='true'><SourceLine endBytecode='122' classname='org.apache.hadoop.mapred.lib.Chain' start='65' end='66' sourcepath='org/apache/hadoop/mapred/lib/Chain.java' sourcefile='Chain.java' startBytecode='0'></SourceLine><Message>In method new org.apache.hadoop.mapred.lib.Chain(boolean)</Message></Method><SourceLine endBytecode='44' classname='org.apache.hadoop.mapred.lib.Chain' start='293' end='293' sourcepath='org/apache/hadoop/mapred/lib/Chain.java' sourcefile='Chain.java' startBytecode='44' primary='true'><Message>At Chain.java:[line 293]</Message></SourceLine><Field isStatic='false' classname='org.apache.hadoop.mapred.lib.Chain' signature='Ljava/lang/ThreadLocal;' name='threadLocalDataOutputBuffer' primary='true'><SourceLine classname='org.apache.hadoop.mapred.lib.Chain' sourcepath='org/apache/hadoop/mapred/lib/Chain.java' sourcefile='Chain.java'><Message>In Chain.java</Message></SourceLine><Message>Field org.apache.hadoop.mapred.lib.Chain.threadLocalDataOutputBuffer</Message></Field></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='277ca99e67debe156a64bcb2f73323f4' rank='14' abbrev='Nm' category='BAD_PRACTICE' priority='1' type='NM_SAME_SIMPLE_NAME_AS_SUPERCLASS' instanceOccurrenceMax='0'><ShortMessage>Class names shouldn't shadow simple name of superclass</ShortMessage><LongMessage>The class name org.apache.hadoop.mapred.lib.CombineFileInputFormat shadows the simple name of the superclass org.apache.hadoop.mapreduce.lib.input.CombineFileInputFormat</LongMessage><Class classname='org.apache.hadoop.mapred.lib.CombineFileInputFormat' primary='true'><SourceLine classname='org.apache.hadoop.mapred.lib.CombineFileInputFormat' start='70' end='164' sourcepath='org/apache/hadoop/mapred/lib/CombineFileInputFormat.java' sourcefile='CombineFileInputFormat.java'><Message>At CombineFileInputFormat.java:[lines 70-164]</Message></SourceLine><Message>In class org.apache.hadoop.mapred.lib.CombineFileInputFormat</Message></Class><Class classname='org.apache.hadoop.mapreduce.lib.input.CombineFileInputFormat'><SourceLine classname='org.apache.hadoop.mapreduce.lib.input.CombineFileInputFormat' start='82' end='774' sourcepath='org/apache/hadoop/mapreduce/lib/input/CombineFileInputFormat.java' sourcefile='CombineFileInputFormat.java'><Message>At CombineFileInputFormat.java:[lines 82-774]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.lib.input.CombineFileInputFormat</Message></Class><SourceLine synthetic='true' classname='org.apache.hadoop.mapred.lib.CombineFileInputFormat' start='70' end='164' sourcepath='org/apache/hadoop/mapred/lib/CombineFileInputFormat.java' sourcefile='CombineFileInputFormat.java'><Message>At CombineFileInputFormat.java:[lines 70-164]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='e0fb170421cd1b0f9c19f75156f82410' cweid='396' rank='20' abbrev='REC' category='STYLE' priority='3' type='REC_CATCH_EXCEPTION' instanceOccurrenceMax='0'><ShortMessage>Exception is caught when Exception is not thrown</ShortMessage><LongMessage>Exception is caught when Exception is not thrown in org.apache.hadoop.mapred.lib.CombineFileRecordReader.initNextRecordReader()</LongMessage><Class classname='org.apache.hadoop.mapred.lib.CombineFileRecordReader' primary='true'><SourceLine classname='org.apache.hadoop.mapred.lib.CombineFileRecordReader' start='41' end='153' sourcepath='org/apache/hadoop/mapred/lib/CombineFileRecordReader.java' sourcefile='CombineFileRecordReader.java'><Message>At CombineFileRecordReader.java:[lines 41-153]</Message></SourceLine><Message>In class org.apache.hadoop.mapred.lib.CombineFileRecordReader</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapred.lib.CombineFileRecordReader' signature='()Z' name='initNextRecordReader' primary='true'><SourceLine endBytecode='378' classname='org.apache.hadoop.mapred.lib.CombineFileRecordReader' start='125' end='153' sourcepath='org/apache/hadoop/mapred/lib/CombineFileRecordReader.java' sourcefile='CombineFileRecordReader.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapred.lib.CombineFileRecordReader.initNextRecordReader()</Message></Method><SourceLine endBytecode='190' classname='org.apache.hadoop.mapred.lib.CombineFileRecordReader' start='149' end='149' sourcepath='org/apache/hadoop/mapred/lib/CombineFileRecordReader.java' sourcefile='CombineFileRecordReader.java' startBytecode='190' primary='true'><Message>At CombineFileRecordReader.java:[line 149]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='a8ed8cf8ec353108beb98988150bcc7a' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from org.apache.hadoop.conf.Configuration to org.apache.hadoop.mapred.JobConf in new org.apache.hadoop.mapred.lib.CombineFileRecordReaderWrapper(FileInputFormat, CombineFileSplit, Configuration, Reporter, Integer)</LongMessage><Class classname='org.apache.hadoop.mapred.lib.CombineFileRecordReaderWrapper' primary='true'><SourceLine classname='org.apache.hadoop.mapred.lib.CombineFileRecordReaderWrapper' start='54' end='84' sourcepath='org/apache/hadoop/mapred/lib/CombineFileRecordReaderWrapper.java' sourcefile='CombineFileRecordReaderWrapper.java'><Message>At CombineFileRecordReaderWrapper.java:[lines 54-84]</Message></SourceLine><Message>In class org.apache.hadoop.mapred.lib.CombineFileRecordReaderWrapper</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapred.lib.CombineFileRecordReaderWrapper' signature='(Lorg/apache/hadoop/mapred/FileInputFormat;Lorg/apache/hadoop/mapred/lib/CombineFileSplit;Lorg/apache/hadoop/conf/Configuration;Lorg/apache/hadoop/mapred/Reporter;Ljava/lang/Integer;)V' name='&lt;init&gt;' primary='true'><SourceLine endBytecode='28' classname='org.apache.hadoop.mapred.lib.CombineFileRecordReaderWrapper' start='54' end='61' sourcepath='org/apache/hadoop/mapred/lib/CombineFileRecordReaderWrapper.java' sourcefile='CombineFileRecordReaderWrapper.java' startBytecode='0'></SourceLine><Message>In method new org.apache.hadoop.mapred.lib.CombineFileRecordReaderWrapper(FileInputFormat, CombineFileSplit, Configuration, Reporter, Integer)</Message></Method><Type role='TYPE_FOUND' descriptor='Lorg/apache/hadoop/conf/Configuration;'><SourceLine classname='org.apache.hadoop.conf.Configuration' start='223' end='3860' sourcepath='org/apache/hadoop/conf/Configuration.java' sourcefile='Configuration.java'><Message>At Configuration.java:[lines 223-3860]</Message></SourceLine><Message>Actual type org.apache.hadoop.conf.Configuration</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/mapred/JobConf;'><SourceLine classname='org.apache.hadoop.mapred.JobConf' start='118' end='2224' sourcepath='org/apache/hadoop/mapred/JobConf.java' sourcefile='JobConf.java'><Message>At JobConf.java:[lines 118-2224]</Message></SourceLine><Message>Expected org.apache.hadoop.mapred.JobConf</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='48' name='conf' register='3'><Message>Value loaded from conf</Message></LocalVariable><SourceLine endBytecode='49' classname='org.apache.hadoop.mapred.lib.CombineFileRecordReaderWrapper' start='60' end='60' sourcepath='org/apache/hadoop/mapred/lib/CombineFileRecordReaderWrapper.java' sourcefile='CombineFileRecordReaderWrapper.java' startBytecode='49' primary='true'><Message>At CombineFileRecordReaderWrapper.java:[line 60]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='9a739041cf190bcce9100e7d51b6aa7b' rank='14' abbrev='Nm' category='BAD_PRACTICE' priority='1' type='NM_SAME_SIMPLE_NAME_AS_SUPERCLASS' instanceOccurrenceMax='0'><ShortMessage>Class names shouldn't shadow simple name of superclass</ShortMessage><LongMessage>The class name org.apache.hadoop.mapred.lib.CombineFileSplit shadows the simple name of the superclass org.apache.hadoop.mapreduce.lib.input.CombineFileSplit</LongMessage><Class classname='org.apache.hadoop.mapred.lib.CombineFileSplit' primary='true'><SourceLine classname='org.apache.hadoop.mapred.lib.CombineFileSplit' start='37' end='59' sourcepath='org/apache/hadoop/mapred/lib/CombineFileSplit.java' sourcefile='CombineFileSplit.java'><Message>At CombineFileSplit.java:[lines 37-59]</Message></SourceLine><Message>In class org.apache.hadoop.mapred.lib.CombineFileSplit</Message></Class><Class classname='org.apache.hadoop.mapreduce.lib.input.CombineFileSplit'><SourceLine classname='org.apache.hadoop.mapreduce.lib.input.CombineFileSplit' start='59' end='198' sourcepath='org/apache/hadoop/mapreduce/lib/input/CombineFileSplit.java' sourcefile='CombineFileSplit.java'><Message>At CombineFileSplit.java:[lines 59-198]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.lib.input.CombineFileSplit</Message></Class><SourceLine synthetic='true' classname='org.apache.hadoop.mapred.lib.CombineFileSplit' start='37' end='59' sourcepath='org/apache/hadoop/mapred/lib/CombineFileSplit.java' sourcefile='CombineFileSplit.java'><Message>At CombineFileSplit.java:[lines 37-59]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='71b24c14bb7af97b8f96eb7e0e9a1cfa' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from org.apache.hadoop.mapred.InputSplit to org.apache.hadoop.mapred.lib.CombineFileSplit in org.apache.hadoop.mapred.lib.CombineSequenceFileInputFormat.getRecordReader(InputSplit, JobConf, Reporter)</LongMessage><Class classname='org.apache.hadoop.mapred.lib.CombineSequenceFileInputFormat' primary='true'><SourceLine classname='org.apache.hadoop.mapred.lib.CombineSequenceFileInputFormat' start='40' end='45' sourcepath='org/apache/hadoop/mapred/lib/CombineSequenceFileInputFormat.java' sourcefile='CombineSequenceFileInputFormat.java'><Message>At CombineSequenceFileInputFormat.java:[lines 40-45]</Message></SourceLine><Message>In class org.apache.hadoop.mapred.lib.CombineSequenceFileInputFormat</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapred.lib.CombineSequenceFileInputFormat' signature='(Lorg/apache/hadoop/mapred/InputSplit;Lorg/apache/hadoop/mapred/JobConf;Lorg/apache/hadoop/mapred/Reporter;)Lorg/apache/hadoop/mapred/RecordReader;' name='getRecordReader' primary='true'><SourceLine endBytecode='8' classname='org.apache.hadoop.mapred.lib.CombineSequenceFileInputFormat' start='45' end='45' sourcepath='org/apache/hadoop/mapred/lib/CombineSequenceFileInputFormat.java' sourcefile='CombineSequenceFileInputFormat.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapred.lib.CombineSequenceFileInputFormat.getRecordReader(InputSplit, JobConf, Reporter)</Message></Method><Type role='TYPE_FOUND' descriptor='Lorg/apache/hadoop/mapred/InputSplit;'><SourceLine classname='org.apache.hadoop.mapred.InputSplit' sourcepath='org/apache/hadoop/mapred/InputSplit.java' sourcefile='InputSplit.java'><Message>In InputSplit.java</Message></SourceLine><Message>Actual type org.apache.hadoop.mapred.InputSplit</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/mapred/lib/CombineFileSplit;'><SourceLine classname='org.apache.hadoop.mapred.lib.CombineFileSplit' start='37' end='59' sourcepath='org/apache/hadoop/mapred/lib/CombineFileSplit.java' sourcefile='CombineFileSplit.java'><Message>At CombineFileSplit.java:[lines 37-59]</Message></SourceLine><Message>Expected org.apache.hadoop.mapred.lib.CombineFileSplit</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='5' name='split' register='1'><Message>Value loaded from split</Message></LocalVariable><SourceLine endBytecode='6' classname='org.apache.hadoop.mapred.lib.CombineSequenceFileInputFormat' start='45' end='45' sourcepath='org/apache/hadoop/mapred/lib/CombineSequenceFileInputFormat.java' sourcefile='CombineSequenceFileInputFormat.java' startBytecode='6' primary='true'><Message>At CombineSequenceFileInputFormat.java:[line 45]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='11cb7ddf759bfd31efaa1d6d2cb37f7a' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from org.apache.hadoop.mapred.InputSplit to org.apache.hadoop.mapred.lib.CombineFileSplit in org.apache.hadoop.mapred.lib.CombineTextInputFormat.getRecordReader(InputSplit, JobConf, Reporter)</LongMessage><Class classname='org.apache.hadoop.mapred.lib.CombineTextInputFormat' primary='true'><SourceLine classname='org.apache.hadoop.mapred.lib.CombineTextInputFormat' start='42' end='47' sourcepath='org/apache/hadoop/mapred/lib/CombineTextInputFormat.java' sourcefile='CombineTextInputFormat.java'><Message>At CombineTextInputFormat.java:[lines 42-47]</Message></SourceLine><Message>In class org.apache.hadoop.mapred.lib.CombineTextInputFormat</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapred.lib.CombineTextInputFormat' signature='(Lorg/apache/hadoop/mapred/InputSplit;Lorg/apache/hadoop/mapred/JobConf;Lorg/apache/hadoop/mapred/Reporter;)Lorg/apache/hadoop/mapred/RecordReader;' name='getRecordReader' primary='true'><SourceLine endBytecode='8' classname='org.apache.hadoop.mapred.lib.CombineTextInputFormat' start='47' end='47' sourcepath='org/apache/hadoop/mapred/lib/CombineTextInputFormat.java' sourcefile='CombineTextInputFormat.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapred.lib.CombineTextInputFormat.getRecordReader(InputSplit, JobConf, Reporter)</Message></Method><Type role='TYPE_FOUND' descriptor='Lorg/apache/hadoop/mapred/InputSplit;'><SourceLine classname='org.apache.hadoop.mapred.InputSplit' sourcepath='org/apache/hadoop/mapred/InputSplit.java' sourcefile='InputSplit.java'><Message>In InputSplit.java</Message></SourceLine><Message>Actual type org.apache.hadoop.mapred.InputSplit</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/mapred/lib/CombineFileSplit;'><SourceLine classname='org.apache.hadoop.mapred.lib.CombineFileSplit' start='37' end='59' sourcepath='org/apache/hadoop/mapred/lib/CombineFileSplit.java' sourcefile='CombineFileSplit.java'><Message>At CombineFileSplit.java:[lines 37-59]</Message></SourceLine><Message>Expected org.apache.hadoop.mapred.lib.CombineFileSplit</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='5' name='split' register='1'><Message>Value loaded from split</Message></LocalVariable><SourceLine endBytecode='6' classname='org.apache.hadoop.mapred.lib.CombineTextInputFormat' start='47' end='47' sourcepath='org/apache/hadoop/mapred/lib/CombineTextInputFormat.java' sourcefile='CombineTextInputFormat.java' startBytecode='6' primary='true'><Message>At CombineTextInputFormat.java:[line 47]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='6d24a0bcc7921f1644506cf4456fa876' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from org.apache.hadoop.mapred.InputSplit to org.apache.hadoop.mapred.lib.TaggedInputSplit in org.apache.hadoop.mapred.lib.DelegatingInputFormat.getRecordReader(InputSplit, JobConf, Reporter)</LongMessage><Class classname='org.apache.hadoop.mapred.lib.DelegatingInputFormat' primary='true'><SourceLine classname='org.apache.hadoop.mapred.lib.DelegatingInputFormat' start='49' end='128' sourcepath='org/apache/hadoop/mapred/lib/DelegatingInputFormat.java' sourcefile='DelegatingInputFormat.java'><Message>At DelegatingInputFormat.java:[lines 49-128]</Message></SourceLine><Message>In class org.apache.hadoop.mapred.lib.DelegatingInputFormat</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapred.lib.DelegatingInputFormat' signature='(Lorg/apache/hadoop/mapred/InputSplit;Lorg/apache/hadoop/mapred/JobConf;Lorg/apache/hadoop/mapred/Reporter;)Lorg/apache/hadoop/mapred/RecordReader;' name='getRecordReader' primary='true'><SourceLine endBytecode='15' classname='org.apache.hadoop.mapred.lib.DelegatingInputFormat' start='125' end='128' sourcepath='org/apache/hadoop/mapred/lib/DelegatingInputFormat.java' sourcefile='DelegatingInputFormat.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapred.lib.DelegatingInputFormat.getRecordReader(InputSplit, JobConf, Reporter)</Message></Method><Type role='TYPE_FOUND' descriptor='Lorg/apache/hadoop/mapred/InputSplit;'><SourceLine classname='org.apache.hadoop.mapred.InputSplit' sourcepath='org/apache/hadoop/mapred/InputSplit.java' sourcefile='InputSplit.java'><Message>In InputSplit.java</Message></SourceLine><Message>Actual type org.apache.hadoop.mapred.InputSplit</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/mapred/lib/TaggedInputSplit;'><SourceLine classname='org.apache.hadoop.mapred.lib.TaggedInputSplit' start='50' end='143' sourcepath='org/apache/hadoop/mapred/lib/TaggedInputSplit.java' sourcefile='TaggedInputSplit.java'><Message>At TaggedInputSplit.java:[lines 50-143]</Message></SourceLine><Message>Expected org.apache.hadoop.mapred.lib.TaggedInputSplit</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='0' name='split' register='1'><Message>Value loaded from split</Message></LocalVariable><SourceLine endBytecode='1' classname='org.apache.hadoop.mapred.lib.DelegatingInputFormat' start='125' end='125' sourcepath='org/apache/hadoop/mapred/lib/DelegatingInputFormat.java' sourcefile='DelegatingInputFormat.java' startBytecode='1' primary='true'><Message>At DelegatingInputFormat.java:[line 125]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='9c81e98ef9335d1f2bbd50c4e8f204a0' rank='14' abbrev='Nm' category='BAD_PRACTICE' priority='1' type='NM_SAME_SIMPLE_NAME_AS_SUPERCLASS' instanceOccurrenceMax='0'><ShortMessage>Class names shouldn't shadow simple name of superclass</ShortMessage><LongMessage>The class name org.apache.hadoop.mapred.lib.InputSampler shadows the simple name of the superclass org.apache.hadoop.mapreduce.lib.partition.InputSampler</LongMessage><Class classname='org.apache.hadoop.mapred.lib.InputSampler' primary='true'><SourceLine classname='org.apache.hadoop.mapred.lib.InputSampler' start='38' end='50' sourcepath='org/apache/hadoop/mapred/lib/InputSampler.java' sourcefile='InputSampler.java'><Message>At InputSampler.java:[lines 38-50]</Message></SourceLine><Message>In class org.apache.hadoop.mapred.lib.InputSampler</Message></Class><Class classname='org.apache.hadoop.mapreduce.lib.partition.InputSampler'><SourceLine classname='org.apache.hadoop.mapreduce.lib.partition.InputSampler' start='57' end='414' sourcepath='org/apache/hadoop/mapreduce/lib/partition/InputSampler.java' sourcefile='InputSampler.java'><Message>At InputSampler.java:[lines 57-414]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.lib.partition.InputSampler</Message></Class><SourceLine synthetic='true' classname='org.apache.hadoop.mapred.lib.InputSampler' start='38' end='50' sourcepath='org/apache/hadoop/mapred/lib/InputSampler.java' sourcefile='InputSampler.java'><Message>At InputSampler.java:[lines 38-50]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='d42744e9d1a4d56e202424e479264752' rank='14' abbrev='Nm' category='BAD_PRACTICE' priority='1' type='NM_SAME_SIMPLE_NAME_AS_SUPERCLASS' instanceOccurrenceMax='0'><ShortMessage>Class names shouldn't shadow simple name of superclass</ShortMessage><LongMessage>The class name org.apache.hadoop.mapred.lib.InputSampler$IntervalSampler shadows the simple name of the superclass org.apache.hadoop.mapreduce.lib.partition.InputSampler$IntervalSampler</LongMessage><Class classname='org.apache.hadoop.mapred.lib.InputSampler$IntervalSampler' primary='true'><SourceLine classname='org.apache.hadoop.mapred.lib.InputSampler$IntervalSampler' start='221' end='262' sourcepath='org/apache/hadoop/mapred/lib/InputSampler.java' sourcefile='InputSampler.java'><Message>At InputSampler.java:[lines 221-262]</Message></SourceLine><Message>In class org.apache.hadoop.mapred.lib.InputSampler$IntervalSampler</Message></Class><Class classname='org.apache.hadoop.mapreduce.lib.partition.InputSampler$IntervalSampler'><SourceLine classname='org.apache.hadoop.mapreduce.lib.partition.InputSampler$IntervalSampler' start='258' end='301' sourcepath='org/apache/hadoop/mapreduce/lib/partition/InputSampler.java' sourcefile='InputSampler.java'><Message>At InputSampler.java:[lines 258-301]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.lib.partition.InputSampler$IntervalSampler</Message></Class><SourceLine synthetic='true' classname='org.apache.hadoop.mapred.lib.InputSampler$IntervalSampler' start='221' end='262' sourcepath='org/apache/hadoop/mapred/lib/InputSampler.java' sourcefile='InputSampler.java'><Message>At InputSampler.java:[lines 221-262]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='19fef2b46f1c50a5e854a45ba15e851f' rank='14' abbrev='Nm' category='BAD_PRACTICE' priority='1' type='NM_SAME_SIMPLE_NAME_AS_SUPERCLASS' instanceOccurrenceMax='0'><ShortMessage>Class names shouldn't shadow simple name of superclass</ShortMessage><LongMessage>The class name org.apache.hadoop.mapred.lib.InputSampler$RandomSampler shadows the simple name of the superclass org.apache.hadoop.mapreduce.lib.partition.InputSampler$RandomSampler</LongMessage><Class classname='org.apache.hadoop.mapred.lib.InputSampler$RandomSampler' primary='true'><SourceLine classname='org.apache.hadoop.mapred.lib.InputSampler$RandomSampler' start='138' end='204' sourcepath='org/apache/hadoop/mapred/lib/InputSampler.java' sourcefile='InputSampler.java'><Message>At InputSampler.java:[lines 138-204]</Message></SourceLine><Message>In class org.apache.hadoop.mapred.lib.InputSampler$RandomSampler</Message></Class><Class classname='org.apache.hadoop.mapreduce.lib.partition.InputSampler$RandomSampler'><SourceLine classname='org.apache.hadoop.mapreduce.lib.partition.InputSampler$RandomSampler' start='172' end='241' sourcepath='org/apache/hadoop/mapreduce/lib/partition/InputSampler.java' sourcefile='InputSampler.java'><Message>At InputSampler.java:[lines 172-241]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.lib.partition.InputSampler$RandomSampler</Message></Class><SourceLine synthetic='true' classname='org.apache.hadoop.mapred.lib.InputSampler$RandomSampler' start='138' end='204' sourcepath='org/apache/hadoop/mapred/lib/InputSampler.java' sourcefile='InputSampler.java'><Message>At InputSampler.java:[lines 138-204]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='f6867c1ae6afc487308d41835da9e333' rank='16' abbrev='Nm' category='BAD_PRACTICE' priority='2' type='NM_SAME_SIMPLE_NAME_AS_INTERFACE' instanceOccurrenceMax='0'><ShortMessage>Class names shouldn't shadow simple name of implemented interface</ShortMessage><LongMessage>The class name org.apache.hadoop.mapred.lib.InputSampler$Sampler shadows the simple name of implemented interface org.apache.hadoop.mapreduce.lib.partition.InputSampler$Sampler</LongMessage><Class classname='org.apache.hadoop.mapred.lib.InputSampler$Sampler' primary='true'><SourceLine classname='org.apache.hadoop.mapred.lib.InputSampler$Sampler' sourcepath='org/apache/hadoop/mapred/lib/InputSampler.java' sourcefile='InputSampler.java'><Message>In InputSampler.java</Message></SourceLine><Message>In class org.apache.hadoop.mapred.lib.InputSampler$Sampler</Message></Class><Class classname='org.apache.hadoop.mapreduce.lib.partition.InputSampler$Sampler'><SourceLine classname='org.apache.hadoop.mapreduce.lib.partition.InputSampler$Sampler' sourcepath='org/apache/hadoop/mapreduce/lib/partition/InputSampler.java' sourcefile='InputSampler.java'><Message>In InputSampler.java</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.lib.partition.InputSampler$Sampler</Message></Class><SourceLine synthetic='true' classname='org.apache.hadoop.mapred.lib.InputSampler$Sampler' sourcepath='org/apache/hadoop/mapred/lib/InputSampler.java' sourcefile='InputSampler.java'><Message>In InputSampler.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='172d0c161b394660573cc1dc4c3262c4' rank='14' abbrev='Nm' category='BAD_PRACTICE' priority='1' type='NM_SAME_SIMPLE_NAME_AS_SUPERCLASS' instanceOccurrenceMax='0'><ShortMessage>Class names shouldn't shadow simple name of superclass</ShortMessage><LongMessage>The class name org.apache.hadoop.mapred.lib.InputSampler$SplitSampler shadows the simple name of the superclass org.apache.hadoop.mapreduce.lib.partition.InputSampler$SplitSampler</LongMessage><Class classname='org.apache.hadoop.mapred.lib.InputSampler$SplitSampler' primary='true'><SourceLine classname='org.apache.hadoop.mapred.lib.InputSampler$SplitSampler' start='78' end='117' sourcepath='org/apache/hadoop/mapred/lib/InputSampler.java' sourcefile='InputSampler.java'><Message>At InputSampler.java:[lines 78-117]</Message></SourceLine><Message>In class org.apache.hadoop.mapred.lib.InputSampler$SplitSampler</Message></Class><Class classname='org.apache.hadoop.mapreduce.lib.partition.InputSampler$SplitSampler'><SourceLine classname='org.apache.hadoop.mapreduce.lib.partition.InputSampler$SplitSampler' start='109' end='150' sourcepath='org/apache/hadoop/mapreduce/lib/partition/InputSampler.java' sourcefile='InputSampler.java'><Message>At InputSampler.java:[lines 109-150]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.lib.partition.InputSampler$SplitSampler</Message></Class><SourceLine synthetic='true' classname='org.apache.hadoop.mapred.lib.InputSampler$SplitSampler' start='78' end='117' sourcepath='org/apache/hadoop/mapred/lib/InputSampler.java' sourcefile='InputSampler.java'><Message>At InputSampler.java:[lines 78-117]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='c29a68f90e78309a82feb5dc3e9d7c50' rank='14' abbrev='Nm' category='BAD_PRACTICE' priority='1' type='NM_SAME_SIMPLE_NAME_AS_SUPERCLASS' instanceOccurrenceMax='0'><ShortMessage>Class names shouldn't shadow simple name of superclass</ShortMessage><LongMessage>The class name org.apache.hadoop.mapred.lib.KeyFieldBasedComparator shadows the simple name of the superclass org.apache.hadoop.mapreduce.lib.partition.KeyFieldBasedComparator</LongMessage><Class classname='org.apache.hadoop.mapred.lib.KeyFieldBasedComparator' primary='true'><SourceLine classname='org.apache.hadoop.mapred.lib.KeyFieldBasedComparator' start='44' end='50' sourcepath='org/apache/hadoop/mapred/lib/KeyFieldBasedComparator.java' sourcefile='KeyFieldBasedComparator.java'><Message>At KeyFieldBasedComparator.java:[lines 44-50]</Message></SourceLine><Message>In class org.apache.hadoop.mapred.lib.KeyFieldBasedComparator</Message></Class><Class classname='org.apache.hadoop.mapreduce.lib.partition.KeyFieldBasedComparator'><SourceLine classname='org.apache.hadoop.mapreduce.lib.partition.KeyFieldBasedComparator' start='55' end='371' sourcepath='org/apache/hadoop/mapreduce/lib/partition/KeyFieldBasedComparator.java' sourcefile='KeyFieldBasedComparator.java'><Message>At KeyFieldBasedComparator.java:[lines 55-371]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.lib.partition.KeyFieldBasedComparator</Message></Class><SourceLine synthetic='true' classname='org.apache.hadoop.mapred.lib.KeyFieldBasedComparator' start='44' end='50' sourcepath='org/apache/hadoop/mapred/lib/KeyFieldBasedComparator.java' sourcefile='KeyFieldBasedComparator.java'><Message>At KeyFieldBasedComparator.java:[lines 44-50]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='986e756ef925a50b9b46ccc68f662841' rank='19' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_COMPARATOR_SHOULD_BE_SERIALIZABLE' instanceOccurrenceMax='0'><ShortMessage>Comparator doesn't implement Serializable</ShortMessage><LongMessage>org.apache.hadoop.mapred.lib.KeyFieldBasedComparator implements Comparator but not Serializable</LongMessage><Class classname='org.apache.hadoop.mapred.lib.KeyFieldBasedComparator' primary='true'><SourceLine classname='org.apache.hadoop.mapred.lib.KeyFieldBasedComparator' start='44' end='50' sourcepath='org/apache/hadoop/mapred/lib/KeyFieldBasedComparator.java' sourcefile='KeyFieldBasedComparator.java'><Message>At KeyFieldBasedComparator.java:[lines 44-50]</Message></SourceLine><Message>In class org.apache.hadoop.mapred.lib.KeyFieldBasedComparator</Message></Class><SourceLine synthetic='true' classname='org.apache.hadoop.mapred.lib.KeyFieldBasedComparator' start='44' end='50' sourcepath='org/apache/hadoop/mapred/lib/KeyFieldBasedComparator.java' sourcefile='KeyFieldBasedComparator.java'><Message>At KeyFieldBasedComparator.java:[lines 44-50]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='1f4e4fd0205346fbff69a718b2c83536' rank='14' abbrev='Nm' category='BAD_PRACTICE' priority='1' type='NM_SAME_SIMPLE_NAME_AS_SUPERCLASS' instanceOccurrenceMax='0'><ShortMessage>Class names shouldn't shadow simple name of superclass</ShortMessage><LongMessage>The class name org.apache.hadoop.mapred.lib.KeyFieldBasedPartitioner shadows the simple name of the superclass org.apache.hadoop.mapreduce.lib.partition.KeyFieldBasedPartitioner</LongMessage><Class classname='org.apache.hadoop.mapred.lib.KeyFieldBasedPartitioner' primary='true'><SourceLine classname='org.apache.hadoop.mapred.lib.KeyFieldBasedPartitioner' start='40' end='46' sourcepath='org/apache/hadoop/mapred/lib/KeyFieldBasedPartitioner.java' sourcefile='KeyFieldBasedPartitioner.java'><Message>At KeyFieldBasedPartitioner.java:[lines 40-46]</Message></SourceLine><Message>In class org.apache.hadoop.mapred.lib.KeyFieldBasedPartitioner</Message></Class><Class classname='org.apache.hadoop.mapreduce.lib.partition.KeyFieldBasedPartitioner'><SourceLine classname='org.apache.hadoop.mapreduce.lib.partition.KeyFieldBasedPartitioner' start='51' end='154' sourcepath='org/apache/hadoop/mapreduce/lib/partition/KeyFieldBasedPartitioner.java' sourcefile='KeyFieldBasedPartitioner.java'><Message>At KeyFieldBasedPartitioner.java:[lines 51-154]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.lib.partition.KeyFieldBasedPartitioner</Message></Class><SourceLine synthetic='true' classname='org.apache.hadoop.mapred.lib.KeyFieldBasedPartitioner' start='40' end='46' sourcepath='org/apache/hadoop/mapred/lib/KeyFieldBasedPartitioner.java' sourcefile='KeyFieldBasedPartitioner.java'><Message>At KeyFieldBasedPartitioner.java:[lines 40-46]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='8e7c5215ac272a28093a5b02cd3b18ad' rank='20' abbrev='SIC' category='PERFORMANCE' priority='3' type='SIC_INNER_SHOULD_BE_STATIC_ANON' instanceOccurrenceMax='0'><ShortMessage>Could be refactored into a named static inner class</ShortMessage><LongMessage>The class org.apache.hadoop.mapred.lib.MultipleOutputs$1 could be refactored into a named _static_ inner class</LongMessage><Class role='CLASS_ANONYMOUS' classname='org.apache.hadoop.mapred.lib.MultipleOutputs$1'><SourceLine classname='org.apache.hadoop.mapred.lib.MultipleOutputs$1' start='511' end='516' sourcepath='org/apache/hadoop/mapred/lib/MultipleOutputs.java' sourcefile='MultipleOutputs.java'><Message>At MultipleOutputs.java:[lines 511-516]</Message></SourceLine><Message>Anonymous class org.apache.hadoop.mapred.lib.MultipleOutputs$1</Message></Class><Class classname='org.apache.hadoop.mapred.lib.MultipleOutputs' primary='true'><SourceLine classname='org.apache.hadoop.mapred.lib.MultipleOutputs' start='118' end='534' sourcepath='org/apache/hadoop/mapred/lib/MultipleOutputs.java' sourcefile='MultipleOutputs.java'><Message>At MultipleOutputs.java:[lines 118-534]</Message></SourceLine><Message>In class org.apache.hadoop.mapred.lib.MultipleOutputs</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapred.lib.MultipleOutputs' signature='(Ljava/lang/String;Ljava/lang/String;Lorg/apache/hadoop/mapred/Reporter;)Lorg/apache/hadoop/mapred/OutputCollector;' name='getCollector' primary='true'><SourceLine endBytecode='328' classname='org.apache.hadoop.mapred.lib.MultipleOutputs' start='491' end='511' sourcepath='org/apache/hadoop/mapred/lib/MultipleOutputs.java' sourcefile='MultipleOutputs.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapred.lib.MultipleOutputs.getCollector(String, String, Reporter)</Message></Method><SourceLine endBytecode='160' classname='org.apache.hadoop.mapred.lib.MultipleOutputs' start='511' end='511' sourcepath='org/apache/hadoop/mapred/lib/MultipleOutputs.java' sourcefile='MultipleOutputs.java' startBytecode='160' primary='true'><Message>At MultipleOutputs.java:[line 511]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='9f754a598bbbbe13b26451d450fdb98b' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from org.apache.hadoop.mapred.InputSplit to org.apache.hadoop.mapred.FileSplit in org.apache.hadoop.mapred.lib.NLineInputFormat.getRecordReader(InputSplit, JobConf, Reporter)</LongMessage><Class classname='org.apache.hadoop.mapred.lib.NLineInputFormat' primary='true'><SourceLine classname='org.apache.hadoop.mapred.lib.NLineInputFormat' start='59' end='107' sourcepath='org/apache/hadoop/mapred/lib/NLineInputFormat.java' sourcefile='NLineInputFormat.java'><Message>At NLineInputFormat.java:[lines 59-107]</Message></SourceLine><Message>In class org.apache.hadoop.mapred.lib.NLineInputFormat</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapred.lib.NLineInputFormat' signature='(Lorg/apache/hadoop/mapred/InputSplit;Lorg/apache/hadoop/mapred/JobConf;Lorg/apache/hadoop/mapred/Reporter;)Lorg/apache/hadoop/mapred/RecordReader;' name='getRecordReader' primary='true'><SourceLine endBytecode='10' classname='org.apache.hadoop.mapred.lib.NLineInputFormat' start='68' end='69' sourcepath='org/apache/hadoop/mapred/lib/NLineInputFormat.java' sourcefile='NLineInputFormat.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapred.lib.NLineInputFormat.getRecordReader(InputSplit, JobConf, Reporter)</Message></Method><Type role='TYPE_FOUND' descriptor='Lorg/apache/hadoop/mapred/InputSplit;'><SourceLine classname='org.apache.hadoop.mapred.InputSplit' sourcepath='org/apache/hadoop/mapred/InputSplit.java' sourcefile='InputSplit.java'><Message>In InputSplit.java</Message></SourceLine><Message>Actual type org.apache.hadoop.mapred.InputSplit</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/mapred/FileSplit;'><SourceLine classname='org.apache.hadoop.mapred.FileSplit' start='39' end='113' sourcepath='org/apache/hadoop/mapred/FileSplit.java' sourcefile='FileSplit.java'><Message>At FileSplit.java:[lines 39-113]</Message></SourceLine><Message>Expected org.apache.hadoop.mapred.FileSplit</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='15' name='genericSplit' register='1'><Message>Value loaded from genericSplit</Message></LocalVariable><SourceLine endBytecode='16' classname='org.apache.hadoop.mapred.lib.NLineInputFormat' start='69' end='69' sourcepath='org/apache/hadoop/mapred/lib/NLineInputFormat.java' sourcefile='NLineInputFormat.java' startBytecode='16' primary='true'><Message>At NLineInputFormat.java:[line 69]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='61491128b9fb45c6c89421f52e18f0b7' rank='20' abbrev='UwF' category='STYLE' priority='3' type='UWF_FIELD_NOT_INITIALIZED_IN_CONSTRUCTOR' instanceOccurrenceMax='0'><ShortMessage>Field not initialized in constructor but dereferenced without null check</ShortMessage><LongMessage>RegexMapper.pattern not initialized in constructor and dereferenced in org.apache.hadoop.mapred.lib.RegexMapper.map(Object, Text, OutputCollector, Reporter)</LongMessage><Class classname='org.apache.hadoop.mapred.lib.RegexMapper' primary='true'><SourceLine classname='org.apache.hadoop.mapred.lib.RegexMapper' start='39' end='63' sourcepath='org/apache/hadoop/mapred/lib/RegexMapper.java' sourcefile='RegexMapper.java'><Message>At RegexMapper.java:[lines 39-63]</Message></SourceLine><Message>In class org.apache.hadoop.mapred.lib.RegexMapper</Message></Class><Field isStatic='false' classname='org.apache.hadoop.mapred.lib.RegexMapper' signature='Ljava/util/regex/Pattern;' name='pattern' primary='true'><SourceLine classname='org.apache.hadoop.mapred.lib.RegexMapper' sourcepath='org/apache/hadoop/mapred/lib/RegexMapper.java' sourcefile='RegexMapper.java'><Message>In RegexMapper.java</Message></SourceLine><Message>Field org.apache.hadoop.mapred.lib.RegexMapper.pattern</Message></Field><Method isStatic='false' classname='org.apache.hadoop.mapred.lib.RegexMapper' signature='(Ljava/lang/Object;Lorg/apache/hadoop/io/Text;Lorg/apache/hadoop/mapred/OutputCollector;Lorg/apache/hadoop/mapred/Reporter;)V' name='map' primary='true'><SourceLine endBytecode='232' classname='org.apache.hadoop.mapred.lib.RegexMapper' start='58' end='63' sourcepath='org/apache/hadoop/mapred/lib/RegexMapper.java' sourcefile='RegexMapper.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapred.lib.RegexMapper.map(Object, Text, OutputCollector, Reporter)</Message></Method><SourceLine endBytecode='12' classname='org.apache.hadoop.mapred.lib.RegexMapper' start='59' end='59' sourcepath='org/apache/hadoop/mapred/lib/RegexMapper.java' sourcefile='RegexMapper.java' startBytecode='12' primary='true'><Message>At RegexMapper.java:[line 59]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='78cf3a5f6f90cf8f8f9544ee97b87b6a' rank='14' abbrev='Nm' category='BAD_PRACTICE' priority='1' type='NM_SAME_SIMPLE_NAME_AS_SUPERCLASS' instanceOccurrenceMax='0'><ShortMessage>Class names shouldn't shadow simple name of superclass</ShortMessage><LongMessage>The class name org.apache.hadoop.mapred.lib.TotalOrderPartitioner shadows the simple name of the superclass org.apache.hadoop.mapreduce.lib.partition.TotalOrderPartitioner</LongMessage><Class classname='org.apache.hadoop.mapred.lib.TotalOrderPartitioner' primary='true'><SourceLine classname='org.apache.hadoop.mapred.lib.TotalOrderPartitioner' start='38' end='68' sourcepath='org/apache/hadoop/mapred/lib/TotalOrderPartitioner.java' sourcefile='TotalOrderPartitioner.java'><Message>At TotalOrderPartitioner.java:[lines 38-68]</Message></SourceLine><Message>In class org.apache.hadoop.mapred.lib.TotalOrderPartitioner</Message></Class><Class classname='org.apache.hadoop.mapreduce.lib.partition.TotalOrderPartitioner'><SourceLine classname='org.apache.hadoop.mapreduce.lib.partition.TotalOrderPartitioner' start='62' end='411' sourcepath='org/apache/hadoop/mapreduce/lib/partition/TotalOrderPartitioner.java' sourcefile='TotalOrderPartitioner.java'><Message>At TotalOrderPartitioner.java:[lines 62-411]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.lib.partition.TotalOrderPartitioner</Message></Class><SourceLine synthetic='true' classname='org.apache.hadoop.mapred.lib.TotalOrderPartitioner' start='38' end='68' sourcepath='org/apache/hadoop/mapred/lib/TotalOrderPartitioner.java' sourcefile='TotalOrderPartitioner.java'><Message>At TotalOrderPartitioner.java:[lines 38-68]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='cde9343a5a53594ad62e9b42bdb44ba4' rank='14' abbrev='Nm' category='BAD_PRACTICE' priority='1' type='NM_SAME_SIMPLE_NAME_AS_SUPERCLASS' instanceOccurrenceMax='0'><ShortMessage>Class names shouldn't shadow simple name of superclass</ShortMessage><LongMessage>The class name org.apache.hadoop.mapred.lib.aggregate.DoubleValueSum shadows the simple name of the superclass org.apache.hadoop.mapreduce.lib.aggregate.DoubleValueSum</LongMessage><Class classname='org.apache.hadoop.mapred.lib.aggregate.DoubleValueSum' primary='true'><SourceLine classname='org.apache.hadoop.mapred.lib.aggregate.DoubleValueSum' start='30' end='30' sourcepath='org/apache/hadoop/mapred/lib/aggregate/DoubleValueSum.java' sourcefile='DoubleValueSum.java'><Message>At DoubleValueSum.java:[line 30]</Message></SourceLine><Message>In class org.apache.hadoop.mapred.lib.aggregate.DoubleValueSum</Message></Class><Class classname='org.apache.hadoop.mapreduce.lib.aggregate.DoubleValueSum'><SourceLine classname='org.apache.hadoop.mapreduce.lib.aggregate.DoubleValueSum' start='36' end='97' sourcepath='org/apache/hadoop/mapreduce/lib/aggregate/DoubleValueSum.java' sourcefile='DoubleValueSum.java'><Message>At DoubleValueSum.java:[lines 36-97]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.lib.aggregate.DoubleValueSum</Message></Class><SourceLine synthetic='true' classname='org.apache.hadoop.mapred.lib.aggregate.DoubleValueSum' start='30' end='30' sourcepath='org/apache/hadoop/mapred/lib/aggregate/DoubleValueSum.java' sourcefile='DoubleValueSum.java'><Message>At DoubleValueSum.java:[line 30]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='f77dfcfcb48326e2225baef1de09d207' rank='14' abbrev='Nm' category='BAD_PRACTICE' priority='1' type='NM_SAME_SIMPLE_NAME_AS_SUPERCLASS' instanceOccurrenceMax='0'><ShortMessage>Class names shouldn't shadow simple name of superclass</ShortMessage><LongMessage>The class name org.apache.hadoop.mapred.lib.aggregate.LongValueMax shadows the simple name of the superclass org.apache.hadoop.mapreduce.lib.aggregate.LongValueMax</LongMessage><Class classname='org.apache.hadoop.mapred.lib.aggregate.LongValueMax' primary='true'><SourceLine classname='org.apache.hadoop.mapred.lib.aggregate.LongValueMax' start='31' end='31' sourcepath='org/apache/hadoop/mapred/lib/aggregate/LongValueMax.java' sourcefile='LongValueMax.java'><Message>At LongValueMax.java:[line 31]</Message></SourceLine><Message>In class org.apache.hadoop.mapred.lib.aggregate.LongValueMax</Message></Class><Class classname='org.apache.hadoop.mapreduce.lib.aggregate.LongValueMax'><SourceLine classname='org.apache.hadoop.mapreduce.lib.aggregate.LongValueMax' start='35' end='101' sourcepath='org/apache/hadoop/mapreduce/lib/aggregate/LongValueMax.java' sourcefile='LongValueMax.java'><Message>At LongValueMax.java:[lines 35-101]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.lib.aggregate.LongValueMax</Message></Class><SourceLine synthetic='true' classname='org.apache.hadoop.mapred.lib.aggregate.LongValueMax' start='31' end='31' sourcepath='org/apache/hadoop/mapred/lib/aggregate/LongValueMax.java' sourcefile='LongValueMax.java'><Message>At LongValueMax.java:[line 31]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='5a8ca2e7e6896f78a1393dd6449852c6' rank='14' abbrev='Nm' category='BAD_PRACTICE' priority='1' type='NM_SAME_SIMPLE_NAME_AS_SUPERCLASS' instanceOccurrenceMax='0'><ShortMessage>Class names shouldn't shadow simple name of superclass</ShortMessage><LongMessage>The class name org.apache.hadoop.mapred.lib.aggregate.LongValueMin shadows the simple name of the superclass org.apache.hadoop.mapreduce.lib.aggregate.LongValueMin</LongMessage><Class classname='org.apache.hadoop.mapred.lib.aggregate.LongValueMin' primary='true'><SourceLine classname='org.apache.hadoop.mapred.lib.aggregate.LongValueMin' start='30' end='30' sourcepath='org/apache/hadoop/mapred/lib/aggregate/LongValueMin.java' sourcefile='LongValueMin.java'><Message>At LongValueMin.java:[line 30]</Message></SourceLine><Message>In class org.apache.hadoop.mapred.lib.aggregate.LongValueMin</Message></Class><Class classname='org.apache.hadoop.mapreduce.lib.aggregate.LongValueMin'><SourceLine classname='org.apache.hadoop.mapreduce.lib.aggregate.LongValueMin' start='35' end='101' sourcepath='org/apache/hadoop/mapreduce/lib/aggregate/LongValueMin.java' sourcefile='LongValueMin.java'><Message>At LongValueMin.java:[lines 35-101]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.lib.aggregate.LongValueMin</Message></Class><SourceLine synthetic='true' classname='org.apache.hadoop.mapred.lib.aggregate.LongValueMin' start='30' end='30' sourcepath='org/apache/hadoop/mapred/lib/aggregate/LongValueMin.java' sourcefile='LongValueMin.java'><Message>At LongValueMin.java:[line 30]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='b212a90fd0ba17de7ec1aac160e0c3fb' rank='14' abbrev='Nm' category='BAD_PRACTICE' priority='1' type='NM_SAME_SIMPLE_NAME_AS_SUPERCLASS' instanceOccurrenceMax='0'><ShortMessage>Class names shouldn't shadow simple name of superclass</ShortMessage><LongMessage>The class name org.apache.hadoop.mapred.lib.aggregate.LongValueSum shadows the simple name of the superclass org.apache.hadoop.mapreduce.lib.aggregate.LongValueSum</LongMessage><Class classname='org.apache.hadoop.mapred.lib.aggregate.LongValueSum' primary='true'><SourceLine classname='org.apache.hadoop.mapred.lib.aggregate.LongValueSum' start='30' end='30' sourcepath='org/apache/hadoop/mapred/lib/aggregate/LongValueSum.java' sourcefile='LongValueSum.java'><Message>At LongValueSum.java:[line 30]</Message></SourceLine><Message>In class org.apache.hadoop.mapred.lib.aggregate.LongValueSum</Message></Class><Class classname='org.apache.hadoop.mapreduce.lib.aggregate.LongValueSum'><SourceLine classname='org.apache.hadoop.mapreduce.lib.aggregate.LongValueSum' start='35' end='96' sourcepath='org/apache/hadoop/mapreduce/lib/aggregate/LongValueSum.java' sourcefile='LongValueSum.java'><Message>At LongValueSum.java:[lines 35-96]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.lib.aggregate.LongValueSum</Message></Class><SourceLine synthetic='true' classname='org.apache.hadoop.mapred.lib.aggregate.LongValueSum' start='30' end='30' sourcepath='org/apache/hadoop/mapred/lib/aggregate/LongValueSum.java' sourcefile='LongValueSum.java'><Message>At LongValueSum.java:[line 30]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='f611949b95b5df89ac93a52a9526ee2c' rank='14' abbrev='Nm' category='BAD_PRACTICE' priority='1' type='NM_SAME_SIMPLE_NAME_AS_SUPERCLASS' instanceOccurrenceMax='0'><ShortMessage>Class names shouldn't shadow simple name of superclass</ShortMessage><LongMessage>The class name org.apache.hadoop.mapred.lib.aggregate.StringValueMax shadows the simple name of the superclass org.apache.hadoop.mapreduce.lib.aggregate.StringValueMax</LongMessage><Class classname='org.apache.hadoop.mapred.lib.aggregate.StringValueMax' primary='true'><SourceLine classname='org.apache.hadoop.mapred.lib.aggregate.StringValueMax' start='30' end='30' sourcepath='org/apache/hadoop/mapred/lib/aggregate/StringValueMax.java' sourcefile='StringValueMax.java'><Message>At StringValueMax.java:[line 30]</Message></SourceLine><Message>In class org.apache.hadoop.mapred.lib.aggregate.StringValueMax</Message></Class><Class classname='org.apache.hadoop.mapreduce.lib.aggregate.StringValueMax'><SourceLine classname='org.apache.hadoop.mapreduce.lib.aggregate.StringValueMax' start='35' end='89' sourcepath='org/apache/hadoop/mapreduce/lib/aggregate/StringValueMax.java' sourcefile='StringValueMax.java'><Message>At StringValueMax.java:[lines 35-89]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.lib.aggregate.StringValueMax</Message></Class><SourceLine synthetic='true' classname='org.apache.hadoop.mapred.lib.aggregate.StringValueMax' start='30' end='30' sourcepath='org/apache/hadoop/mapred/lib/aggregate/StringValueMax.java' sourcefile='StringValueMax.java'><Message>At StringValueMax.java:[line 30]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='9ffef187f0ca3e11d3d49d672226ec42' rank='14' abbrev='Nm' category='BAD_PRACTICE' priority='1' type='NM_SAME_SIMPLE_NAME_AS_SUPERCLASS' instanceOccurrenceMax='0'><ShortMessage>Class names shouldn't shadow simple name of superclass</ShortMessage><LongMessage>The class name org.apache.hadoop.mapred.lib.aggregate.StringValueMin shadows the simple name of the superclass org.apache.hadoop.mapreduce.lib.aggregate.StringValueMin</LongMessage><Class classname='org.apache.hadoop.mapred.lib.aggregate.StringValueMin' primary='true'><SourceLine classname='org.apache.hadoop.mapred.lib.aggregate.StringValueMin' start='30' end='30' sourcepath='org/apache/hadoop/mapred/lib/aggregate/StringValueMin.java' sourcefile='StringValueMin.java'><Message>At StringValueMin.java:[line 30]</Message></SourceLine><Message>In class org.apache.hadoop.mapred.lib.aggregate.StringValueMin</Message></Class><Class classname='org.apache.hadoop.mapreduce.lib.aggregate.StringValueMin'><SourceLine classname='org.apache.hadoop.mapreduce.lib.aggregate.StringValueMin' start='35' end='89' sourcepath='org/apache/hadoop/mapreduce/lib/aggregate/StringValueMin.java' sourcefile='StringValueMin.java'><Message>At StringValueMin.java:[lines 35-89]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.lib.aggregate.StringValueMin</Message></Class><SourceLine synthetic='true' classname='org.apache.hadoop.mapred.lib.aggregate.StringValueMin' start='30' end='30' sourcepath='org/apache/hadoop/mapred/lib/aggregate/StringValueMin.java' sourcefile='StringValueMin.java'><Message>At StringValueMin.java:[line 30]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='1ff170245b59c0273fb46cdad2ce02ef' rank='14' abbrev='Nm' category='BAD_PRACTICE' priority='1' type='NM_SAME_SIMPLE_NAME_AS_SUPERCLASS' instanceOccurrenceMax='0'><ShortMessage>Class names shouldn't shadow simple name of superclass</ShortMessage><LongMessage>The class name org.apache.hadoop.mapred.lib.aggregate.UniqValueCount shadows the simple name of the superclass org.apache.hadoop.mapreduce.lib.aggregate.UniqValueCount</LongMessage><Class classname='org.apache.hadoop.mapred.lib.aggregate.UniqValueCount' primary='true'><SourceLine classname='org.apache.hadoop.mapred.lib.aggregate.UniqValueCount' start='37' end='47' sourcepath='org/apache/hadoop/mapred/lib/aggregate/UniqValueCount.java' sourcefile='UniqValueCount.java'><Message>At UniqValueCount.java:[lines 37-47]</Message></SourceLine><Message>In class org.apache.hadoop.mapred.lib.aggregate.UniqValueCount</Message></Class><Class classname='org.apache.hadoop.mapreduce.lib.aggregate.UniqValueCount'><SourceLine classname='org.apache.hadoop.mapreduce.lib.aggregate.UniqValueCount' start='39' end='130' sourcepath='org/apache/hadoop/mapreduce/lib/aggregate/UniqValueCount.java' sourcefile='UniqValueCount.java'><Message>At UniqValueCount.java:[lines 39-130]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.lib.aggregate.UniqValueCount</Message></Class><SourceLine synthetic='true' classname='org.apache.hadoop.mapred.lib.aggregate.UniqValueCount' start='37' end='47' sourcepath='org/apache/hadoop/mapred/lib/aggregate/UniqValueCount.java' sourcefile='UniqValueCount.java'><Message>At UniqValueCount.java:[lines 37-47]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='293f4b8c72301075849c548dc6b8ac35' rank='14' abbrev='Nm' category='BAD_PRACTICE' priority='1' type='NM_SAME_SIMPLE_NAME_AS_SUPERCLASS' instanceOccurrenceMax='0'><ShortMessage>Class names shouldn't shadow simple name of superclass</ShortMessage><LongMessage>The class name org.apache.hadoop.mapred.lib.aggregate.UserDefinedValueAggregatorDescriptor shadows the simple name of the superclass org.apache.hadoop.mapreduce.lib.aggregate.UserDefinedValueAggregatorDescriptor</LongMessage><Class classname='org.apache.hadoop.mapred.lib.aggregate.UserDefinedValueAggregatorDescriptor' primary='true'><SourceLine classname='org.apache.hadoop.mapred.lib.aggregate.UserDefinedValueAggregatorDescriptor' start='45' end='64' sourcepath='org/apache/hadoop/mapred/lib/aggregate/UserDefinedValueAggregatorDescriptor.java' sourcefile='UserDefinedValueAggregatorDescriptor.java'><Message>At UserDefinedValueAggregatorDescriptor.java:[lines 45-64]</Message></SourceLine><Message>In class org.apache.hadoop.mapred.lib.aggregate.UserDefinedValueAggregatorDescriptor</Message></Class><Class classname='org.apache.hadoop.mapreduce.lib.aggregate.UserDefinedValueAggregatorDescriptor'><SourceLine classname='org.apache.hadoop.mapreduce.lib.aggregate.UserDefinedValueAggregatorDescriptor' start='45' end='121' sourcepath='org/apache/hadoop/mapreduce/lib/aggregate/UserDefinedValueAggregatorDescriptor.java' sourcefile='UserDefinedValueAggregatorDescriptor.java'><Message>At UserDefinedValueAggregatorDescriptor.java:[lines 45-121]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.lib.aggregate.UserDefinedValueAggregatorDescriptor</Message></Class><SourceLine synthetic='true' classname='org.apache.hadoop.mapred.lib.aggregate.UserDefinedValueAggregatorDescriptor' start='45' end='64' sourcepath='org/apache/hadoop/mapred/lib/aggregate/UserDefinedValueAggregatorDescriptor.java' sourcefile='UserDefinedValueAggregatorDescriptor.java'><Message>At UserDefinedValueAggregatorDescriptor.java:[lines 45-64]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='c6e7d8707de2dbeb76730a70241d03e5' rank='16' abbrev='Nm' category='BAD_PRACTICE' priority='2' type='NM_SAME_SIMPLE_NAME_AS_INTERFACE' instanceOccurrenceMax='0'><ShortMessage>Class names shouldn't shadow simple name of implemented interface</ShortMessage><LongMessage>The class name org.apache.hadoop.mapred.lib.aggregate.ValueAggregator shadows the simple name of implemented interface org.apache.hadoop.mapreduce.lib.aggregate.ValueAggregator</LongMessage><Class classname='org.apache.hadoop.mapred.lib.aggregate.ValueAggregator' primary='true'><SourceLine classname='org.apache.hadoop.mapred.lib.aggregate.ValueAggregator' sourcepath='org/apache/hadoop/mapred/lib/aggregate/ValueAggregator.java' sourcefile='ValueAggregator.java'><Message>In ValueAggregator.java</Message></SourceLine><Message>In class org.apache.hadoop.mapred.lib.aggregate.ValueAggregator</Message></Class><Class classname='org.apache.hadoop.mapreduce.lib.aggregate.ValueAggregator'><SourceLine classname='org.apache.hadoop.mapreduce.lib.aggregate.ValueAggregator' sourcepath='org/apache/hadoop/mapreduce/lib/aggregate/ValueAggregator.java' sourcefile='ValueAggregator.java'><Message>In ValueAggregator.java</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.lib.aggregate.ValueAggregator</Message></Class><SourceLine synthetic='true' classname='org.apache.hadoop.mapred.lib.aggregate.ValueAggregator' sourcepath='org/apache/hadoop/mapred/lib/aggregate/ValueAggregator.java' sourcefile='ValueAggregator.java'><Message>In ValueAggregator.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='8893df36de9351ed75210e7015ef0a43' rank='14' abbrev='Nm' category='BAD_PRACTICE' priority='1' type='NM_SAME_SIMPLE_NAME_AS_SUPERCLASS' instanceOccurrenceMax='0'><ShortMessage>Class names shouldn't shadow simple name of superclass</ShortMessage><LongMessage>The class name org.apache.hadoop.mapred.lib.aggregate.ValueAggregatorBaseDescriptor shadows the simple name of the superclass org.apache.hadoop.mapreduce.lib.aggregate.ValueAggregatorBaseDescriptor</LongMessage><Class classname='org.apache.hadoop.mapred.lib.aggregate.ValueAggregatorBaseDescriptor' primary='true'><SourceLine classname='org.apache.hadoop.mapred.lib.aggregate.ValueAggregatorBaseDescriptor' start='34' end='113' sourcepath='org/apache/hadoop/mapred/lib/aggregate/ValueAggregatorBaseDescriptor.java' sourcefile='ValueAggregatorBaseDescriptor.java'><Message>At ValueAggregatorBaseDescriptor.java:[lines 34-113]</Message></SourceLine><Message>In class org.apache.hadoop.mapred.lib.aggregate.ValueAggregatorBaseDescriptor</Message></Class><Class classname='org.apache.hadoop.mapreduce.lib.aggregate.ValueAggregatorBaseDescriptor'><SourceLine classname='org.apache.hadoop.mapreduce.lib.aggregate.ValueAggregatorBaseDescriptor' start='36' end='165' sourcepath='org/apache/hadoop/mapreduce/lib/aggregate/ValueAggregatorBaseDescriptor.java' sourcefile='ValueAggregatorBaseDescriptor.java'><Message>At ValueAggregatorBaseDescriptor.java:[lines 36-165]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.lib.aggregate.ValueAggregatorBaseDescriptor</Message></Class><SourceLine synthetic='true' classname='org.apache.hadoop.mapred.lib.aggregate.ValueAggregatorBaseDescriptor' start='34' end='113' sourcepath='org/apache/hadoop/mapred/lib/aggregate/ValueAggregatorBaseDescriptor.java' sourcefile='ValueAggregatorBaseDescriptor.java'><Message>At ValueAggregatorBaseDescriptor.java:[lines 34-113]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='1b34806776861414b257a0172ecdd9bd' rank='15' abbrev='ST' category='STYLE' priority='1' type='ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD' instanceOccurrenceMax='0'><ShortMessage>Write to static field from instance method</ShortMessage><LongMessage>Write to static field org.apache.hadoop.mapred.lib.aggregate.ValueAggregatorBaseDescriptor.maxNumItems from instance method org.apache.hadoop.mapred.lib.aggregate.ValueAggregatorBaseDescriptor.configure(JobConf)</LongMessage><Class classname='org.apache.hadoop.mapred.lib.aggregate.ValueAggregatorBaseDescriptor' primary='true'><SourceLine classname='org.apache.hadoop.mapred.lib.aggregate.ValueAggregatorBaseDescriptor' start='34' end='113' sourcepath='org/apache/hadoop/mapred/lib/aggregate/ValueAggregatorBaseDescriptor.java' sourcefile='ValueAggregatorBaseDescriptor.java'><Message>At ValueAggregatorBaseDescriptor.java:[lines 34-113]</Message></SourceLine><Message>In class org.apache.hadoop.mapred.lib.aggregate.ValueAggregatorBaseDescriptor</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapred.lib.aggregate.ValueAggregatorBaseDescriptor' signature='(Lorg/apache/hadoop/mapred/JobConf;)V' name='configure' primary='true'><SourceLine endBytecode='77' classname='org.apache.hadoop.mapred.lib.aggregate.ValueAggregatorBaseDescriptor' start='110' end='113' sourcepath='org/apache/hadoop/mapred/lib/aggregate/ValueAggregatorBaseDescriptor.java' sourcefile='ValueAggregatorBaseDescriptor.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapred.lib.aggregate.ValueAggregatorBaseDescriptor.configure(JobConf)</Message></Method><Field isStatic='true' classname='org.apache.hadoop.mapred.lib.aggregate.ValueAggregatorBaseDescriptor' signature='J' name='maxNumItems' primary='true'><SourceLine classname='org.apache.hadoop.mapred.lib.aggregate.ValueAggregatorBaseDescriptor' sourcepath='org/apache/hadoop/mapred/lib/aggregate/ValueAggregatorBaseDescriptor.java' sourcefile='ValueAggregatorBaseDescriptor.java'><Message>In ValueAggregatorBaseDescriptor.java</Message></SourceLine><Message>Field org.apache.hadoop.mapred.lib.aggregate.ValueAggregatorBaseDescriptor.maxNumItems</Message></Field><SourceLine endBytecode='14' classname='org.apache.hadoop.mapred.lib.aggregate.ValueAggregatorBaseDescriptor' start='111' end='111' sourcepath='org/apache/hadoop/mapred/lib/aggregate/ValueAggregatorBaseDescriptor.java' sourcefile='ValueAggregatorBaseDescriptor.java' startBytecode='14' primary='true'><Message>At ValueAggregatorBaseDescriptor.java:[line 111]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='a898f7c19d6638a12a4d16cd3f7762cb' rank='16' abbrev='Nm' category='BAD_PRACTICE' priority='2' type='NM_SAME_SIMPLE_NAME_AS_INTERFACE' instanceOccurrenceMax='0'><ShortMessage>Class names shouldn't shadow simple name of implemented interface</ShortMessage><LongMessage>The class name org.apache.hadoop.mapred.lib.aggregate.ValueAggregatorDescriptor shadows the simple name of implemented interface org.apache.hadoop.mapreduce.lib.aggregate.ValueAggregatorDescriptor</LongMessage><Class classname='org.apache.hadoop.mapred.lib.aggregate.ValueAggregatorDescriptor' primary='true'><SourceLine classname='org.apache.hadoop.mapred.lib.aggregate.ValueAggregatorDescriptor' start='45' end='45' sourcepath='org/apache/hadoop/mapred/lib/aggregate/ValueAggregatorDescriptor.java' sourcefile='ValueAggregatorDescriptor.java'><Message>At ValueAggregatorDescriptor.java:[line 45]</Message></SourceLine><Message>In class org.apache.hadoop.mapred.lib.aggregate.ValueAggregatorDescriptor</Message></Class><Class classname='org.apache.hadoop.mapreduce.lib.aggregate.ValueAggregatorDescriptor'><SourceLine classname='org.apache.hadoop.mapreduce.lib.aggregate.ValueAggregatorDescriptor' start='48' end='48' sourcepath='org/apache/hadoop/mapreduce/lib/aggregate/ValueAggregatorDescriptor.java' sourcefile='ValueAggregatorDescriptor.java'><Message>At ValueAggregatorDescriptor.java:[line 48]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.lib.aggregate.ValueAggregatorDescriptor</Message></Class><SourceLine synthetic='true' classname='org.apache.hadoop.mapred.lib.aggregate.ValueAggregatorDescriptor' start='45' end='45' sourcepath='org/apache/hadoop/mapred/lib/aggregate/ValueAggregatorDescriptor.java' sourcefile='ValueAggregatorDescriptor.java'><Message>At ValueAggregatorDescriptor.java:[line 45]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='47504f6990d77de99eb8cd288df64f8a' cweid='563' rank='9' abbrev='DLS' category='CORRECTNESS' priority='2' type='DLS_DEAD_STORE_OF_CLASS_LITERAL' instanceOccurrenceMax='0'><ShortMessage>Dead store of class literal</ShortMessage><LongMessage>Dead store of org.apache.hadoop.mapred.TextInputFormat.class in org.apache.hadoop.mapred.lib.aggregate.ValueAggregatorJob.createValueAggregatorJob(String[], Class)</LongMessage><Class classname='org.apache.hadoop.mapred.lib.aggregate.ValueAggregatorJob' primary='true'><SourceLine classname='org.apache.hadoop.mapred.lib.aggregate.ValueAggregatorJob' start='84' end='237' sourcepath='org/apache/hadoop/mapred/lib/aggregate/ValueAggregatorJob.java' sourcefile='ValueAggregatorJob.java'><Message>At ValueAggregatorJob.java:[lines 84-237]</Message></SourceLine><Message>In class org.apache.hadoop.mapred.lib.aggregate.ValueAggregatorJob</Message></Class><Method isStatic='true' classname='org.apache.hadoop.mapred.lib.aggregate.ValueAggregatorJob' signature='([Ljava/lang/String;Ljava/lang/Class;)Lorg/apache/hadoop/mapred/JobConf;' name='createValueAggregatorJob' primary='true'><SourceLine endBytecode='163' classname='org.apache.hadoop.mapred.lib.aggregate.ValueAggregatorJob' start='118' end='185' sourcepath='org/apache/hadoop/mapred/lib/aggregate/ValueAggregatorJob.java' sourcefile='ValueAggregatorJob.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapred.lib.aggregate.ValueAggregatorJob.createValueAggregatorJob(String[], Class)</Message></Method><LocalVariable role='LOCAL_VARIABLE_NAMED' pc='78' name='theInputFormat' register='7'><Message>Local variable named theInputFormat</Message></LocalVariable><Type descriptor='Lorg.apache.hadoop.mapred.TextInputFormat;'><SourceLine classname='org.apache.hadoop.mapred.TextInputFormat' start='39' end='67' sourcepath='org/apache/hadoop/mapred/TextInputFormat.java' sourcefile='TextInputFormat.java'><Message>At TextInputFormat.java:[lines 39-67]</Message></SourceLine><Message>Type org.apache.hadoop.mapred.TextInputFormat</Message></Type><SourceLine endBytecode='76' classname='org.apache.hadoop.mapred.lib.aggregate.ValueAggregatorJob' start='137' end='137' sourcepath='org/apache/hadoop/mapred/lib/aggregate/ValueAggregatorJob.java' sourcefile='ValueAggregatorJob.java' startBytecode='76' primary='true'><Message>At ValueAggregatorJob.java:[line 137]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='bb7e11060d32eaa22e4212f0d09de9cc' cweid='382' rank='19' abbrev='Dm' category='BAD_PRACTICE' priority='3' type='DM_EXIT' instanceOccurrenceMax='0'><ShortMessage>Method invokes System.exit(...)</ShortMessage><LongMessage>org.apache.hadoop.mapred.lib.aggregate.ValueAggregatorJob.createValueAggregatorJob(String[], Class) invokes System.exit(...), which shuts down the entire virtual machine</LongMessage><Class classname='org.apache.hadoop.mapred.lib.aggregate.ValueAggregatorJob' primary='true'><SourceLine classname='org.apache.hadoop.mapred.lib.aggregate.ValueAggregatorJob' start='84' end='237' sourcepath='org/apache/hadoop/mapred/lib/aggregate/ValueAggregatorJob.java' sourcefile='ValueAggregatorJob.java'><Message>At ValueAggregatorJob.java:[lines 84-237]</Message></SourceLine><Message>In class org.apache.hadoop.mapred.lib.aggregate.ValueAggregatorJob</Message></Class><Method isStatic='true' classname='org.apache.hadoop.mapred.lib.aggregate.ValueAggregatorJob' signature='([Ljava/lang/String;Ljava/lang/Class;)Lorg/apache/hadoop/mapred/JobConf;' name='createValueAggregatorJob' primary='true'><SourceLine endBytecode='828' classname='org.apache.hadoop.mapred.lib.aggregate.ValueAggregatorJob' start='118' end='185' sourcepath='org/apache/hadoop/mapred/lib/aggregate/ValueAggregatorJob.java' sourcefile='ValueAggregatorJob.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapred.lib.aggregate.ValueAggregatorJob.createValueAggregatorJob(String[], Class)</Message></Method><SourceLine endBytecode='44' classname='org.apache.hadoop.mapred.lib.aggregate.ValueAggregatorJob' start='128' end='128' sourcepath='org/apache/hadoop/mapred/lib/aggregate/ValueAggregatorJob.java' sourcefile='ValueAggregatorJob.java' startBytecode='44' primary='true'><Message>At ValueAggregatorJob.java:[line 128]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='a55f4e338b2fb8e309420abaa76e874a' rank='14' abbrev='Nm' category='BAD_PRACTICE' priority='1' type='NM_SAME_SIMPLE_NAME_AS_SUPERCLASS' instanceOccurrenceMax='0'><ShortMessage>Class names shouldn't shadow simple name of superclass</ShortMessage><LongMessage>The class name org.apache.hadoop.mapred.lib.aggregate.ValueHistogram shadows the simple name of the superclass org.apache.hadoop.mapreduce.lib.aggregate.ValueHistogram</LongMessage><Class classname='org.apache.hadoop.mapred.lib.aggregate.ValueHistogram' primary='true'><SourceLine classname='org.apache.hadoop.mapred.lib.aggregate.ValueHistogram' start='30' end='30' sourcepath='org/apache/hadoop/mapred/lib/aggregate/ValueHistogram.java' sourcefile='ValueHistogram.java'><Message>At ValueHistogram.java:[line 30]</Message></SourceLine><Message>In class org.apache.hadoop.mapred.lib.aggregate.ValueHistogram</Message></Class><Class classname='org.apache.hadoop.mapreduce.lib.aggregate.ValueHistogram'><SourceLine classname='org.apache.hadoop.mapreduce.lib.aggregate.ValueHistogram' start='40' end='178' sourcepath='org/apache/hadoop/mapreduce/lib/aggregate/ValueHistogram.java' sourcefile='ValueHistogram.java'><Message>At ValueHistogram.java:[lines 40-178]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.lib.aggregate.ValueHistogram</Message></Class><SourceLine synthetic='true' classname='org.apache.hadoop.mapred.lib.aggregate.ValueHistogram' start='30' end='30' sourcepath='org/apache/hadoop/mapred/lib/aggregate/ValueHistogram.java' sourcefile='ValueHistogram.java'><Message>At ValueHistogram.java:[line 30]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='d90ba5d6a44684aa552bd791b57662d' rank='14' abbrev='Nm' category='BAD_PRACTICE' priority='1' type='NM_SAME_SIMPLE_NAME_AS_SUPERCLASS' instanceOccurrenceMax='0'><ShortMessage>Class names shouldn't shadow simple name of superclass</ShortMessage><LongMessage>The class name org.apache.hadoop.mapred.lib.db.DBConfiguration shadows the simple name of the superclass org.apache.hadoop.mapreduce.lib.db.DBConfiguration</LongMessage><Class classname='org.apache.hadoop.mapred.lib.db.DBConfiguration' primary='true'><SourceLine classname='org.apache.hadoop.mapred.lib.db.DBConfiguration' start='97' end='117' sourcepath='org/apache/hadoop/mapred/lib/db/DBConfiguration.java' sourcefile='DBConfiguration.java'><Message>At DBConfiguration.java:[lines 97-117]</Message></SourceLine><Message>In class org.apache.hadoop.mapred.lib.db.DBConfiguration</Message></Class><Class classname='org.apache.hadoop.mapreduce.lib.db.DBConfiguration'><SourceLine classname='org.apache.hadoop.mapreduce.lib.db.DBConfiguration' start='115' end='261' sourcepath='org/apache/hadoop/mapreduce/lib/db/DBConfiguration.java' sourcefile='DBConfiguration.java'><Message>At DBConfiguration.java:[lines 115-261]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.lib.db.DBConfiguration</Message></Class><SourceLine synthetic='true' classname='org.apache.hadoop.mapred.lib.db.DBConfiguration' start='97' end='117' sourcepath='org/apache/hadoop/mapred/lib/db/DBConfiguration.java' sourcefile='DBConfiguration.java'><Message>At DBConfiguration.java:[lines 97-117]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='be8843039bb3605b2e785067e4bc4390' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from org.apache.hadoop.mapred.InputSplit to org.apache.hadoop.mapreduce.lib.db.DBInputFormat$DBInputSplit in org.apache.hadoop.mapred.lib.db.DBInputFormat.getRecordReader(InputSplit, JobConf, Reporter)</LongMessage><Class classname='org.apache.hadoop.mapred.lib.db.DBInputFormat' primary='true'><SourceLine classname='org.apache.hadoop.mapred.lib.db.DBInputFormat' start='41' end='238' sourcepath='org/apache/hadoop/mapred/lib/db/DBInputFormat.java' sourcefile='DBInputFormat.java'><Message>At DBInputFormat.java:[lines 41-238]</Message></SourceLine><Message>In class org.apache.hadoop.mapred.lib.db.DBInputFormat</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapred.lib.db.DBInputFormat' signature='(Lorg/apache/hadoop/mapred/InputSplit;Lorg/apache/hadoop/mapred/JobConf;Lorg/apache/hadoop/mapred/Reporter;)Lorg/apache/hadoop/mapred/RecordReader;' name='getRecordReader' primary='true'><SourceLine endBytecode='9' classname='org.apache.hadoop.mapred.lib.db.DBInputFormat' start='171' end='171' sourcepath='org/apache/hadoop/mapred/lib/db/DBInputFormat.java' sourcefile='DBInputFormat.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapred.lib.db.DBInputFormat.getRecordReader(InputSplit, JobConf, Reporter)</Message></Method><Type role='TYPE_FOUND' descriptor='Lorg/apache/hadoop/mapred/InputSplit;'><SourceLine classname='org.apache.hadoop.mapred.InputSplit' sourcepath='org/apache/hadoop/mapred/InputSplit.java' sourcefile='InputSplit.java'><Message>In InputSplit.java</Message></SourceLine><Message>Actual type org.apache.hadoop.mapred.InputSplit</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/mapreduce/lib/db/DBInputFormat$DBInputSplit;'><SourceLine classname='org.apache.hadoop.mapreduce.lib.db.DBInputFormat$DBInputSplit' start='90' end='146' sourcepath='org/apache/hadoop/mapreduce/lib/db/DBInputFormat.java' sourcefile='DBInputFormat.java'><Message>At DBInputFormat.java:[lines 90-146]</Message></SourceLine><Message>Expected org.apache.hadoop.mapreduce.lib.db.DBInputFormat$DBInputSplit</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='5' name='split' register='1'><Message>Value loaded from split</Message></LocalVariable><SourceLine endBytecode='6' classname='org.apache.hadoop.mapred.lib.db.DBInputFormat' start='171' end='171' sourcepath='org/apache/hadoop/mapred/lib/db/DBInputFormat.java' sourcefile='DBInputFormat.java' startBytecode='6' primary='true'><Message>At DBInputFormat.java:[line 171]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='112ff1af71ee8653ca434614afdcf3a4' rank='14' abbrev='Nm' category='BAD_PRACTICE' priority='1' type='NM_SAME_SIMPLE_NAME_AS_SUPERCLASS' instanceOccurrenceMax='0'><ShortMessage>Class names shouldn't shadow simple name of superclass</ShortMessage><LongMessage>The class name org.apache.hadoop.mapred.lib.db.DBInputFormat shadows the simple name of the superclass org.apache.hadoop.mapreduce.lib.db.DBInputFormat</LongMessage><Class classname='org.apache.hadoop.mapred.lib.db.DBInputFormat' primary='true'><SourceLine classname='org.apache.hadoop.mapred.lib.db.DBInputFormat' start='41' end='238' sourcepath='org/apache/hadoop/mapred/lib/db/DBInputFormat.java' sourcefile='DBInputFormat.java'><Message>At DBInputFormat.java:[lines 41-238]</Message></SourceLine><Message>In class org.apache.hadoop.mapred.lib.db.DBInputFormat</Message></Class><Class classname='org.apache.hadoop.mapreduce.lib.db.DBInputFormat'><SourceLine classname='org.apache.hadoop.mapreduce.lib.db.DBInputFormat' start='61' end='373' sourcepath='org/apache/hadoop/mapreduce/lib/db/DBInputFormat.java' sourcefile='DBInputFormat.java'><Message>At DBInputFormat.java:[lines 61-373]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.lib.db.DBInputFormat</Message></Class><SourceLine synthetic='true' classname='org.apache.hadoop.mapred.lib.db.DBInputFormat' start='41' end='238' sourcepath='org/apache/hadoop/mapred/lib/db/DBInputFormat.java' sourcefile='DBInputFormat.java'><Message>At DBInputFormat.java:[lines 41-238]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='700cbddf3dc99efab3ed859e2b865bc2' rank='14' abbrev='Nm' category='BAD_PRACTICE' priority='1' type='NM_SAME_SIMPLE_NAME_AS_SUPERCLASS' instanceOccurrenceMax='0'><ShortMessage>Class names shouldn't shadow simple name of superclass</ShortMessage><LongMessage>The class name org.apache.hadoop.mapred.lib.db.DBInputFormat$DBInputSplit shadows the simple name of the superclass org.apache.hadoop.mapreduce.lib.db.DBInputFormat$DBInputSplit</LongMessage><Class classname='org.apache.hadoop.mapred.lib.db.DBInputFormat$DBInputSplit' primary='true'><SourceLine classname='org.apache.hadoop.mapred.lib.db.DBInputFormat$DBInputSplit' start='148' end='158' sourcepath='org/apache/hadoop/mapred/lib/db/DBInputFormat.java' sourcefile='DBInputFormat.java'><Message>At DBInputFormat.java:[lines 148-158]</Message></SourceLine><Message>In class org.apache.hadoop.mapred.lib.db.DBInputFormat$DBInputSplit</Message></Class><Class classname='org.apache.hadoop.mapreduce.lib.db.DBInputFormat$DBInputSplit'><SourceLine classname='org.apache.hadoop.mapreduce.lib.db.DBInputFormat$DBInputSplit' start='90' end='146' sourcepath='org/apache/hadoop/mapreduce/lib/db/DBInputFormat.java' sourcefile='DBInputFormat.java'><Message>At DBInputFormat.java:[lines 90-146]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.lib.db.DBInputFormat$DBInputSplit</Message></Class><SourceLine synthetic='true' classname='org.apache.hadoop.mapred.lib.db.DBInputFormat$DBInputSplit' start='148' end='158' sourcepath='org/apache/hadoop/mapred/lib/db/DBInputFormat.java' sourcefile='DBInputFormat.java'><Message>At DBInputFormat.java:[lines 148-158]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='625c71c5a68c324599d3a5a908b1376b' rank='19' abbrev='Nm' category='BAD_PRACTICE' priority='3' type='NM_WRONG_PACKAGE_INTENTIONAL' instanceOccurrenceMax='0'><ShortMessage>Method doesn't override method in superclass due to wrong package for parameter</ShortMessage><LongMessage>org.apache.hadoop.mapred.lib.db.DBInputFormat$DBRecordReader.next(LongWritable, DBWritable) doesn't override method in superclass because parameter type org.apache.hadoop.mapred.lib.db.DBWritable doesn't match superclass parameter type org.apache.hadoop.mapreduce.lib.db.DBWritable</LongMessage><Class classname='org.apache.hadoop.mapred.lib.db.DBInputFormat$DBRecordReader' primary='true'><SourceLine classname='org.apache.hadoop.mapred.lib.db.DBInputFormat$DBRecordReader' start='49' end='89' sourcepath='org/apache/hadoop/mapred/lib/db/DBInputFormat.java' sourcefile='DBInputFormat.java'><Message>At DBInputFormat.java:[lines 49-89]</Message></SourceLine><Message>In class org.apache.hadoop.mapred.lib.db.DBInputFormat$DBRecordReader</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapred.lib.db.DBInputFormat$DBRecordReader' signature='(Lorg/apache/hadoop/io/LongWritable;Lorg/apache/hadoop/mapred/lib/db/DBWritable;)Z' name='next' primary='true'><SourceLine endBytecode='96' classname='org.apache.hadoop.mapred.lib.db.DBInputFormat$DBRecordReader' start='89' end='89' sourcepath='org/apache/hadoop/mapred/lib/db/DBInputFormat.java' sourcefile='DBInputFormat.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapred.lib.db.DBInputFormat$DBRecordReader.next(LongWritable, DBWritable)</Message></Method><Class role='CLASS_SUPERCLASS' classname='org.apache.hadoop.mapreduce.lib.db.DBRecordReader'><SourceLine classname='org.apache.hadoop.mapreduce.lib.db.DBRecordReader' start='54' end='275' sourcepath='org/apache/hadoop/mapreduce/lib/db/DBRecordReader.java' sourcefile='DBRecordReader.java'><Message>At DBRecordReader.java:[lines 54-275]</Message></SourceLine><Message>superclass is org.apache.hadoop.mapreduce.lib.db.DBRecordReader</Message></Class><Method isStatic='false' role='METHOD_DID_YOU_MEAN_TO_OVERRIDE' classname='org.apache.hadoop.mapreduce.lib.db.DBRecordReader' signature='(Lorg/apache/hadoop/io/LongWritable;Lorg/apache/hadoop/mapreduce/lib/db/DBWritable;)Z' name='next'><SourceLine endBytecode='112' classname='org.apache.hadoop.mapreduce.lib.db.DBRecordReader' start='207' end='209' sourcepath='org/apache/hadoop/mapreduce/lib/db/DBRecordReader.java' sourcefile='DBRecordReader.java' startBytecode='0'></SourceLine><Message>Did you intend to override org.apache.hadoop.mapreduce.lib.db.DBRecordReader.next(LongWritable, DBWritable)</Message></Method><Type role='TYPE_FOUND' descriptor='Lorg/apache/hadoop/mapred/lib/db/DBWritable;'><SourceLine classname='org.apache.hadoop.mapred.lib.db.DBWritable' sourcepath='org/apache/hadoop/mapred/lib/db/DBWritable.java' sourcefile='DBWritable.java'><Message>In DBWritable.java</Message></SourceLine><Message>Actual type org.apache.hadoop.mapred.lib.db.DBWritable</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/mapreduce/lib/db/DBWritable;'><SourceLine classname='org.apache.hadoop.mapreduce.lib.db.DBWritable' sourcepath='org/apache/hadoop/mapreduce/lib/db/DBWritable.java' sourcefile='DBWritable.java'><Message>In DBWritable.java</Message></SourceLine><Message>Expected org.apache.hadoop.mapreduce.lib.db.DBWritable</Message></Type><Method isStatic='false' role='METHOD_OVERRIDDEN' classname='org.apache.hadoop.mapred.lib.db.DBInputFormat$DBRecordReader' signature='(Lorg/apache/hadoop/io/LongWritable;Lorg/apache/hadoop/mapreduce/lib/db/DBWritable;)Z' name='next'><SourceLine endBytecode='69' classname='org.apache.hadoop.mapred.lib.db.DBInputFormat$DBRecordReader' start='49' end='49' sourcepath='org/apache/hadoop/mapred/lib/db/DBInputFormat.java' sourcefile='DBInputFormat.java' startBytecode='0'></SourceLine><Message>Overrides org.apache.hadoop.mapred.lib.db.DBInputFormat$DBRecordReader.next(LongWritable, DBWritable)</Message></Method><SourceLine synthetic='true' endBytecode='96' classname='org.apache.hadoop.mapred.lib.db.DBInputFormat$DBRecordReader' start='89' end='89' sourcepath='org/apache/hadoop/mapred/lib/db/DBInputFormat.java' sourcefile='DBInputFormat.java' startBytecode='0'><Message>At DBInputFormat.java:[line 89]</Message></SourceLine><Property name='edu.umd.cs.findbugs.detect.Naming$NamingProperty.CONFUSING_METHOD_IS_DEPRECATED' value='true'></Property></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='8d113c973f7c5fdc00226926f4c1e2ea' rank='14' abbrev='Nm' category='BAD_PRACTICE' priority='1' type='NM_SAME_SIMPLE_NAME_AS_SUPERCLASS' instanceOccurrenceMax='0'><ShortMessage>Class names shouldn't shadow simple name of superclass</ShortMessage><LongMessage>The class name org.apache.hadoop.mapred.lib.db.DBInputFormat$NullDBWritable shadows the simple name of the superclass org.apache.hadoop.mapreduce.lib.db.DBInputFormat$NullDBWritable</LongMessage><Class classname='org.apache.hadoop.mapred.lib.db.DBInputFormat$NullDBWritable' primary='true'><SourceLine classname='org.apache.hadoop.mapred.lib.db.DBInputFormat$NullDBWritable' start='135' end='135' sourcepath='org/apache/hadoop/mapred/lib/db/DBInputFormat.java' sourcefile='DBInputFormat.java'><Message>At DBInputFormat.java:[line 135]</Message></SourceLine><Message>In class org.apache.hadoop.mapred.lib.db.DBInputFormat$NullDBWritable</Message></Class><Class classname='org.apache.hadoop.mapreduce.lib.db.DBInputFormat$NullDBWritable'><SourceLine classname='org.apache.hadoop.mapreduce.lib.db.DBInputFormat$NullDBWritable' start='73' end='81' sourcepath='org/apache/hadoop/mapreduce/lib/db/DBInputFormat.java' sourcefile='DBInputFormat.java'><Message>At DBInputFormat.java:[lines 73-81]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.lib.db.DBInputFormat$NullDBWritable</Message></Class><SourceLine synthetic='true' classname='org.apache.hadoop.mapred.lib.db.DBInputFormat$NullDBWritable' start='135' end='135' sourcepath='org/apache/hadoop/mapred/lib/db/DBInputFormat.java' sourcefile='DBInputFormat.java'><Message>At DBInputFormat.java:[line 135]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='88f1143c1f2e3ac9aeb2d8fb73d88d14' rank='20' abbrev='RI' category='STYLE' priority='3' type='RI_REDUNDANT_INTERFACES' instanceOccurrenceMax='0'><ShortMessage>Class implements same interface as superclass</ShortMessage><LongMessage>Class org.apache.hadoop.mapred.lib.db.DBInputFormat$NullDBWritable implements same interface as superclass</LongMessage><Class classname='org.apache.hadoop.mapred.lib.db.DBInputFormat$NullDBWritable' primary='true'><SourceLine classname='org.apache.hadoop.mapred.lib.db.DBInputFormat$NullDBWritable' start='135' end='135' sourcepath='org/apache/hadoop/mapred/lib/db/DBInputFormat.java' sourcefile='DBInputFormat.java'><Message>At DBInputFormat.java:[line 135]</Message></SourceLine><Message>In class org.apache.hadoop.mapred.lib.db.DBInputFormat$NullDBWritable</Message></Class><Class role='INTERFACE_TYPE' classname='org.apache.hadoop.io.Writable'><SourceLine classname='org.apache.hadoop.io.Writable' sourcepath='org/apache/hadoop/io/Writable.java' sourcefile='Writable.java'><Message>In Writable.java</Message></SourceLine><Message>Interface org.apache.hadoop.io.Writable</Message></Class><SourceLine synthetic='true' classname='org.apache.hadoop.mapred.lib.db.DBInputFormat$NullDBWritable' start='135' end='135' sourcepath='org/apache/hadoop/mapred/lib/db/DBInputFormat.java' sourcefile='DBInputFormat.java'><Message>At DBInputFormat.java:[line 135]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='c478857d12391c8936bcfc97d83a6642' rank='14' abbrev='Nm' category='BAD_PRACTICE' priority='1' type='NM_SAME_SIMPLE_NAME_AS_SUPERCLASS' instanceOccurrenceMax='0'><ShortMessage>Class names shouldn't shadow simple name of superclass</ShortMessage><LongMessage>The class name org.apache.hadoop.mapred.lib.db.DBOutputFormat shadows the simple name of the superclass org.apache.hadoop.mapreduce.lib.db.DBOutputFormat</LongMessage><Class classname='org.apache.hadoop.mapred.lib.db.DBOutputFormat' primary='true'><SourceLine classname='org.apache.hadoop.mapred.lib.db.DBOutputFormat' start='40' end='121' sourcepath='org/apache/hadoop/mapred/lib/db/DBOutputFormat.java' sourcefile='DBOutputFormat.java'><Message>At DBOutputFormat.java:[lines 40-121]</Message></SourceLine><Message>In class org.apache.hadoop.mapred.lib.db.DBOutputFormat</Message></Class><Class classname='org.apache.hadoop.mapreduce.lib.db.DBOutputFormat'><SourceLine classname='org.apache.hadoop.mapreduce.lib.db.DBOutputFormat' start='51' end='247' sourcepath='org/apache/hadoop/mapreduce/lib/db/DBOutputFormat.java' sourcefile='DBOutputFormat.java'><Message>At DBOutputFormat.java:[lines 51-247]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.lib.db.DBOutputFormat</Message></Class><SourceLine synthetic='true' classname='org.apache.hadoop.mapred.lib.db.DBOutputFormat' start='40' end='121' sourcepath='org/apache/hadoop/mapred/lib/db/DBOutputFormat.java' sourcefile='DBOutputFormat.java'><Message>At DBOutputFormat.java:[lines 40-121]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='fe9dcbe656e1b0882e7ff0a9109df398' rank='14' abbrev='Nm' category='BAD_PRACTICE' priority='1' type='NM_SAME_SIMPLE_NAME_AS_SUPERCLASS' instanceOccurrenceMax='0'><ShortMessage>Class names shouldn't shadow simple name of superclass</ShortMessage><LongMessage>The class name org.apache.hadoop.mapred.lib.db.DBOutputFormat$DBRecordWriter shadows the simple name of the superclass org.apache.hadoop.mapreduce.lib.db.DBOutputFormat$DBRecordWriter</LongMessage><Class classname='org.apache.hadoop.mapred.lib.db.DBOutputFormat$DBRecordWriter' primary='true'><SourceLine classname='org.apache.hadoop.mapred.lib.db.DBOutputFormat$DBRecordWriter' start='52' end='59' sourcepath='org/apache/hadoop/mapred/lib/db/DBOutputFormat.java' sourcefile='DBOutputFormat.java'><Message>At DBOutputFormat.java:[lines 52-59]</Message></SourceLine><Message>In class org.apache.hadoop.mapred.lib.db.DBOutputFormat$DBRecordWriter</Message></Class><Class classname='org.apache.hadoop.mapreduce.lib.db.DBOutputFormat$DBRecordWriter'><SourceLine classname='org.apache.hadoop.mapreduce.lib.db.DBOutputFormat$DBRecordWriter' start='70' end='127' sourcepath='org/apache/hadoop/mapreduce/lib/db/DBOutputFormat.java' sourcefile='DBOutputFormat.java'><Message>At DBOutputFormat.java:[lines 70-127]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.lib.db.DBOutputFormat$DBRecordWriter</Message></Class><SourceLine synthetic='true' classname='org.apache.hadoop.mapred.lib.db.DBOutputFormat$DBRecordWriter' start='52' end='59' sourcepath='org/apache/hadoop/mapred/lib/db/DBOutputFormat.java' sourcefile='DBOutputFormat.java'><Message>At DBOutputFormat.java:[lines 52-59]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='2e5562b3ca6713397172045c3af12baf' rank='16' abbrev='Nm' category='BAD_PRACTICE' priority='2' type='NM_SAME_SIMPLE_NAME_AS_INTERFACE' instanceOccurrenceMax='0'><ShortMessage>Class names shouldn't shadow simple name of implemented interface</ShortMessage><LongMessage>The class name org.apache.hadoop.mapred.lib.db.DBWritable shadows the simple name of implemented interface org.apache.hadoop.mapreduce.lib.db.DBWritable</LongMessage><Class classname='org.apache.hadoop.mapred.lib.db.DBWritable' primary='true'><SourceLine classname='org.apache.hadoop.mapred.lib.db.DBWritable' sourcepath='org/apache/hadoop/mapred/lib/db/DBWritable.java' sourcefile='DBWritable.java'><Message>In DBWritable.java</Message></SourceLine><Message>In class org.apache.hadoop.mapred.lib.db.DBWritable</Message></Class><Class classname='org.apache.hadoop.mapreduce.lib.db.DBWritable'><SourceLine classname='org.apache.hadoop.mapreduce.lib.db.DBWritable' sourcepath='org/apache/hadoop/mapreduce/lib/db/DBWritable.java' sourcefile='DBWritable.java'><Message>In DBWritable.java</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.lib.db.DBWritable</Message></Class><SourceLine synthetic='true' classname='org.apache.hadoop.mapred.lib.db.DBWritable' sourcepath='org/apache/hadoop/mapred/lib/db/DBWritable.java' sourcefile='DBWritable.java'><Message>In DBWritable.java</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='2d0ea3798b1889aed143d209913996eb' rank='17' abbrev='No' category='MT_CORRECTNESS' priority='3' type='NO_NOTIFY_NOT_NOTIFYALL' instanceOccurrenceMax='0'><ShortMessage>Using notify() rather than notifyAll()</ShortMessage><LongMessage>Using notify rather than notifyAll in org.apache.hadoop.mapred.pipes.OutputHandler.authenticate(String)</LongMessage><Class classname='org.apache.hadoop.mapred.pipes.OutputHandler' primary='true'><SourceLine classname='org.apache.hadoop.mapred.pipes.OutputHandler' start='43' end='188' sourcepath='org/apache/hadoop/mapred/pipes/OutputHandler.java' sourcefile='OutputHandler.java'><Message>At OutputHandler.java:[lines 43-188]</Message></SourceLine><Message>In class org.apache.hadoop.mapred.pipes.OutputHandler</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapred.pipes.OutputHandler' signature='(Ljava/lang/String;)Z' name='authenticate' primary='true'><SourceLine endBytecode='186' classname='org.apache.hadoop.mapred.pipes.OutputHandler' start='163' end='171' sourcepath='org/apache/hadoop/mapred/pipes/OutputHandler.java' sourcefile='OutputHandler.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapred.pipes.OutputHandler.authenticate(String)</Message></Method><SourceLine endBytecode='66' classname='org.apache.hadoop.mapred.pipes.OutputHandler' start='170' end='170' sourcepath='org/apache/hadoop/mapred/pipes/OutputHandler.java' sourcefile='OutputHandler.java' startBytecode='66' primary='true'><Message>At OutputHandler.java:[line 170]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='3bf4429bd11258f9283af5033f4ba92' rank='17' abbrev='No' category='MT_CORRECTNESS' priority='3' type='NO_NOTIFY_NOT_NOTIFYALL' instanceOccurrenceMax='0'><ShortMessage>Using notify() rather than notifyAll()</ShortMessage><LongMessage>Using notify rather than notifyAll in org.apache.hadoop.mapred.pipes.OutputHandler.done()</LongMessage><Class classname='org.apache.hadoop.mapred.pipes.OutputHandler' primary='true'><SourceLine classname='org.apache.hadoop.mapred.pipes.OutputHandler' start='43' end='188' sourcepath='org/apache/hadoop/mapred/pipes/OutputHandler.java' sourcefile='OutputHandler.java'><Message>At OutputHandler.java:[lines 43-188]</Message></SourceLine><Message>In class org.apache.hadoop.mapred.pipes.OutputHandler</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapred.pipes.OutputHandler' signature='()V' name='done' primary='true'><SourceLine endBytecode='142' classname='org.apache.hadoop.mapred.pipes.OutputHandler' start='109' end='113' sourcepath='org/apache/hadoop/mapred/pipes/OutputHandler.java' sourcefile='OutputHandler.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapred.pipes.OutputHandler.done()</Message></Method><SourceLine endBytecode='10' classname='org.apache.hadoop.mapred.pipes.OutputHandler' start='111' end='111' sourcepath='org/apache/hadoop/mapred/pipes/OutputHandler.java' sourcefile='OutputHandler.java' startBytecode='10' primary='true'><Message>At OutputHandler.java:[line 111]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='4260a1dfd6744f4452e72b7bb44cd30f' rank='17' abbrev='No' category='MT_CORRECTNESS' priority='3' type='NO_NOTIFY_NOT_NOTIFYALL' instanceOccurrenceMax='0'><ShortMessage>Using notify() rather than notifyAll()</ShortMessage><LongMessage>Using notify rather than notifyAll in org.apache.hadoop.mapred.pipes.OutputHandler.failed(Throwable)</LongMessage><Class classname='org.apache.hadoop.mapred.pipes.OutputHandler' primary='true'><SourceLine classname='org.apache.hadoop.mapred.pipes.OutputHandler' start='43' end='188' sourcepath='org/apache/hadoop/mapred/pipes/OutputHandler.java' sourcefile='OutputHandler.java'><Message>At OutputHandler.java:[lines 43-188]</Message></SourceLine><Message>In class org.apache.hadoop.mapred.pipes.OutputHandler</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapred.pipes.OutputHandler' signature='(Ljava/lang/Throwable;)V' name='failed' primary='true'><SourceLine endBytecode='155' classname='org.apache.hadoop.mapred.pipes.OutputHandler' start='127' end='131' sourcepath='org/apache/hadoop/mapred/pipes/OutputHandler.java' sourcefile='OutputHandler.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapred.pipes.OutputHandler.failed(Throwable)</Message></Method><SourceLine endBytecode='10' classname='org.apache.hadoop.mapred.pipes.OutputHandler' start='129' end='129' sourcepath='org/apache/hadoop/mapred/pipes/OutputHandler.java' sourcefile='OutputHandler.java' startBytecode='10' primary='true'><Message>At OutputHandler.java:[line 129]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='55e7c1f0e400ee2ce9e1d1392e0f6f81' cweid='366' rank='20' abbrev='IS' category='MT_CORRECTNESS' priority='3' type='IS2_INCONSISTENT_SYNC' instanceOccurrenceMax='0'><ShortMessage>Inconsistent synchronization</ShortMessage><LongMessage>Inconsistent synchronization of org.apache.hadoop.mapred.pipes.PipesNonJavaInputFormat$PipesDummyRecordReader.progress; locked 50% of time</LongMessage><Class classname='org.apache.hadoop.mapred.pipes.PipesNonJavaInputFormat$PipesDummyRecordReader' primary='true'><SourceLine classname='org.apache.hadoop.mapred.pipes.PipesNonJavaInputFormat$PipesDummyRecordReader' start='69' end='98' sourcepath='org/apache/hadoop/mapred/pipes/PipesNonJavaInputFormat.java' sourcefile='PipesNonJavaInputFormat.java'><Message>At PipesNonJavaInputFormat.java:[lines 69-98]</Message></SourceLine><Message>In class org.apache.hadoop.mapred.pipes.PipesNonJavaInputFormat$PipesDummyRecordReader</Message></Class><Field isStatic='false' classname='org.apache.hadoop.mapred.pipes.PipesNonJavaInputFormat$PipesDummyRecordReader' signature='F' name='progress' primary='true'><SourceLine classname='org.apache.hadoop.mapred.pipes.PipesNonJavaInputFormat$PipesDummyRecordReader' sourcepath='org/apache/hadoop/mapred/pipes/PipesNonJavaInputFormat.java' sourcefile='PipesNonJavaInputFormat.java'><Message>In PipesNonJavaInputFormat.java</Message></SourceLine><Message>Field org.apache.hadoop.mapred.pipes.PipesNonJavaInputFormat$PipesDummyRecordReader.progress</Message></Field><Int role='INT_SYNC_PERCENT' value='50'><Message>Synchronized 50% of the time</Message></Int><SourceLine role='SOURCE_LINE_UNSYNC_ACCESS' endBytecode='1' classname='org.apache.hadoop.mapred.pipes.PipesNonJavaInputFormat$PipesDummyRecordReader' start='92' end='92' sourcepath='org/apache/hadoop/mapred/pipes/PipesNonJavaInputFormat.java' sourcefile='PipesNonJavaInputFormat.java' startBytecode='1' primary='true'><Message>Unsynchronized access at PipesNonJavaInputFormat.java:[line 92]</Message></SourceLine><SourceLine role='SOURCE_LINE_SYNC_ACCESS' endBytecode='5' classname='org.apache.hadoop.mapred.pipes.PipesNonJavaInputFormat$PipesDummyRecordReader' start='97' end='97' sourcepath='org/apache/hadoop/mapred/pipes/PipesNonJavaInputFormat.java' sourcefile='PipesNonJavaInputFormat.java' startBytecode='5'><Message>Synchronized access at PipesNonJavaInputFormat.java:[line 97]</Message></SourceLine><Property name='edu.umd.cs.findbugs.detect.InconsistentSyncWarningProperty.ONLY_UNSYNC_IN_GETTERS' value='true'></Property></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='ba3522bff672225432f64903844365a6' rank='20' abbrev='SIC' category='PERFORMANCE' priority='3' type='SIC_INNER_SHOULD_BE_STATIC_ANON' instanceOccurrenceMax='0'><ShortMessage>Could be refactored into a named static inner class</ShortMessage><LongMessage>The class org.apache.hadoop.mapred.pipes.Submitter$1 could be refactored into a named _static_ inner class</LongMessage><Class role='CLASS_ANONYMOUS' classname='org.apache.hadoop.mapred.pipes.Submitter$1'><SourceLine classname='org.apache.hadoop.mapred.pipes.Submitter$1' start='494' end='496' sourcepath='org/apache/hadoop/mapred/pipes/Submitter.java' sourcefile='Submitter.java'><Message>At Submitter.java:[lines 494-496]</Message></SourceLine><Message>Anonymous class org.apache.hadoop.mapred.pipes.Submitter$1</Message></Class><Class classname='org.apache.hadoop.mapred.pipes.Submitter' primary='true'><SourceLine classname='org.apache.hadoop.mapred.pipes.Submitter' start='73' end='520' sourcepath='org/apache/hadoop/mapred/pipes/Submitter.java' sourcefile='Submitter.java'><Message>At Submitter.java:[lines 73-520]</Message></SourceLine><Message>In class org.apache.hadoop.mapred.pipes.Submitter</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapred.pipes.Submitter' signature='([Ljava/lang/String;)I' name='run' primary='true'><SourceLine endBytecode='1305' classname='org.apache.hadoop.mapred.pipes.Submitter' start='393' end='508' sourcepath='org/apache/hadoop/mapred/pipes/Submitter.java' sourcefile='Submitter.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapred.pipes.Submitter.run(String[])</Message></Method><SourceLine endBytecode='657' classname='org.apache.hadoop.mapred.pipes.Submitter' start='492' end='492' sourcepath='org/apache/hadoop/mapred/pipes/Submitter.java' sourcefile='Submitter.java' startBytecode='657' primary='true'><Message>At Submitter.java:[line 492]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='933bbf18093f414b864c1c02d666baf6' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from org.apache.hadoop.mapreduce.MapContext to org.apache.hadoop.mapreduce.Mapper$Context in org.apache.hadoop.mapreduce.ContextFactory.cloneContext(JobContext, Configuration)</LongMessage><Class classname='org.apache.hadoop.mapreduce.ContextFactory' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.ContextFactory' start='32' end='240' sourcepath='org/apache/hadoop/mapreduce/ContextFactory.java' sourcefile='ContextFactory.java'><Message>At ContextFactory.java:[lines 32-240]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.ContextFactory</Message></Class><Method isStatic='true' classname='org.apache.hadoop.mapreduce.ContextFactory' signature='(Lorg/apache/hadoop/mapreduce/JobContext;Lorg/apache/hadoop/conf/Configuration;)Lorg/apache/hadoop/mapreduce/JobContext;' name='cloneContext' primary='true'><SourceLine endBytecode='74' classname='org.apache.hadoop.mapreduce.ContextFactory' start='158' end='175' sourcepath='org/apache/hadoop/mapreduce/ContextFactory.java' sourcefile='ContextFactory.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapreduce.ContextFactory.cloneContext(JobContext, Configuration)</Message></Method><Type role='TYPE_FOUND' descriptor='Lorg/apache/hadoop/mapreduce/MapContext;'><SourceLine classname='org.apache.hadoop.mapreduce.MapContext' sourcepath='org/apache/hadoop/mapreduce/MapContext.java' sourcefile='MapContext.java'><Message>In MapContext.java</Message></SourceLine><Message>Actual type org.apache.hadoop.mapreduce.MapContext</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/mapreduce/Mapper$Context;'><SourceLine classname='org.apache.hadoop.mapreduce.Mapper$Context' start='106' end='106' sourcepath='org/apache/hadoop/mapreduce/Mapper.java' sourcefile='Mapper.java'><Message>At Mapper.java:[line 106]</Message></SourceLine><Message>Expected org.apache.hadoop.mapreduce.Mapper$Context</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='7' name='original' register='0'><Message>Value loaded from original</Message></LocalVariable><SourceLine endBytecode='8' classname='org.apache.hadoop.mapreduce.ContextFactory' start='159' end='159' sourcepath='org/apache/hadoop/mapreduce/ContextFactory.java' sourcefile='ContextFactory.java' startBytecode='8' primary='true'><Message>At ContextFactory.java:[line 159]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='5df697d520cf23308cbd33b9ca34c058' rank='20' abbrev='DP' category='MALICIOUS_CODE' priority='3' type='DP_DO_INSIDE_DO_PRIVILEGED' instanceOccurrenceMax='0'><ShortMessage>Method invoked that should be only be invoked inside a doPrivileged block</ShortMessage><LongMessage>Invocation of reflect.Field.setAccessible(boolean), which should be invoked from within a doPrivileged block, in org.apache.hadoop.mapreduce.ContextFactory.&lt;static initializer for ContextFactory&gt;()</LongMessage><Class classname='org.apache.hadoop.mapreduce.ContextFactory' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.ContextFactory' start='32' end='240' sourcepath='org/apache/hadoop/mapreduce/ContextFactory.java' sourcefile='ContextFactory.java'><Message>At ContextFactory.java:[lines 32-240]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.ContextFactory</Message></Class><Method isStatic='true' classname='org.apache.hadoop.mapreduce.ContextFactory' signature='()V' name='&lt;clinit&gt;' primary='true'><SourceLine endBytecode='1362' classname='org.apache.hadoop.mapreduce.ContextFactory' start='47' end='141' sourcepath='org/apache/hadoop/mapreduce/ContextFactory.java' sourcefile='ContextFactory.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapreduce.ContextFactory.&lt;static initializer for ContextFactory&gt;()</Message></Method><Method isStatic='false' role='METHOD_CALLED' classname='java.lang.reflect.Field' signature='(Z)V' name='setAccessible'><SourceLine classname='java.lang.reflect.Field' sourcepath='java/lang/reflect/Field.java' sourcefile='Field.java'></SourceLine><Message>Called method reflect.Field.setAccessible(boolean)</Message></Method><SourceLine endBytecode='279' classname='org.apache.hadoop.mapreduce.ContextFactory' start='111' end='111' sourcepath='org/apache/hadoop/mapreduce/ContextFactory.java' sourcefile='ContextFactory.java' startBytecode='279' primary='true'><Message>At ContextFactory.java:[line 111]</Message></SourceLine><SourceLine role='SOURCE_LINE_ANOTHER_INSTANCE' endBytecode='368' classname='org.apache.hadoop.mapreduce.ContextFactory' start='127' end='127' sourcepath='org/apache/hadoop/mapreduce/ContextFactory.java' sourcefile='ContextFactory.java' startBytecode='368'><Message>Another occurrence at ContextFactory.java:[line 127]</Message></SourceLine><SourceLine role='SOURCE_LINE_ANOTHER_INSTANCE' endBytecode='385' classname='org.apache.hadoop.mapreduce.ContextFactory' start='129' end='129' sourcepath='org/apache/hadoop/mapreduce/ContextFactory.java' sourcefile='ContextFactory.java' startBytecode='385'><Message>Another occurrence at ContextFactory.java:[line 129]</Message></SourceLine><SourceLine role='SOURCE_LINE_ANOTHER_INSTANCE' endBytecode='402' classname='org.apache.hadoop.mapreduce.ContextFactory' start='131' end='131' sourcepath='org/apache/hadoop/mapreduce/ContextFactory.java' sourcefile='ContextFactory.java' startBytecode='402'><Message>Another occurrence at ContextFactory.java:[line 131]</Message></SourceLine><SourceLine role='SOURCE_LINE_ANOTHER_INSTANCE' endBytecode='419' classname='org.apache.hadoop.mapreduce.ContextFactory' start='133' end='133' sourcepath='org/apache/hadoop/mapreduce/ContextFactory.java' sourcefile='ContextFactory.java' startBytecode='419'><Message>Another occurrence at ContextFactory.java:[line 133]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='e1f79316c5f62350b79d32334df41dfa' rank='20' abbrev='SIC' category='PERFORMANCE' priority='3' type='SIC_INNER_SHOULD_BE_STATIC_ANON' instanceOccurrenceMax='0'><ShortMessage>Could be refactored into a named static inner class</ShortMessage><LongMessage>The class org.apache.hadoop.mapreduce.Counters$GroupFactory$1 could be refactored into a named _static_ inner class</LongMessage><Class role='CLASS_ANONYMOUS' classname='org.apache.hadoop.mapreduce.Counters$GroupFactory$1'><SourceLine classname='org.apache.hadoop.mapreduce.Counters$GroupFactory$1' start='114' end='116' sourcepath='org/apache/hadoop/mapreduce/Counters.java' sourcefile='Counters.java'><Message>At Counters.java:[lines 114-116]</Message></SourceLine><Message>Anonymous class org.apache.hadoop.mapreduce.Counters$GroupFactory$1</Message></Class><Class classname='org.apache.hadoop.mapreduce.Counters$GroupFactory' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.Counters$GroupFactory' start='107' end='129' sourcepath='org/apache/hadoop/mapreduce/Counters.java' sourcefile='Counters.java'><Message>At Counters.java:[lines 107-129]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.Counters$GroupFactory</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapreduce.Counters$GroupFactory' signature='(Ljava/lang/Class;)Lorg/apache/hadoop/mapreduce/counters/CounterGroupFactory$FrameworkGroupFactory;' name='newFrameworkGroupFactory' primary='true'><SourceLine endBytecode='79' classname='org.apache.hadoop.mapreduce.Counters$GroupFactory' start='114' end='114' sourcepath='org/apache/hadoop/mapreduce/Counters.java' sourcefile='Counters.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapreduce.Counters$GroupFactory.newFrameworkGroupFactory(Class)</Message></Method><SourceLine endBytecode='6' classname='org.apache.hadoop.mapreduce.Counters$GroupFactory' start='114' end='114' sourcepath='org/apache/hadoop/mapreduce/Counters.java' sourcefile='Counters.java' startBytecode='6' primary='true'><Message>At Counters.java:[line 114]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='89d987c720279550bb56ebec1f167f5f' rank='20' abbrev='PZLA' category='STYLE' priority='3' type='PZLA_PREFER_ZERO_LENGTH_ARRAYS' instanceOccurrenceMax='0'><ShortMessage>Consider returning a zero length array rather than null</ShortMessage><LongMessage>Should org.apache.hadoop.mapreduce.CryptoUtils.createIV(Configuration) return a zero length array rather than null?</LongMessage><Class classname='org.apache.hadoop.mapreduce.CryptoUtils' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.CryptoUtils' start='48' end='223' sourcepath='org/apache/hadoop/mapreduce/CryptoUtils.java' sourcefile='CryptoUtils.java'><Message>At CryptoUtils.java:[lines 48-223]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.CryptoUtils</Message></Class><Method isStatic='true' classname='org.apache.hadoop.mapreduce.CryptoUtils' signature='(Lorg/apache/hadoop/conf/Configuration;)[B' name='createIV' primary='true'><SourceLine endBytecode='134' classname='org.apache.hadoop.mapreduce.CryptoUtils' start='65' end='72' sourcepath='org/apache/hadoop/mapreduce/CryptoUtils.java' sourcefile='CryptoUtils.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapreduce.CryptoUtils.createIV(Configuration)</Message></Method><SourceLine endBytecode='34' classname='org.apache.hadoop.mapreduce.CryptoUtils' start='72' end='72' sourcepath='org/apache/hadoop/mapreduce/CryptoUtils.java' sourcefile='CryptoUtils.java' startBytecode='34' primary='true'><Message>At CryptoUtils.java:[line 72]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='8c8e1db0903c74167652007cf28b38c1' rank='20' abbrev='PZLA' category='STYLE' priority='3' type='PZLA_PREFER_ZERO_LENGTH_ARRAYS' instanceOccurrenceMax='0'><ShortMessage>Consider returning a zero length array rather than null</ShortMessage><LongMessage>Should org.apache.hadoop.mapreduce.InputSplit.getLocationInfo() return a zero length array rather than null?</LongMessage><Class classname='org.apache.hadoop.mapreduce.InputSplit' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.InputSplit' start='44' end='75' sourcepath='org/apache/hadoop/mapreduce/InputSplit.java' sourcefile='InputSplit.java'><Message>At InputSplit.java:[lines 44-75]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.InputSplit</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapreduce.InputSplit' signature='()[Lorg/apache/hadoop/mapred/SplitLocationInfo;' name='getLocationInfo' primary='true'><SourceLine endBytecode='43' classname='org.apache.hadoop.mapreduce.InputSplit' start='75' end='75' sourcepath='org/apache/hadoop/mapreduce/InputSplit.java' sourcefile='InputSplit.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapreduce.InputSplit.getLocationInfo()</Message></Method><SourceLine endBytecode='1' classname='org.apache.hadoop.mapreduce.InputSplit' start='75' end='75' sourcepath='org/apache/hadoop/mapreduce/InputSplit.java' sourcefile='InputSplit.java' startBytecode='1' primary='true'><Message>At InputSplit.java:[line 75]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='e351f263ec2c60a643795e42c946d3a1' rank='20' abbrev='Dm' category='PERFORMANCE' priority='3' type='DM_STRING_TOSTRING' instanceOccurrenceMax='0'><ShortMessage>Method invokes toString() method on a String</ShortMessage><LongMessage>org.apache.hadoop.mapreduce.Job.getTrackingURL() invokes toString() method on a String</LongMessage><Class classname='org.apache.hadoop.mapreduce.Job' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.Job' start='83' end='1792' sourcepath='org/apache/hadoop/mapreduce/Job.java' sourcefile='Job.java'><Message>At Job.java:[lines 83-1792]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.Job</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapreduce.Job' signature='()Ljava/lang/String;' name='getTrackingURL' primary='true'><SourceLine endBytecode='63' classname='org.apache.hadoop.mapreduce.Job' start='370' end='371' sourcepath='org/apache/hadoop/mapreduce/Job.java' sourcefile='Job.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapreduce.Job.getTrackingURL()</Message></Method><SourceLine endBytecode='14' classname='org.apache.hadoop.mapreduce.Job' start='371' end='371' sourcepath='org/apache/hadoop/mapreduce/Job.java' sourcefile='Job.java' startBytecode='14' primary='true'><Message>At Job.java:[line 371]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='698a51bc8c9aeaf1ab7a36f38c2a4b5e' rank='20' abbrev='RI' category='STYLE' priority='3' type='RI_REDUNDANT_INTERFACES' instanceOccurrenceMax='0'><ShortMessage>Class implements same interface as superclass</ShortMessage><LongMessage>Class org.apache.hadoop.mapreduce.Job implements same interface as superclass</LongMessage><Class classname='org.apache.hadoop.mapreduce.Job' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.Job' start='83' end='1792' sourcepath='org/apache/hadoop/mapreduce/Job.java' sourcefile='Job.java'><Message>At Job.java:[lines 83-1792]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.Job</Message></Class><Class role='INTERFACE_TYPE' classname='org.apache.hadoop.mapreduce.JobContext'><SourceLine classname='org.apache.hadoop.mapreduce.JobContext' sourcepath='org/apache/hadoop/mapreduce/JobContext.java' sourcefile='JobContext.java'><Message>In JobContext.java</Message></SourceLine><Message>Interface org.apache.hadoop.mapreduce.JobContext</Message></Class><SourceLine synthetic='true' classname='org.apache.hadoop.mapreduce.Job' start='83' end='1792' sourcepath='org/apache/hadoop/mapreduce/Job.java' sourcefile='Job.java'><Message>At Job.java:[lines 83-1792]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='5413e0e1aa85b9a7990bb47e2e2cc1c3' cweid='396' rank='20' abbrev='REC' category='STYLE' priority='3' type='REC_CATCH_EXCEPTION' instanceOccurrenceMax='0'><ShortMessage>Exception is caught when Exception is not thrown</ShortMessage><LongMessage>Exception is caught when Exception is not thrown in org.apache.hadoop.mapreduce.JobID.forName(String)</LongMessage><Class classname='org.apache.hadoop.mapreduce.JobID' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.JobID' start='47' end='156' sourcepath='org/apache/hadoop/mapreduce/JobID.java' sourcefile='JobID.java'><Message>At JobID.java:[lines 47-156]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.JobID</Message></Class><Method isStatic='true' classname='org.apache.hadoop.mapreduce.JobID' signature='(Ljava/lang/String;)Lorg/apache/hadoop/mapreduce/JobID;' name='forName' primary='true'><SourceLine endBytecode='197' classname='org.apache.hadoop.mapreduce.JobID' start='144' end='156' sourcepath='org/apache/hadoop/mapreduce/JobID.java' sourcefile='JobID.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapreduce.JobID.forName(String)</Message></Method><SourceLine endBytecode='50' classname='org.apache.hadoop.mapreduce.JobID' start='154' end='154' sourcepath='org/apache/hadoop/mapreduce/JobID.java' sourcefile='JobID.java' startBytecode='50' primary='true'><Message>At JobID.java:[line 154]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='167336d6c78617fa30a5422bf1fd7141' rank='20' abbrev='RI' category='STYLE' priority='3' type='RI_REDUNDANT_INTERFACES' instanceOccurrenceMax='0'><ShortMessage>Class implements same interface as superclass</ShortMessage><LongMessage>Class org.apache.hadoop.mapreduce.JobID implements same interface as superclass</LongMessage><Class classname='org.apache.hadoop.mapreduce.JobID' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.JobID' start='47' end='156' sourcepath='org/apache/hadoop/mapreduce/JobID.java' sourcefile='JobID.java'><Message>At JobID.java:[lines 47-156]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.JobID</Message></Class><Class role='INTERFACE_TYPE' classname='java.lang.Comparable'><SourceLine classname='java.lang.Comparable' sourcepath='java/lang/Comparable.java' sourcefile='Comparable.java'><Message>In Comparable.java</Message></SourceLine><Message>Interface java.lang.Comparable</Message></Class><SourceLine synthetic='true' classname='org.apache.hadoop.mapreduce.JobID' start='47' end='156' sourcepath='org/apache/hadoop/mapreduce/JobID.java' sourcefile='JobID.java'><Message>At JobID.java:[lines 47-156]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='58cb4bc9098c56354f3ce9c422ff217f' cweid='366' rank='20' abbrev='IS' category='MT_CORRECTNESS' priority='3' type='IS2_INCONSISTENT_SYNC' instanceOccurrenceMax='0'><ShortMessage>Inconsistent synchronization</ShortMessage><LongMessage>Inconsistent synchronization of org.apache.hadoop.mapreduce.JobStatus.jobFile; locked 66% of time</LongMessage><Class classname='org.apache.hadoop.mapreduce.JobStatus' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.JobStatus' start='45' end='656' sourcepath='org/apache/hadoop/mapreduce/JobStatus.java' sourcefile='JobStatus.java'><Message>At JobStatus.java:[lines 45-656]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.JobStatus</Message></Class><Field isStatic='false' classname='org.apache.hadoop.mapreduce.JobStatus' signature='Ljava/lang/String;' name='jobFile' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.JobStatus' sourcepath='org/apache/hadoop/mapreduce/JobStatus.java' sourcefile='JobStatus.java'><Message>In JobStatus.java</Message></SourceLine><Message>Field org.apache.hadoop.mapreduce.JobStatus.jobFile</Message></Field><Int role='INT_SYNC_PERCENT' value='66'><Message>Synchronized 66% of the time</Message></Int><SourceLine role='SOURCE_LINE_UNSYNC_ACCESS' endBytecode='1' classname='org.apache.hadoop.mapreduce.JobStatus' start='520' end='520' sourcepath='org/apache/hadoop/mapreduce/JobStatus.java' sourcefile='JobStatus.java' startBytecode='1' primary='true'><Message>Unsynchronized access at JobStatus.java:[line 520]</Message></SourceLine><SourceLine role='SOURCE_LINE_SYNC_ACCESS' endBytecode='141' classname='org.apache.hadoop.mapreduce.JobStatus' start='468' end='468' sourcepath='org/apache/hadoop/mapreduce/JobStatus.java' sourcefile='JobStatus.java' startBytecode='141'><Message>Synchronized access at JobStatus.java:[line 468]</Message></SourceLine><SourceLine role='SOURCE_LINE_SYNC_ACCESS' endBytecode='178' classname='org.apache.hadoop.mapreduce.JobStatus' start='496' end='496' sourcepath='org/apache/hadoop/mapreduce/JobStatus.java' sourcefile='JobStatus.java' startBytecode='178'><Message>Synchronized access at JobStatus.java:[line 496]</Message></SourceLine><Property name='edu.umd.cs.findbugs.detect.InconsistentSyncWarningProperty.ONLY_UNSYNC_IN_GETTERS' value='true'></Property></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='b5ace83b242d45f2448e67a5d5743a97' cweid='366' rank='20' abbrev='IS' category='MT_CORRECTNESS' priority='3' type='IS2_INCONSISTENT_SYNC' instanceOccurrenceMax='0'><ShortMessage>Inconsistent synchronization</ShortMessage><LongMessage>Inconsistent synchronization of org.apache.hadoop.mapreduce.JobStatus.jobName; locked 66% of time</LongMessage><Class classname='org.apache.hadoop.mapreduce.JobStatus' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.JobStatus' start='45' end='656' sourcepath='org/apache/hadoop/mapreduce/JobStatus.java' sourcefile='JobStatus.java'><Message>At JobStatus.java:[lines 45-656]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.JobStatus</Message></Class><Field isStatic='false' classname='org.apache.hadoop.mapreduce.JobStatus' signature='Ljava/lang/String;' name='jobName' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.JobStatus' sourcepath='org/apache/hadoop/mapreduce/JobStatus.java' sourcefile='JobStatus.java'><Message>In JobStatus.java</Message></SourceLine><Message>Field org.apache.hadoop.mapreduce.JobStatus.jobName</Message></Field><Int role='INT_SYNC_PERCENT' value='66'><Message>Synchronized 66% of the time</Message></Int><SourceLine role='SOURCE_LINE_UNSYNC_ACCESS' endBytecode='1' classname='org.apache.hadoop.mapreduce.JobStatus' start='513' end='513' sourcepath='org/apache/hadoop/mapreduce/JobStatus.java' sourcefile='JobStatus.java' startBytecode='1' primary='true'><Message>Unsynchronized access at JobStatus.java:[line 513]</Message></SourceLine><SourceLine role='SOURCE_LINE_SYNC_ACCESS' endBytecode='123' classname='org.apache.hadoop.mapreduce.JobStatus' start='466' end='466' sourcepath='org/apache/hadoop/mapreduce/JobStatus.java' sourcefile='JobStatus.java' startBytecode='123'><Message>Synchronized access at JobStatus.java:[line 466]</Message></SourceLine><SourceLine role='SOURCE_LINE_SYNC_ACCESS' endBytecode='156' classname='org.apache.hadoop.mapreduce.JobStatus' start='494' end='494' sourcepath='org/apache/hadoop/mapreduce/JobStatus.java' sourcefile='JobStatus.java' startBytecode='156'><Message>Synchronized access at JobStatus.java:[line 494]</Message></SourceLine><Property name='edu.umd.cs.findbugs.detect.InconsistentSyncWarningProperty.ONLY_UNSYNC_IN_GETTERS' value='true'></Property></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='49c04b2c1ffb5d4f1538e1deac706287' cweid='366' rank='20' abbrev='IS' category='MT_CORRECTNESS' priority='3' type='IS2_INCONSISTENT_SYNC' instanceOccurrenceMax='0'><ShortMessage>Inconsistent synchronization</ShortMessage><LongMessage>Inconsistent synchronization of org.apache.hadoop.mapreduce.JobStatus.jobid; locked 75% of time</LongMessage><Class classname='org.apache.hadoop.mapreduce.JobStatus' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.JobStatus' start='45' end='656' sourcepath='org/apache/hadoop/mapreduce/JobStatus.java' sourcefile='JobStatus.java'><Message>At JobStatus.java:[lines 45-656]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.JobStatus</Message></Class><Field isStatic='false' classname='org.apache.hadoop.mapreduce.JobStatus' signature='Lorg/apache/hadoop/mapreduce/JobID;' name='jobid' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.JobStatus' sourcepath='org/apache/hadoop/mapreduce/JobStatus.java' sourcefile='JobStatus.java'><Message>In JobStatus.java</Message></SourceLine><Message>Field org.apache.hadoop.mapreduce.JobStatus.jobid</Message></Field><Int role='INT_SYNC_PERCENT' value='75'><Message>Synchronized 75% of the time</Message></Int><SourceLine role='SOURCE_LINE_UNSYNC_ACCESS' endBytecode='1' classname='org.apache.hadoop.mapreduce.JobStatus' start='401' end='401' sourcepath='org/apache/hadoop/mapreduce/JobStatus.java' sourcefile='JobStatus.java' startBytecode='1' primary='true'><Message>Unsynchronized access at JobStatus.java:[line 401]</Message></SourceLine><SourceLine role='SOURCE_LINE_SYNC_ACCESS' endBytecode='1' classname='org.apache.hadoop.mapreduce.JobStatus' start='453' end='453' sourcepath='org/apache/hadoop/mapreduce/JobStatus.java' sourcefile='JobStatus.java' startBytecode='1'><Message>Synchronized access at JobStatus.java:[line 453]</Message></SourceLine><SourceLine role='SOURCE_LINE_SYNC_ACCESS' endBytecode='8' classname='org.apache.hadoop.mapreduce.JobStatus' start='480' end='480' sourcepath='org/apache/hadoop/mapreduce/JobStatus.java' sourcefile='JobStatus.java' startBytecode='8'><Message>Synchronized access at JobStatus.java:[line 480]</Message></SourceLine><SourceLine role='SOURCE_LINE_SYNC_ACCESS' endBytecode='12' classname='org.apache.hadoop.mapreduce.JobStatus' start='481' end='481' sourcepath='org/apache/hadoop/mapreduce/JobStatus.java' sourcefile='JobStatus.java' startBytecode='12'><Message>Synchronized access at JobStatus.java:[line 481]</Message></SourceLine><SourceLine role='SOURCE_LINE_SYNC_ACCESS' endBytecode='22' classname='org.apache.hadoop.mapreduce.JobStatus' start='640' end='640' sourcepath='org/apache/hadoop/mapreduce/JobStatus.java' sourcefile='JobStatus.java' startBytecode='22'><Message>Synchronized access at JobStatus.java:[line 640]</Message></SourceLine><Property name='edu.umd.cs.findbugs.detect.InconsistentSyncWarningProperty.ONLY_UNSYNC_IN_GETTERS' value='true'></Property></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='8277778e5d14ccc380a1691e8b1bd035' rank='19' abbrev='Nm' category='BAD_PRACTICE' priority='3' type='NM_CONFUSING' instanceOccurrenceMax='0'><ShortMessage>Confusing method names</ShortMessage><LongMessage>Confusing to have methods org.apache.hadoop.mapreduce.JobStatus.getJobACLs() and org.apache.hadoop.mapreduce.jobhistory.JobSubmittedEvent.getJobAcls()</LongMessage><Class classname='org.apache.hadoop.mapreduce.JobStatus' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.JobStatus' start='45' end='656' sourcepath='org/apache/hadoop/mapreduce/JobStatus.java' sourcefile='JobStatus.java'><Message>At JobStatus.java:[lines 45-656]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.JobStatus</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapreduce.JobStatus' signature='()Ljava/util/Map;' name='getJobACLs' primary='true'><SourceLine endBytecode='46' classname='org.apache.hadoop.mapreduce.JobStatus' start='422' end='422' sourcepath='org/apache/hadoop/mapreduce/JobStatus.java' sourcefile='JobStatus.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapreduce.JobStatus.getJobACLs()</Message></Method><Class classname='org.apache.hadoop.mapreduce.jobhistory.JobSubmittedEvent'><SourceLine classname='org.apache.hadoop.mapreduce.jobhistory.JobSubmittedEvent' start='44' end='268' sourcepath='org/apache/hadoop/mapreduce/jobhistory/JobSubmittedEvent.java' sourcefile='JobSubmittedEvent.java'><Message>At JobSubmittedEvent.java:[lines 44-268]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.jobhistory.JobSubmittedEvent</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapreduce.jobhistory.JobSubmittedEvent' signature='()Ljava/util/Map;' name='getJobAcls'><SourceLine endBytecode='260' classname='org.apache.hadoop.mapreduce.jobhistory.JobSubmittedEvent' start='192' end='201' sourcepath='org/apache/hadoop/mapreduce/jobhistory/JobSubmittedEvent.java' sourcefile='JobSubmittedEvent.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapreduce.jobhistory.JobSubmittedEvent.getJobAcls()</Message></Method><SourceLine synthetic='true' endBytecode='46' classname='org.apache.hadoop.mapreduce.JobStatus' start='422' end='422' sourcepath='org/apache/hadoop/mapreduce/JobStatus.java' sourcefile='JobStatus.java' startBytecode='0'><Message>At JobStatus.java:[line 422]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='bedb6a6ab11d07ecf3f82609e3273bac' rank='19' abbrev='Nm' category='BAD_PRACTICE' priority='3' type='NM_CONFUSING' instanceOccurrenceMax='0'><ShortMessage>Confusing method names</ShortMessage><LongMessage>Confusing to have methods org.apache.hadoop.mapreduce.JobStatus.getUsername() and org.apache.hadoop.mapreduce.jobhistory.JobSubmittedEvent.getUserName()</LongMessage><Class classname='org.apache.hadoop.mapreduce.JobStatus' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.JobStatus' start='45' end='656' sourcepath='org/apache/hadoop/mapreduce/JobStatus.java' sourcefile='JobStatus.java'><Message>At JobStatus.java:[lines 45-656]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.JobStatus</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapreduce.JobStatus' signature='()Ljava/lang/String;' name='getUsername' primary='true'><SourceLine endBytecode='46' classname='org.apache.hadoop.mapreduce.JobStatus' start='406' end='406' sourcepath='org/apache/hadoop/mapreduce/JobStatus.java' sourcefile='JobStatus.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapreduce.JobStatus.getUsername()</Message></Method><Class classname='org.apache.hadoop.mapreduce.jobhistory.JobSubmittedEvent'><SourceLine classname='org.apache.hadoop.mapreduce.jobhistory.JobSubmittedEvent' start='44' end='268' sourcepath='org/apache/hadoop/mapreduce/jobhistory/JobSubmittedEvent.java' sourcefile='JobSubmittedEvent.java'><Message>At JobSubmittedEvent.java:[lines 44-268]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.jobhistory.JobSubmittedEvent</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapreduce.jobhistory.JobSubmittedEvent' signature='()Ljava/lang/String;' name='getUserName'><SourceLine endBytecode='54' classname='org.apache.hadoop.mapreduce.jobhistory.JobSubmittedEvent' start='185' end='185' sourcepath='org/apache/hadoop/mapreduce/jobhistory/JobSubmittedEvent.java' sourcefile='JobSubmittedEvent.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapreduce.jobhistory.JobSubmittedEvent.getUserName()</Message></Method><SourceLine synthetic='true' endBytecode='46' classname='org.apache.hadoop.mapreduce.JobStatus' start='406' end='406' sourcepath='org/apache/hadoop/mapreduce/JobStatus.java' sourcefile='JobStatus.java' startBytecode='0'><Message>At JobStatus.java:[line 406]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='73aa02bb9b5797f1da7c3d27da4c0a2d' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST_OF_RETURN_VALUE' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast of return value from method</ShortMessage><LongMessage>Unchecked/unconfirmed cast from org.apache.hadoop.conf.Configuration to org.apache.hadoop.mapred.JobConf of return value in org.apache.hadoop.mapreduce.JobSubmitter.checkSpecs(Job)</LongMessage><Class classname='org.apache.hadoop.mapreduce.JobSubmitter' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.JobSubmitter' start='72' end='473' sourcepath='org/apache/hadoop/mapreduce/JobSubmitter.java' sourcefile='JobSubmitter.java'><Message>At JobSubmitter.java:[lines 72-473]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.JobSubmitter</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapreduce.JobSubmitter' signature='(Lorg/apache/hadoop/mapreduce/Job;)V' name='checkSpecs' primary='true'><SourceLine endBytecode='31' classname='org.apache.hadoop.mapreduce.JobSubmitter' start='273' end='284' sourcepath='org/apache/hadoop/mapreduce/JobSubmitter.java' sourcefile='JobSubmitter.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapreduce.JobSubmitter.checkSpecs(Job)</Message></Method><Type role='TYPE_FOUND' descriptor='Lorg/apache/hadoop/conf/Configuration;'><SourceLine classname='org.apache.hadoop.conf.Configuration' start='223' end='3860' sourcepath='org/apache/hadoop/conf/Configuration.java' sourcefile='Configuration.java'><Message>At Configuration.java:[lines 223-3860]</Message></SourceLine><Message>Actual type org.apache.hadoop.conf.Configuration</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/mapred/JobConf;'><SourceLine classname='org.apache.hadoop.mapred.JobConf' start='118' end='2224' sourcepath='org/apache/hadoop/mapred/JobConf.java' sourcefile='JobConf.java'><Message>At JobConf.java:[lines 118-2224]</Message></SourceLine><Message>Expected org.apache.hadoop.mapred.JobConf</Message></Type><SourceLine endBytecode='4' classname='org.apache.hadoop.mapreduce.JobSubmitter' start='273' end='273' sourcepath='org/apache/hadoop/mapreduce/JobSubmitter.java' sourcefile='JobSubmitter.java' startBytecode='4' primary='true'><Message>At JobSubmitter.java:[line 273]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='44e07d14859b73ad99cac814b6f1aaef' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST_OF_RETURN_VALUE' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast of return value from method</ShortMessage><LongMessage>Unchecked/unconfirmed cast from org.apache.hadoop.conf.Configuration to org.apache.hadoop.mapred.JobConf of return value in org.apache.hadoop.mapreduce.JobSubmitter.writeSplits(JobContext, Path)</LongMessage><Class classname='org.apache.hadoop.mapreduce.JobSubmitter' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.JobSubmitter' start='72' end='473' sourcepath='org/apache/hadoop/mapreduce/JobSubmitter.java' sourcefile='JobSubmitter.java'><Message>At JobSubmitter.java:[lines 72-473]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.JobSubmitter</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapreduce.JobSubmitter' signature='(Lorg/apache/hadoop/mapreduce/JobContext;Lorg/apache/hadoop/fs/Path;)I' name='writeSplits' primary='true'><SourceLine endBytecode='19' classname='org.apache.hadoop.mapreduce.JobSubmitter' start='327' end='334' sourcepath='org/apache/hadoop/mapreduce/JobSubmitter.java' sourcefile='JobSubmitter.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapreduce.JobSubmitter.writeSplits(JobContext, Path)</Message></Method><Type role='TYPE_FOUND' descriptor='Lorg/apache/hadoop/conf/Configuration;'><SourceLine classname='org.apache.hadoop.conf.Configuration' start='223' end='3860' sourcepath='org/apache/hadoop/conf/Configuration.java' sourcefile='Configuration.java'><Message>At Configuration.java:[lines 223-3860]</Message></SourceLine><Message>Actual type org.apache.hadoop.conf.Configuration</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/mapred/JobConf;'><SourceLine classname='org.apache.hadoop.mapred.JobConf' start='118' end='2224' sourcepath='org/apache/hadoop/mapred/JobConf.java' sourcefile='JobConf.java'><Message>At JobConf.java:[lines 118-2224]</Message></SourceLine><Message>Expected org.apache.hadoop.mapred.JobConf</Message></Type><SourceLine endBytecode='6' classname='org.apache.hadoop.mapreduce.JobSubmitter' start='327' end='327' sourcepath='org/apache/hadoop/mapreduce/JobSubmitter.java' sourcefile='JobSubmitter.java' startBytecode='6' primary='true'><Message>At JobSubmitter.java:[line 327]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='e34714149984580c491b2dbdcc8edfb3' rank='20' abbrev='SIC' category='PERFORMANCE' priority='3' type='SIC_INNER_SHOULD_BE_STATIC_ANON' instanceOccurrenceMax='0'><ShortMessage>Could be refactored into a named static inner class</ShortMessage><LongMessage>The class org.apache.hadoop.mapreduce.JobSubmitter$1 could be refactored into a named _static_ inner class</LongMessage><Class role='CLASS_ANONYMOUS' classname='org.apache.hadoop.mapreduce.JobSubmitter$1'><SourceLine classname='org.apache.hadoop.mapreduce.JobSubmitter$1' start='344' end='358' sourcepath='org/apache/hadoop/mapreduce/JobSubmitter.java' sourcefile='JobSubmitter.java'><Message>At JobSubmitter.java:[lines 344-358]</Message></SourceLine><Message>Anonymous class org.apache.hadoop.mapreduce.JobSubmitter$1</Message></Class><Class classname='org.apache.hadoop.mapreduce.JobSubmitter' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.JobSubmitter' start='72' end='473' sourcepath='org/apache/hadoop/mapreduce/JobSubmitter.java' sourcefile='JobSubmitter.java'><Message>At JobSubmitter.java:[lines 72-473]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.JobSubmitter</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapreduce.JobSubmitter' signature='(Lorg/apache/hadoop/mapred/JobConf;Lorg/apache/hadoop/fs/Path;)I' name='writeOldSplits' primary='true'><SourceLine endBytecode='136' classname='org.apache.hadoop.mapreduce.JobSubmitter' start='340' end='364' sourcepath='org/apache/hadoop/mapreduce/JobSubmitter.java' sourcefile='JobSubmitter.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapreduce.JobSubmitter.writeOldSplits(JobConf, Path)</Message></Method><SourceLine endBytecode='21' classname='org.apache.hadoop.mapreduce.JobSubmitter' start='344' end='344' sourcepath='org/apache/hadoop/mapreduce/JobSubmitter.java' sourcefile='JobSubmitter.java' startBytecode='21' primary='true'><Message>At JobSubmitter.java:[line 344]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='d38ec0b3278ab22d3a162588d34c83c5' rank='19' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_COMPARATOR_SHOULD_BE_SERIALIZABLE' instanceOccurrenceMax='0'><ShortMessage>Comparator doesn't implement Serializable</ShortMessage><LongMessage>org.apache.hadoop.mapreduce.JobSubmitter$SplitComparator implements Comparator but not Serializable</LongMessage><Class classname='org.apache.hadoop.mapreduce.JobSubmitter$SplitComparator' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.JobSubmitter$SplitComparator' start='367' end='383' sourcepath='org/apache/hadoop/mapreduce/JobSubmitter.java' sourcefile='JobSubmitter.java'><Message>At JobSubmitter.java:[lines 367-383]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.JobSubmitter$SplitComparator</Message></Class><SourceLine synthetic='true' classname='org.apache.hadoop.mapreduce.JobSubmitter$SplitComparator' start='367' end='383' sourcepath='org/apache/hadoop/mapreduce/JobSubmitter.java' sourcefile='JobSubmitter.java'><Message>At JobSubmitter.java:[lines 367-383]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='bec42bb5aba30d18dfb0f747dea60604' cweid='374' rank='18' abbrev='EI' category='MALICIOUS_CODE' priority='2' type='EI_EXPOSE_REP' instanceOccurrenceMax='0'><ShortMessage>May expose internal representation by returning reference to mutable object</ShortMessage><LongMessage>org.apache.hadoop.mapreduce.QueueAclsInfo.getOperations() may expose internal representation by returning QueueAclsInfo.operations</LongMessage><Class classname='org.apache.hadoop.mapreduce.QueueAclsInfo' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.QueueAclsInfo' start='46' end='94' sourcepath='org/apache/hadoop/mapreduce/QueueAclsInfo.java' sourcefile='QueueAclsInfo.java'><Message>At QueueAclsInfo.java:[lines 46-94]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.QueueAclsInfo</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapreduce.QueueAclsInfo' signature='()[Ljava/lang/String;' name='getOperations' primary='true'><SourceLine endBytecode='46' classname='org.apache.hadoop.mapreduce.QueueAclsInfo' start='81' end='81' sourcepath='org/apache/hadoop/mapreduce/QueueAclsInfo.java' sourcefile='QueueAclsInfo.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapreduce.QueueAclsInfo.getOperations()</Message></Method><Field isStatic='false' classname='org.apache.hadoop.mapreduce.QueueAclsInfo' signature='[Ljava/lang/String;' name='operations' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.QueueAclsInfo' sourcepath='org/apache/hadoop/mapreduce/QueueAclsInfo.java' sourcefile='QueueAclsInfo.java'><Message>In QueueAclsInfo.java</Message></SourceLine><Message>Field org.apache.hadoop.mapreduce.QueueAclsInfo.operations</Message></Field><SourceLine endBytecode='4' classname='org.apache.hadoop.mapreduce.QueueAclsInfo' start='81' end='81' sourcepath='org/apache/hadoop/mapreduce/QueueAclsInfo.java' sourcefile='QueueAclsInfo.java' startBytecode='4' primary='true'><Message>At QueueAclsInfo.java:[line 81]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='700a81affe4fd0dff4a372ab3b84989f' cweid='374' rank='18' abbrev='EI2' category='MALICIOUS_CODE' priority='2' type='EI_EXPOSE_REP2' instanceOccurrenceMax='0'><ShortMessage>May expose internal representation by incorporating reference to mutable object</ShortMessage><LongMessage>new org.apache.hadoop.mapreduce.QueueAclsInfo(String, String[]) may expose internal representation by storing an externally mutable object into QueueAclsInfo.operations</LongMessage><Class classname='org.apache.hadoop.mapreduce.QueueAclsInfo' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.QueueAclsInfo' start='46' end='94' sourcepath='org/apache/hadoop/mapreduce/QueueAclsInfo.java' sourcefile='QueueAclsInfo.java'><Message>At QueueAclsInfo.java:[lines 46-94]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.QueueAclsInfo</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapreduce.QueueAclsInfo' signature='(Ljava/lang/String;[Ljava/lang/String;)V' name='&lt;init&gt;' primary='true'><SourceLine endBytecode='88' classname='org.apache.hadoop.mapreduce.QueueAclsInfo' start='57' end='60' sourcepath='org/apache/hadoop/mapreduce/QueueAclsInfo.java' sourcefile='QueueAclsInfo.java' startBytecode='0'></SourceLine><Message>In method new org.apache.hadoop.mapreduce.QueueAclsInfo(String, String[])</Message></Method><Field isStatic='false' classname='org.apache.hadoop.mapreduce.QueueAclsInfo' signature='[Ljava/lang/String;' name='operations' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.QueueAclsInfo' sourcepath='org/apache/hadoop/mapreduce/QueueAclsInfo.java' sourcefile='QueueAclsInfo.java'><Message>In QueueAclsInfo.java</Message></SourceLine><Message>Field org.apache.hadoop.mapreduce.QueueAclsInfo.operations</Message></Field><LocalVariable role='LOCAL_VARIABLE_NAMED' pc='11' name='operations' register='2'><Message>Local variable named operations</Message></LocalVariable><SourceLine endBytecode='11' classname='org.apache.hadoop.mapreduce.QueueAclsInfo' start='59' end='59' sourcepath='org/apache/hadoop/mapreduce/QueueAclsInfo.java' sourcefile='QueueAclsInfo.java' startBytecode='11' primary='true'><Message>At QueueAclsInfo.java:[line 59]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='6796b2bfee0493eac4886a7b0d417a33' cweid='374' rank='18' abbrev='EI' category='MALICIOUS_CODE' priority='2' type='EI_EXPOSE_REP' instanceOccurrenceMax='0'><ShortMessage>May expose internal representation by returning reference to mutable object</ShortMessage><LongMessage>org.apache.hadoop.mapreduce.QueueInfo.getJobStatuses() may expose internal representation by returning QueueInfo.stats</LongMessage><Class classname='org.apache.hadoop.mapreduce.QueueInfo' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.QueueInfo' start='43' end='230' sourcepath='org/apache/hadoop/mapreduce/QueueInfo.java' sourcefile='QueueInfo.java'><Message>At QueueInfo.java:[lines 43-230]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.QueueInfo</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapreduce.QueueInfo' signature='()[Lorg/apache/hadoop/mapreduce/JobStatus;' name='getJobStatuses' primary='true'><SourceLine endBytecode='46' classname='org.apache.hadoop.mapreduce.QueueInfo' start='189' end='189' sourcepath='org/apache/hadoop/mapreduce/QueueInfo.java' sourcefile='QueueInfo.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapreduce.QueueInfo.getJobStatuses()</Message></Method><Field isStatic='false' classname='org.apache.hadoop.mapreduce.QueueInfo' signature='[Lorg/apache/hadoop/mapreduce/JobStatus;' name='stats' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.QueueInfo' sourcepath='org/apache/hadoop/mapreduce/QueueInfo.java' sourcefile='QueueInfo.java'><Message>In QueueInfo.java</Message></SourceLine><Message>Field org.apache.hadoop.mapreduce.QueueInfo.stats</Message></Field><SourceLine endBytecode='4' classname='org.apache.hadoop.mapreduce.QueueInfo' start='189' end='189' sourcepath='org/apache/hadoop/mapreduce/QueueInfo.java' sourcefile='QueueInfo.java' startBytecode='4' primary='true'><Message>At QueueInfo.java:[line 189]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='4220186af9bd5182c7e2b7455598b3fe' cweid='374' rank='18' abbrev='EI2' category='MALICIOUS_CODE' priority='2' type='EI_EXPOSE_REP2' instanceOccurrenceMax='0'><ShortMessage>May expose internal representation by incorporating reference to mutable object</ShortMessage><LongMessage>new org.apache.hadoop.mapreduce.QueueInfo(String, String, QueueState, JobStatus[]) may expose internal representation by storing an externally mutable object into QueueInfo.stats</LongMessage><Class classname='org.apache.hadoop.mapreduce.QueueInfo' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.QueueInfo' start='43' end='230' sourcepath='org/apache/hadoop/mapreduce/QueueInfo.java' sourcefile='QueueInfo.java'><Message>At QueueInfo.java:[lines 43-230]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.QueueInfo</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapreduce.QueueInfo' signature='(Ljava/lang/String;Ljava/lang/String;Lorg/apache/hadoop/mapreduce/QueueState;[Lorg/apache/hadoop/mapreduce/JobStatus;)V' name='&lt;init&gt;' primary='true'><SourceLine endBytecode='111' classname='org.apache.hadoop.mapreduce.QueueInfo' start='92' end='95' sourcepath='org/apache/hadoop/mapreduce/QueueInfo.java' sourcefile='QueueInfo.java' startBytecode='0'></SourceLine><Message>In method new org.apache.hadoop.mapreduce.QueueInfo(String, String, QueueState, JobStatus[])</Message></Method><Field isStatic='false' classname='org.apache.hadoop.mapreduce.QueueInfo' signature='[Lorg/apache/hadoop/mapreduce/JobStatus;' name='stats' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.QueueInfo' sourcepath='org/apache/hadoop/mapreduce/QueueInfo.java' sourcefile='QueueInfo.java'><Message>In QueueInfo.java</Message></SourceLine><Message>Field org.apache.hadoop.mapreduce.QueueInfo.stats</Message></Field><LocalVariable role='LOCAL_VARIABLE_NAMED' pc='14' name='stats' register='4'><Message>Local variable named stats</Message></LocalVariable><SourceLine endBytecode='14' classname='org.apache.hadoop.mapreduce.QueueInfo' start='94' end='94' sourcepath='org/apache/hadoop/mapreduce/QueueInfo.java' sourcefile='QueueInfo.java' startBytecode='14' primary='true'><Message>At QueueInfo.java:[line 94]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='7609f71766d00c09a5d4b1c2ccf4da23' cweid='391' rank='19' abbrev='DE' category='BAD_PRACTICE' priority='3' type='DE_MIGHT_IGNORE' instanceOccurrenceMax='0'><ShortMessage>Method might ignore exception</ShortMessage><LongMessage>org.apache.hadoop.mapreduce.TaskAttemptID.forName(String) might ignore java.lang.Exception</LongMessage><Class classname='org.apache.hadoop.mapreduce.TaskAttemptID' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.TaskAttemptID' start='48' end='201' sourcepath='org/apache/hadoop/mapreduce/TaskAttemptID.java' sourcefile='TaskAttemptID.java'><Message>At TaskAttemptID.java:[lines 48-201]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.TaskAttemptID</Message></Class><Method isStatic='true' classname='org.apache.hadoop.mapreduce.TaskAttemptID' signature='(Ljava/lang/String;)Lorg/apache/hadoop/mapreduce/TaskAttemptID;' name='forName' primary='true'><SourceLine endBytecode='366' classname='org.apache.hadoop.mapreduce.TaskAttemptID' start='174' end='201' sourcepath='org/apache/hadoop/mapreduce/TaskAttemptID.java' sourcefile='TaskAttemptID.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapreduce.TaskAttemptID.forName(String)</Message></Method><Class role='CLASS_EXCEPTION' classname='java.lang.Exception'><SourceLine classname='java.lang.Exception' start='54' end='123' sourcepath='java/lang/Exception.java' sourcefile='Exception.java'><Message>At Exception.java:[lines 54-123]</Message></SourceLine><Message>Exception class java.lang.Exception</Message></Class><SourceLine endBytecode='114' classname='org.apache.hadoop.mapreduce.TaskAttemptID' start='194' end='194' sourcepath='org/apache/hadoop/mapreduce/TaskAttemptID.java' sourcefile='TaskAttemptID.java' startBytecode='114' primary='true'><Message>At TaskAttemptID.java:[line 194]</Message></SourceLine><SourceLine endBytecode='114' classname='org.apache.hadoop.mapreduce.TaskAttemptID' start='194' end='194' sourcepath='org/apache/hadoop/mapreduce/TaskAttemptID.java' sourcefile='TaskAttemptID.java' startBytecode='114' primary='true'><Message>At TaskAttemptID.java:[line 194]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='c0a9da89d9a7c64434b96dbfb37b551c' cweid='396' rank='20' abbrev='REC' category='STYLE' priority='3' type='REC_CATCH_EXCEPTION' instanceOccurrenceMax='0'><ShortMessage>Exception is caught when Exception is not thrown</ShortMessage><LongMessage>Exception is caught when Exception is not thrown in org.apache.hadoop.mapreduce.TaskAttemptID.forName(String)</LongMessage><Class classname='org.apache.hadoop.mapreduce.TaskAttemptID' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.TaskAttemptID' start='48' end='201' sourcepath='org/apache/hadoop/mapreduce/TaskAttemptID.java' sourcefile='TaskAttemptID.java'><Message>At TaskAttemptID.java:[lines 48-201]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.TaskAttemptID</Message></Class><Method isStatic='true' classname='org.apache.hadoop.mapreduce.TaskAttemptID' signature='(Ljava/lang/String;)Lorg/apache/hadoop/mapreduce/TaskAttemptID;' name='forName' primary='true'><SourceLine endBytecode='366' classname='org.apache.hadoop.mapreduce.TaskAttemptID' start='174' end='201' sourcepath='org/apache/hadoop/mapreduce/TaskAttemptID.java' sourcefile='TaskAttemptID.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapreduce.TaskAttemptID.forName(String)</Message></Method><SourceLine endBytecode='114' classname='org.apache.hadoop.mapreduce.TaskAttemptID' start='194' end='194' sourcepath='org/apache/hadoop/mapreduce/TaskAttemptID.java' sourcefile='TaskAttemptID.java' startBytecode='114' primary='true'><Message>At TaskAttemptID.java:[line 194]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='c19e76dddf71b8d4cc4cc706bc8384c6' cweid='374' rank='18' abbrev='EI' category='MALICIOUS_CODE' priority='2' type='EI_EXPOSE_REP' instanceOccurrenceMax='0'><ShortMessage>May expose internal representation by returning reference to mutable object</ShortMessage><LongMessage>org.apache.hadoop.mapreduce.TaskReport.getDiagnostics() may expose internal representation by returning TaskReport.diagnostics</LongMessage><Class classname='org.apache.hadoop.mapreduce.TaskReport' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.TaskReport' start='49' end='238' sourcepath='org/apache/hadoop/mapreduce/TaskReport.java' sourcefile='TaskReport.java'><Message>At TaskReport.java:[lines 49-238]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.TaskReport</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapreduce.TaskReport' signature='()[Ljava/lang/String;' name='getDiagnostics' primary='true'><SourceLine endBytecode='46' classname='org.apache.hadoop.mapreduce.TaskReport' start='98' end='98' sourcepath='org/apache/hadoop/mapreduce/TaskReport.java' sourcefile='TaskReport.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapreduce.TaskReport.getDiagnostics()</Message></Method><Field isStatic='false' classname='org.apache.hadoop.mapreduce.TaskReport' signature='[Ljava/lang/String;' name='diagnostics' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.TaskReport' sourcepath='org/apache/hadoop/mapreduce/TaskReport.java' sourcefile='TaskReport.java'><Message>In TaskReport.java</Message></SourceLine><Message>Field org.apache.hadoop.mapreduce.TaskReport.diagnostics</Message></Field><SourceLine endBytecode='4' classname='org.apache.hadoop.mapreduce.TaskReport' start='98' end='98' sourcepath='org/apache/hadoop/mapreduce/TaskReport.java' sourcefile='TaskReport.java' startBytecode='4' primary='true'><Message>At TaskReport.java:[line 98]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='8e36b59a8575abbe26f4dde14a4bb66a' cweid='374' rank='18' abbrev='EI2' category='MALICIOUS_CODE' priority='2' type='EI_EXPOSE_REP2' instanceOccurrenceMax='0'><ShortMessage>May expose internal representation by incorporating reference to mutable object</ShortMessage><LongMessage>new org.apache.hadoop.mapreduce.TaskReport(TaskID, float, String, String[], TIPStatus, long, long, Counters) may expose internal representation by storing an externally mutable object into TaskReport.diagnostics</LongMessage><Class classname='org.apache.hadoop.mapreduce.TaskReport' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.TaskReport' start='49' end='238' sourcepath='org/apache/hadoop/mapreduce/TaskReport.java' sourcefile='TaskReport.java'><Message>At TaskReport.java:[lines 49-238]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.TaskReport</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapreduce.TaskReport' signature='(Lorg/apache/hadoop/mapred/TaskID;FLjava/lang/String;[Ljava/lang/String;Lorg/apache/hadoop/mapred/TIPStatus;JJLorg/apache/hadoop/mapreduce/Counters;)V' name='&lt;init&gt;' primary='true'><SourceLine endBytecode='237' classname='org.apache.hadoop.mapreduce.TaskReport' start='70' end='79' sourcepath='org/apache/hadoop/mapreduce/TaskReport.java' sourcefile='TaskReport.java' startBytecode='0'></SourceLine><Message>In method new org.apache.hadoop.mapreduce.TaskReport(TaskID, float, String, String[], TIPStatus, long, long, Counters)</Message></Method><Field isStatic='false' classname='org.apache.hadoop.mapreduce.TaskReport' signature='[Ljava/lang/String;' name='diagnostics' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.TaskReport' sourcepath='org/apache/hadoop/mapreduce/TaskReport.java' sourcefile='TaskReport.java'><Message>In TaskReport.java</Message></SourceLine><Message>Field org.apache.hadoop.mapreduce.TaskReport.diagnostics</Message></Field><LocalVariable role='LOCAL_VARIABLE_NAMED' pc='44' name='diagnostics' register='4'><Message>Local variable named diagnostics</Message></LocalVariable><SourceLine endBytecode='44' classname='org.apache.hadoop.mapreduce.TaskReport' start='74' end='74' sourcepath='org/apache/hadoop/mapreduce/TaskReport.java' sourcefile='TaskReport.java' startBytecode='44' primary='true'><Message>At TaskReport.java:[line 74]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='9bb087ae925bf6a0fac088003398cc2' rank='20' abbrev='FE' category='STYLE' priority='3' type='FE_FLOATING_POINT_EQUALITY' instanceOccurrenceMax='0'><ShortMessage>Test for floating point equality</ShortMessage><LongMessage>Test for floating point equality in org.apache.hadoop.mapreduce.TaskReport.equals(Object)</LongMessage><Class classname='org.apache.hadoop.mapreduce.TaskReport' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.TaskReport' start='49' end='238' sourcepath='org/apache/hadoop/mapreduce/TaskReport.java' sourcefile='TaskReport.java'><Message>At TaskReport.java:[lines 49-238]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.TaskReport</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapreduce.TaskReport' signature='(Ljava/lang/Object;)Z' name='equals' primary='true'><SourceLine endBytecode='264' classname='org.apache.hadoop.mapreduce.TaskReport' start='171' end='184' sourcepath='org/apache/hadoop/mapreduce/TaskReport.java' sourcefile='TaskReport.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapreduce.TaskReport.equals(Object)</Message></Method><SourceLine endBytecode='80' classname='org.apache.hadoop.mapreduce.TaskReport' start='179' end='179' sourcepath='org/apache/hadoop/mapreduce/TaskReport.java' sourcefile='TaskReport.java' startBytecode='80' primary='true'><Message>At TaskReport.java:[line 179]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='6be0f76a7677079d4eace96196a01751' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST_OF_RETURN_VALUE' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast of return value from method</ShortMessage><LongMessage>Unchecked/unconfirmed cast from java.util.Collection&lt;java.lang.String&gt; to java.util.ArrayList of return value in org.apache.hadoop.mapreduce.filecache.DistributedCache.getArchiveClassPaths(Configuration)</LongMessage><Class classname='org.apache.hadoop.mapreduce.filecache.DistributedCache' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.filecache.DistributedCache' start='135' end='547' sourcepath='org/apache/hadoop/mapreduce/filecache/DistributedCache.java' sourcefile='DistributedCache.java'><Message>At DistributedCache.java:[lines 135-547]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.filecache.DistributedCache</Message></Class><Method isStatic='true' classname='org.apache.hadoop.mapreduce.filecache.DistributedCache' signature='(Lorg/apache/hadoop/conf/Configuration;)[Lorg/apache/hadoop/fs/Path;' name='getArchiveClassPaths' primary='true'><SourceLine endBytecode='33' classname='org.apache.hadoop.mapreduce.filecache.DistributedCache' start='436' end='445' sourcepath='org/apache/hadoop/mapreduce/filecache/DistributedCache.java' sourcefile='DistributedCache.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapreduce.filecache.DistributedCache.getArchiveClassPaths(Configuration)</Message></Method><Type role='TYPE_FOUND' descriptor='Ljava/util/Collection;' typeParameters='&lt;java.lang.String&gt;'><SourceLine classname='java.util.Collection' start='410' end='602' sourcepath='java/util/Collection.java' sourcefile='Collection.java'><Message>At Collection.java:[lines 410-602]</Message></SourceLine><Message>Actual type java.util.Collection&lt;java.lang.String&gt;</Message></Type><Type role='TYPE_EXPECTED' descriptor='Ljava/util/ArrayList;'><SourceLine classname='java.util.ArrayList' start='107' end='1467' sourcepath='java/util/ArrayList.java' sourcefile='ArrayList.java'><Message>At ArrayList.java:[lines 107-1467]</Message></SourceLine><Message>Expected java.util.ArrayList</Message></Type><SourceLine endBytecode='6' classname='org.apache.hadoop.mapreduce.filecache.DistributedCache' start='436' end='436' sourcepath='org/apache/hadoop/mapreduce/filecache/DistributedCache.java' sourcefile='DistributedCache.java' startBytecode='6' primary='true'><Message>At DistributedCache.java:[line 436]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='62ab5ef21da3cb730a999b4c87d62c49' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST_OF_RETURN_VALUE' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast of return value from method</ShortMessage><LongMessage>Unchecked/unconfirmed cast from java.util.Collection&lt;java.lang.String&gt; to java.util.ArrayList of return value in org.apache.hadoop.mapreduce.filecache.DistributedCache.getFileClassPaths(Configuration)</LongMessage><Class classname='org.apache.hadoop.mapreduce.filecache.DistributedCache' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.filecache.DistributedCache' start='135' end='547' sourcepath='org/apache/hadoop/mapreduce/filecache/DistributedCache.java' sourcefile='DistributedCache.java'><Message>At DistributedCache.java:[lines 135-547]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.filecache.DistributedCache</Message></Class><Method isStatic='true' classname='org.apache.hadoop.mapreduce.filecache.DistributedCache' signature='(Lorg/apache/hadoop/conf/Configuration;)[Lorg/apache/hadoop/fs/Path;' name='getFileClassPaths' primary='true'><SourceLine endBytecode='33' classname='org.apache.hadoop.mapreduce.filecache.DistributedCache' start='380' end='389' sourcepath='org/apache/hadoop/mapreduce/filecache/DistributedCache.java' sourcefile='DistributedCache.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapreduce.filecache.DistributedCache.getFileClassPaths(Configuration)</Message></Method><Type role='TYPE_FOUND' descriptor='Ljava/util/Collection;' typeParameters='&lt;java.lang.String&gt;'><SourceLine classname='java.util.Collection' start='410' end='602' sourcepath='java/util/Collection.java' sourcefile='Collection.java'><Message>At Collection.java:[lines 410-602]</Message></SourceLine><Message>Actual type java.util.Collection&lt;java.lang.String&gt;</Message></Type><Type role='TYPE_EXPECTED' descriptor='Ljava/util/ArrayList;'><SourceLine classname='java.util.ArrayList' start='107' end='1467' sourcepath='java/util/ArrayList.java' sourcefile='ArrayList.java'><Message>At ArrayList.java:[lines 107-1467]</Message></SourceLine><Message>Expected java.util.ArrayList</Message></Type><SourceLine endBytecode='6' classname='org.apache.hadoop.mapreduce.filecache.DistributedCache' start='380' end='380' sourcepath='org/apache/hadoop/mapreduce/filecache/DistributedCache.java' sourcefile='DistributedCache.java' startBytecode='6' primary='true'><Message>At DistributedCache.java:[line 380]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='e7bda7226d428461ff60b6439d0756d7' rank='20' abbrev='PZLA' category='STYLE' priority='3' type='PZLA_PREFER_ZERO_LENGTH_ARRAYS' instanceOccurrenceMax='0'><ShortMessage>Consider returning a zero length array rather than null</ShortMessage><LongMessage>Should org.apache.hadoop.mapreduce.filecache.DistributedCache.getArchiveClassPaths(Configuration) return a zero length array rather than null?</LongMessage><Class classname='org.apache.hadoop.mapreduce.filecache.DistributedCache' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.filecache.DistributedCache' start='135' end='547' sourcepath='org/apache/hadoop/mapreduce/filecache/DistributedCache.java' sourcefile='DistributedCache.java'><Message>At DistributedCache.java:[lines 135-547]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.filecache.DistributedCache</Message></Class><Method isStatic='true' classname='org.apache.hadoop.mapreduce.filecache.DistributedCache' signature='(Lorg/apache/hadoop/conf/Configuration;)[Lorg/apache/hadoop/fs/Path;' name='getArchiveClassPaths' primary='true'><SourceLine endBytecode='204' classname='org.apache.hadoop.mapreduce.filecache.DistributedCache' start='436' end='445' sourcepath='org/apache/hadoop/mapreduce/filecache/DistributedCache.java' sourcefile='DistributedCache.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapreduce.filecache.DistributedCache.getArchiveClassPaths(Configuration)</Message></Method><SourceLine endBytecode='18' classname='org.apache.hadoop.mapreduce.filecache.DistributedCache' start='439' end='439' sourcepath='org/apache/hadoop/mapreduce/filecache/DistributedCache.java' sourcefile='DistributedCache.java' startBytecode='18' primary='true'><Message>At DistributedCache.java:[line 439]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='f03cb6cedc6a86250db2c3619919982b' rank='20' abbrev='PZLA' category='STYLE' priority='3' type='PZLA_PREFER_ZERO_LENGTH_ARRAYS' instanceOccurrenceMax='0'><ShortMessage>Consider returning a zero length array rather than null</ShortMessage><LongMessage>Should org.apache.hadoop.mapreduce.filecache.DistributedCache.getFileClassPaths(Configuration) return a zero length array rather than null?</LongMessage><Class classname='org.apache.hadoop.mapreduce.filecache.DistributedCache' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.filecache.DistributedCache' start='135' end='547' sourcepath='org/apache/hadoop/mapreduce/filecache/DistributedCache.java' sourcefile='DistributedCache.java'><Message>At DistributedCache.java:[lines 135-547]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.filecache.DistributedCache</Message></Class><Method isStatic='true' classname='org.apache.hadoop.mapreduce.filecache.DistributedCache' signature='(Lorg/apache/hadoop/conf/Configuration;)[Lorg/apache/hadoop/fs/Path;' name='getFileClassPaths' primary='true'><SourceLine endBytecode='204' classname='org.apache.hadoop.mapreduce.filecache.DistributedCache' start='380' end='389' sourcepath='org/apache/hadoop/mapreduce/filecache/DistributedCache.java' sourcefile='DistributedCache.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapreduce.filecache.DistributedCache.getFileClassPaths(Configuration)</Message></Method><SourceLine endBytecode='18' classname='org.apache.hadoop.mapreduce.filecache.DistributedCache' start='383' end='383' sourcepath='org/apache/hadoop/mapreduce/filecache/DistributedCache.java' sourcefile='DistributedCache.java' startBytecode='18' primary='true'><Message>At DistributedCache.java:[line 383]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='8ed1fafe124e6a94d49bb870402f271f' rank='20' abbrev='PZLA' category='STYLE' priority='3' type='PZLA_PREFER_ZERO_LENGTH_ARRAYS' instanceOccurrenceMax='0'><ShortMessage>Consider returning a zero length array rather than null</ShortMessage><LongMessage>Should org.apache.hadoop.mapreduce.filecache.DistributedCache.parseBooleans(String[]) return a zero length array rather than null?</LongMessage><Class classname='org.apache.hadoop.mapreduce.filecache.DistributedCache' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.filecache.DistributedCache' start='135' end='547' sourcepath='org/apache/hadoop/mapreduce/filecache/DistributedCache.java' sourcefile='DistributedCache.java'><Message>At DistributedCache.java:[lines 135-547]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.filecache.DistributedCache</Message></Class><Method isStatic='true' classname='org.apache.hadoop.mapreduce.filecache.DistributedCache' signature='([Ljava/lang/String;)[Z' name='parseBooleans' primary='true'><SourceLine endBytecode='141' classname='org.apache.hadoop.mapreduce.filecache.DistributedCache' start='472' end='479' sourcepath='org/apache/hadoop/mapreduce/filecache/DistributedCache.java' sourcefile='DistributedCache.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapreduce.filecache.DistributedCache.parseBooleans(String[])</Message></Method><SourceLine endBytecode='6' classname='org.apache.hadoop.mapreduce.filecache.DistributedCache' start='473' end='473' sourcepath='org/apache/hadoop/mapreduce/filecache/DistributedCache.java' sourcefile='DistributedCache.java' startBytecode='6' primary='true'><Message>At DistributedCache.java:[line 473]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='f198a0d025f2909cb46b76b52946910c' rank='20' abbrev='PZLA' category='STYLE' priority='3' type='PZLA_PREFER_ZERO_LENGTH_ARRAYS' instanceOccurrenceMax='0'><ShortMessage>Consider returning a zero length array rather than null</ShortMessage><LongMessage>Should org.apache.hadoop.mapreduce.filecache.DistributedCache.parseTimestamps(String[]) return a zero length array rather than null?</LongMessage><Class classname='org.apache.hadoop.mapreduce.filecache.DistributedCache' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.filecache.DistributedCache' start='135' end='547' sourcepath='org/apache/hadoop/mapreduce/filecache/DistributedCache.java' sourcefile='DistributedCache.java'><Message>At DistributedCache.java:[lines 135-547]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.filecache.DistributedCache</Message></Class><Method isStatic='true' classname='org.apache.hadoop.mapreduce.filecache.DistributedCache' signature='([Ljava/lang/String;)[J' name='parseTimestamps' primary='true'><SourceLine endBytecode='140' classname='org.apache.hadoop.mapreduce.filecache.DistributedCache' start='231' end='238' sourcepath='org/apache/hadoop/mapreduce/filecache/DistributedCache.java' sourcefile='DistributedCache.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapreduce.filecache.DistributedCache.parseTimestamps(String[])</Message></Method><SourceLine endBytecode='5' classname='org.apache.hadoop.mapreduce.filecache.DistributedCache' start='232' end='232' sourcepath='org/apache/hadoop/mapreduce/filecache/DistributedCache.java' sourcefile='DistributedCache.java' startBytecode='5' primary='true'><Message>At DistributedCache.java:[line 232]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='160a33786c64c0e45f2f2dbf10fd36a9' rank='20' abbrev='RI' category='STYLE' priority='3' type='RI_REDUNDANT_INTERFACES' instanceOccurrenceMax='0'><ShortMessage>Class implements same interface as superclass</ShortMessage><LongMessage>Class org.apache.hadoop.mapreduce.jobhistory.AMStarted implements same interface as superclass</LongMessage><Class classname='org.apache.hadoop.mapreduce.jobhistory.AMStarted' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.jobhistory.AMStarted' start='10' end='167' sourcepath='org/apache/hadoop/mapreduce/jobhistory/AMStarted.java' sourcefile='AMStarted.java'><Message>At AMStarted.java:[lines 10-167]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.jobhistory.AMStarted</Message></Class><Class role='INTERFACE_TYPE' classname='org.apache.avro.specific.SpecificRecord'><SourceLine classname='org.apache.avro.specific.SpecificRecord' sourcepath='org/apache/avro/specific/SpecificRecord.java' sourcefile='SpecificRecord.java'><Message>In SpecificRecord.java</Message></SourceLine><Message>Interface org.apache.avro.specific.SpecificRecord</Message></Class><SourceLine synthetic='true' classname='org.apache.hadoop.mapreduce.jobhistory.AMStarted' start='10' end='167' sourcepath='org/apache/hadoop/mapreduce/jobhistory/AMStarted.java' sourcefile='AMStarted.java'><Message>At AMStarted.java:[lines 10-167]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='38384d7009a31dcf0482162bf0dfb052' rank='20' abbrev='RI' category='STYLE' priority='3' type='RI_REDUNDANT_INTERFACES' instanceOccurrenceMax='0'><ShortMessage>Class implements same interface as superclass</ShortMessage><LongMessage>Class org.apache.hadoop.mapreduce.jobhistory.AMStarted$Builder implements same interface as superclass</LongMessage><Class classname='org.apache.hadoop.mapreduce.jobhistory.AMStarted$Builder' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.jobhistory.AMStarted$Builder' start='173' end='405' sourcepath='org/apache/hadoop/mapreduce/jobhistory/AMStarted.java' sourcefile='AMStarted.java'><Message>At AMStarted.java:[lines 173-405]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.jobhistory.AMStarted$Builder</Message></Class><Class role='INTERFACE_TYPE' classname='org.apache.avro.data.RecordBuilder'><SourceLine classname='org.apache.avro.data.RecordBuilder' sourcepath='org/apache/avro/data/RecordBuilder.java' sourcefile='RecordBuilder.java'><Message>In RecordBuilder.java</Message></SourceLine><Message>Interface org.apache.avro.data.RecordBuilder</Message></Class><SourceLine synthetic='true' classname='org.apache.hadoop.mapreduce.jobhistory.AMStarted$Builder' start='173' end='405' sourcepath='org/apache/hadoop/mapreduce/jobhistory/AMStarted.java' sourcefile='AMStarted.java'><Message>At AMStarted.java:[lines 173-405]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='71d9fe8d7ff14b78a03f930b400abda4' cweid='218' rank='20' abbrev='MS' category='MALICIOUS_CODE' priority='3' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.mapreduce.jobhistory.AvroArrayUtils.NULL_PROGRESS_SPLITS_ARRAY isn't final but should be</LongMessage><Class classname='org.apache.hadoop.mapreduce.jobhistory.AvroArrayUtils' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.jobhistory.AvroArrayUtils' start='28' end='56' sourcepath='org/apache/hadoop/mapreduce/jobhistory/AvroArrayUtils.java' sourcefile='AvroArrayUtils.java'><Message>At AvroArrayUtils.java:[lines 28-56]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.jobhistory.AvroArrayUtils</Message></Class><Field isStatic='true' classname='org.apache.hadoop.mapreduce.jobhistory.AvroArrayUtils' signature='Ljava/util/List;' name='NULL_PROGRESS_SPLITS_ARRAY' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.jobhistory.AvroArrayUtils' sourcepath='org/apache/hadoop/mapreduce/jobhistory/AvroArrayUtils.java' sourcefile='AvroArrayUtils.java'><Message>In AvroArrayUtils.java</Message></SourceLine><Message>Field org.apache.hadoop.mapreduce.jobhistory.AvroArrayUtils.NULL_PROGRESS_SPLITS_ARRAY</Message></Field><SourceLine endBytecode='23' classname='org.apache.hadoop.mapreduce.jobhistory.AvroArrayUtils' start='33' end='33' sourcepath='org/apache/hadoop/mapreduce/jobhistory/AvroArrayUtils.java' sourcefile='AvroArrayUtils.java' startBytecode='23' primary='true'><Message>At AvroArrayUtils.java:[line 33]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='f01d36940846a9e8d7ae6ad5bacacd81' rank='20' abbrev='UrF' category='STYLE' priority='3' type='URF_UNREAD_PUBLIC_OR_PROTECTED_FIELD' instanceOccurrenceMax='0'><ShortMessage>Unread public/protected field</ShortMessage><LongMessage>Unread public/protected field: org.apache.hadoop.mapreduce.jobhistory.AvroArrayUtils.NULL_PROGRESS_SPLITS_ARRAY</LongMessage><Class classname='org.apache.hadoop.mapreduce.jobhistory.AvroArrayUtils' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.jobhistory.AvroArrayUtils' start='28' end='56' sourcepath='org/apache/hadoop/mapreduce/jobhistory/AvroArrayUtils.java' sourcefile='AvroArrayUtils.java'><Message>At AvroArrayUtils.java:[lines 28-56]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.jobhistory.AvroArrayUtils</Message></Class><Field isStatic='true' classname='org.apache.hadoop.mapreduce.jobhistory.AvroArrayUtils' signature='Ljava/util/List;' name='NULL_PROGRESS_SPLITS_ARRAY' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.jobhistory.AvroArrayUtils' sourcepath='org/apache/hadoop/mapreduce/jobhistory/AvroArrayUtils.java' sourcefile='AvroArrayUtils.java'><Message>In AvroArrayUtils.java</Message></SourceLine><Message>Field org.apache.hadoop.mapreduce.jobhistory.AvroArrayUtils.NULL_PROGRESS_SPLITS_ARRAY</Message></Field><SourceLine endBytecode='23' classname='org.apache.hadoop.mapreduce.jobhistory.AvroArrayUtils' start='33' end='33' sourcepath='org/apache/hadoop/mapreduce/jobhistory/AvroArrayUtils.java' sourcefile='AvroArrayUtils.java' startBytecode='23' primary='true'><Message>At AvroArrayUtils.java:[line 33]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='1264dba3391e3b9bd7d74dbfad87cc3b' rank='20' abbrev='RI' category='STYLE' priority='3' type='RI_REDUNDANT_INTERFACES' instanceOccurrenceMax='0'><ShortMessage>Class implements same interface as superclass</ShortMessage><LongMessage>Class org.apache.hadoop.mapreduce.jobhistory.Event implements same interface as superclass</LongMessage><Class classname='org.apache.hadoop.mapreduce.jobhistory.Event' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.jobhistory.Event' start='10' end='91' sourcepath='org/apache/hadoop/mapreduce/jobhistory/Event.java' sourcefile='Event.java'><Message>At Event.java:[lines 10-91]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.jobhistory.Event</Message></Class><Class role='INTERFACE_TYPE' classname='org.apache.avro.specific.SpecificRecord'><SourceLine classname='org.apache.avro.specific.SpecificRecord' sourcepath='org/apache/avro/specific/SpecificRecord.java' sourcefile='SpecificRecord.java'><Message>In SpecificRecord.java</Message></SourceLine><Message>Interface org.apache.avro.specific.SpecificRecord</Message></Class><SourceLine synthetic='true' classname='org.apache.hadoop.mapreduce.jobhistory.Event' start='10' end='91' sourcepath='org/apache/hadoop/mapreduce/jobhistory/Event.java' sourcefile='Event.java'><Message>At Event.java:[lines 10-91]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='333f5f3c82aee315a113c1d4d4eb59b4' rank='20' abbrev='RI' category='STYLE' priority='3' type='RI_REDUNDANT_INTERFACES' instanceOccurrenceMax='0'><ShortMessage>Class implements same interface as superclass</ShortMessage><LongMessage>Class org.apache.hadoop.mapreduce.jobhistory.Event$Builder implements same interface as superclass</LongMessage><Class classname='org.apache.hadoop.mapreduce.jobhistory.Event$Builder' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.jobhistory.Event$Builder' start='97' end='192' sourcepath='org/apache/hadoop/mapreduce/jobhistory/Event.java' sourcefile='Event.java'><Message>At Event.java:[lines 97-192]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.jobhistory.Event$Builder</Message></Class><Class role='INTERFACE_TYPE' classname='org.apache.avro.data.RecordBuilder'><SourceLine classname='org.apache.avro.data.RecordBuilder' sourcepath='org/apache/avro/data/RecordBuilder.java' sourcefile='RecordBuilder.java'><Message>In RecordBuilder.java</Message></SourceLine><Message>Interface org.apache.avro.data.RecordBuilder</Message></Class><SourceLine synthetic='true' classname='org.apache.hadoop.mapreduce.jobhistory.Event$Builder' start='97' end='192' sourcepath='org/apache/hadoop/mapreduce/jobhistory/Event.java' sourcefile='Event.java'><Message>At Event.java:[lines 97-192]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='3f5f76cf3db329538b76b79724f01c53' cweid='374' rank='18' abbrev='EI' category='MALICIOUS_CODE' priority='2' type='EI_EXPOSE_REP' instanceOccurrenceMax='0'><ShortMessage>May expose internal representation by returning reference to mutable object</ShortMessage><LongMessage>org.apache.hadoop.mapreduce.jobhistory.HistoryViewer$AnalyzedJob.getMapTasks() may expose internal representation by returning HistoryViewer$AnalyzedJob.mapTasks</LongMessage><Class classname='org.apache.hadoop.mapreduce.jobhistory.HistoryViewer$AnalyzedJob' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.jobhistory.HistoryViewer$AnalyzedJob' start='314' end='370' sourcepath='org/apache/hadoop/mapreduce/jobhistory/HistoryViewer.java' sourcefile='HistoryViewer.java'><Message>At HistoryViewer.java:[lines 314-370]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.jobhistory.HistoryViewer$AnalyzedJob</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapreduce.jobhistory.HistoryViewer$AnalyzedJob' signature='()[Lorg/apache/hadoop/mapreduce/jobhistory/JobHistoryParser$TaskAttemptInfo;' name='getMapTasks' primary='true'><SourceLine endBytecode='46' classname='org.apache.hadoop.mapreduce.jobhistory.HistoryViewer$AnalyzedJob' start='321' end='321' sourcepath='org/apache/hadoop/mapreduce/jobhistory/HistoryViewer.java' sourcefile='HistoryViewer.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapreduce.jobhistory.HistoryViewer$AnalyzedJob.getMapTasks()</Message></Method><Field isStatic='false' classname='org.apache.hadoop.mapreduce.jobhistory.HistoryViewer$AnalyzedJob' signature='[Lorg/apache/hadoop/mapreduce/jobhistory/JobHistoryParser$TaskAttemptInfo;' name='mapTasks' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.jobhistory.HistoryViewer$AnalyzedJob' sourcepath='org/apache/hadoop/mapreduce/jobhistory/HistoryViewer.java' sourcefile='HistoryViewer.java'><Message>In HistoryViewer.java</Message></SourceLine><Message>Field org.apache.hadoop.mapreduce.jobhistory.HistoryViewer$AnalyzedJob.mapTasks</Message></Field><SourceLine endBytecode='4' classname='org.apache.hadoop.mapreduce.jobhistory.HistoryViewer$AnalyzedJob' start='321' end='321' sourcepath='org/apache/hadoop/mapreduce/jobhistory/HistoryViewer.java' sourcefile='HistoryViewer.java' startBytecode='4' primary='true'><Message>At HistoryViewer.java:[line 321]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='a259149a259a5b0df8e6e10880593596' cweid='374' rank='18' abbrev='EI' category='MALICIOUS_CODE' priority='2' type='EI_EXPOSE_REP' instanceOccurrenceMax='0'><ShortMessage>May expose internal representation by returning reference to mutable object</ShortMessage><LongMessage>org.apache.hadoop.mapreduce.jobhistory.HistoryViewer$AnalyzedJob.getReduceTasks() may expose internal representation by returning HistoryViewer$AnalyzedJob.reduceTasks</LongMessage><Class classname='org.apache.hadoop.mapreduce.jobhistory.HistoryViewer$AnalyzedJob' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.jobhistory.HistoryViewer$AnalyzedJob' start='314' end='370' sourcepath='org/apache/hadoop/mapreduce/jobhistory/HistoryViewer.java' sourcefile='HistoryViewer.java'><Message>At HistoryViewer.java:[lines 314-370]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.jobhistory.HistoryViewer$AnalyzedJob</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapreduce.jobhistory.HistoryViewer$AnalyzedJob' signature='()[Lorg/apache/hadoop/mapreduce/jobhistory/JobHistoryParser$TaskAttemptInfo;' name='getReduceTasks' primary='true'><SourceLine endBytecode='46' classname='org.apache.hadoop.mapreduce.jobhistory.HistoryViewer$AnalyzedJob' start='325' end='325' sourcepath='org/apache/hadoop/mapreduce/jobhistory/HistoryViewer.java' sourcefile='HistoryViewer.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapreduce.jobhistory.HistoryViewer$AnalyzedJob.getReduceTasks()</Message></Method><Field isStatic='false' classname='org.apache.hadoop.mapreduce.jobhistory.HistoryViewer$AnalyzedJob' signature='[Lorg/apache/hadoop/mapreduce/jobhistory/JobHistoryParser$TaskAttemptInfo;' name='reduceTasks' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.jobhistory.HistoryViewer$AnalyzedJob' sourcepath='org/apache/hadoop/mapreduce/jobhistory/HistoryViewer.java' sourcefile='HistoryViewer.java'><Message>In HistoryViewer.java</Message></SourceLine><Message>Field org.apache.hadoop.mapreduce.jobhistory.HistoryViewer$AnalyzedJob.reduceTasks</Message></Field><SourceLine endBytecode='4' classname='org.apache.hadoop.mapreduce.jobhistory.HistoryViewer$AnalyzedJob' start='325' end='325' sourcepath='org/apache/hadoop/mapreduce/jobhistory/HistoryViewer.java' sourcefile='HistoryViewer.java' startBytecode='4' primary='true'><Message>At HistoryViewer.java:[line 325]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='8df52014638bfa0ab4fe91c7a85f647a' cweid='476' rank='20' abbrev='RCN' category='STYLE' priority='3' type='RCN_REDUNDANT_NULLCHECK_OF_NONNULL_VALUE' instanceOccurrenceMax='0'><ShortMessage>Redundant nullcheck of value known to be non-null</ShortMessage><LongMessage>Redundant nullcheck of taskList, which is known to be non-null in org.apache.hadoop.mapreduce.jobhistory.HumanReadableHistoryViewerPrinter.printTasks(PrintStream, TaskType, String)</LongMessage><Class classname='org.apache.hadoop.mapreduce.jobhistory.HumanReadableHistoryViewerPrinter' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.jobhistory.HumanReadableHistoryViewerPrinter' start='58' end='461' sourcepath='org/apache/hadoop/mapreduce/jobhistory/HumanReadableHistoryViewerPrinter.java' sourcefile='HumanReadableHistoryViewerPrinter.java'><Message>At HumanReadableHistoryViewerPrinter.java:[lines 58-461]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.jobhistory.HumanReadableHistoryViewerPrinter</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapreduce.jobhistory.HumanReadableHistoryViewerPrinter' signature='(Ljava/io/PrintStream;Lorg/apache/hadoop/mapreduce/TaskType;Ljava/lang/String;)V' name='printTasks' primary='true'><SourceLine endBytecode='594' classname='org.apache.hadoop.mapreduce.jobhistory.HumanReadableHistoryViewerPrinter' start='364' end='396' sourcepath='org/apache/hadoop/mapreduce/jobhistory/HumanReadableHistoryViewerPrinter.java' sourcefile='HumanReadableHistoryViewerPrinter.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapreduce.jobhistory.HumanReadableHistoryViewerPrinter.printTasks(PrintStream, TaskType, String)</Message></Method><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='283' name='taskList' register='6'><Message>Value loaded from taskList</Message></LocalVariable><Method isStatic='false' role='METHOD_RETURN_VALUE_OF' classname='java.lang.StringBuilder' signature='()V' name='&lt;init&gt;'><SourceLine endBytecode='34' classname='java.lang.StringBuilder' start='89' end='90' sourcepath='java/lang/StringBuilder.java' sourcefile='StringBuilder.java' startBytecode='0'></SourceLine><Message>Return value of new StringBuilder() of type void</Message></Method><SourceLine role='SOURCE_REDUNDANT_NULL_CHECK' endBytecode='285' classname='org.apache.hadoop.mapreduce.jobhistory.HumanReadableHistoryViewerPrinter' start='390' end='390' sourcepath='org/apache/hadoop/mapreduce/jobhistory/HumanReadableHistoryViewerPrinter.java' sourcefile='HumanReadableHistoryViewerPrinter.java' startBytecode='285' primary='true'><Message>Redundant null check at HumanReadableHistoryViewerPrinter.java:[line 390]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='326752882ff048f9489667574f6af5f7' rank='20' abbrev='RI' category='STYLE' priority='3' type='RI_REDUNDANT_INTERFACES' instanceOccurrenceMax='0'><ShortMessage>Class implements same interface as superclass</ShortMessage><LongMessage>Class org.apache.hadoop.mapreduce.jobhistory.JhCounter implements same interface as superclass</LongMessage><Class classname='org.apache.hadoop.mapreduce.jobhistory.JhCounter' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.jobhistory.JhCounter' start='10' end='110' sourcepath='org/apache/hadoop/mapreduce/jobhistory/JhCounter.java' sourcefile='JhCounter.java'><Message>At JhCounter.java:[lines 10-110]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.jobhistory.JhCounter</Message></Class><Class role='INTERFACE_TYPE' classname='org.apache.avro.specific.SpecificRecord'><SourceLine classname='org.apache.avro.specific.SpecificRecord' sourcepath='org/apache/avro/specific/SpecificRecord.java' sourcefile='SpecificRecord.java'><Message>In SpecificRecord.java</Message></SourceLine><Message>Interface org.apache.avro.specific.SpecificRecord</Message></Class><SourceLine synthetic='true' classname='org.apache.hadoop.mapreduce.jobhistory.JhCounter' start='10' end='110' sourcepath='org/apache/hadoop/mapreduce/jobhistory/JhCounter.java' sourcefile='JhCounter.java'><Message>At JhCounter.java:[lines 10-110]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='71e2ad1d81c9b00a7d1dd6d0a81b97f1' rank='20' abbrev='RI' category='STYLE' priority='3' type='RI_REDUNDANT_INTERFACES' instanceOccurrenceMax='0'><ShortMessage>Class implements same interface as superclass</ShortMessage><LongMessage>Class org.apache.hadoop.mapreduce.jobhistory.JhCounter$Builder implements same interface as superclass</LongMessage><Class classname='org.apache.hadoop.mapreduce.jobhistory.JhCounter$Builder' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.jobhistory.JhCounter$Builder' start='116' end='245' sourcepath='org/apache/hadoop/mapreduce/jobhistory/JhCounter.java' sourcefile='JhCounter.java'><Message>At JhCounter.java:[lines 116-245]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.jobhistory.JhCounter$Builder</Message></Class><Class role='INTERFACE_TYPE' classname='org.apache.avro.data.RecordBuilder'><SourceLine classname='org.apache.avro.data.RecordBuilder' sourcepath='org/apache/avro/data/RecordBuilder.java' sourcefile='RecordBuilder.java'><Message>In RecordBuilder.java</Message></SourceLine><Message>Interface org.apache.avro.data.RecordBuilder</Message></Class><SourceLine synthetic='true' classname='org.apache.hadoop.mapreduce.jobhistory.JhCounter$Builder' start='116' end='245' sourcepath='org/apache/hadoop/mapreduce/jobhistory/JhCounter.java' sourcefile='JhCounter.java'><Message>At JhCounter.java:[lines 116-245]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='7a629c17cee48834a5afea0dd9cdc075' rank='20' abbrev='RI' category='STYLE' priority='3' type='RI_REDUNDANT_INTERFACES' instanceOccurrenceMax='0'><ShortMessage>Class implements same interface as superclass</ShortMessage><LongMessage>Class org.apache.hadoop.mapreduce.jobhistory.JhCounterGroup implements same interface as superclass</LongMessage><Class classname='org.apache.hadoop.mapreduce.jobhistory.JhCounterGroup' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.jobhistory.JhCounterGroup' start='10' end='110' sourcepath='org/apache/hadoop/mapreduce/jobhistory/JhCounterGroup.java' sourcefile='JhCounterGroup.java'><Message>At JhCounterGroup.java:[lines 10-110]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.jobhistory.JhCounterGroup</Message></Class><Class role='INTERFACE_TYPE' classname='org.apache.avro.specific.SpecificRecord'><SourceLine classname='org.apache.avro.specific.SpecificRecord' sourcepath='org/apache/avro/specific/SpecificRecord.java' sourcefile='SpecificRecord.java'><Message>In SpecificRecord.java</Message></SourceLine><Message>Interface org.apache.avro.specific.SpecificRecord</Message></Class><SourceLine synthetic='true' classname='org.apache.hadoop.mapreduce.jobhistory.JhCounterGroup' start='10' end='110' sourcepath='org/apache/hadoop/mapreduce/jobhistory/JhCounterGroup.java' sourcefile='JhCounterGroup.java'><Message>At JhCounterGroup.java:[lines 10-110]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='ab6d2caa88b76d86cf7a335f32b6ec28' rank='20' abbrev='RI' category='STYLE' priority='3' type='RI_REDUNDANT_INTERFACES' instanceOccurrenceMax='0'><ShortMessage>Class implements same interface as superclass</ShortMessage><LongMessage>Class org.apache.hadoop.mapreduce.jobhistory.JhCounterGroup$Builder implements same interface as superclass</LongMessage><Class classname='org.apache.hadoop.mapreduce.jobhistory.JhCounterGroup$Builder' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.jobhistory.JhCounterGroup$Builder' start='116' end='246' sourcepath='org/apache/hadoop/mapreduce/jobhistory/JhCounterGroup.java' sourcefile='JhCounterGroup.java'><Message>At JhCounterGroup.java:[lines 116-246]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.jobhistory.JhCounterGroup$Builder</Message></Class><Class role='INTERFACE_TYPE' classname='org.apache.avro.data.RecordBuilder'><SourceLine classname='org.apache.avro.data.RecordBuilder' sourcepath='org/apache/avro/data/RecordBuilder.java' sourcefile='RecordBuilder.java'><Message>In RecordBuilder.java</Message></SourceLine><Message>Interface org.apache.avro.data.RecordBuilder</Message></Class><SourceLine synthetic='true' classname='org.apache.hadoop.mapreduce.jobhistory.JhCounterGroup$Builder' start='116' end='246' sourcepath='org/apache/hadoop/mapreduce/jobhistory/JhCounterGroup.java' sourcefile='JhCounterGroup.java'><Message>At JhCounterGroup.java:[lines 116-246]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='5ea4a3aea55cc9afff1d36fb4b3a1a37' rank='20' abbrev='RI' category='STYLE' priority='3' type='RI_REDUNDANT_INTERFACES' instanceOccurrenceMax='0'><ShortMessage>Class implements same interface as superclass</ShortMessage><LongMessage>Class org.apache.hadoop.mapreduce.jobhistory.JhCounters implements same interface as superclass</LongMessage><Class classname='org.apache.hadoop.mapreduce.jobhistory.JhCounters' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.jobhistory.JhCounters' start='10' end='91' sourcepath='org/apache/hadoop/mapreduce/jobhistory/JhCounters.java' sourcefile='JhCounters.java'><Message>At JhCounters.java:[lines 10-91]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.jobhistory.JhCounters</Message></Class><Class role='INTERFACE_TYPE' classname='org.apache.avro.specific.SpecificRecord'><SourceLine classname='org.apache.avro.specific.SpecificRecord' sourcepath='org/apache/avro/specific/SpecificRecord.java' sourcefile='SpecificRecord.java'><Message>In SpecificRecord.java</Message></SourceLine><Message>Interface org.apache.avro.specific.SpecificRecord</Message></Class><SourceLine synthetic='true' classname='org.apache.hadoop.mapreduce.jobhistory.JhCounters' start='10' end='91' sourcepath='org/apache/hadoop/mapreduce/jobhistory/JhCounters.java' sourcefile='JhCounters.java'><Message>At JhCounters.java:[lines 10-91]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='def24c0f69374caff96c835ad3229286' rank='20' abbrev='RI' category='STYLE' priority='3' type='RI_REDUNDANT_INTERFACES' instanceOccurrenceMax='0'><ShortMessage>Class implements same interface as superclass</ShortMessage><LongMessage>Class org.apache.hadoop.mapreduce.jobhistory.JhCounters$Builder implements same interface as superclass</LongMessage><Class classname='org.apache.hadoop.mapreduce.jobhistory.JhCounters$Builder' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.jobhistory.JhCounters$Builder' start='97' end='192' sourcepath='org/apache/hadoop/mapreduce/jobhistory/JhCounters.java' sourcefile='JhCounters.java'><Message>At JhCounters.java:[lines 97-192]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.jobhistory.JhCounters$Builder</Message></Class><Class role='INTERFACE_TYPE' classname='org.apache.avro.data.RecordBuilder'><SourceLine classname='org.apache.avro.data.RecordBuilder' sourcepath='org/apache/avro/data/RecordBuilder.java' sourcefile='RecordBuilder.java'><Message>In RecordBuilder.java</Message></SourceLine><Message>Interface org.apache.avro.data.RecordBuilder</Message></Class><SourceLine synthetic='true' classname='org.apache.hadoop.mapreduce.jobhistory.JhCounters$Builder' start='97' end='192' sourcepath='org/apache/hadoop/mapreduce/jobhistory/JhCounters.java' sourcefile='JhCounters.java'><Message>At JhCounters.java:[lines 97-192]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='3438c3a2c453f40de3f12129a18a6295' rank='20' abbrev='RI' category='STYLE' priority='3' type='RI_REDUNDANT_INTERFACES' instanceOccurrenceMax='0'><ShortMessage>Class implements same interface as superclass</ShortMessage><LongMessage>Class org.apache.hadoop.mapreduce.jobhistory.JobFinished implements same interface as superclass</LongMessage><Class classname='org.apache.hadoop.mapreduce.jobhistory.JobFinished' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.jobhistory.JobFinished' start='10' end='262' sourcepath='org/apache/hadoop/mapreduce/jobhistory/JobFinished.java' sourcefile='JobFinished.java'><Message>At JobFinished.java:[lines 10-262]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.jobhistory.JobFinished</Message></Class><Class role='INTERFACE_TYPE' classname='org.apache.avro.specific.SpecificRecord'><SourceLine classname='org.apache.avro.specific.SpecificRecord' sourcepath='org/apache/avro/specific/SpecificRecord.java' sourcefile='SpecificRecord.java'><Message>In SpecificRecord.java</Message></SourceLine><Message>Interface org.apache.avro.specific.SpecificRecord</Message></Class><SourceLine synthetic='true' classname='org.apache.hadoop.mapreduce.jobhistory.JobFinished' start='10' end='262' sourcepath='org/apache/hadoop/mapreduce/jobhistory/JobFinished.java' sourcefile='JobFinished.java'><Message>At JobFinished.java:[lines 10-262]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='2682a74386d51f7db6c8421dbeff5657' cweid='396' rank='20' abbrev='REC' category='STYLE' priority='3' type='REC_CATCH_EXCEPTION' instanceOccurrenceMax='0'><ShortMessage>Exception is caught when Exception is not thrown</ShortMessage><LongMessage>Exception is caught when Exception is not thrown in org.apache.hadoop.mapreduce.jobhistory.JobFinished$Builder.build()</LongMessage><Class classname='org.apache.hadoop.mapreduce.jobhistory.JobFinished$Builder' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.jobhistory.JobFinished$Builder' start='268' end='671' sourcepath='org/apache/hadoop/mapreduce/jobhistory/JobFinished.java' sourcefile='JobFinished.java'><Message>At JobFinished.java:[lines 268-671]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.jobhistory.JobFinished$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapreduce.jobhistory.JobFinished$Builder' signature='()Lorg/apache/hadoop/mapreduce/jobhistory/JobFinished;' name='build' primary='true'><SourceLine endBytecode='811' classname='org.apache.hadoop.mapreduce.jobhistory.JobFinished$Builder' start='657' end='671' sourcepath='org/apache/hadoop/mapreduce/jobhistory/JobFinished.java' sourcefile='JobFinished.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapreduce.jobhistory.JobFinished$Builder.build()</Message></Method><SourceLine endBytecode='404' classname='org.apache.hadoop.mapreduce.jobhistory.JobFinished$Builder' start='670' end='670' sourcepath='org/apache/hadoop/mapreduce/jobhistory/JobFinished.java' sourcefile='JobFinished.java' startBytecode='404' primary='true'><Message>At JobFinished.java:[line 670]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='a45349456239032a33601c3711aba2e2' rank='20' abbrev='RI' category='STYLE' priority='3' type='RI_REDUNDANT_INTERFACES' instanceOccurrenceMax='0'><ShortMessage>Class implements same interface as superclass</ShortMessage><LongMessage>Class org.apache.hadoop.mapreduce.jobhistory.JobFinished$Builder implements same interface as superclass</LongMessage><Class classname='org.apache.hadoop.mapreduce.jobhistory.JobFinished$Builder' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.jobhistory.JobFinished$Builder' start='268' end='671' sourcepath='org/apache/hadoop/mapreduce/jobhistory/JobFinished.java' sourcefile='JobFinished.java'><Message>At JobFinished.java:[lines 268-671]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.jobhistory.JobFinished$Builder</Message></Class><Class role='INTERFACE_TYPE' classname='org.apache.avro.data.RecordBuilder'><SourceLine classname='org.apache.avro.data.RecordBuilder' sourcepath='org/apache/avro/data/RecordBuilder.java' sourcefile='RecordBuilder.java'><Message>In RecordBuilder.java</Message></SourceLine><Message>Interface org.apache.avro.data.RecordBuilder</Message></Class><SourceLine synthetic='true' classname='org.apache.hadoop.mapreduce.jobhistory.JobFinished$Builder' start='268' end='671' sourcepath='org/apache/hadoop/mapreduce/jobhistory/JobFinished.java' sourcefile='JobFinished.java'><Message>At JobFinished.java:[lines 268-671]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='ed4477a56cd61dbb2546688bb5a37a49' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from org.apache.hadoop.mapreduce.jobhistory.HistoryEvent to org.apache.hadoop.mapreduce.jobhistory.AMStartedEvent in org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser.handleEvent(HistoryEvent)</LongMessage><Class classname='org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser' start='59' end='447' sourcepath='org/apache/hadoop/mapreduce/jobhistory/JobHistoryParser.java' sourcefile='JobHistoryParser.java'><Message>At JobHistoryParser.java:[lines 59-447]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser' signature='(Lorg/apache/hadoop/mapreduce/jobhistory/HistoryEvent;)V' name='handleEvent' primary='true'><SourceLine endBytecode='94' classname='org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser' start='170' end='243' sourcepath='org/apache/hadoop/mapreduce/jobhistory/JobHistoryParser.java' sourcefile='JobHistoryParser.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser.handleEvent(HistoryEvent)</Message></Method><Type role='TYPE_FOUND' descriptor='Lorg/apache/hadoop/mapreduce/jobhistory/HistoryEvent;'><SourceLine classname='org.apache.hadoop.mapreduce.jobhistory.HistoryEvent' sourcepath='org/apache/hadoop/mapreduce/jobhistory/HistoryEvent.java' sourcefile='HistoryEvent.java'><Message>In HistoryEvent.java</Message></SourceLine><Message>Actual type org.apache.hadoop.mapreduce.jobhistory.HistoryEvent</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/mapreduce/jobhistory/AMStartedEvent;'><SourceLine classname='org.apache.hadoop.mapreduce.jobhistory.AMStartedEvent' start='40' end='191' sourcepath='org/apache/hadoop/mapreduce/jobhistory/AMStartedEvent.java' sourcefile='AMStartedEvent.java'><Message>At AMStartedEvent.java:[lines 40-191]</Message></SourceLine><Message>Expected org.apache.hadoop.mapreduce.jobhistory.AMStartedEvent</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='332' name='event' register='1'><Message>Value loaded from event</Message></LocalVariable><SourceLine endBytecode='333' classname='org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser' start='238' end='238' sourcepath='org/apache/hadoop/mapreduce/jobhistory/JobHistoryParser.java' sourcefile='JobHistoryParser.java' startBytecode='333' primary='true'><Message>At JobHistoryParser.java:[line 238]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='800daa23a908c82a883e1bfc25831d57' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from org.apache.hadoop.mapreduce.jobhistory.HistoryEvent to org.apache.hadoop.mapreduce.jobhistory.JobFinishedEvent in org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser.handleEvent(HistoryEvent)</LongMessage><Class classname='org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser' start='59' end='447' sourcepath='org/apache/hadoop/mapreduce/jobhistory/JobHistoryParser.java' sourcefile='JobHistoryParser.java'><Message>At JobHistoryParser.java:[lines 59-447]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser' signature='(Lorg/apache/hadoop/mapreduce/jobhistory/HistoryEvent;)V' name='handleEvent' primary='true'><SourceLine endBytecode='94' classname='org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser' start='170' end='243' sourcepath='org/apache/hadoop/mapreduce/jobhistory/JobHistoryParser.java' sourcefile='JobHistoryParser.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser.handleEvent(HistoryEvent)</Message></Method><Type role='TYPE_FOUND' descriptor='Lorg/apache/hadoop/mapreduce/jobhistory/HistoryEvent;'><SourceLine classname='org.apache.hadoop.mapreduce.jobhistory.HistoryEvent' sourcepath='org/apache/hadoop/mapreduce/jobhistory/HistoryEvent.java' sourcefile='HistoryEvent.java'><Message>In HistoryEvent.java</Message></SourceLine><Message>Actual type org.apache.hadoop.mapreduce.jobhistory.HistoryEvent</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/mapreduce/jobhistory/JobFinishedEvent;'><SourceLine classname='org.apache.hadoop.mapreduce.jobhistory.JobFinishedEvent' start='41' end='186' sourcepath='org/apache/hadoop/mapreduce/jobhistory/JobFinishedEvent.java' sourcefile='JobFinishedEvent.java'><Message>At JobFinishedEvent.java:[lines 41-186]</Message></SourceLine><Message>Expected org.apache.hadoop.mapreduce.jobhistory.JobFinishedEvent</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='222' name='event' register='1'><Message>Value loaded from event</Message></LocalVariable><SourceLine endBytecode='223' classname='org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser' start='196' end='196' sourcepath='org/apache/hadoop/mapreduce/jobhistory/JobHistoryParser.java' sourcefile='JobHistoryParser.java' startBytecode='223' primary='true'><Message>At JobHistoryParser.java:[line 196]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='ced99fbd15bee98dace07cd73d608fa9' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from org.apache.hadoop.mapreduce.jobhistory.HistoryEvent to org.apache.hadoop.mapreduce.jobhistory.JobInfoChangeEvent in org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser.handleEvent(HistoryEvent)</LongMessage><Class classname='org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser' start='59' end='447' sourcepath='org/apache/hadoop/mapreduce/jobhistory/JobHistoryParser.java' sourcefile='JobHistoryParser.java'><Message>At JobHistoryParser.java:[lines 59-447]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser' signature='(Lorg/apache/hadoop/mapreduce/jobhistory/HistoryEvent;)V' name='handleEvent' primary='true'><SourceLine endBytecode='94' classname='org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser' start='170' end='243' sourcepath='org/apache/hadoop/mapreduce/jobhistory/JobHistoryParser.java' sourcefile='JobHistoryParser.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser.handleEvent(HistoryEvent)</Message></Method><Type role='TYPE_FOUND' descriptor='Lorg/apache/hadoop/mapreduce/jobhistory/HistoryEvent;'><SourceLine classname='org.apache.hadoop.mapreduce.jobhistory.HistoryEvent' sourcepath='org/apache/hadoop/mapreduce/jobhistory/HistoryEvent.java' sourcefile='HistoryEvent.java'><Message>In HistoryEvent.java</Message></SourceLine><Message>Actual type org.apache.hadoop.mapreduce.jobhistory.HistoryEvent</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/mapreduce/jobhistory/JobInfoChangeEvent;'><SourceLine classname='org.apache.hadoop.mapreduce.jobhistory.JobInfoChangeEvent' start='38' end='81' sourcepath='org/apache/hadoop/mapreduce/jobhistory/JobInfoChangeEvent.java' sourcefile='JobInfoChangeEvent.java'><Message>At JobInfoChangeEvent.java:[lines 38-81]</Message></SourceLine><Message>Expected org.apache.hadoop.mapreduce.jobhistory.JobInfoChangeEvent</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='167' name='event' register='1'><Message>Value loaded from event</Message></LocalVariable><SourceLine endBytecode='168' classname='org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser' start='179' end='179' sourcepath='org/apache/hadoop/mapreduce/jobhistory/JobHistoryParser.java' sourcefile='JobHistoryParser.java' startBytecode='168' primary='true'><Message>At JobHistoryParser.java:[line 179]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='99d435793bf7d26c85f11f8e95f6596f' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from org.apache.hadoop.mapreduce.jobhistory.HistoryEvent to org.apache.hadoop.mapreduce.jobhistory.JobInitedEvent in org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser.handleEvent(HistoryEvent)</LongMessage><Class classname='org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser' start='59' end='447' sourcepath='org/apache/hadoop/mapreduce/jobhistory/JobHistoryParser.java' sourcefile='JobHistoryParser.java'><Message>At JobHistoryParser.java:[lines 59-447]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser' signature='(Lorg/apache/hadoop/mapreduce/jobhistory/HistoryEvent;)V' name='handleEvent' primary='true'><SourceLine endBytecode='94' classname='org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser' start='170' end='243' sourcepath='org/apache/hadoop/mapreduce/jobhistory/JobHistoryParser.java' sourcefile='JobHistoryParser.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser.handleEvent(HistoryEvent)</Message></Method><Type role='TYPE_FOUND' descriptor='Lorg/apache/hadoop/mapreduce/jobhistory/HistoryEvent;'><SourceLine classname='org.apache.hadoop.mapreduce.jobhistory.HistoryEvent' sourcepath='org/apache/hadoop/mapreduce/jobhistory/HistoryEvent.java' sourcefile='HistoryEvent.java'><Message>In HistoryEvent.java</Message></SourceLine><Message>Actual type org.apache.hadoop.mapreduce.jobhistory.HistoryEvent</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/mapreduce/jobhistory/JobInitedEvent;'><SourceLine classname='org.apache.hadoop.mapreduce.jobhistory.JobInitedEvent' start='38' end='95' sourcepath='org/apache/hadoop/mapreduce/jobhistory/JobInitedEvent.java' sourcefile='JobInitedEvent.java'><Message>At JobInitedEvent.java:[lines 38-95]</Message></SourceLine><Message>Expected org.apache.hadoop.mapreduce.jobhistory.JobInitedEvent</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='178' name='event' register='1'><Message>Value loaded from event</Message></LocalVariable><SourceLine endBytecode='179' classname='org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser' start='182' end='182' sourcepath='org/apache/hadoop/mapreduce/jobhistory/JobHistoryParser.java' sourcefile='JobHistoryParser.java' startBytecode='179' primary='true'><Message>At JobHistoryParser.java:[line 182]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='98805cd7d3bca12fb4e600ad36b3c1d6' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from org.apache.hadoop.mapreduce.jobhistory.HistoryEvent to org.apache.hadoop.mapreduce.jobhistory.JobPriorityChangeEvent in org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser.handleEvent(HistoryEvent)</LongMessage><Class classname='org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser' start='59' end='447' sourcepath='org/apache/hadoop/mapreduce/jobhistory/JobHistoryParser.java' sourcefile='JobHistoryParser.java'><Message>At JobHistoryParser.java:[lines 59-447]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser' signature='(Lorg/apache/hadoop/mapreduce/jobhistory/HistoryEvent;)V' name='handleEvent' primary='true'><SourceLine endBytecode='94' classname='org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser' start='170' end='243' sourcepath='org/apache/hadoop/mapreduce/jobhistory/JobHistoryParser.java' sourcefile='JobHistoryParser.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser.handleEvent(HistoryEvent)</Message></Method><Type role='TYPE_FOUND' descriptor='Lorg/apache/hadoop/mapreduce/jobhistory/HistoryEvent;'><SourceLine classname='org.apache.hadoop.mapreduce.jobhistory.HistoryEvent' sourcepath='org/apache/hadoop/mapreduce/jobhistory/HistoryEvent.java' sourcefile='HistoryEvent.java'><Message>In HistoryEvent.java</Message></SourceLine><Message>Actual type org.apache.hadoop.mapreduce.jobhistory.HistoryEvent</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/mapreduce/jobhistory/JobPriorityChangeEvent;'><SourceLine classname='org.apache.hadoop.mapreduce.jobhistory.JobPriorityChangeEvent' start='39' end='80' sourcepath='org/apache/hadoop/mapreduce/jobhistory/JobPriorityChangeEvent.java' sourcefile='JobPriorityChangeEvent.java'><Message>At JobPriorityChangeEvent.java:[lines 39-80]</Message></SourceLine><Message>Expected org.apache.hadoop.mapreduce.jobhistory.JobPriorityChangeEvent</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='189' name='event' register='1'><Message>Value loaded from event</Message></LocalVariable><SourceLine endBytecode='190' classname='org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser' start='185' end='185' sourcepath='org/apache/hadoop/mapreduce/jobhistory/JobHistoryParser.java' sourcefile='JobHistoryParser.java' startBytecode='190' primary='true'><Message>At JobHistoryParser.java:[line 185]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='55bbe4c177659684d16adfaf968b1990' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from org.apache.hadoop.mapreduce.jobhistory.HistoryEvent to org.apache.hadoop.mapreduce.jobhistory.JobQueueChangeEvent in org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser.handleEvent(HistoryEvent)</LongMessage><Class classname='org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser' start='59' end='447' sourcepath='org/apache/hadoop/mapreduce/jobhistory/JobHistoryParser.java' sourcefile='JobHistoryParser.java'><Message>At JobHistoryParser.java:[lines 59-447]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser' signature='(Lorg/apache/hadoop/mapreduce/jobhistory/HistoryEvent;)V' name='handleEvent' primary='true'><SourceLine endBytecode='94' classname='org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser' start='170' end='243' sourcepath='org/apache/hadoop/mapreduce/jobhistory/JobHistoryParser.java' sourcefile='JobHistoryParser.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser.handleEvent(HistoryEvent)</Message></Method><Type role='TYPE_FOUND' descriptor='Lorg/apache/hadoop/mapreduce/jobhistory/HistoryEvent;'><SourceLine classname='org.apache.hadoop.mapreduce.jobhistory.HistoryEvent' sourcepath='org/apache/hadoop/mapreduce/jobhistory/HistoryEvent.java' sourcefile='HistoryEvent.java'><Message>In HistoryEvent.java</Message></SourceLine><Message>Actual type org.apache.hadoop.mapreduce.jobhistory.HistoryEvent</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/mapreduce/jobhistory/JobQueueChangeEvent;'><SourceLine classname='org.apache.hadoop.mapreduce.jobhistory.JobQueueChangeEvent' start='31' end='78' sourcepath='org/apache/hadoop/mapreduce/jobhistory/JobQueueChangeEvent.java' sourcefile='JobQueueChangeEvent.java'><Message>At JobQueueChangeEvent.java:[lines 31-78]</Message></SourceLine><Message>Expected org.apache.hadoop.mapreduce.jobhistory.JobQueueChangeEvent</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='200' name='event' register='1'><Message>Value loaded from event</Message></LocalVariable><SourceLine endBytecode='201' classname='org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser' start='188' end='188' sourcepath='org/apache/hadoop/mapreduce/jobhistory/JobHistoryParser.java' sourcefile='JobHistoryParser.java' startBytecode='201' primary='true'><Message>At JobHistoryParser.java:[line 188]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='c625199c3fc2006d379675eb0e8bc55f' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from org.apache.hadoop.mapreduce.jobhistory.HistoryEvent to org.apache.hadoop.mapreduce.jobhistory.JobSubmittedEvent in org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser.handleEvent(HistoryEvent)</LongMessage><Class classname='org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser' start='59' end='447' sourcepath='org/apache/hadoop/mapreduce/jobhistory/JobHistoryParser.java' sourcefile='JobHistoryParser.java'><Message>At JobHistoryParser.java:[lines 59-447]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser' signature='(Lorg/apache/hadoop/mapreduce/jobhistory/HistoryEvent;)V' name='handleEvent' primary='true'><SourceLine endBytecode='94' classname='org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser' start='170' end='243' sourcepath='org/apache/hadoop/mapreduce/jobhistory/JobHistoryParser.java' sourcefile='JobHistoryParser.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser.handleEvent(HistoryEvent)</Message></Method><Type role='TYPE_FOUND' descriptor='Lorg/apache/hadoop/mapreduce/jobhistory/HistoryEvent;'><SourceLine classname='org.apache.hadoop.mapreduce.jobhistory.HistoryEvent' sourcepath='org/apache/hadoop/mapreduce/jobhistory/HistoryEvent.java' sourcefile='HistoryEvent.java'><Message>In HistoryEvent.java</Message></SourceLine><Message>Actual type org.apache.hadoop.mapreduce.jobhistory.HistoryEvent</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/mapreduce/jobhistory/JobSubmittedEvent;'><SourceLine classname='org.apache.hadoop.mapreduce.jobhistory.JobSubmittedEvent' start='44' end='268' sourcepath='org/apache/hadoop/mapreduce/jobhistory/JobSubmittedEvent.java' sourcefile='JobSubmittedEvent.java'><Message>At JobSubmittedEvent.java:[lines 44-268]</Message></SourceLine><Message>Expected org.apache.hadoop.mapreduce.jobhistory.JobSubmittedEvent</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='153' name='event' register='1'><Message>Value loaded from event</Message></LocalVariable><SourceLine endBytecode='154' classname='org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser' start='174' end='174' sourcepath='org/apache/hadoop/mapreduce/jobhistory/JobHistoryParser.java' sourcefile='JobHistoryParser.java' startBytecode='154' primary='true'><Message>At JobHistoryParser.java:[line 174]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='406e2c6c9fb48940c9ae0436c63eaacd' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from org.apache.hadoop.mapreduce.jobhistory.HistoryEvent to org.apache.hadoop.mapreduce.jobhistory.JobUnsuccessfulCompletionEvent in org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser.handleEvent(HistoryEvent)</LongMessage><Class classname='org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser' start='59' end='447' sourcepath='org/apache/hadoop/mapreduce/jobhistory/JobHistoryParser.java' sourcefile='JobHistoryParser.java'><Message>At JobHistoryParser.java:[lines 59-447]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser' signature='(Lorg/apache/hadoop/mapreduce/jobhistory/HistoryEvent;)V' name='handleEvent' primary='true'><SourceLine endBytecode='94' classname='org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser' start='170' end='243' sourcepath='org/apache/hadoop/mapreduce/jobhistory/JobHistoryParser.java' sourcefile='JobHistoryParser.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser.handleEvent(HistoryEvent)</Message></Method><Type role='TYPE_FOUND' descriptor='Lorg/apache/hadoop/mapreduce/jobhistory/HistoryEvent;'><SourceLine classname='org.apache.hadoop.mapreduce.jobhistory.HistoryEvent' sourcepath='org/apache/hadoop/mapreduce/jobhistory/HistoryEvent.java' sourcefile='HistoryEvent.java'><Message>In HistoryEvent.java</Message></SourceLine><Message>Actual type org.apache.hadoop.mapreduce.jobhistory.HistoryEvent</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/mapreduce/jobhistory/JobUnsuccessfulCompletionEvent;'><SourceLine classname='org.apache.hadoop.mapreduce.jobhistory.JobUnsuccessfulCompletionEvent' start='42' end='183' sourcepath='org/apache/hadoop/mapreduce/jobhistory/JobUnsuccessfulCompletionEvent.java' sourcefile='JobUnsuccessfulCompletionEvent.java'><Message>At JobUnsuccessfulCompletionEvent.java:[lines 42-183]</Message></SourceLine><Message>Expected org.apache.hadoop.mapreduce.jobhistory.JobUnsuccessfulCompletionEvent</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='211' name='event' register='1'><Message>Value loaded from event</Message></LocalVariable><SourceLine endBytecode='212' classname='org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser' start='193' end='193' sourcepath='org/apache/hadoop/mapreduce/jobhistory/JobHistoryParser.java' sourcefile='JobHistoryParser.java' startBytecode='212' primary='true'><Message>At JobHistoryParser.java:[line 193]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='44c7e36f29d6dbdeb11eeaea1523bb09' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from org.apache.hadoop.mapreduce.jobhistory.HistoryEvent to org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinishedEvent in org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser.handleEvent(HistoryEvent)</LongMessage><Class classname='org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser' start='59' end='447' sourcepath='org/apache/hadoop/mapreduce/jobhistory/JobHistoryParser.java' sourcefile='JobHistoryParser.java'><Message>At JobHistoryParser.java:[lines 59-447]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser' signature='(Lorg/apache/hadoop/mapreduce/jobhistory/HistoryEvent;)V' name='handleEvent' primary='true'><SourceLine endBytecode='94' classname='org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser' start='170' end='243' sourcepath='org/apache/hadoop/mapreduce/jobhistory/JobHistoryParser.java' sourcefile='JobHistoryParser.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser.handleEvent(HistoryEvent)</Message></Method><Type role='TYPE_FOUND' descriptor='Lorg/apache/hadoop/mapreduce/jobhistory/HistoryEvent;'><SourceLine classname='org.apache.hadoop.mapreduce.jobhistory.HistoryEvent' sourcepath='org/apache/hadoop/mapreduce/jobhistory/HistoryEvent.java' sourcefile='HistoryEvent.java'><Message>In HistoryEvent.java</Message></SourceLine><Message>Actual type org.apache.hadoop.mapreduce.jobhistory.HistoryEvent</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/mapreduce/jobhistory/MapAttemptFinishedEvent;'><SourceLine classname='org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinishedEvent' start='45' end='277' sourcepath='org/apache/hadoop/mapreduce/jobhistory/MapAttemptFinishedEvent.java' sourcefile='MapAttemptFinishedEvent.java'><Message>At MapAttemptFinishedEvent.java:[lines 45-277]</Message></SourceLine><Message>Expected org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinishedEvent</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='299' name='event' register='1'><Message>Value loaded from event</Message></LocalVariable><SourceLine endBytecode='300' classname='org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser' start='228' end='228' sourcepath='org/apache/hadoop/mapreduce/jobhistory/JobHistoryParser.java' sourcefile='JobHistoryParser.java' startBytecode='300' primary='true'><Message>At JobHistoryParser.java:[line 228]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='dfe71f33af0def93c85e5e2c500211c8' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from org.apache.hadoop.mapreduce.jobhistory.HistoryEvent to org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinishedEvent in org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser.handleEvent(HistoryEvent)</LongMessage><Class classname='org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser' start='59' end='447' sourcepath='org/apache/hadoop/mapreduce/jobhistory/JobHistoryParser.java' sourcefile='JobHistoryParser.java'><Message>At JobHistoryParser.java:[lines 59-447]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser' signature='(Lorg/apache/hadoop/mapreduce/jobhistory/HistoryEvent;)V' name='handleEvent' primary='true'><SourceLine endBytecode='94' classname='org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser' start='170' end='243' sourcepath='org/apache/hadoop/mapreduce/jobhistory/JobHistoryParser.java' sourcefile='JobHistoryParser.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser.handleEvent(HistoryEvent)</Message></Method><Type role='TYPE_FOUND' descriptor='Lorg/apache/hadoop/mapreduce/jobhistory/HistoryEvent;'><SourceLine classname='org.apache.hadoop.mapreduce.jobhistory.HistoryEvent' sourcepath='org/apache/hadoop/mapreduce/jobhistory/HistoryEvent.java' sourcefile='HistoryEvent.java'><Message>In HistoryEvent.java</Message></SourceLine><Message>Actual type org.apache.hadoop.mapreduce.jobhistory.HistoryEvent</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/mapreduce/jobhistory/ReduceAttemptFinishedEvent;'><SourceLine classname='org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinishedEvent' start='45' end='281' sourcepath='org/apache/hadoop/mapreduce/jobhistory/ReduceAttemptFinishedEvent.java' sourcefile='ReduceAttemptFinishedEvent.java'><Message>At ReduceAttemptFinishedEvent.java:[lines 45-281]</Message></SourceLine><Message>Expected org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinishedEvent</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='310' name='event' register='1'><Message>Value loaded from event</Message></LocalVariable><SourceLine endBytecode='311' classname='org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser' start='231' end='231' sourcepath='org/apache/hadoop/mapreduce/jobhistory/JobHistoryParser.java' sourcefile='JobHistoryParser.java' startBytecode='311' primary='true'><Message>At JobHistoryParser.java:[line 231]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='8bab3e33df52688a19db942da2e0e2d6' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from org.apache.hadoop.mapreduce.jobhistory.HistoryEvent to org.apache.hadoop.mapreduce.jobhistory.TaskAttemptFinishedEvent in org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser.handleEvent(HistoryEvent)</LongMessage><Class classname='org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser' start='59' end='447' sourcepath='org/apache/hadoop/mapreduce/jobhistory/JobHistoryParser.java' sourcefile='JobHistoryParser.java'><Message>At JobHistoryParser.java:[lines 59-447]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser' signature='(Lorg/apache/hadoop/mapreduce/jobhistory/HistoryEvent;)V' name='handleEvent' primary='true'><SourceLine endBytecode='94' classname='org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser' start='170' end='243' sourcepath='org/apache/hadoop/mapreduce/jobhistory/JobHistoryParser.java' sourcefile='JobHistoryParser.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser.handleEvent(HistoryEvent)</Message></Method><Type role='TYPE_FOUND' descriptor='Lorg/apache/hadoop/mapreduce/jobhistory/HistoryEvent;'><SourceLine classname='org.apache.hadoop.mapreduce.jobhistory.HistoryEvent' sourcepath='org/apache/hadoop/mapreduce/jobhistory/HistoryEvent.java' sourcefile='HistoryEvent.java'><Message>In HistoryEvent.java</Message></SourceLine><Message>Actual type org.apache.hadoop.mapreduce.jobhistory.HistoryEvent</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/mapreduce/jobhistory/TaskAttemptFinishedEvent;'><SourceLine classname='org.apache.hadoop.mapreduce.jobhistory.TaskAttemptFinishedEvent' start='44' end='184' sourcepath='org/apache/hadoop/mapreduce/jobhistory/TaskAttemptFinishedEvent.java' sourcefile='TaskAttemptFinishedEvent.java'><Message>At TaskAttemptFinishedEvent.java:[lines 44-184]</Message></SourceLine><Message>Expected org.apache.hadoop.mapreduce.jobhistory.TaskAttemptFinishedEvent</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='321' name='event' register='1'><Message>Value loaded from event</Message></LocalVariable><SourceLine endBytecode='322' classname='org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser' start='235' end='235' sourcepath='org/apache/hadoop/mapreduce/jobhistory/JobHistoryParser.java' sourcefile='JobHistoryParser.java' startBytecode='322' primary='true'><Message>At JobHistoryParser.java:[line 235]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='f760aebac10671e9b465c8caaf05a369' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from org.apache.hadoop.mapreduce.jobhistory.HistoryEvent to org.apache.hadoop.mapreduce.jobhistory.TaskAttemptStartedEvent in org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser.handleEvent(HistoryEvent)</LongMessage><Class classname='org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser' start='59' end='447' sourcepath='org/apache/hadoop/mapreduce/jobhistory/JobHistoryParser.java' sourcefile='JobHistoryParser.java'><Message>At JobHistoryParser.java:[lines 59-447]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser' signature='(Lorg/apache/hadoop/mapreduce/jobhistory/HistoryEvent;)V' name='handleEvent' primary='true'><SourceLine endBytecode='94' classname='org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser' start='170' end='243' sourcepath='org/apache/hadoop/mapreduce/jobhistory/JobHistoryParser.java' sourcefile='JobHistoryParser.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser.handleEvent(HistoryEvent)</Message></Method><Type role='TYPE_FOUND' descriptor='Lorg/apache/hadoop/mapreduce/jobhistory/HistoryEvent;'><SourceLine classname='org.apache.hadoop.mapreduce.jobhistory.HistoryEvent' sourcepath='org/apache/hadoop/mapreduce/jobhistory/HistoryEvent.java' sourcefile='HistoryEvent.java'><Message>In HistoryEvent.java</Message></SourceLine><Message>Actual type org.apache.hadoop.mapreduce.jobhistory.HistoryEvent</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/mapreduce/jobhistory/TaskAttemptStartedEvent;'><SourceLine classname='org.apache.hadoop.mapreduce.jobhistory.TaskAttemptStartedEvent' start='42' end='158' sourcepath='org/apache/hadoop/mapreduce/jobhistory/TaskAttemptStartedEvent.java' sourcefile='TaskAttemptStartedEvent.java'><Message>At TaskAttemptStartedEvent.java:[lines 42-158]</Message></SourceLine><Message>Expected org.apache.hadoop.mapreduce.jobhistory.TaskAttemptStartedEvent</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='277' name='event' register='1'><Message>Value loaded from event</Message></LocalVariable><SourceLine endBytecode='278' classname='org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser' start='214' end='214' sourcepath='org/apache/hadoop/mapreduce/jobhistory/JobHistoryParser.java' sourcefile='JobHistoryParser.java' startBytecode='278' primary='true'><Message>At JobHistoryParser.java:[line 214]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='f5903e55b4416374cbdaa32b3555c6ca' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from org.apache.hadoop.mapreduce.jobhistory.HistoryEvent to org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletionEvent in org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser.handleEvent(HistoryEvent)</LongMessage><Class classname='org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser' start='59' end='447' sourcepath='org/apache/hadoop/mapreduce/jobhistory/JobHistoryParser.java' sourcefile='JobHistoryParser.java'><Message>At JobHistoryParser.java:[lines 59-447]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser' signature='(Lorg/apache/hadoop/mapreduce/jobhistory/HistoryEvent;)V' name='handleEvent' primary='true'><SourceLine endBytecode='94' classname='org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser' start='170' end='243' sourcepath='org/apache/hadoop/mapreduce/jobhistory/JobHistoryParser.java' sourcefile='JobHistoryParser.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser.handleEvent(HistoryEvent)</Message></Method><Type role='TYPE_FOUND' descriptor='Lorg/apache/hadoop/mapreduce/jobhistory/HistoryEvent;'><SourceLine classname='org.apache.hadoop.mapreduce.jobhistory.HistoryEvent' sourcepath='org/apache/hadoop/mapreduce/jobhistory/HistoryEvent.java' sourcefile='HistoryEvent.java'><Message>In HistoryEvent.java</Message></SourceLine><Message>Actual type org.apache.hadoop.mapreduce.jobhistory.HistoryEvent</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/mapreduce/jobhistory/TaskAttemptUnsuccessfulCompletionEvent;'><SourceLine classname='org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletionEvent' start='46' end='300' sourcepath='org/apache/hadoop/mapreduce/jobhistory/TaskAttemptUnsuccessfulCompletionEvent.java' sourcefile='TaskAttemptUnsuccessfulCompletionEvent.java'><Message>At TaskAttemptUnsuccessfulCompletionEvent.java:[lines 46-300]</Message></SourceLine><Message>Expected org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletionEvent</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='288' name='event' register='1'><Message>Value loaded from event</Message></LocalVariable><SourceLine endBytecode='289' classname='org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser' start='224' end='224' sourcepath='org/apache/hadoop/mapreduce/jobhistory/JobHistoryParser.java' sourcefile='JobHistoryParser.java' startBytecode='289' primary='true'><Message>At JobHistoryParser.java:[line 224]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='4742a639d6c1db29b1a37ba1a8a1aa8' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from org.apache.hadoop.mapreduce.jobhistory.HistoryEvent to org.apache.hadoop.mapreduce.jobhistory.TaskFailedEvent in org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser.handleEvent(HistoryEvent)</LongMessage><Class classname='org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser' start='59' end='447' sourcepath='org/apache/hadoop/mapreduce/jobhistory/JobHistoryParser.java' sourcefile='JobHistoryParser.java'><Message>At JobHistoryParser.java:[lines 59-447]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser' signature='(Lorg/apache/hadoop/mapreduce/jobhistory/HistoryEvent;)V' name='handleEvent' primary='true'><SourceLine endBytecode='94' classname='org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser' start='170' end='243' sourcepath='org/apache/hadoop/mapreduce/jobhistory/JobHistoryParser.java' sourcefile='JobHistoryParser.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser.handleEvent(HistoryEvent)</Message></Method><Type role='TYPE_FOUND' descriptor='Lorg/apache/hadoop/mapreduce/jobhistory/HistoryEvent;'><SourceLine classname='org.apache.hadoop.mapreduce.jobhistory.HistoryEvent' sourcepath='org/apache/hadoop/mapreduce/jobhistory/HistoryEvent.java' sourcefile='HistoryEvent.java'><Message>In HistoryEvent.java</Message></SourceLine><Message>Actual type org.apache.hadoop.mapreduce.jobhistory.HistoryEvent</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/mapreduce/jobhistory/TaskFailedEvent;'><SourceLine classname='org.apache.hadoop.mapreduce.jobhistory.TaskFailedEvent' start='44' end='184' sourcepath='org/apache/hadoop/mapreduce/jobhistory/TaskFailedEvent.java' sourcefile='TaskFailedEvent.java'><Message>At TaskFailedEvent.java:[lines 44-184]</Message></SourceLine><Message>Expected org.apache.hadoop.mapreduce.jobhistory.TaskFailedEvent</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='244' name='event' register='1'><Message>Value loaded from event</Message></LocalVariable><SourceLine endBytecode='245' classname='org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser' start='202' end='202' sourcepath='org/apache/hadoop/mapreduce/jobhistory/JobHistoryParser.java' sourcefile='JobHistoryParser.java' startBytecode='245' primary='true'><Message>At JobHistoryParser.java:[line 202]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='2aac6ed4a3fe84c84adaabd7d0df263a' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from org.apache.hadoop.mapreduce.jobhistory.HistoryEvent to org.apache.hadoop.mapreduce.jobhistory.TaskFinishedEvent in org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser.handleEvent(HistoryEvent)</LongMessage><Class classname='org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser' start='59' end='447' sourcepath='org/apache/hadoop/mapreduce/jobhistory/JobHistoryParser.java' sourcefile='JobHistoryParser.java'><Message>At JobHistoryParser.java:[lines 59-447]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser' signature='(Lorg/apache/hadoop/mapreduce/jobhistory/HistoryEvent;)V' name='handleEvent' primary='true'><SourceLine endBytecode='94' classname='org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser' start='170' end='243' sourcepath='org/apache/hadoop/mapreduce/jobhistory/JobHistoryParser.java' sourcefile='JobHistoryParser.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser.handleEvent(HistoryEvent)</Message></Method><Type role='TYPE_FOUND' descriptor='Lorg/apache/hadoop/mapreduce/jobhistory/HistoryEvent;'><SourceLine classname='org.apache.hadoop.mapreduce.jobhistory.HistoryEvent' sourcepath='org/apache/hadoop/mapreduce/jobhistory/HistoryEvent.java' sourcefile='HistoryEvent.java'><Message>In HistoryEvent.java</Message></SourceLine><Message>Actual type org.apache.hadoop.mapreduce.jobhistory.HistoryEvent</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/mapreduce/jobhistory/TaskFinishedEvent;'><SourceLine classname='org.apache.hadoop.mapreduce.jobhistory.TaskFinishedEvent' start='45' end='162' sourcepath='org/apache/hadoop/mapreduce/jobhistory/TaskFinishedEvent.java' sourcefile='TaskFinishedEvent.java'><Message>At TaskFinishedEvent.java:[lines 45-162]</Message></SourceLine><Message>Expected org.apache.hadoop.mapreduce.jobhistory.TaskFinishedEvent</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='266' name='event' register='1'><Message>Value loaded from event</Message></LocalVariable><SourceLine endBytecode='267' classname='org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser' start='208' end='208' sourcepath='org/apache/hadoop/mapreduce/jobhistory/JobHistoryParser.java' sourcefile='JobHistoryParser.java' startBytecode='267' primary='true'><Message>At JobHistoryParser.java:[line 208]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='d4a4e728e290865ef77afa6fa4c1567d' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from org.apache.hadoop.mapreduce.jobhistory.HistoryEvent to org.apache.hadoop.mapreduce.jobhistory.TaskStartedEvent in org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser.handleEvent(HistoryEvent)</LongMessage><Class classname='org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser' start='59' end='447' sourcepath='org/apache/hadoop/mapreduce/jobhistory/JobHistoryParser.java' sourcefile='JobHistoryParser.java'><Message>At JobHistoryParser.java:[lines 59-447]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser' signature='(Lorg/apache/hadoop/mapreduce/jobhistory/HistoryEvent;)V' name='handleEvent' primary='true'><SourceLine endBytecode='94' classname='org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser' start='170' end='243' sourcepath='org/apache/hadoop/mapreduce/jobhistory/JobHistoryParser.java' sourcefile='JobHistoryParser.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser.handleEvent(HistoryEvent)</Message></Method><Type role='TYPE_FOUND' descriptor='Lorg/apache/hadoop/mapreduce/jobhistory/HistoryEvent;'><SourceLine classname='org.apache.hadoop.mapreduce.jobhistory.HistoryEvent' sourcepath='org/apache/hadoop/mapreduce/jobhistory/HistoryEvent.java' sourcefile='HistoryEvent.java'><Message>In HistoryEvent.java</Message></SourceLine><Message>Actual type org.apache.hadoop.mapreduce.jobhistory.HistoryEvent</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/mapreduce/jobhistory/TaskStartedEvent;'><SourceLine classname='org.apache.hadoop.mapreduce.jobhistory.TaskStartedEvent' start='39' end='92' sourcepath='org/apache/hadoop/mapreduce/jobhistory/TaskStartedEvent.java' sourcefile='TaskStartedEvent.java'><Message>At TaskStartedEvent.java:[lines 39-92]</Message></SourceLine><Message>Expected org.apache.hadoop.mapreduce.jobhistory.TaskStartedEvent</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='233' name='event' register='1'><Message>Value loaded from event</Message></LocalVariable><SourceLine endBytecode='234' classname='org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser' start='199' end='199' sourcepath='org/apache/hadoop/mapreduce/jobhistory/JobHistoryParser.java' sourcefile='JobHistoryParser.java' startBytecode='234' primary='true'><Message>At JobHistoryParser.java:[line 199]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='511c26f704c0cc1d3151c1556c9bb782' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from org.apache.hadoop.mapreduce.jobhistory.HistoryEvent to org.apache.hadoop.mapreduce.jobhistory.TaskUpdatedEvent in org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser.handleEvent(HistoryEvent)</LongMessage><Class classname='org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser' start='59' end='447' sourcepath='org/apache/hadoop/mapreduce/jobhistory/JobHistoryParser.java' sourcefile='JobHistoryParser.java'><Message>At JobHistoryParser.java:[lines 59-447]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser' signature='(Lorg/apache/hadoop/mapreduce/jobhistory/HistoryEvent;)V' name='handleEvent' primary='true'><SourceLine endBytecode='94' classname='org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser' start='170' end='243' sourcepath='org/apache/hadoop/mapreduce/jobhistory/JobHistoryParser.java' sourcefile='JobHistoryParser.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser.handleEvent(HistoryEvent)</Message></Method><Type role='TYPE_FOUND' descriptor='Lorg/apache/hadoop/mapreduce/jobhistory/HistoryEvent;'><SourceLine classname='org.apache.hadoop.mapreduce.jobhistory.HistoryEvent' sourcepath='org/apache/hadoop/mapreduce/jobhistory/HistoryEvent.java' sourcefile='HistoryEvent.java'><Message>In HistoryEvent.java</Message></SourceLine><Message>Actual type org.apache.hadoop.mapreduce.jobhistory.HistoryEvent</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/mapreduce/jobhistory/TaskUpdatedEvent;'><SourceLine classname='org.apache.hadoop.mapreduce.jobhistory.TaskUpdatedEvent' start='38' end='76' sourcepath='org/apache/hadoop/mapreduce/jobhistory/TaskUpdatedEvent.java' sourcefile='TaskUpdatedEvent.java'><Message>At TaskUpdatedEvent.java:[lines 38-76]</Message></SourceLine><Message>Expected org.apache.hadoop.mapreduce.jobhistory.TaskUpdatedEvent</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='255' name='event' register='1'><Message>Value loaded from event</Message></LocalVariable><SourceLine endBytecode='256' classname='org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser' start='205' end='205' sourcepath='org/apache/hadoop/mapreduce/jobhistory/JobHistoryParser.java' sourcefile='JobHistoryParser.java' startBytecode='256' primary='true'><Message>At JobHistoryParser.java:[line 205]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='3ec551e7bc8d14a526e5d18cd1164874' rank='19' abbrev='Nm' category='BAD_PRACTICE' priority='3' type='NM_CONFUSING' instanceOccurrenceMax='0'><ShortMessage>Confusing method names</ShortMessage><LongMessage>Confusing to have methods org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser$TaskAttemptInfo.getHostname() and org.apache.hadoop.mapreduce.task.reduce.MapHost.getHostName()</LongMessage><Class classname='org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser$TaskAttemptInfo' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser$TaskAttemptInfo' start='676' end='739' sourcepath='org/apache/hadoop/mapreduce/jobhistory/JobHistoryParser.java' sourcefile='JobHistoryParser.java'><Message>At JobHistoryParser.java:[lines 676-739]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser$TaskAttemptInfo</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser$TaskAttemptInfo' signature='()Ljava/lang/String;' name='getHostname' primary='true'><SourceLine endBytecode='46' classname='org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser$TaskAttemptInfo' start='727' end='727' sourcepath='org/apache/hadoop/mapreduce/jobhistory/JobHistoryParser.java' sourcefile='JobHistoryParser.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser$TaskAttemptInfo.getHostname()</Message></Method><Class classname='org.apache.hadoop.mapreduce.task.reduce.MapHost'><SourceLine classname='org.apache.hadoop.mapreduce.task.reduce.MapHost' start='39' end='105' sourcepath='org/apache/hadoop/mapreduce/task/reduce/MapHost.java' sourcefile='MapHost.java'><Message>At MapHost.java:[lines 39-105]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.task.reduce.MapHost</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapreduce.task.reduce.MapHost' signature='()Ljava/lang/String;' name='getHostName'><SourceLine endBytecode='46' classname='org.apache.hadoop.mapreduce.task.reduce.MapHost' start='54' end='54' sourcepath='org/apache/hadoop/mapreduce/task/reduce/MapHost.java' sourcefile='MapHost.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapreduce.task.reduce.MapHost.getHostName()</Message></Method><SourceLine synthetic='true' endBytecode='46' classname='org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser$TaskAttemptInfo' start='727' end='727' sourcepath='org/apache/hadoop/mapreduce/jobhistory/JobHistoryParser.java' sourcefile='JobHistoryParser.java' startBytecode='0'><Message>At JobHistoryParser.java:[line 727]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='913d63d54b40a9c2fbe931d8d3792bba' rank='19' abbrev='Nm' category='BAD_PRACTICE' priority='3' type='NM_CONFUSING' instanceOccurrenceMax='0'><ShortMessage>Confusing method names</ShortMessage><LongMessage>Confusing to have methods org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser$TaskAttemptInfo.getRackname() and org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinishedEvent.getRackName()</LongMessage><Class classname='org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser$TaskAttemptInfo' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser$TaskAttemptInfo' start='676' end='739' sourcepath='org/apache/hadoop/mapreduce/jobhistory/JobHistoryParser.java' sourcefile='JobHistoryParser.java'><Message>At JobHistoryParser.java:[lines 676-739]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser$TaskAttemptInfo</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser$TaskAttemptInfo' signature='()Ljava/lang/String;' name='getRackname' primary='true'><SourceLine endBytecode='46' classname='org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser$TaskAttemptInfo' start='731' end='731' sourcepath='org/apache/hadoop/mapreduce/jobhistory/JobHistoryParser.java' sourcefile='JobHistoryParser.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser$TaskAttemptInfo.getRackname()</Message></Method><Class classname='org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinishedEvent'><SourceLine classname='org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinishedEvent' start='45' end='277' sourcepath='org/apache/hadoop/mapreduce/jobhistory/MapAttemptFinishedEvent.java' sourcefile='MapAttemptFinishedEvent.java'><Message>At MapAttemptFinishedEvent.java:[lines 45-277]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinishedEvent</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinishedEvent' signature='()Ljava/lang/String;' name='getRackName'><SourceLine endBytecode='73' classname='org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinishedEvent' start='222' end='222' sourcepath='org/apache/hadoop/mapreduce/jobhistory/MapAttemptFinishedEvent.java' sourcefile='MapAttemptFinishedEvent.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinishedEvent.getRackName()</Message></Method><SourceLine synthetic='true' endBytecode='46' classname='org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser$TaskAttemptInfo' start='731' end='731' sourcepath='org/apache/hadoop/mapreduce/jobhistory/JobHistoryParser.java' sourcefile='JobHistoryParser.java' startBytecode='0'><Message>At JobHistoryParser.java:[line 731]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='2b45ca14f750ea0153ac6d473e80acf2' rank='20' abbrev='RI' category='STYLE' priority='3' type='RI_REDUNDANT_INTERFACES' instanceOccurrenceMax='0'><ShortMessage>Class implements same interface as superclass</ShortMessage><LongMessage>Class org.apache.hadoop.mapreduce.jobhistory.JobInfoChange implements same interface as superclass</LongMessage><Class classname='org.apache.hadoop.mapreduce.jobhistory.JobInfoChange' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.jobhistory.JobInfoChange' start='10' end='110' sourcepath='org/apache/hadoop/mapreduce/jobhistory/JobInfoChange.java' sourcefile='JobInfoChange.java'><Message>At JobInfoChange.java:[lines 10-110]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.jobhistory.JobInfoChange</Message></Class><Class role='INTERFACE_TYPE' classname='org.apache.avro.specific.SpecificRecord'><SourceLine classname='org.apache.avro.specific.SpecificRecord' sourcepath='org/apache/avro/specific/SpecificRecord.java' sourcefile='SpecificRecord.java'><Message>In SpecificRecord.java</Message></SourceLine><Message>Interface org.apache.avro.specific.SpecificRecord</Message></Class><SourceLine synthetic='true' classname='org.apache.hadoop.mapreduce.jobhistory.JobInfoChange' start='10' end='110' sourcepath='org/apache/hadoop/mapreduce/jobhistory/JobInfoChange.java' sourcefile='JobInfoChange.java'><Message>At JobInfoChange.java:[lines 10-110]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='85086807a10d4b51450c6fe393dc8cce' rank='20' abbrev='RI' category='STYLE' priority='3' type='RI_REDUNDANT_INTERFACES' instanceOccurrenceMax='0'><ShortMessage>Class implements same interface as superclass</ShortMessage><LongMessage>Class org.apache.hadoop.mapreduce.jobhistory.JobInfoChange$Builder implements same interface as superclass</LongMessage><Class classname='org.apache.hadoop.mapreduce.jobhistory.JobInfoChange$Builder' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.jobhistory.JobInfoChange$Builder' start='116' end='244' sourcepath='org/apache/hadoop/mapreduce/jobhistory/JobInfoChange.java' sourcefile='JobInfoChange.java'><Message>At JobInfoChange.java:[lines 116-244]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.jobhistory.JobInfoChange$Builder</Message></Class><Class role='INTERFACE_TYPE' classname='org.apache.avro.data.RecordBuilder'><SourceLine classname='org.apache.avro.data.RecordBuilder' sourcepath='org/apache/avro/data/RecordBuilder.java' sourcefile='RecordBuilder.java'><Message>In RecordBuilder.java</Message></SourceLine><Message>Interface org.apache.avro.data.RecordBuilder</Message></Class><SourceLine synthetic='true' classname='org.apache.hadoop.mapreduce.jobhistory.JobInfoChange$Builder' start='116' end='244' sourcepath='org/apache/hadoop/mapreduce/jobhistory/JobInfoChange.java' sourcefile='JobInfoChange.java'><Message>At JobInfoChange.java:[lines 116-244]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='c964aa3b75a32e6ef28bacfa8b3147c6' rank='20' abbrev='RI' category='STYLE' priority='3' type='RI_REDUNDANT_INTERFACES' instanceOccurrenceMax='0'><ShortMessage>Class implements same interface as superclass</ShortMessage><LongMessage>Class org.apache.hadoop.mapreduce.jobhistory.JobInited implements same interface as superclass</LongMessage><Class classname='org.apache.hadoop.mapreduce.jobhistory.JobInited' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.jobhistory.JobInited' start='10' end='167' sourcepath='org/apache/hadoop/mapreduce/jobhistory/JobInited.java' sourcefile='JobInited.java'><Message>At JobInited.java:[lines 10-167]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.jobhistory.JobInited</Message></Class><Class role='INTERFACE_TYPE' classname='org.apache.avro.specific.SpecificRecord'><SourceLine classname='org.apache.avro.specific.SpecificRecord' sourcepath='org/apache/avro/specific/SpecificRecord.java' sourcefile='SpecificRecord.java'><Message>In SpecificRecord.java</Message></SourceLine><Message>Interface org.apache.avro.specific.SpecificRecord</Message></Class><SourceLine synthetic='true' classname='org.apache.hadoop.mapreduce.jobhistory.JobInited' start='10' end='167' sourcepath='org/apache/hadoop/mapreduce/jobhistory/JobInited.java' sourcefile='JobInited.java'><Message>At JobInited.java:[lines 10-167]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='59339a94558a088f79c1baca07eed188' rank='20' abbrev='RI' category='STYLE' priority='3' type='RI_REDUNDANT_INTERFACES' instanceOccurrenceMax='0'><ShortMessage>Class implements same interface as superclass</ShortMessage><LongMessage>Class org.apache.hadoop.mapreduce.jobhistory.JobInited$Builder implements same interface as superclass</LongMessage><Class classname='org.apache.hadoop.mapreduce.jobhistory.JobInited$Builder' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.jobhistory.JobInited$Builder' start='173' end='404' sourcepath='org/apache/hadoop/mapreduce/jobhistory/JobInited.java' sourcefile='JobInited.java'><Message>At JobInited.java:[lines 173-404]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.jobhistory.JobInited$Builder</Message></Class><Class role='INTERFACE_TYPE' classname='org.apache.avro.data.RecordBuilder'><SourceLine classname='org.apache.avro.data.RecordBuilder' sourcepath='org/apache/avro/data/RecordBuilder.java' sourcefile='RecordBuilder.java'><Message>In RecordBuilder.java</Message></SourceLine><Message>Interface org.apache.avro.data.RecordBuilder</Message></Class><SourceLine synthetic='true' classname='org.apache.hadoop.mapreduce.jobhistory.JobInited$Builder' start='173' end='404' sourcepath='org/apache/hadoop/mapreduce/jobhistory/JobInited.java' sourcefile='JobInited.java'><Message>At JobInited.java:[lines 173-404]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='effdaaac438c41117c166ac934b0d045' rank='20' abbrev='RI' category='STYLE' priority='3' type='RI_REDUNDANT_INTERFACES' instanceOccurrenceMax='0'><ShortMessage>Class implements same interface as superclass</ShortMessage><LongMessage>Class org.apache.hadoop.mapreduce.jobhistory.JobPriorityChange implements same interface as superclass</LongMessage><Class classname='org.apache.hadoop.mapreduce.jobhistory.JobPriorityChange' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.jobhistory.JobPriorityChange' start='10' end='91' sourcepath='org/apache/hadoop/mapreduce/jobhistory/JobPriorityChange.java' sourcefile='JobPriorityChange.java'><Message>At JobPriorityChange.java:[lines 10-91]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.jobhistory.JobPriorityChange</Message></Class><Class role='INTERFACE_TYPE' classname='org.apache.avro.specific.SpecificRecord'><SourceLine classname='org.apache.avro.specific.SpecificRecord' sourcepath='org/apache/avro/specific/SpecificRecord.java' sourcefile='SpecificRecord.java'><Message>In SpecificRecord.java</Message></SourceLine><Message>Interface org.apache.avro.specific.SpecificRecord</Message></Class><SourceLine synthetic='true' classname='org.apache.hadoop.mapreduce.jobhistory.JobPriorityChange' start='10' end='91' sourcepath='org/apache/hadoop/mapreduce/jobhistory/JobPriorityChange.java' sourcefile='JobPriorityChange.java'><Message>At JobPriorityChange.java:[lines 10-91]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='f94483fe6886e05be833a63a5aa639bd' rank='20' abbrev='RI' category='STYLE' priority='3' type='RI_REDUNDANT_INTERFACES' instanceOccurrenceMax='0'><ShortMessage>Class implements same interface as superclass</ShortMessage><LongMessage>Class org.apache.hadoop.mapreduce.jobhistory.JobPriorityChange$Builder implements same interface as superclass</LongMessage><Class classname='org.apache.hadoop.mapreduce.jobhistory.JobPriorityChange$Builder' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.jobhistory.JobPriorityChange$Builder' start='97' end='192' sourcepath='org/apache/hadoop/mapreduce/jobhistory/JobPriorityChange.java' sourcefile='JobPriorityChange.java'><Message>At JobPriorityChange.java:[lines 97-192]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.jobhistory.JobPriorityChange$Builder</Message></Class><Class role='INTERFACE_TYPE' classname='org.apache.avro.data.RecordBuilder'><SourceLine classname='org.apache.avro.data.RecordBuilder' sourcepath='org/apache/avro/data/RecordBuilder.java' sourcefile='RecordBuilder.java'><Message>In RecordBuilder.java</Message></SourceLine><Message>Interface org.apache.avro.data.RecordBuilder</Message></Class><SourceLine synthetic='true' classname='org.apache.hadoop.mapreduce.jobhistory.JobPriorityChange$Builder' start='97' end='192' sourcepath='org/apache/hadoop/mapreduce/jobhistory/JobPriorityChange.java' sourcefile='JobPriorityChange.java'><Message>At JobPriorityChange.java:[lines 97-192]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='b4fe140c850d66a32c70b7f12c15478d' rank='20' abbrev='RI' category='STYLE' priority='3' type='RI_REDUNDANT_INTERFACES' instanceOccurrenceMax='0'><ShortMessage>Class implements same interface as superclass</ShortMessage><LongMessage>Class org.apache.hadoop.mapreduce.jobhistory.JobQueueChange implements same interface as superclass</LongMessage><Class classname='org.apache.hadoop.mapreduce.jobhistory.JobQueueChange' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.jobhistory.JobQueueChange' start='10' end='91' sourcepath='org/apache/hadoop/mapreduce/jobhistory/JobQueueChange.java' sourcefile='JobQueueChange.java'><Message>At JobQueueChange.java:[lines 10-91]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.jobhistory.JobQueueChange</Message></Class><Class role='INTERFACE_TYPE' classname='org.apache.avro.specific.SpecificRecord'><SourceLine classname='org.apache.avro.specific.SpecificRecord' sourcepath='org/apache/avro/specific/SpecificRecord.java' sourcefile='SpecificRecord.java'><Message>In SpecificRecord.java</Message></SourceLine><Message>Interface org.apache.avro.specific.SpecificRecord</Message></Class><SourceLine synthetic='true' classname='org.apache.hadoop.mapreduce.jobhistory.JobQueueChange' start='10' end='91' sourcepath='org/apache/hadoop/mapreduce/jobhistory/JobQueueChange.java' sourcefile='JobQueueChange.java'><Message>At JobQueueChange.java:[lines 10-91]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='6a1539118fb716662d2f92de23c44e93' rank='20' abbrev='RI' category='STYLE' priority='3' type='RI_REDUNDANT_INTERFACES' instanceOccurrenceMax='0'><ShortMessage>Class implements same interface as superclass</ShortMessage><LongMessage>Class org.apache.hadoop.mapreduce.jobhistory.JobQueueChange$Builder implements same interface as superclass</LongMessage><Class classname='org.apache.hadoop.mapreduce.jobhistory.JobQueueChange$Builder' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.jobhistory.JobQueueChange$Builder' start='97' end='192' sourcepath='org/apache/hadoop/mapreduce/jobhistory/JobQueueChange.java' sourcefile='JobQueueChange.java'><Message>At JobQueueChange.java:[lines 97-192]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.jobhistory.JobQueueChange$Builder</Message></Class><Class role='INTERFACE_TYPE' classname='org.apache.avro.data.RecordBuilder'><SourceLine classname='org.apache.avro.data.RecordBuilder' sourcepath='org/apache/avro/data/RecordBuilder.java' sourcefile='RecordBuilder.java'><Message>In RecordBuilder.java</Message></SourceLine><Message>Interface org.apache.avro.data.RecordBuilder</Message></Class><SourceLine synthetic='true' classname='org.apache.hadoop.mapreduce.jobhistory.JobQueueChange$Builder' start='97' end='192' sourcepath='org/apache/hadoop/mapreduce/jobhistory/JobQueueChange.java' sourcefile='JobQueueChange.java'><Message>At JobQueueChange.java:[lines 97-192]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='82cdbba69c67d37c9705e83c27845730' rank='20' abbrev='RI' category='STYLE' priority='3' type='RI_REDUNDANT_INTERFACES' instanceOccurrenceMax='0'><ShortMessage>Class implements same interface as superclass</ShortMessage><LongMessage>Class org.apache.hadoop.mapreduce.jobhistory.JobStatusChanged implements same interface as superclass</LongMessage><Class classname='org.apache.hadoop.mapreduce.jobhistory.JobStatusChanged' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.jobhistory.JobStatusChanged' start='10' end='91' sourcepath='org/apache/hadoop/mapreduce/jobhistory/JobStatusChanged.java' sourcefile='JobStatusChanged.java'><Message>At JobStatusChanged.java:[lines 10-91]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.jobhistory.JobStatusChanged</Message></Class><Class role='INTERFACE_TYPE' classname='org.apache.avro.specific.SpecificRecord'><SourceLine classname='org.apache.avro.specific.SpecificRecord' sourcepath='org/apache/avro/specific/SpecificRecord.java' sourcefile='SpecificRecord.java'><Message>In SpecificRecord.java</Message></SourceLine><Message>Interface org.apache.avro.specific.SpecificRecord</Message></Class><SourceLine synthetic='true' classname='org.apache.hadoop.mapreduce.jobhistory.JobStatusChanged' start='10' end='91' sourcepath='org/apache/hadoop/mapreduce/jobhistory/JobStatusChanged.java' sourcefile='JobStatusChanged.java'><Message>At JobStatusChanged.java:[lines 10-91]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='d1ce1ce2582b8b611c01504549305d3f' rank='20' abbrev='RI' category='STYLE' priority='3' type='RI_REDUNDANT_INTERFACES' instanceOccurrenceMax='0'><ShortMessage>Class implements same interface as superclass</ShortMessage><LongMessage>Class org.apache.hadoop.mapreduce.jobhistory.JobStatusChanged$Builder implements same interface as superclass</LongMessage><Class classname='org.apache.hadoop.mapreduce.jobhistory.JobStatusChanged$Builder' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.jobhistory.JobStatusChanged$Builder' start='97' end='192' sourcepath='org/apache/hadoop/mapreduce/jobhistory/JobStatusChanged.java' sourcefile='JobStatusChanged.java'><Message>At JobStatusChanged.java:[lines 97-192]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.jobhistory.JobStatusChanged$Builder</Message></Class><Class role='INTERFACE_TYPE' classname='org.apache.avro.data.RecordBuilder'><SourceLine classname='org.apache.avro.data.RecordBuilder' sourcepath='org/apache/avro/data/RecordBuilder.java' sourcefile='RecordBuilder.java'><Message>In RecordBuilder.java</Message></SourceLine><Message>Interface org.apache.avro.data.RecordBuilder</Message></Class><SourceLine synthetic='true' classname='org.apache.hadoop.mapreduce.jobhistory.JobStatusChanged$Builder' start='97' end='192' sourcepath='org/apache/hadoop/mapreduce/jobhistory/JobStatusChanged.java' sourcefile='JobStatusChanged.java'><Message>At JobStatusChanged.java:[lines 97-192]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='b3cc9ea6fdbbdfb0c5ab869d79949907' rank='20' abbrev='RI' category='STYLE' priority='3' type='RI_REDUNDANT_INTERFACES' instanceOccurrenceMax='0'><ShortMessage>Class implements same interface as superclass</ShortMessage><LongMessage>Class org.apache.hadoop.mapreduce.jobhistory.JobSubmitted implements same interface as superclass</LongMessage><Class classname='org.apache.hadoop.mapreduce.jobhistory.JobSubmitted' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.jobhistory.JobSubmitted' start='10' end='281' sourcepath='org/apache/hadoop/mapreduce/jobhistory/JobSubmitted.java' sourcefile='JobSubmitted.java'><Message>At JobSubmitted.java:[lines 10-281]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.jobhistory.JobSubmitted</Message></Class><Class role='INTERFACE_TYPE' classname='org.apache.avro.specific.SpecificRecord'><SourceLine classname='org.apache.avro.specific.SpecificRecord' sourcepath='org/apache/avro/specific/SpecificRecord.java' sourcefile='SpecificRecord.java'><Message>In SpecificRecord.java</Message></SourceLine><Message>Interface org.apache.avro.specific.SpecificRecord</Message></Class><SourceLine synthetic='true' classname='org.apache.hadoop.mapreduce.jobhistory.JobSubmitted' start='10' end='281' sourcepath='org/apache/hadoop/mapreduce/jobhistory/JobSubmitted.java' sourcefile='JobSubmitted.java'><Message>At JobSubmitted.java:[lines 10-281]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='f4ddda49cc584224f4052fc4942b79ce' cweid='396' rank='20' abbrev='REC' category='STYLE' priority='3' type='REC_CATCH_EXCEPTION' instanceOccurrenceMax='0'><ShortMessage>Exception is caught when Exception is not thrown</ShortMessage><LongMessage>Exception is caught when Exception is not thrown in org.apache.hadoop.mapreduce.jobhistory.JobSubmitted$Builder.build()</LongMessage><Class classname='org.apache.hadoop.mapreduce.jobhistory.JobSubmitted$Builder' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.jobhistory.JobSubmitted$Builder' start='287' end='731' sourcepath='org/apache/hadoop/mapreduce/jobhistory/JobSubmitted.java' sourcefile='JobSubmitted.java'><Message>At JobSubmitted.java:[lines 287-731]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.jobhistory.JobSubmitted$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapreduce.jobhistory.JobSubmitted$Builder' signature='()Lorg/apache/hadoop/mapreduce/jobhistory/JobSubmitted;' name='build' primary='true'><SourceLine endBytecode='867' classname='org.apache.hadoop.mapreduce.jobhistory.JobSubmitted$Builder' start='716' end='731' sourcepath='org/apache/hadoop/mapreduce/jobhistory/JobSubmitted.java' sourcefile='JobSubmitted.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapreduce.jobhistory.JobSubmitted$Builder.build()</Message></Method><SourceLine endBytecode='421' classname='org.apache.hadoop.mapreduce.jobhistory.JobSubmitted$Builder' start='730' end='730' sourcepath='org/apache/hadoop/mapreduce/jobhistory/JobSubmitted.java' sourcefile='JobSubmitted.java' startBytecode='421' primary='true'><Message>At JobSubmitted.java:[line 730]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='eb5e681cadf0e953cfcf76248a4f85a7' rank='20' abbrev='RI' category='STYLE' priority='3' type='RI_REDUNDANT_INTERFACES' instanceOccurrenceMax='0'><ShortMessage>Class implements same interface as superclass</ShortMessage><LongMessage>Class org.apache.hadoop.mapreduce.jobhistory.JobSubmitted$Builder implements same interface as superclass</LongMessage><Class classname='org.apache.hadoop.mapreduce.jobhistory.JobSubmitted$Builder' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.jobhistory.JobSubmitted$Builder' start='287' end='731' sourcepath='org/apache/hadoop/mapreduce/jobhistory/JobSubmitted.java' sourcefile='JobSubmitted.java'><Message>At JobSubmitted.java:[lines 287-731]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.jobhistory.JobSubmitted$Builder</Message></Class><Class role='INTERFACE_TYPE' classname='org.apache.avro.data.RecordBuilder'><SourceLine classname='org.apache.avro.data.RecordBuilder' sourcepath='org/apache/avro/data/RecordBuilder.java' sourcefile='RecordBuilder.java'><Message>In RecordBuilder.java</Message></SourceLine><Message>Interface org.apache.avro.data.RecordBuilder</Message></Class><SourceLine synthetic='true' classname='org.apache.hadoop.mapreduce.jobhistory.JobSubmitted$Builder' start='287' end='731' sourcepath='org/apache/hadoop/mapreduce/jobhistory/JobSubmitted.java' sourcefile='JobSubmitted.java'><Message>At JobSubmitted.java:[lines 287-731]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='fe7ab4c95ea3d9c56aeb35a02e461cfd' rank='20' abbrev='RI' category='STYLE' priority='3' type='RI_REDUNDANT_INTERFACES' instanceOccurrenceMax='0'><ShortMessage>Class implements same interface as superclass</ShortMessage><LongMessage>Class org.apache.hadoop.mapreduce.jobhistory.JobUnsuccessfulCompletion implements same interface as superclass</LongMessage><Class classname='org.apache.hadoop.mapreduce.jobhistory.JobUnsuccessfulCompletion' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.jobhistory.JobUnsuccessfulCompletion' start='10' end='243' sourcepath='org/apache/hadoop/mapreduce/jobhistory/JobUnsuccessfulCompletion.java' sourcefile='JobUnsuccessfulCompletion.java'><Message>At JobUnsuccessfulCompletion.java:[lines 10-243]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.jobhistory.JobUnsuccessfulCompletion</Message></Class><Class role='INTERFACE_TYPE' classname='org.apache.avro.specific.SpecificRecord'><SourceLine classname='org.apache.avro.specific.SpecificRecord' sourcepath='org/apache/avro/specific/SpecificRecord.java' sourcefile='SpecificRecord.java'><Message>In SpecificRecord.java</Message></SourceLine><Message>Interface org.apache.avro.specific.SpecificRecord</Message></Class><SourceLine synthetic='true' classname='org.apache.hadoop.mapreduce.jobhistory.JobUnsuccessfulCompletion' start='10' end='243' sourcepath='org/apache/hadoop/mapreduce/jobhistory/JobUnsuccessfulCompletion.java' sourcefile='JobUnsuccessfulCompletion.java'><Message>At JobUnsuccessfulCompletion.java:[lines 10-243]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='7bcd7e8ceb799cc9e92dd1d1e9018ee' cweid='396' rank='20' abbrev='REC' category='STYLE' priority='3' type='REC_CATCH_EXCEPTION' instanceOccurrenceMax='0'><ShortMessage>Exception is caught when Exception is not thrown</ShortMessage><LongMessage>Exception is caught when Exception is not thrown in org.apache.hadoop.mapreduce.jobhistory.JobUnsuccessfulCompletion$Builder.build()</LongMessage><Class classname='org.apache.hadoop.mapreduce.jobhistory.JobUnsuccessfulCompletion$Builder' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.jobhistory.JobUnsuccessfulCompletion$Builder' start='249' end='617' sourcepath='org/apache/hadoop/mapreduce/jobhistory/JobUnsuccessfulCompletion.java' sourcefile='JobUnsuccessfulCompletion.java'><Message>At JobUnsuccessfulCompletion.java:[lines 249-617]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.jobhistory.JobUnsuccessfulCompletion$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapreduce.jobhistory.JobUnsuccessfulCompletion$Builder' signature='()Lorg/apache/hadoop/mapreduce/jobhistory/JobUnsuccessfulCompletion;' name='build' primary='true'><SourceLine endBytecode='749' classname='org.apache.hadoop.mapreduce.jobhistory.JobUnsuccessfulCompletion$Builder' start='604' end='617' sourcepath='org/apache/hadoop/mapreduce/jobhistory/JobUnsuccessfulCompletion.java' sourcefile='JobUnsuccessfulCompletion.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapreduce.jobhistory.JobUnsuccessfulCompletion$Builder.build()</Message></Method><SourceLine endBytecode='369' classname='org.apache.hadoop.mapreduce.jobhistory.JobUnsuccessfulCompletion$Builder' start='616' end='616' sourcepath='org/apache/hadoop/mapreduce/jobhistory/JobUnsuccessfulCompletion.java' sourcefile='JobUnsuccessfulCompletion.java' startBytecode='369' primary='true'><Message>At JobUnsuccessfulCompletion.java:[line 616]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='8601e6d15bb77f0bb9d6df6b715580e0' rank='20' abbrev='RI' category='STYLE' priority='3' type='RI_REDUNDANT_INTERFACES' instanceOccurrenceMax='0'><ShortMessage>Class implements same interface as superclass</ShortMessage><LongMessage>Class org.apache.hadoop.mapreduce.jobhistory.JobUnsuccessfulCompletion$Builder implements same interface as superclass</LongMessage><Class classname='org.apache.hadoop.mapreduce.jobhistory.JobUnsuccessfulCompletion$Builder' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.jobhistory.JobUnsuccessfulCompletion$Builder' start='249' end='617' sourcepath='org/apache/hadoop/mapreduce/jobhistory/JobUnsuccessfulCompletion.java' sourcefile='JobUnsuccessfulCompletion.java'><Message>At JobUnsuccessfulCompletion.java:[lines 249-617]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.jobhistory.JobUnsuccessfulCompletion$Builder</Message></Class><Class role='INTERFACE_TYPE' classname='org.apache.avro.data.RecordBuilder'><SourceLine classname='org.apache.avro.data.RecordBuilder' sourcepath='org/apache/avro/data/RecordBuilder.java' sourcefile='RecordBuilder.java'><Message>In RecordBuilder.java</Message></SourceLine><Message>Interface org.apache.avro.data.RecordBuilder</Message></Class><SourceLine synthetic='true' classname='org.apache.hadoop.mapreduce.jobhistory.JobUnsuccessfulCompletion$Builder' start='249' end='617' sourcepath='org/apache/hadoop/mapreduce/jobhistory/JobUnsuccessfulCompletion.java' sourcefile='JobUnsuccessfulCompletion.java'><Message>At JobUnsuccessfulCompletion.java:[lines 249-617]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='835124cad3c7f7f06bf4a02a9783a7f0' rank='20' abbrev='RI' category='STYLE' priority='3' type='RI_REDUNDANT_INTERFACES' instanceOccurrenceMax='0'><ShortMessage>Class implements same interface as superclass</ShortMessage><LongMessage>Class org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished implements same interface as superclass</LongMessage><Class classname='org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished' start='10' end='338' sourcepath='org/apache/hadoop/mapreduce/jobhistory/MapAttemptFinished.java' sourcefile='MapAttemptFinished.java'><Message>At MapAttemptFinished.java:[lines 10-338]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished</Message></Class><Class role='INTERFACE_TYPE' classname='org.apache.avro.specific.SpecificRecord'><SourceLine classname='org.apache.avro.specific.SpecificRecord' sourcepath='org/apache/avro/specific/SpecificRecord.java' sourcefile='SpecificRecord.java'><Message>In SpecificRecord.java</Message></SourceLine><Message>Interface org.apache.avro.specific.SpecificRecord</Message></Class><SourceLine synthetic='true' classname='org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished' start='10' end='338' sourcepath='org/apache/hadoop/mapreduce/jobhistory/MapAttemptFinished.java' sourcefile='MapAttemptFinished.java'><Message>At MapAttemptFinished.java:[lines 10-338]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='d4c5772380addf4025ad5d4e2c8358be' cweid='396' rank='20' abbrev='REC' category='STYLE' priority='3' type='REC_CATCH_EXCEPTION' instanceOccurrenceMax='0'><ShortMessage>Exception is caught when Exception is not thrown</ShortMessage><LongMessage>Exception is caught when Exception is not thrown in org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished$Builder.build()</LongMessage><Class classname='org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished$Builder' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished$Builder' start='344' end='891' sourcepath='org/apache/hadoop/mapreduce/jobhistory/MapAttemptFinished.java' sourcefile='MapAttemptFinished.java'><Message>At MapAttemptFinished.java:[lines 344-891]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished$Builder' signature='()Lorg/apache/hadoop/mapreduce/jobhistory/MapAttemptFinished;' name='build' primary='true'><SourceLine endBytecode='1055' classname='org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished$Builder' start='873' end='891' sourcepath='org/apache/hadoop/mapreduce/jobhistory/MapAttemptFinished.java' sourcefile='MapAttemptFinished.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished$Builder.build()</Message></Method><SourceLine endBytecode='532' classname='org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished$Builder' start='890' end='890' sourcepath='org/apache/hadoop/mapreduce/jobhistory/MapAttemptFinished.java' sourcefile='MapAttemptFinished.java' startBytecode='532' primary='true'><Message>At MapAttemptFinished.java:[line 890]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='2a9037b2094388aae8335e2c0ebd32c4' rank='20' abbrev='RI' category='STYLE' priority='3' type='RI_REDUNDANT_INTERFACES' instanceOccurrenceMax='0'><ShortMessage>Class implements same interface as superclass</ShortMessage><LongMessage>Class org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished$Builder implements same interface as superclass</LongMessage><Class classname='org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished$Builder' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished$Builder' start='344' end='891' sourcepath='org/apache/hadoop/mapreduce/jobhistory/MapAttemptFinished.java' sourcefile='MapAttemptFinished.java'><Message>At MapAttemptFinished.java:[lines 344-891]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished$Builder</Message></Class><Class role='INTERFACE_TYPE' classname='org.apache.avro.data.RecordBuilder'><SourceLine classname='org.apache.avro.data.RecordBuilder' sourcepath='org/apache/avro/data/RecordBuilder.java' sourcefile='RecordBuilder.java'><Message>In RecordBuilder.java</Message></SourceLine><Message>Interface org.apache.avro.data.RecordBuilder</Message></Class><SourceLine synthetic='true' classname='org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished$Builder' start='344' end='891' sourcepath='org/apache/hadoop/mapreduce/jobhistory/MapAttemptFinished.java' sourcefile='MapAttemptFinished.java'><Message>At MapAttemptFinished.java:[lines 344-891]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='724435531d3cfa1160f0003e30858291' rank='20' abbrev='Dm' category='PERFORMANCE' priority='3' type='DM_STRING_TOSTRING' instanceOccurrenceMax='0'><ShortMessage>Method invokes toString() method on a String</ShortMessage><LongMessage>org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinishedEvent.getHostname() invokes toString() method on a String</LongMessage><Class classname='org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinishedEvent' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinishedEvent' start='45' end='277' sourcepath='org/apache/hadoop/mapreduce/jobhistory/MapAttemptFinishedEvent.java' sourcefile='MapAttemptFinishedEvent.java'><Message>At MapAttemptFinishedEvent.java:[lines 45-277]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinishedEvent</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinishedEvent' signature='()Ljava/lang/String;' name='getHostname' primary='true'><SourceLine endBytecode='49' classname='org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinishedEvent' start='216' end='216' sourcepath='org/apache/hadoop/mapreduce/jobhistory/MapAttemptFinishedEvent.java' sourcefile='MapAttemptFinishedEvent.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinishedEvent.getHostname()</Message></Method><SourceLine endBytecode='4' classname='org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinishedEvent' start='216' end='216' sourcepath='org/apache/hadoop/mapreduce/jobhistory/MapAttemptFinishedEvent.java' sourcefile='MapAttemptFinishedEvent.java' startBytecode='4' primary='true'><Message>At MapAttemptFinishedEvent.java:[line 216]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='c009d256629d66c61475fbf7e6efd084' rank='20' abbrev='Dm' category='PERFORMANCE' priority='3' type='DM_STRING_TOSTRING' instanceOccurrenceMax='0'><ShortMessage>Method invokes toString() method on a String</ShortMessage><LongMessage>org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinishedEvent.getRackName() invokes toString() method on a String</LongMessage><Class classname='org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinishedEvent' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinishedEvent' start='45' end='277' sourcepath='org/apache/hadoop/mapreduce/jobhistory/MapAttemptFinishedEvent.java' sourcefile='MapAttemptFinishedEvent.java'><Message>At MapAttemptFinishedEvent.java:[lines 45-277]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinishedEvent</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinishedEvent' signature='()Ljava/lang/String;' name='getRackName' primary='true'><SourceLine endBytecode='73' classname='org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinishedEvent' start='222' end='222' sourcepath='org/apache/hadoop/mapreduce/jobhistory/MapAttemptFinishedEvent.java' sourcefile='MapAttemptFinishedEvent.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinishedEvent.getRackName()</Message></Method><SourceLine endBytecode='15' classname='org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinishedEvent' start='222' end='222' sourcepath='org/apache/hadoop/mapreduce/jobhistory/MapAttemptFinishedEvent.java' sourcefile='MapAttemptFinishedEvent.java' startBytecode='15' primary='true'><Message>At MapAttemptFinishedEvent.java:[line 222]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='3f54e123ba5e5b44825ccb2d1034e9c8' rank='20' abbrev='Dm' category='PERFORMANCE' priority='3' type='DM_STRING_TOSTRING' instanceOccurrenceMax='0'><ShortMessage>Method invokes toString() method on a String</ShortMessage><LongMessage>org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinishedEvent.getState() invokes toString() method on a String</LongMessage><Class classname='org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinishedEvent' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinishedEvent' start='45' end='277' sourcepath='org/apache/hadoop/mapreduce/jobhistory/MapAttemptFinishedEvent.java' sourcefile='MapAttemptFinishedEvent.java'><Message>At MapAttemptFinishedEvent.java:[lines 45-277]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinishedEvent</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinishedEvent' signature='()Ljava/lang/String;' name='getState' primary='true'><SourceLine endBytecode='49' classname='org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinishedEvent' start='229' end='229' sourcepath='org/apache/hadoop/mapreduce/jobhistory/MapAttemptFinishedEvent.java' sourcefile='MapAttemptFinishedEvent.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinishedEvent.getState()</Message></Method><SourceLine endBytecode='4' classname='org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinishedEvent' start='229' end='229' sourcepath='org/apache/hadoop/mapreduce/jobhistory/MapAttemptFinishedEvent.java' sourcefile='MapAttemptFinishedEvent.java' startBytecode='4' primary='true'><Message>At MapAttemptFinishedEvent.java:[line 229]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='d55ded4bca9fb18f2e4a3f66a2560283' rank='20' abbrev='Dm' category='PERFORMANCE' priority='3' type='DM_STRING_TOSTRING' instanceOccurrenceMax='0'><ShortMessage>Method invokes toString() method on a String</ShortMessage><LongMessage>org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinishedEvent.getTaskStatus() invokes toString() method on a String</LongMessage><Class classname='org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinishedEvent' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinishedEvent' start='45' end='277' sourcepath='org/apache/hadoop/mapreduce/jobhistory/MapAttemptFinishedEvent.java' sourcefile='MapAttemptFinishedEvent.java'><Message>At MapAttemptFinishedEvent.java:[lines 45-277]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinishedEvent</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinishedEvent' signature='()Ljava/lang/String;' name='getTaskStatus' primary='true'><SourceLine endBytecode='49' classname='org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinishedEvent' start='203' end='203' sourcepath='org/apache/hadoop/mapreduce/jobhistory/MapAttemptFinishedEvent.java' sourcefile='MapAttemptFinishedEvent.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinishedEvent.getTaskStatus()</Message></Method><SourceLine endBytecode='4' classname='org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinishedEvent' start='203' end='203' sourcepath='org/apache/hadoop/mapreduce/jobhistory/MapAttemptFinishedEvent.java' sourcefile='MapAttemptFinishedEvent.java' startBytecode='4' primary='true'><Message>At MapAttemptFinishedEvent.java:[line 203]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='b680bf53f79437f9ab5c688f2b1812ca' cweid='374' rank='18' abbrev='EI' category='MALICIOUS_CODE' priority='2' type='EI_EXPOSE_REP' instanceOccurrenceMax='0'><ShortMessage>May expose internal representation by returning reference to mutable object</ShortMessage><LongMessage>org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinishedEvent.getClockSplits() may expose internal representation by returning MapAttemptFinishedEvent.clockSplits</LongMessage><Class classname='org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinishedEvent' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinishedEvent' start='45' end='277' sourcepath='org/apache/hadoop/mapreduce/jobhistory/MapAttemptFinishedEvent.java' sourcefile='MapAttemptFinishedEvent.java'><Message>At MapAttemptFinishedEvent.java:[lines 45-277]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinishedEvent</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinishedEvent' signature='()[I' name='getClockSplits' primary='true'><SourceLine endBytecode='46' classname='org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinishedEvent' start='244' end='244' sourcepath='org/apache/hadoop/mapreduce/jobhistory/MapAttemptFinishedEvent.java' sourcefile='MapAttemptFinishedEvent.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinishedEvent.getClockSplits()</Message></Method><Field isStatic='false' classname='org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinishedEvent' signature='[I' name='clockSplits' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinishedEvent' sourcepath='org/apache/hadoop/mapreduce/jobhistory/MapAttemptFinishedEvent.java' sourcefile='MapAttemptFinishedEvent.java'><Message>In MapAttemptFinishedEvent.java</Message></SourceLine><Message>Field org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinishedEvent.clockSplits</Message></Field><SourceLine endBytecode='4' classname='org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinishedEvent' start='244' end='244' sourcepath='org/apache/hadoop/mapreduce/jobhistory/MapAttemptFinishedEvent.java' sourcefile='MapAttemptFinishedEvent.java' startBytecode='4' primary='true'><Message>At MapAttemptFinishedEvent.java:[line 244]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='f8596e9add6fb90202577a1c2053405b' cweid='374' rank='18' abbrev='EI' category='MALICIOUS_CODE' priority='2' type='EI_EXPOSE_REP' instanceOccurrenceMax='0'><ShortMessage>May expose internal representation by returning reference to mutable object</ShortMessage><LongMessage>org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinishedEvent.getCpuUsages() may expose internal representation by returning MapAttemptFinishedEvent.cpuUsages</LongMessage><Class classname='org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinishedEvent' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinishedEvent' start='45' end='277' sourcepath='org/apache/hadoop/mapreduce/jobhistory/MapAttemptFinishedEvent.java' sourcefile='MapAttemptFinishedEvent.java'><Message>At MapAttemptFinishedEvent.java:[lines 45-277]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinishedEvent</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinishedEvent' signature='()[I' name='getCpuUsages' primary='true'><SourceLine endBytecode='46' classname='org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinishedEvent' start='247' end='247' sourcepath='org/apache/hadoop/mapreduce/jobhistory/MapAttemptFinishedEvent.java' sourcefile='MapAttemptFinishedEvent.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinishedEvent.getCpuUsages()</Message></Method><Field isStatic='false' classname='org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinishedEvent' signature='[I' name='cpuUsages' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinishedEvent' sourcepath='org/apache/hadoop/mapreduce/jobhistory/MapAttemptFinishedEvent.java' sourcefile='MapAttemptFinishedEvent.java'><Message>In MapAttemptFinishedEvent.java</Message></SourceLine><Message>Field org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinishedEvent.cpuUsages</Message></Field><SourceLine endBytecode='4' classname='org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinishedEvent' start='247' end='247' sourcepath='org/apache/hadoop/mapreduce/jobhistory/MapAttemptFinishedEvent.java' sourcefile='MapAttemptFinishedEvent.java' startBytecode='4' primary='true'><Message>At MapAttemptFinishedEvent.java:[line 247]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='6be99dab66a44f1331e62b7778f7a7e6' cweid='374' rank='18' abbrev='EI' category='MALICIOUS_CODE' priority='2' type='EI_EXPOSE_REP' instanceOccurrenceMax='0'><ShortMessage>May expose internal representation by returning reference to mutable object</ShortMessage><LongMessage>org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinishedEvent.getPhysMemKbytes() may expose internal representation by returning MapAttemptFinishedEvent.physMemKbytes</LongMessage><Class classname='org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinishedEvent' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinishedEvent' start='45' end='277' sourcepath='org/apache/hadoop/mapreduce/jobhistory/MapAttemptFinishedEvent.java' sourcefile='MapAttemptFinishedEvent.java'><Message>At MapAttemptFinishedEvent.java:[lines 45-277]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinishedEvent</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinishedEvent' signature='()[I' name='getPhysMemKbytes' primary='true'><SourceLine endBytecode='46' classname='org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinishedEvent' start='253' end='253' sourcepath='org/apache/hadoop/mapreduce/jobhistory/MapAttemptFinishedEvent.java' sourcefile='MapAttemptFinishedEvent.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinishedEvent.getPhysMemKbytes()</Message></Method><Field isStatic='false' classname='org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinishedEvent' signature='[I' name='physMemKbytes' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinishedEvent' sourcepath='org/apache/hadoop/mapreduce/jobhistory/MapAttemptFinishedEvent.java' sourcefile='MapAttemptFinishedEvent.java'><Message>In MapAttemptFinishedEvent.java</Message></SourceLine><Message>Field org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinishedEvent.physMemKbytes</Message></Field><SourceLine endBytecode='4' classname='org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinishedEvent' start='253' end='253' sourcepath='org/apache/hadoop/mapreduce/jobhistory/MapAttemptFinishedEvent.java' sourcefile='MapAttemptFinishedEvent.java' startBytecode='4' primary='true'><Message>At MapAttemptFinishedEvent.java:[line 253]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='610198a8998e839c0faad5457937c019' cweid='374' rank='18' abbrev='EI' category='MALICIOUS_CODE' priority='2' type='EI_EXPOSE_REP' instanceOccurrenceMax='0'><ShortMessage>May expose internal representation by returning reference to mutable object</ShortMessage><LongMessage>org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinishedEvent.getVMemKbytes() may expose internal representation by returning MapAttemptFinishedEvent.vMemKbytes</LongMessage><Class classname='org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinishedEvent' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinishedEvent' start='45' end='277' sourcepath='org/apache/hadoop/mapreduce/jobhistory/MapAttemptFinishedEvent.java' sourcefile='MapAttemptFinishedEvent.java'><Message>At MapAttemptFinishedEvent.java:[lines 45-277]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinishedEvent</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinishedEvent' signature='()[I' name='getVMemKbytes' primary='true'><SourceLine endBytecode='46' classname='org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinishedEvent' start='250' end='250' sourcepath='org/apache/hadoop/mapreduce/jobhistory/MapAttemptFinishedEvent.java' sourcefile='MapAttemptFinishedEvent.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinishedEvent.getVMemKbytes()</Message></Method><Field isStatic='false' classname='org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinishedEvent' signature='[I' name='vMemKbytes' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinishedEvent' sourcepath='org/apache/hadoop/mapreduce/jobhistory/MapAttemptFinishedEvent.java' sourcefile='MapAttemptFinishedEvent.java'><Message>In MapAttemptFinishedEvent.java</Message></SourceLine><Message>Field org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinishedEvent.vMemKbytes</Message></Field><SourceLine endBytecode='4' classname='org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinishedEvent' start='250' end='250' sourcepath='org/apache/hadoop/mapreduce/jobhistory/MapAttemptFinishedEvent.java' sourcefile='MapAttemptFinishedEvent.java' startBytecode='4' primary='true'><Message>At MapAttemptFinishedEvent.java:[line 250]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='4e9319e8e26b05964ad6f4d6537a5692' cweid='374' rank='18' abbrev='EI2' category='MALICIOUS_CODE' priority='2' type='EI_EXPOSE_REP2' instanceOccurrenceMax='0'><ShortMessage>May expose internal representation by incorporating reference to mutable object</ShortMessage><LongMessage>new org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinishedEvent(TaskAttemptID, TaskType, String, long, long, String, int, String, String, Counters, int[][], long) may expose internal representation by storing an externally mutable object into MapAttemptFinishedEvent.allSplits</LongMessage><Class classname='org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinishedEvent' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinishedEvent' start='45' end='277' sourcepath='org/apache/hadoop/mapreduce/jobhistory/MapAttemptFinishedEvent.java' sourcefile='MapAttemptFinishedEvent.java'><Message>At MapAttemptFinishedEvent.java:[lines 45-277]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinishedEvent</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinishedEvent' signature='(Lorg/apache/hadoop/mapreduce/TaskAttemptID;Lorg/apache/hadoop/mapreduce/TaskType;Ljava/lang/String;JJLjava/lang/String;ILjava/lang/String;Ljava/lang/String;Lorg/apache/hadoop/mapreduce/Counters;[[IJ)V' name='&lt;init&gt;' primary='true'><SourceLine endBytecode='348' classname='org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinishedEvent' start='88' end='105' sourcepath='org/apache/hadoop/mapreduce/jobhistory/MapAttemptFinishedEvent.java' sourcefile='MapAttemptFinishedEvent.java' startBytecode='0'></SourceLine><Message>In method new org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinishedEvent(TaskAttemptID, TaskType, String, long, long, String, int, String, String, Counters, int[][], long)</Message></Method><Field isStatic='false' classname='org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinishedEvent' signature='[[I' name='allSplits' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinishedEvent' sourcepath='org/apache/hadoop/mapreduce/jobhistory/MapAttemptFinishedEvent.java' sourcefile='MapAttemptFinishedEvent.java'><Message>In MapAttemptFinishedEvent.java</Message></SourceLine><Message>Field org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinishedEvent.allSplits</Message></Field><LocalVariable role='LOCAL_VARIABLE_NAMED' pc='69' name='allSplits' register='13'><Message>Local variable named allSplits</Message></LocalVariable><SourceLine endBytecode='69' classname='org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinishedEvent' start='99' end='99' sourcepath='org/apache/hadoop/mapreduce/jobhistory/MapAttemptFinishedEvent.java' sourcefile='MapAttemptFinishedEvent.java' startBytecode='69' primary='true'><Message>At MapAttemptFinishedEvent.java:[line 99]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='5336db5a2ba75d42392d682160c56267' rank='20' abbrev='RI' category='STYLE' priority='3' type='RI_REDUNDANT_INTERFACES' instanceOccurrenceMax='0'><ShortMessage>Class implements same interface as superclass</ShortMessage><LongMessage>Class org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished implements same interface as superclass</LongMessage><Class classname='org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished' start='10' end='357' sourcepath='org/apache/hadoop/mapreduce/jobhistory/ReduceAttemptFinished.java' sourcefile='ReduceAttemptFinished.java'><Message>At ReduceAttemptFinished.java:[lines 10-357]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished</Message></Class><Class role='INTERFACE_TYPE' classname='org.apache.avro.specific.SpecificRecord'><SourceLine classname='org.apache.avro.specific.SpecificRecord' sourcepath='org/apache/avro/specific/SpecificRecord.java' sourcefile='SpecificRecord.java'><Message>In SpecificRecord.java</Message></SourceLine><Message>Interface org.apache.avro.specific.SpecificRecord</Message></Class><SourceLine synthetic='true' classname='org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished' start='10' end='357' sourcepath='org/apache/hadoop/mapreduce/jobhistory/ReduceAttemptFinished.java' sourcefile='ReduceAttemptFinished.java'><Message>At ReduceAttemptFinished.java:[lines 10-357]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='f71809f81981ccd71dd6c91238ab810d' cweid='396' rank='20' abbrev='REC' category='STYLE' priority='3' type='REC_CATCH_EXCEPTION' instanceOccurrenceMax='0'><ShortMessage>Exception is caught when Exception is not thrown</ShortMessage><LongMessage>Exception is caught when Exception is not thrown in org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished$Builder.build()</LongMessage><Class classname='org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished$Builder' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished$Builder' start='363' end='944' sourcepath='org/apache/hadoop/mapreduce/jobhistory/ReduceAttemptFinished.java' sourcefile='ReduceAttemptFinished.java'><Message>At ReduceAttemptFinished.java:[lines 363-944]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished$Builder' signature='()Lorg/apache/hadoop/mapreduce/jobhistory/ReduceAttemptFinished;' name='build' primary='true'><SourceLine endBytecode='1118' classname='org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished$Builder' start='925' end='944' sourcepath='org/apache/hadoop/mapreduce/jobhistory/ReduceAttemptFinished.java' sourcefile='ReduceAttemptFinished.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished$Builder.build()</Message></Method><SourceLine endBytecode='570' classname='org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished$Builder' start='943' end='943' sourcepath='org/apache/hadoop/mapreduce/jobhistory/ReduceAttemptFinished.java' sourcefile='ReduceAttemptFinished.java' startBytecode='570' primary='true'><Message>At ReduceAttemptFinished.java:[line 943]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='76d2e11c7eb39cd6ccf9f95355445cae' rank='20' abbrev='RI' category='STYLE' priority='3' type='RI_REDUNDANT_INTERFACES' instanceOccurrenceMax='0'><ShortMessage>Class implements same interface as superclass</ShortMessage><LongMessage>Class org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished$Builder implements same interface as superclass</LongMessage><Class classname='org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished$Builder' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished$Builder' start='363' end='944' sourcepath='org/apache/hadoop/mapreduce/jobhistory/ReduceAttemptFinished.java' sourcefile='ReduceAttemptFinished.java'><Message>At ReduceAttemptFinished.java:[lines 363-944]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished$Builder</Message></Class><Class role='INTERFACE_TYPE' classname='org.apache.avro.data.RecordBuilder'><SourceLine classname='org.apache.avro.data.RecordBuilder' sourcepath='org/apache/avro/data/RecordBuilder.java' sourcefile='RecordBuilder.java'><Message>In RecordBuilder.java</Message></SourceLine><Message>Interface org.apache.avro.data.RecordBuilder</Message></Class><SourceLine synthetic='true' classname='org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished$Builder' start='363' end='944' sourcepath='org/apache/hadoop/mapreduce/jobhistory/ReduceAttemptFinished.java' sourcefile='ReduceAttemptFinished.java'><Message>At ReduceAttemptFinished.java:[lines 363-944]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='caa07d4f058f0e2b33a98bdcceef1e67' rank='20' abbrev='Dm' category='PERFORMANCE' priority='3' type='DM_STRING_TOSTRING' instanceOccurrenceMax='0'><ShortMessage>Method invokes toString() method on a String</ShortMessage><LongMessage>org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinishedEvent.getHostname() invokes toString() method on a String</LongMessage><Class classname='org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinishedEvent' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinishedEvent' start='45' end='281' sourcepath='org/apache/hadoop/mapreduce/jobhistory/ReduceAttemptFinishedEvent.java' sourcefile='ReduceAttemptFinishedEvent.java'><Message>At ReduceAttemptFinishedEvent.java:[lines 45-281]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinishedEvent</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinishedEvent' signature='()Ljava/lang/String;' name='getHostname' primary='true'><SourceLine endBytecode='49' classname='org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinishedEvent' start='218' end='218' sourcepath='org/apache/hadoop/mapreduce/jobhistory/ReduceAttemptFinishedEvent.java' sourcefile='ReduceAttemptFinishedEvent.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinishedEvent.getHostname()</Message></Method><SourceLine endBytecode='4' classname='org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinishedEvent' start='218' end='218' sourcepath='org/apache/hadoop/mapreduce/jobhistory/ReduceAttemptFinishedEvent.java' sourcefile='ReduceAttemptFinishedEvent.java' startBytecode='4' primary='true'><Message>At ReduceAttemptFinishedEvent.java:[line 218]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='2d7eee7d8c85df1d4e005290db85ee9d' rank='20' abbrev='Dm' category='PERFORMANCE' priority='3' type='DM_STRING_TOSTRING' instanceOccurrenceMax='0'><ShortMessage>Method invokes toString() method on a String</ShortMessage><LongMessage>org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinishedEvent.getRackName() invokes toString() method on a String</LongMessage><Class classname='org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinishedEvent' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinishedEvent' start='45' end='281' sourcepath='org/apache/hadoop/mapreduce/jobhistory/ReduceAttemptFinishedEvent.java' sourcefile='ReduceAttemptFinishedEvent.java'><Message>At ReduceAttemptFinishedEvent.java:[lines 45-281]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinishedEvent</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinishedEvent' signature='()Ljava/lang/String;' name='getRackName' primary='true'><SourceLine endBytecode='73' classname='org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinishedEvent' start='224' end='224' sourcepath='org/apache/hadoop/mapreduce/jobhistory/ReduceAttemptFinishedEvent.java' sourcefile='ReduceAttemptFinishedEvent.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinishedEvent.getRackName()</Message></Method><SourceLine endBytecode='15' classname='org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinishedEvent' start='224' end='224' sourcepath='org/apache/hadoop/mapreduce/jobhistory/ReduceAttemptFinishedEvent.java' sourcefile='ReduceAttemptFinishedEvent.java' startBytecode='15' primary='true'><Message>At ReduceAttemptFinishedEvent.java:[line 224]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='e1898283c689f6742354f847321594e4' rank='20' abbrev='Dm' category='PERFORMANCE' priority='3' type='DM_STRING_TOSTRING' instanceOccurrenceMax='0'><ShortMessage>Method invokes toString() method on a String</ShortMessage><LongMessage>org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinishedEvent.getState() invokes toString() method on a String</LongMessage><Class classname='org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinishedEvent' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinishedEvent' start='45' end='281' sourcepath='org/apache/hadoop/mapreduce/jobhistory/ReduceAttemptFinishedEvent.java' sourcefile='ReduceAttemptFinishedEvent.java'><Message>At ReduceAttemptFinishedEvent.java:[lines 45-281]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinishedEvent</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinishedEvent' signature='()Ljava/lang/String;' name='getState' primary='true'><SourceLine endBytecode='49' classname='org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinishedEvent' start='231' end='231' sourcepath='org/apache/hadoop/mapreduce/jobhistory/ReduceAttemptFinishedEvent.java' sourcefile='ReduceAttemptFinishedEvent.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinishedEvent.getState()</Message></Method><SourceLine endBytecode='4' classname='org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinishedEvent' start='231' end='231' sourcepath='org/apache/hadoop/mapreduce/jobhistory/ReduceAttemptFinishedEvent.java' sourcefile='ReduceAttemptFinishedEvent.java' startBytecode='4' primary='true'><Message>At ReduceAttemptFinishedEvent.java:[line 231]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='da20d5cc9ebeaea964dba06e60d197de' rank='20' abbrev='Dm' category='PERFORMANCE' priority='3' type='DM_STRING_TOSTRING' instanceOccurrenceMax='0'><ShortMessage>Method invokes toString() method on a String</ShortMessage><LongMessage>org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinishedEvent.getTaskStatus() invokes toString() method on a String</LongMessage><Class classname='org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinishedEvent' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinishedEvent' start='45' end='281' sourcepath='org/apache/hadoop/mapreduce/jobhistory/ReduceAttemptFinishedEvent.java' sourcefile='ReduceAttemptFinishedEvent.java'><Message>At ReduceAttemptFinishedEvent.java:[lines 45-281]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinishedEvent</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinishedEvent' signature='()Ljava/lang/String;' name='getTaskStatus' primary='true'><SourceLine endBytecode='49' classname='org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinishedEvent' start='203' end='203' sourcepath='org/apache/hadoop/mapreduce/jobhistory/ReduceAttemptFinishedEvent.java' sourcefile='ReduceAttemptFinishedEvent.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinishedEvent.getTaskStatus()</Message></Method><SourceLine endBytecode='4' classname='org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinishedEvent' start='203' end='203' sourcepath='org/apache/hadoop/mapreduce/jobhistory/ReduceAttemptFinishedEvent.java' sourcefile='ReduceAttemptFinishedEvent.java' startBytecode='4' primary='true'><Message>At ReduceAttemptFinishedEvent.java:[line 203]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='f91dc37d2359948a50a1e7db6d4682ec' cweid='374' rank='18' abbrev='EI' category='MALICIOUS_CODE' priority='2' type='EI_EXPOSE_REP' instanceOccurrenceMax='0'><ShortMessage>May expose internal representation by returning reference to mutable object</ShortMessage><LongMessage>org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinishedEvent.getClockSplits() may expose internal representation by returning ReduceAttemptFinishedEvent.clockSplits</LongMessage><Class classname='org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinishedEvent' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinishedEvent' start='45' end='281' sourcepath='org/apache/hadoop/mapreduce/jobhistory/ReduceAttemptFinishedEvent.java' sourcefile='ReduceAttemptFinishedEvent.java'><Message>At ReduceAttemptFinishedEvent.java:[lines 45-281]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinishedEvent</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinishedEvent' signature='()[I' name='getClockSplits' primary='true'><SourceLine endBytecode='46' classname='org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinishedEvent' start='247' end='247' sourcepath='org/apache/hadoop/mapreduce/jobhistory/ReduceAttemptFinishedEvent.java' sourcefile='ReduceAttemptFinishedEvent.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinishedEvent.getClockSplits()</Message></Method><Field isStatic='false' classname='org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinishedEvent' signature='[I' name='clockSplits' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinishedEvent' sourcepath='org/apache/hadoop/mapreduce/jobhistory/ReduceAttemptFinishedEvent.java' sourcefile='ReduceAttemptFinishedEvent.java'><Message>In ReduceAttemptFinishedEvent.java</Message></SourceLine><Message>Field org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinishedEvent.clockSplits</Message></Field><SourceLine endBytecode='4' classname='org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinishedEvent' start='247' end='247' sourcepath='org/apache/hadoop/mapreduce/jobhistory/ReduceAttemptFinishedEvent.java' sourcefile='ReduceAttemptFinishedEvent.java' startBytecode='4' primary='true'><Message>At ReduceAttemptFinishedEvent.java:[line 247]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='4242803af002a2a7dfe25a6c06a9b476' cweid='374' rank='18' abbrev='EI' category='MALICIOUS_CODE' priority='2' type='EI_EXPOSE_REP' instanceOccurrenceMax='0'><ShortMessage>May expose internal representation by returning reference to mutable object</ShortMessage><LongMessage>org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinishedEvent.getCpuUsages() may expose internal representation by returning ReduceAttemptFinishedEvent.cpuUsages</LongMessage><Class classname='org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinishedEvent' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinishedEvent' start='45' end='281' sourcepath='org/apache/hadoop/mapreduce/jobhistory/ReduceAttemptFinishedEvent.java' sourcefile='ReduceAttemptFinishedEvent.java'><Message>At ReduceAttemptFinishedEvent.java:[lines 45-281]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinishedEvent</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinishedEvent' signature='()[I' name='getCpuUsages' primary='true'><SourceLine endBytecode='46' classname='org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinishedEvent' start='250' end='250' sourcepath='org/apache/hadoop/mapreduce/jobhistory/ReduceAttemptFinishedEvent.java' sourcefile='ReduceAttemptFinishedEvent.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinishedEvent.getCpuUsages()</Message></Method><Field isStatic='false' classname='org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinishedEvent' signature='[I' name='cpuUsages' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinishedEvent' sourcepath='org/apache/hadoop/mapreduce/jobhistory/ReduceAttemptFinishedEvent.java' sourcefile='ReduceAttemptFinishedEvent.java'><Message>In ReduceAttemptFinishedEvent.java</Message></SourceLine><Message>Field org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinishedEvent.cpuUsages</Message></Field><SourceLine endBytecode='4' classname='org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinishedEvent' start='250' end='250' sourcepath='org/apache/hadoop/mapreduce/jobhistory/ReduceAttemptFinishedEvent.java' sourcefile='ReduceAttemptFinishedEvent.java' startBytecode='4' primary='true'><Message>At ReduceAttemptFinishedEvent.java:[line 250]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='a7626bd5aaf0cb92d90c362d5c497230' cweid='374' rank='18' abbrev='EI' category='MALICIOUS_CODE' priority='2' type='EI_EXPOSE_REP' instanceOccurrenceMax='0'><ShortMessage>May expose internal representation by returning reference to mutable object</ShortMessage><LongMessage>org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinishedEvent.getPhysMemKbytes() may expose internal representation by returning ReduceAttemptFinishedEvent.physMemKbytes</LongMessage><Class classname='org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinishedEvent' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinishedEvent' start='45' end='281' sourcepath='org/apache/hadoop/mapreduce/jobhistory/ReduceAttemptFinishedEvent.java' sourcefile='ReduceAttemptFinishedEvent.java'><Message>At ReduceAttemptFinishedEvent.java:[lines 45-281]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinishedEvent</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinishedEvent' signature='()[I' name='getPhysMemKbytes' primary='true'><SourceLine endBytecode='46' classname='org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinishedEvent' start='256' end='256' sourcepath='org/apache/hadoop/mapreduce/jobhistory/ReduceAttemptFinishedEvent.java' sourcefile='ReduceAttemptFinishedEvent.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinishedEvent.getPhysMemKbytes()</Message></Method><Field isStatic='false' classname='org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinishedEvent' signature='[I' name='physMemKbytes' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinishedEvent' sourcepath='org/apache/hadoop/mapreduce/jobhistory/ReduceAttemptFinishedEvent.java' sourcefile='ReduceAttemptFinishedEvent.java'><Message>In ReduceAttemptFinishedEvent.java</Message></SourceLine><Message>Field org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinishedEvent.physMemKbytes</Message></Field><SourceLine endBytecode='4' classname='org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinishedEvent' start='256' end='256' sourcepath='org/apache/hadoop/mapreduce/jobhistory/ReduceAttemptFinishedEvent.java' sourcefile='ReduceAttemptFinishedEvent.java' startBytecode='4' primary='true'><Message>At ReduceAttemptFinishedEvent.java:[line 256]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='400feeb6d09f7b728c3baa7f22d3a19e' cweid='374' rank='18' abbrev='EI' category='MALICIOUS_CODE' priority='2' type='EI_EXPOSE_REP' instanceOccurrenceMax='0'><ShortMessage>May expose internal representation by returning reference to mutable object</ShortMessage><LongMessage>org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinishedEvent.getVMemKbytes() may expose internal representation by returning ReduceAttemptFinishedEvent.vMemKbytes</LongMessage><Class classname='org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinishedEvent' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinishedEvent' start='45' end='281' sourcepath='org/apache/hadoop/mapreduce/jobhistory/ReduceAttemptFinishedEvent.java' sourcefile='ReduceAttemptFinishedEvent.java'><Message>At ReduceAttemptFinishedEvent.java:[lines 45-281]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinishedEvent</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinishedEvent' signature='()[I' name='getVMemKbytes' primary='true'><SourceLine endBytecode='46' classname='org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinishedEvent' start='253' end='253' sourcepath='org/apache/hadoop/mapreduce/jobhistory/ReduceAttemptFinishedEvent.java' sourcefile='ReduceAttemptFinishedEvent.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinishedEvent.getVMemKbytes()</Message></Method><Field isStatic='false' classname='org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinishedEvent' signature='[I' name='vMemKbytes' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinishedEvent' sourcepath='org/apache/hadoop/mapreduce/jobhistory/ReduceAttemptFinishedEvent.java' sourcefile='ReduceAttemptFinishedEvent.java'><Message>In ReduceAttemptFinishedEvent.java</Message></SourceLine><Message>Field org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinishedEvent.vMemKbytes</Message></Field><SourceLine endBytecode='4' classname='org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinishedEvent' start='253' end='253' sourcepath='org/apache/hadoop/mapreduce/jobhistory/ReduceAttemptFinishedEvent.java' sourcefile='ReduceAttemptFinishedEvent.java' startBytecode='4' primary='true'><Message>At ReduceAttemptFinishedEvent.java:[line 253]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='cc673b476f0c8fc910d1991a7f75f196' cweid='374' rank='18' abbrev='EI2' category='MALICIOUS_CODE' priority='2' type='EI_EXPOSE_REP2' instanceOccurrenceMax='0'><ShortMessage>May expose internal representation by incorporating reference to mutable object</ShortMessage><LongMessage>new org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinishedEvent(TaskAttemptID, TaskType, String, long, long, long, String, int, String, String, Counters, int[][], long) may expose internal representation by storing an externally mutable object into ReduceAttemptFinishedEvent.allSplits</LongMessage><Class classname='org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinishedEvent' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinishedEvent' start='45' end='281' sourcepath='org/apache/hadoop/mapreduce/jobhistory/ReduceAttemptFinishedEvent.java' sourcefile='ReduceAttemptFinishedEvent.java'><Message>At ReduceAttemptFinishedEvent.java:[lines 45-281]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinishedEvent</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinishedEvent' signature='(Lorg/apache/hadoop/mapreduce/TaskAttemptID;Lorg/apache/hadoop/mapreduce/TaskType;Ljava/lang/String;JJJLjava/lang/String;ILjava/lang/String;Ljava/lang/String;Lorg/apache/hadoop/mapreduce/Counters;[[IJ)V' name='&lt;init&gt;' primary='true'><SourceLine endBytecode='368' classname='org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinishedEvent' start='87' end='105' sourcepath='org/apache/hadoop/mapreduce/jobhistory/ReduceAttemptFinishedEvent.java' sourcefile='ReduceAttemptFinishedEvent.java' startBytecode='0'></SourceLine><Message>In method new org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinishedEvent(TaskAttemptID, TaskType, String, long, long, long, String, int, String, String, Counters, int[][], long)</Message></Method><Field isStatic='false' classname='org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinishedEvent' signature='[[I' name='allSplits' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinishedEvent' sourcepath='org/apache/hadoop/mapreduce/jobhistory/ReduceAttemptFinishedEvent.java' sourcefile='ReduceAttemptFinishedEvent.java'><Message>In ReduceAttemptFinishedEvent.java</Message></SourceLine><Message>Field org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinishedEvent.allSplits</Message></Field><LocalVariable role='LOCAL_VARIABLE_NAMED' pc='75' name='allSplits' register='15'><Message>Local variable named allSplits</Message></LocalVariable><SourceLine endBytecode='75' classname='org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinishedEvent' start='99' end='99' sourcepath='org/apache/hadoop/mapreduce/jobhistory/ReduceAttemptFinishedEvent.java' sourcefile='ReduceAttemptFinishedEvent.java' startBytecode='75' primary='true'><Message>At ReduceAttemptFinishedEvent.java:[line 99]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='1d1a37463a480722673f0392965815b' rank='20' abbrev='RI' category='STYLE' priority='3' type='RI_REDUNDANT_INTERFACES' instanceOccurrenceMax='0'><ShortMessage>Class implements same interface as superclass</ShortMessage><LongMessage>Class org.apache.hadoop.mapreduce.jobhistory.TaskAttemptFinished implements same interface as superclass</LongMessage><Class classname='org.apache.hadoop.mapreduce.jobhistory.TaskAttemptFinished' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.jobhistory.TaskAttemptFinished' start='10' end='224' sourcepath='org/apache/hadoop/mapreduce/jobhistory/TaskAttemptFinished.java' sourcefile='TaskAttemptFinished.java'><Message>At TaskAttemptFinished.java:[lines 10-224]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.jobhistory.TaskAttemptFinished</Message></Class><Class role='INTERFACE_TYPE' classname='org.apache.avro.specific.SpecificRecord'><SourceLine classname='org.apache.avro.specific.SpecificRecord' sourcepath='org/apache/avro/specific/SpecificRecord.java' sourcefile='SpecificRecord.java'><Message>In SpecificRecord.java</Message></SourceLine><Message>Interface org.apache.avro.specific.SpecificRecord</Message></Class><SourceLine synthetic='true' classname='org.apache.hadoop.mapreduce.jobhistory.TaskAttemptFinished' start='10' end='224' sourcepath='org/apache/hadoop/mapreduce/jobhistory/TaskAttemptFinished.java' sourcefile='TaskAttemptFinished.java'><Message>At TaskAttemptFinished.java:[lines 10-224]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='d1314e760a5f848c6fb57ef39153ac1e' cweid='396' rank='20' abbrev='REC' category='STYLE' priority='3' type='REC_CATCH_EXCEPTION' instanceOccurrenceMax='0'><ShortMessage>Exception is caught when Exception is not thrown</ShortMessage><LongMessage>Exception is caught when Exception is not thrown in org.apache.hadoop.mapreduce.jobhistory.TaskAttemptFinished$Builder.build()</LongMessage><Class classname='org.apache.hadoop.mapreduce.jobhistory.TaskAttemptFinished$Builder' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.jobhistory.TaskAttemptFinished$Builder' start='230' end='569' sourcepath='org/apache/hadoop/mapreduce/jobhistory/TaskAttemptFinished.java' sourcefile='TaskAttemptFinished.java'><Message>At TaskAttemptFinished.java:[lines 230-569]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.jobhistory.TaskAttemptFinished$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapreduce.jobhistory.TaskAttemptFinished$Builder' signature='()Lorg/apache/hadoop/mapreduce/jobhistory/TaskAttemptFinished;' name='build' primary='true'><SourceLine endBytecode='681' classname='org.apache.hadoop.mapreduce.jobhistory.TaskAttemptFinished$Builder' start='557' end='569' sourcepath='org/apache/hadoop/mapreduce/jobhistory/TaskAttemptFinished.java' sourcefile='TaskAttemptFinished.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapreduce.jobhistory.TaskAttemptFinished$Builder.build()</Message></Method><SourceLine endBytecode='316' classname='org.apache.hadoop.mapreduce.jobhistory.TaskAttemptFinished$Builder' start='568' end='568' sourcepath='org/apache/hadoop/mapreduce/jobhistory/TaskAttemptFinished.java' sourcefile='TaskAttemptFinished.java' startBytecode='316' primary='true'><Message>At TaskAttemptFinished.java:[line 568]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='d96b094785025dffd6085462f30d7d60' rank='20' abbrev='RI' category='STYLE' priority='3' type='RI_REDUNDANT_INTERFACES' instanceOccurrenceMax='0'><ShortMessage>Class implements same interface as superclass</ShortMessage><LongMessage>Class org.apache.hadoop.mapreduce.jobhistory.TaskAttemptFinished$Builder implements same interface as superclass</LongMessage><Class classname='org.apache.hadoop.mapreduce.jobhistory.TaskAttemptFinished$Builder' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.jobhistory.TaskAttemptFinished$Builder' start='230' end='569' sourcepath='org/apache/hadoop/mapreduce/jobhistory/TaskAttemptFinished.java' sourcefile='TaskAttemptFinished.java'><Message>At TaskAttemptFinished.java:[lines 230-569]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.jobhistory.TaskAttemptFinished$Builder</Message></Class><Class role='INTERFACE_TYPE' classname='org.apache.avro.data.RecordBuilder'><SourceLine classname='org.apache.avro.data.RecordBuilder' sourcepath='org/apache/avro/data/RecordBuilder.java' sourcefile='RecordBuilder.java'><Message>In RecordBuilder.java</Message></SourceLine><Message>Interface org.apache.avro.data.RecordBuilder</Message></Class><SourceLine synthetic='true' classname='org.apache.hadoop.mapreduce.jobhistory.TaskAttemptFinished$Builder' start='230' end='569' sourcepath='org/apache/hadoop/mapreduce/jobhistory/TaskAttemptFinished.java' sourcefile='TaskAttemptFinished.java'><Message>At TaskAttemptFinished.java:[lines 230-569]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='ac9aa4d961a53aec10bda90f7d899114' rank='20' abbrev='Dm' category='PERFORMANCE' priority='3' type='DM_STRING_TOSTRING' instanceOccurrenceMax='0'><ShortMessage>Method invokes toString() method on a String</ShortMessage><LongMessage>org.apache.hadoop.mapreduce.jobhistory.TaskAttemptFinishedEvent.getHostname() invokes toString() method on a String</LongMessage><Class classname='org.apache.hadoop.mapreduce.jobhistory.TaskAttemptFinishedEvent' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.jobhistory.TaskAttemptFinishedEvent' start='44' end='184' sourcepath='org/apache/hadoop/mapreduce/jobhistory/TaskAttemptFinishedEvent.java' sourcefile='TaskAttemptFinishedEvent.java'><Message>At TaskAttemptFinishedEvent.java:[lines 44-184]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.jobhistory.TaskAttemptFinishedEvent</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapreduce.jobhistory.TaskAttemptFinishedEvent' signature='()Ljava/lang/String;' name='getHostname' primary='true'><SourceLine endBytecode='49' classname='org.apache.hadoop.mapreduce.jobhistory.TaskAttemptFinishedEvent' start='143' end='143' sourcepath='org/apache/hadoop/mapreduce/jobhistory/TaskAttemptFinishedEvent.java' sourcefile='TaskAttemptFinishedEvent.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapreduce.jobhistory.TaskAttemptFinishedEvent.getHostname()</Message></Method><SourceLine endBytecode='4' classname='org.apache.hadoop.mapreduce.jobhistory.TaskAttemptFinishedEvent' start='143' end='143' sourcepath='org/apache/hadoop/mapreduce/jobhistory/TaskAttemptFinishedEvent.java' sourcefile='TaskAttemptFinishedEvent.java' startBytecode='4' primary='true'><Message>At TaskAttemptFinishedEvent.java:[line 143]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='99b36d53714a66fea2dce1018ff4513b' rank='20' abbrev='Dm' category='PERFORMANCE' priority='3' type='DM_STRING_TOSTRING' instanceOccurrenceMax='0'><ShortMessage>Method invokes toString() method on a String</ShortMessage><LongMessage>org.apache.hadoop.mapreduce.jobhistory.TaskAttemptFinishedEvent.getRackName() invokes toString() method on a String</LongMessage><Class classname='org.apache.hadoop.mapreduce.jobhistory.TaskAttemptFinishedEvent' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.jobhistory.TaskAttemptFinishedEvent' start='44' end='184' sourcepath='org/apache/hadoop/mapreduce/jobhistory/TaskAttemptFinishedEvent.java' sourcefile='TaskAttemptFinishedEvent.java'><Message>At TaskAttemptFinishedEvent.java:[lines 44-184]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.jobhistory.TaskAttemptFinishedEvent</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapreduce.jobhistory.TaskAttemptFinishedEvent' signature='()Ljava/lang/String;' name='getRackName' primary='true'><SourceLine endBytecode='73' classname='org.apache.hadoop.mapreduce.jobhistory.TaskAttemptFinishedEvent' start='147' end='147' sourcepath='org/apache/hadoop/mapreduce/jobhistory/TaskAttemptFinishedEvent.java' sourcefile='TaskAttemptFinishedEvent.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapreduce.jobhistory.TaskAttemptFinishedEvent.getRackName()</Message></Method><SourceLine endBytecode='15' classname='org.apache.hadoop.mapreduce.jobhistory.TaskAttemptFinishedEvent' start='147' end='147' sourcepath='org/apache/hadoop/mapreduce/jobhistory/TaskAttemptFinishedEvent.java' sourcefile='TaskAttemptFinishedEvent.java' startBytecode='15' primary='true'><Message>At TaskAttemptFinishedEvent.java:[line 147]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='9576550f982d2c26f8d48a4f1bff2771' rank='20' abbrev='Dm' category='PERFORMANCE' priority='3' type='DM_STRING_TOSTRING' instanceOccurrenceMax='0'><ShortMessage>Method invokes toString() method on a String</ShortMessage><LongMessage>org.apache.hadoop.mapreduce.jobhistory.TaskAttemptFinishedEvent.getState() invokes toString() method on a String</LongMessage><Class classname='org.apache.hadoop.mapreduce.jobhistory.TaskAttemptFinishedEvent' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.jobhistory.TaskAttemptFinishedEvent' start='44' end='184' sourcepath='org/apache/hadoop/mapreduce/jobhistory/TaskAttemptFinishedEvent.java' sourcefile='TaskAttemptFinishedEvent.java'><Message>At TaskAttemptFinishedEvent.java:[lines 44-184]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.jobhistory.TaskAttemptFinishedEvent</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapreduce.jobhistory.TaskAttemptFinishedEvent' signature='()Ljava/lang/String;' name='getState' primary='true'><SourceLine endBytecode='49' classname='org.apache.hadoop.mapreduce.jobhistory.TaskAttemptFinishedEvent' start='154' end='154' sourcepath='org/apache/hadoop/mapreduce/jobhistory/TaskAttemptFinishedEvent.java' sourcefile='TaskAttemptFinishedEvent.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapreduce.jobhistory.TaskAttemptFinishedEvent.getState()</Message></Method><SourceLine endBytecode='4' classname='org.apache.hadoop.mapreduce.jobhistory.TaskAttemptFinishedEvent' start='154' end='154' sourcepath='org/apache/hadoop/mapreduce/jobhistory/TaskAttemptFinishedEvent.java' sourcefile='TaskAttemptFinishedEvent.java' startBytecode='4' primary='true'><Message>At TaskAttemptFinishedEvent.java:[line 154]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='62fe3cb84c871cbebe19839db5a6b6b5' rank='20' abbrev='Dm' category='PERFORMANCE' priority='3' type='DM_STRING_TOSTRING' instanceOccurrenceMax='0'><ShortMessage>Method invokes toString() method on a String</ShortMessage><LongMessage>org.apache.hadoop.mapreduce.jobhistory.TaskAttemptFinishedEvent.getTaskStatus() invokes toString() method on a String</LongMessage><Class classname='org.apache.hadoop.mapreduce.jobhistory.TaskAttemptFinishedEvent' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.jobhistory.TaskAttemptFinishedEvent' start='44' end='184' sourcepath='org/apache/hadoop/mapreduce/jobhistory/TaskAttemptFinishedEvent.java' sourcefile='TaskAttemptFinishedEvent.java'><Message>At TaskAttemptFinishedEvent.java:[lines 44-184]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.jobhistory.TaskAttemptFinishedEvent</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapreduce.jobhistory.TaskAttemptFinishedEvent' signature='()Ljava/lang/String;' name='getTaskStatus' primary='true'><SourceLine endBytecode='49' classname='org.apache.hadoop.mapreduce.jobhistory.TaskAttemptFinishedEvent' start='132' end='132' sourcepath='org/apache/hadoop/mapreduce/jobhistory/TaskAttemptFinishedEvent.java' sourcefile='TaskAttemptFinishedEvent.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapreduce.jobhistory.TaskAttemptFinishedEvent.getTaskStatus()</Message></Method><SourceLine endBytecode='4' classname='org.apache.hadoop.mapreduce.jobhistory.TaskAttemptFinishedEvent' start='132' end='132' sourcepath='org/apache/hadoop/mapreduce/jobhistory/TaskAttemptFinishedEvent.java' sourcefile='TaskAttemptFinishedEvent.java' startBytecode='4' primary='true'><Message>At TaskAttemptFinishedEvent.java:[line 132]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='61c3ae805d8e4fffec178b6cba2fd17b' rank='20' abbrev='RI' category='STYLE' priority='3' type='RI_REDUNDANT_INTERFACES' instanceOccurrenceMax='0'><ShortMessage>Class implements same interface as superclass</ShortMessage><LongMessage>Class org.apache.hadoop.mapreduce.jobhistory.TaskAttemptStarted implements same interface as superclass</LongMessage><Class classname='org.apache.hadoop.mapreduce.jobhistory.TaskAttemptStarted' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.jobhistory.TaskAttemptStarted' start='10' end='243' sourcepath='org/apache/hadoop/mapreduce/jobhistory/TaskAttemptStarted.java' sourcefile='TaskAttemptStarted.java'><Message>At TaskAttemptStarted.java:[lines 10-243]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.jobhistory.TaskAttemptStarted</Message></Class><Class role='INTERFACE_TYPE' classname='org.apache.avro.specific.SpecificRecord'><SourceLine classname='org.apache.avro.specific.SpecificRecord' sourcepath='org/apache/avro/specific/SpecificRecord.java' sourcefile='SpecificRecord.java'><Message>In SpecificRecord.java</Message></SourceLine><Message>Interface org.apache.avro.specific.SpecificRecord</Message></Class><SourceLine synthetic='true' classname='org.apache.hadoop.mapreduce.jobhistory.TaskAttemptStarted' start='10' end='243' sourcepath='org/apache/hadoop/mapreduce/jobhistory/TaskAttemptStarted.java' sourcefile='TaskAttemptStarted.java'><Message>At TaskAttemptStarted.java:[lines 10-243]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='724a3a7b459a0f5204e941b1d6e8d4fa' cweid='396' rank='20' abbrev='REC' category='STYLE' priority='3' type='REC_CATCH_EXCEPTION' instanceOccurrenceMax='0'><ShortMessage>Exception is caught when Exception is not thrown</ShortMessage><LongMessage>Exception is caught when Exception is not thrown in org.apache.hadoop.mapreduce.jobhistory.TaskAttemptStarted$Builder.build()</LongMessage><Class classname='org.apache.hadoop.mapreduce.jobhistory.TaskAttemptStarted$Builder' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.jobhistory.TaskAttemptStarted$Builder' start='249' end='621' sourcepath='org/apache/hadoop/mapreduce/jobhistory/TaskAttemptStarted.java' sourcefile='TaskAttemptStarted.java'><Message>At TaskAttemptStarted.java:[lines 249-621]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.jobhistory.TaskAttemptStarted$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapreduce.jobhistory.TaskAttemptStarted$Builder' signature='()Lorg/apache/hadoop/mapreduce/jobhistory/TaskAttemptStarted;' name='build' primary='true'><SourceLine endBytecode='745' classname='org.apache.hadoop.mapreduce.jobhistory.TaskAttemptStarted$Builder' start='608' end='621' sourcepath='org/apache/hadoop/mapreduce/jobhistory/TaskAttemptStarted.java' sourcefile='TaskAttemptStarted.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapreduce.jobhistory.TaskAttemptStarted$Builder.build()</Message></Method><SourceLine endBytecode='357' classname='org.apache.hadoop.mapreduce.jobhistory.TaskAttemptStarted$Builder' start='620' end='620' sourcepath='org/apache/hadoop/mapreduce/jobhistory/TaskAttemptStarted.java' sourcefile='TaskAttemptStarted.java' startBytecode='357' primary='true'><Message>At TaskAttemptStarted.java:[line 620]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='ce99d5fbf269fe460171b9d691280995' rank='20' abbrev='RI' category='STYLE' priority='3' type='RI_REDUNDANT_INTERFACES' instanceOccurrenceMax='0'><ShortMessage>Class implements same interface as superclass</ShortMessage><LongMessage>Class org.apache.hadoop.mapreduce.jobhistory.TaskAttemptStarted$Builder implements same interface as superclass</LongMessage><Class classname='org.apache.hadoop.mapreduce.jobhistory.TaskAttemptStarted$Builder' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.jobhistory.TaskAttemptStarted$Builder' start='249' end='621' sourcepath='org/apache/hadoop/mapreduce/jobhistory/TaskAttemptStarted.java' sourcefile='TaskAttemptStarted.java'><Message>At TaskAttemptStarted.java:[lines 249-621]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.jobhistory.TaskAttemptStarted$Builder</Message></Class><Class role='INTERFACE_TYPE' classname='org.apache.avro.data.RecordBuilder'><SourceLine classname='org.apache.avro.data.RecordBuilder' sourcepath='org/apache/avro/data/RecordBuilder.java' sourcefile='RecordBuilder.java'><Message>In RecordBuilder.java</Message></SourceLine><Message>Interface org.apache.avro.data.RecordBuilder</Message></Class><SourceLine synthetic='true' classname='org.apache.hadoop.mapreduce.jobhistory.TaskAttemptStarted$Builder' start='249' end='621' sourcepath='org/apache/hadoop/mapreduce/jobhistory/TaskAttemptStarted.java' sourcefile='TaskAttemptStarted.java'><Message>At TaskAttemptStarted.java:[lines 249-621]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='12f70ce2b9e4f0320acf1db35b829377' rank='20' abbrev='RI' category='STYLE' priority='3' type='RI_REDUNDANT_INTERFACES' instanceOccurrenceMax='0'><ShortMessage>Class implements same interface as superclass</ShortMessage><LongMessage>Class org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion implements same interface as superclass</LongMessage><Class classname='org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion' start='10' end='319' sourcepath='org/apache/hadoop/mapreduce/jobhistory/TaskAttemptUnsuccessfulCompletion.java' sourcefile='TaskAttemptUnsuccessfulCompletion.java'><Message>At TaskAttemptUnsuccessfulCompletion.java:[lines 10-319]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion</Message></Class><Class role='INTERFACE_TYPE' classname='org.apache.avro.specific.SpecificRecord'><SourceLine classname='org.apache.avro.specific.SpecificRecord' sourcepath='org/apache/avro/specific/SpecificRecord.java' sourcefile='SpecificRecord.java'><Message>In SpecificRecord.java</Message></SourceLine><Message>Interface org.apache.avro.specific.SpecificRecord</Message></Class><SourceLine synthetic='true' classname='org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion' start='10' end='319' sourcepath='org/apache/hadoop/mapreduce/jobhistory/TaskAttemptUnsuccessfulCompletion.java' sourcefile='TaskAttemptUnsuccessfulCompletion.java'><Message>At TaskAttemptUnsuccessfulCompletion.java:[lines 10-319]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='1bc9f0f99682e209064b385dc954036f' cweid='396' rank='20' abbrev='REC' category='STYLE' priority='3' type='REC_CATCH_EXCEPTION' instanceOccurrenceMax='0'><ShortMessage>Exception is caught when Exception is not thrown</ShortMessage><LongMessage>Exception is caught when Exception is not thrown in org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion$Builder.build()</LongMessage><Class classname='org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion$Builder' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion$Builder' start='325' end='838' sourcepath='org/apache/hadoop/mapreduce/jobhistory/TaskAttemptUnsuccessfulCompletion.java' sourcefile='TaskAttemptUnsuccessfulCompletion.java'><Message>At TaskAttemptUnsuccessfulCompletion.java:[lines 325-838]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion$Builder</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion$Builder' signature='()Lorg/apache/hadoop/mapreduce/jobhistory/TaskAttemptUnsuccessfulCompletion;' name='build' primary='true'><SourceLine endBytecode='992' classname='org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion$Builder' start='821' end='838' sourcepath='org/apache/hadoop/mapreduce/jobhistory/TaskAttemptUnsuccessfulCompletion.java' sourcefile='TaskAttemptUnsuccessfulCompletion.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion$Builder.build()</Message></Method><SourceLine endBytecode='494' classname='org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion$Builder' start='837' end='837' sourcepath='org/apache/hadoop/mapreduce/jobhistory/TaskAttemptUnsuccessfulCompletion.java' sourcefile='TaskAttemptUnsuccessfulCompletion.java' startBytecode='494' primary='true'><Message>At TaskAttemptUnsuccessfulCompletion.java:[line 837]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='8c7dd4957092c24db576952f758b54fc' rank='20' abbrev='RI' category='STYLE' priority='3' type='RI_REDUNDANT_INTERFACES' instanceOccurrenceMax='0'><ShortMessage>Class implements same interface as superclass</ShortMessage><LongMessage>Class org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion$Builder implements same interface as superclass</LongMessage><Class classname='org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion$Builder' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion$Builder' start='325' end='838' sourcepath='org/apache/hadoop/mapreduce/jobhistory/TaskAttemptUnsuccessfulCompletion.java' sourcefile='TaskAttemptUnsuccessfulCompletion.java'><Message>At TaskAttemptUnsuccessfulCompletion.java:[lines 325-838]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion$Builder</Message></Class><Class role='INTERFACE_TYPE' classname='org.apache.avro.data.RecordBuilder'><SourceLine classname='org.apache.avro.data.RecordBuilder' sourcepath='org/apache/avro/data/RecordBuilder.java' sourcefile='RecordBuilder.java'><Message>In RecordBuilder.java</Message></SourceLine><Message>Interface org.apache.avro.data.RecordBuilder</Message></Class><SourceLine synthetic='true' classname='org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion$Builder' start='325' end='838' sourcepath='org/apache/hadoop/mapreduce/jobhistory/TaskAttemptUnsuccessfulCompletion.java' sourcefile='TaskAttemptUnsuccessfulCompletion.java'><Message>At TaskAttemptUnsuccessfulCompletion.java:[lines 325-838]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='d61ad24ea5d912088f9177361c8e9a7f' rank='20' abbrev='Dm' category='PERFORMANCE' priority='3' type='DM_STRING_TOSTRING' instanceOccurrenceMax='0'><ShortMessage>Method invokes toString() method on a String</ShortMessage><LongMessage>org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletionEvent.getError() invokes toString() method on a String</LongMessage><Class classname='org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletionEvent' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletionEvent' start='46' end='300' sourcepath='org/apache/hadoop/mapreduce/jobhistory/TaskAttemptUnsuccessfulCompletionEvent.java' sourcefile='TaskAttemptUnsuccessfulCompletionEvent.java'><Message>At TaskAttemptUnsuccessfulCompletionEvent.java:[lines 46-300]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletionEvent</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletionEvent' signature='()Ljava/lang/String;' name='getError' primary='true'><SourceLine endBytecode='49' classname='org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletionEvent' start='237' end='237' sourcepath='org/apache/hadoop/mapreduce/jobhistory/TaskAttemptUnsuccessfulCompletionEvent.java' sourcefile='TaskAttemptUnsuccessfulCompletionEvent.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletionEvent.getError()</Message></Method><SourceLine endBytecode='4' classname='org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletionEvent' start='237' end='237' sourcepath='org/apache/hadoop/mapreduce/jobhistory/TaskAttemptUnsuccessfulCompletionEvent.java' sourcefile='TaskAttemptUnsuccessfulCompletionEvent.java' startBytecode='4' primary='true'><Message>At TaskAttemptUnsuccessfulCompletionEvent.java:[line 237]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='f3ca2f137a3f2e53c6e02724e37022d9' rank='20' abbrev='Dm' category='PERFORMANCE' priority='3' type='DM_STRING_TOSTRING' instanceOccurrenceMax='0'><ShortMessage>Method invokes toString() method on a String</ShortMessage><LongMessage>org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletionEvent.getRackName() invokes toString() method on a String</LongMessage><Class classname='org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletionEvent' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletionEvent' start='46' end='300' sourcepath='org/apache/hadoop/mapreduce/jobhistory/TaskAttemptUnsuccessfulCompletionEvent.java' sourcefile='TaskAttemptUnsuccessfulCompletionEvent.java'><Message>At TaskAttemptUnsuccessfulCompletionEvent.java:[lines 46-300]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletionEvent</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletionEvent' signature='()Ljava/lang/String;' name='getRackName' primary='true'><SourceLine endBytecode='73' classname='org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletionEvent' start='233' end='233' sourcepath='org/apache/hadoop/mapreduce/jobhistory/TaskAttemptUnsuccessfulCompletionEvent.java' sourcefile='TaskAttemptUnsuccessfulCompletionEvent.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletionEvent.getRackName()</Message></Method><SourceLine endBytecode='15' classname='org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletionEvent' start='233' end='233' sourcepath='org/apache/hadoop/mapreduce/jobhistory/TaskAttemptUnsuccessfulCompletionEvent.java' sourcefile='TaskAttemptUnsuccessfulCompletionEvent.java' startBytecode='15' primary='true'><Message>At TaskAttemptUnsuccessfulCompletionEvent.java:[line 233]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='e9a734ac71d5c4e62cdee883dcf2e344' rank='20' abbrev='Dm' category='PERFORMANCE' priority='3' type='DM_STRING_TOSTRING' instanceOccurrenceMax='0'><ShortMessage>Method invokes toString() method on a String</ShortMessage><LongMessage>org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletionEvent.getTaskStatus() invokes toString() method on a String</LongMessage><Class classname='org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletionEvent' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletionEvent' start='46' end='300' sourcepath='org/apache/hadoop/mapreduce/jobhistory/TaskAttemptUnsuccessfulCompletionEvent.java' sourcefile='TaskAttemptUnsuccessfulCompletionEvent.java'><Message>At TaskAttemptUnsuccessfulCompletionEvent.java:[lines 46-300]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletionEvent</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletionEvent' signature='()Ljava/lang/String;' name='getTaskStatus' primary='true'><SourceLine endBytecode='49' classname='org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletionEvent' start='243' end='243' sourcepath='org/apache/hadoop/mapreduce/jobhistory/TaskAttemptUnsuccessfulCompletionEvent.java' sourcefile='TaskAttemptUnsuccessfulCompletionEvent.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletionEvent.getTaskStatus()</Message></Method><SourceLine endBytecode='4' classname='org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletionEvent' start='243' end='243' sourcepath='org/apache/hadoop/mapreduce/jobhistory/TaskAttemptUnsuccessfulCompletionEvent.java' sourcefile='TaskAttemptUnsuccessfulCompletionEvent.java' startBytecode='4' primary='true'><Message>At TaskAttemptUnsuccessfulCompletionEvent.java:[line 243]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='baf28da06ab12dba64e42bb9cb20a8a' cweid='374' rank='18' abbrev='EI' category='MALICIOUS_CODE' priority='2' type='EI_EXPOSE_REP' instanceOccurrenceMax='0'><ShortMessage>May expose internal representation by returning reference to mutable object</ShortMessage><LongMessage>org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletionEvent.getClockSplits() may expose internal representation by returning TaskAttemptUnsuccessfulCompletionEvent.clockSplits</LongMessage><Class classname='org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletionEvent' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletionEvent' start='46' end='300' sourcepath='org/apache/hadoop/mapreduce/jobhistory/TaskAttemptUnsuccessfulCompletionEvent.java' sourcefile='TaskAttemptUnsuccessfulCompletionEvent.java'><Message>At TaskAttemptUnsuccessfulCompletionEvent.java:[lines 46-300]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletionEvent</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletionEvent' signature='()[I' name='getClockSplits' primary='true'><SourceLine endBytecode='46' classname='org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletionEvent' start='265' end='265' sourcepath='org/apache/hadoop/mapreduce/jobhistory/TaskAttemptUnsuccessfulCompletionEvent.java' sourcefile='TaskAttemptUnsuccessfulCompletionEvent.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletionEvent.getClockSplits()</Message></Method><Field isStatic='false' classname='org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletionEvent' signature='[I' name='clockSplits' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletionEvent' sourcepath='org/apache/hadoop/mapreduce/jobhistory/TaskAttemptUnsuccessfulCompletionEvent.java' sourcefile='TaskAttemptUnsuccessfulCompletionEvent.java'><Message>In TaskAttemptUnsuccessfulCompletionEvent.java</Message></SourceLine><Message>Field org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletionEvent.clockSplits</Message></Field><SourceLine endBytecode='4' classname='org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletionEvent' start='265' end='265' sourcepath='org/apache/hadoop/mapreduce/jobhistory/TaskAttemptUnsuccessfulCompletionEvent.java' sourcefile='TaskAttemptUnsuccessfulCompletionEvent.java' startBytecode='4' primary='true'><Message>At TaskAttemptUnsuccessfulCompletionEvent.java:[line 265]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='49ffd8567b5690055005326664cada5e' cweid='374' rank='18' abbrev='EI' category='MALICIOUS_CODE' priority='2' type='EI_EXPOSE_REP' instanceOccurrenceMax='0'><ShortMessage>May expose internal representation by returning reference to mutable object</ShortMessage><LongMessage>org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletionEvent.getCpuUsages() may expose internal representation by returning TaskAttemptUnsuccessfulCompletionEvent.cpuUsages</LongMessage><Class classname='org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletionEvent' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletionEvent' start='46' end='300' sourcepath='org/apache/hadoop/mapreduce/jobhistory/TaskAttemptUnsuccessfulCompletionEvent.java' sourcefile='TaskAttemptUnsuccessfulCompletionEvent.java'><Message>At TaskAttemptUnsuccessfulCompletionEvent.java:[lines 46-300]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletionEvent</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletionEvent' signature='()[I' name='getCpuUsages' primary='true'><SourceLine endBytecode='46' classname='org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletionEvent' start='268' end='268' sourcepath='org/apache/hadoop/mapreduce/jobhistory/TaskAttemptUnsuccessfulCompletionEvent.java' sourcefile='TaskAttemptUnsuccessfulCompletionEvent.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletionEvent.getCpuUsages()</Message></Method><Field isStatic='false' classname='org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletionEvent' signature='[I' name='cpuUsages' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletionEvent' sourcepath='org/apache/hadoop/mapreduce/jobhistory/TaskAttemptUnsuccessfulCompletionEvent.java' sourcefile='TaskAttemptUnsuccessfulCompletionEvent.java'><Message>In TaskAttemptUnsuccessfulCompletionEvent.java</Message></SourceLine><Message>Field org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletionEvent.cpuUsages</Message></Field><SourceLine endBytecode='4' classname='org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletionEvent' start='268' end='268' sourcepath='org/apache/hadoop/mapreduce/jobhistory/TaskAttemptUnsuccessfulCompletionEvent.java' sourcefile='TaskAttemptUnsuccessfulCompletionEvent.java' startBytecode='4' primary='true'><Message>At TaskAttemptUnsuccessfulCompletionEvent.java:[line 268]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='b68bfb098233fb83ef3881b2cf6b1ca8' cweid='374' rank='18' abbrev='EI' category='MALICIOUS_CODE' priority='2' type='EI_EXPOSE_REP' instanceOccurrenceMax='0'><ShortMessage>May expose internal representation by returning reference to mutable object</ShortMessage><LongMessage>org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletionEvent.getPhysMemKbytes() may expose internal representation by returning TaskAttemptUnsuccessfulCompletionEvent.physMemKbytes</LongMessage><Class classname='org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletionEvent' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletionEvent' start='46' end='300' sourcepath='org/apache/hadoop/mapreduce/jobhistory/TaskAttemptUnsuccessfulCompletionEvent.java' sourcefile='TaskAttemptUnsuccessfulCompletionEvent.java'><Message>At TaskAttemptUnsuccessfulCompletionEvent.java:[lines 46-300]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletionEvent</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletionEvent' signature='()[I' name='getPhysMemKbytes' primary='true'><SourceLine endBytecode='46' classname='org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletionEvent' start='274' end='274' sourcepath='org/apache/hadoop/mapreduce/jobhistory/TaskAttemptUnsuccessfulCompletionEvent.java' sourcefile='TaskAttemptUnsuccessfulCompletionEvent.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletionEvent.getPhysMemKbytes()</Message></Method><Field isStatic='false' classname='org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletionEvent' signature='[I' name='physMemKbytes' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletionEvent' sourcepath='org/apache/hadoop/mapreduce/jobhistory/TaskAttemptUnsuccessfulCompletionEvent.java' sourcefile='TaskAttemptUnsuccessfulCompletionEvent.java'><Message>In TaskAttemptUnsuccessfulCompletionEvent.java</Message></SourceLine><Message>Field org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletionEvent.physMemKbytes</Message></Field><SourceLine endBytecode='4' classname='org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletionEvent' start='274' end='274' sourcepath='org/apache/hadoop/mapreduce/jobhistory/TaskAttemptUnsuccessfulCompletionEvent.java' sourcefile='TaskAttemptUnsuccessfulCompletionEvent.java' startBytecode='4' primary='true'><Message>At TaskAttemptUnsuccessfulCompletionEvent.java:[line 274]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='dda2f8201acb04cbe99e687e2935fa74' cweid='374' rank='18' abbrev='EI' category='MALICIOUS_CODE' priority='2' type='EI_EXPOSE_REP' instanceOccurrenceMax='0'><ShortMessage>May expose internal representation by returning reference to mutable object</ShortMessage><LongMessage>org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletionEvent.getVMemKbytes() may expose internal representation by returning TaskAttemptUnsuccessfulCompletionEvent.vMemKbytes</LongMessage><Class classname='org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletionEvent' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletionEvent' start='46' end='300' sourcepath='org/apache/hadoop/mapreduce/jobhistory/TaskAttemptUnsuccessfulCompletionEvent.java' sourcefile='TaskAttemptUnsuccessfulCompletionEvent.java'><Message>At TaskAttemptUnsuccessfulCompletionEvent.java:[lines 46-300]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletionEvent</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletionEvent' signature='()[I' name='getVMemKbytes' primary='true'><SourceLine endBytecode='46' classname='org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletionEvent' start='271' end='271' sourcepath='org/apache/hadoop/mapreduce/jobhistory/TaskAttemptUnsuccessfulCompletionEvent.java' sourcefile='TaskAttemptUnsuccessfulCompletionEvent.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletionEvent.getVMemKbytes()</Message></Method><Field isStatic='false' classname='org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletionEvent' signature='[I' name='vMemKbytes' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletionEvent' sourcepath='org/apache/hadoop/mapreduce/jobhistory/TaskAttemptUnsuccessfulCompletionEvent.java' sourcefile='TaskAttemptUnsuccessfulCompletionEvent.java'><Message>In TaskAttemptUnsuccessfulCompletionEvent.java</Message></SourceLine><Message>Field org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletionEvent.vMemKbytes</Message></Field><SourceLine endBytecode='4' classname='org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletionEvent' start='271' end='271' sourcepath='org/apache/hadoop/mapreduce/jobhistory/TaskAttemptUnsuccessfulCompletionEvent.java' sourcefile='TaskAttemptUnsuccessfulCompletionEvent.java' startBytecode='4' primary='true'><Message>At TaskAttemptUnsuccessfulCompletionEvent.java:[line 271]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='a83adbd9ba45a1059c48a88b4d0d0ebe' cweid='374' rank='18' abbrev='EI2' category='MALICIOUS_CODE' priority='2' type='EI_EXPOSE_REP2' instanceOccurrenceMax='0'><ShortMessage>May expose internal representation by incorporating reference to mutable object</ShortMessage><LongMessage>new org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletionEvent(TaskAttemptID, TaskType, String, long, String, int, String, String, Counters, int[][], long) may expose internal representation by storing an externally mutable object into TaskAttemptUnsuccessfulCompletionEvent.allSplits</LongMessage><Class classname='org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletionEvent' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletionEvent' start='46' end='300' sourcepath='org/apache/hadoop/mapreduce/jobhistory/TaskAttemptUnsuccessfulCompletionEvent.java' sourcefile='TaskAttemptUnsuccessfulCompletionEvent.java'><Message>At TaskAttemptUnsuccessfulCompletionEvent.java:[lines 46-300]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletionEvent</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletionEvent' signature='(Lorg/apache/hadoop/mapreduce/TaskAttemptID;Lorg/apache/hadoop/mapreduce/TaskType;Ljava/lang/String;JLjava/lang/String;ILjava/lang/String;Ljava/lang/String;Lorg/apache/hadoop/mapreduce/Counters;[[IJ)V' name='&lt;init&gt;' primary='true'><SourceLine endBytecode='344' classname='org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletionEvent' start='86' end='106' sourcepath='org/apache/hadoop/mapreduce/jobhistory/TaskAttemptUnsuccessfulCompletionEvent.java' sourcefile='TaskAttemptUnsuccessfulCompletionEvent.java' startBytecode='0'></SourceLine><Message>In method new org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletionEvent(TaskAttemptID, TaskType, String, long, String, int, String, String, Counters, int[][], long)</Message></Method><Field isStatic='false' classname='org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletionEvent' signature='[[I' name='allSplits' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletionEvent' sourcepath='org/apache/hadoop/mapreduce/jobhistory/TaskAttemptUnsuccessfulCompletionEvent.java' sourcefile='TaskAttemptUnsuccessfulCompletionEvent.java'><Message>In TaskAttemptUnsuccessfulCompletionEvent.java</Message></SourceLine><Message>Field org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletionEvent.allSplits</Message></Field><LocalVariable role='LOCAL_VARIABLE_NAMED' pc='63' name='allSplits' register='11'><Message>Local variable named allSplits</Message></LocalVariable><SourceLine endBytecode='63' classname='org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletionEvent' start='96' end='96' sourcepath='org/apache/hadoop/mapreduce/jobhistory/TaskAttemptUnsuccessfulCompletionEvent.java' sourcefile='TaskAttemptUnsuccessfulCompletionEvent.java' startBytecode='63' primary='true'><Message>At TaskAttemptUnsuccessfulCompletionEvent.java:[line 96]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='e1318aa94692f235b97552700721490b' rank='20' abbrev='RI' category='STYLE' priority='3' type='RI_REDUNDANT_INTERFACES' instanceOccurrenceMax='0'><ShortMessage>Class implements same interface as superclass</ShortMessage><LongMessage>Class org.apache.hadoop.mapreduce.jobhistory.TaskFailed implements same interface as superclass</LongMessage><Class classname='org.apache.hadoop.mapreduce.jobhistory.TaskFailed' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.jobhistory.TaskFailed' start='10' end='186' sourcepath='org/apache/hadoop/mapreduce/jobhistory/TaskFailed.java' sourcefile='TaskFailed.java'><Message>At TaskFailed.java:[lines 10-186]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.jobhistory.TaskFailed</Message></Class><Class role='INTERFACE_TYPE' classname='org.apache.avro.specific.SpecificRecord'><SourceLine classname='org.apache.avro.specific.SpecificRecord' sourcepath='org/apache/avro/specific/SpecificRecord.java' sourcefile='SpecificRecord.java'><Message>In SpecificRecord.java</Message></SourceLine><Message>Interface org.apache.avro.specific.SpecificRecord</Message></Class><SourceLine synthetic='true' classname='org.apache.hadoop.mapreduce.jobhistory.TaskFailed' start='10' end='186' sourcepath='org/apache/hadoop/mapreduce/jobhistory/TaskFailed.java' sourcefile='TaskFailed.java'><Message>At TaskFailed.java:[lines 10-186]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='bf1c45b5430820626dfafeab4b81f22f' rank='20' abbrev='RI' category='STYLE' priority='3' type='RI_REDUNDANT_INTERFACES' instanceOccurrenceMax='0'><ShortMessage>Class implements same interface as superclass</ShortMessage><LongMessage>Class org.apache.hadoop.mapreduce.jobhistory.TaskFailed$Builder implements same interface as superclass</LongMessage><Class classname='org.apache.hadoop.mapreduce.jobhistory.TaskFailed$Builder' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.jobhistory.TaskFailed$Builder' start='192' end='461' sourcepath='org/apache/hadoop/mapreduce/jobhistory/TaskFailed.java' sourcefile='TaskFailed.java'><Message>At TaskFailed.java:[lines 192-461]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.jobhistory.TaskFailed$Builder</Message></Class><Class role='INTERFACE_TYPE' classname='org.apache.avro.data.RecordBuilder'><SourceLine classname='org.apache.avro.data.RecordBuilder' sourcepath='org/apache/avro/data/RecordBuilder.java' sourcefile='RecordBuilder.java'><Message>In RecordBuilder.java</Message></SourceLine><Message>Interface org.apache.avro.data.RecordBuilder</Message></Class><SourceLine synthetic='true' classname='org.apache.hadoop.mapreduce.jobhistory.TaskFailed$Builder' start='192' end='461' sourcepath='org/apache/hadoop/mapreduce/jobhistory/TaskFailed.java' sourcefile='TaskFailed.java'><Message>At TaskFailed.java:[lines 192-461]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='b6ee73ff939775578928082baadae6d9' rank='20' abbrev='RI' category='STYLE' priority='3' type='RI_REDUNDANT_INTERFACES' instanceOccurrenceMax='0'><ShortMessage>Class implements same interface as superclass</ShortMessage><LongMessage>Class org.apache.hadoop.mapreduce.jobhistory.TaskFinished implements same interface as superclass</LongMessage><Class classname='org.apache.hadoop.mapreduce.jobhistory.TaskFinished' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.jobhistory.TaskFinished' start='10' end='167' sourcepath='org/apache/hadoop/mapreduce/jobhistory/TaskFinished.java' sourcefile='TaskFinished.java'><Message>At TaskFinished.java:[lines 10-167]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.jobhistory.TaskFinished</Message></Class><Class role='INTERFACE_TYPE' classname='org.apache.avro.specific.SpecificRecord'><SourceLine classname='org.apache.avro.specific.SpecificRecord' sourcepath='org/apache/avro/specific/SpecificRecord.java' sourcefile='SpecificRecord.java'><Message>In SpecificRecord.java</Message></SourceLine><Message>Interface org.apache.avro.specific.SpecificRecord</Message></Class><SourceLine synthetic='true' classname='org.apache.hadoop.mapreduce.jobhistory.TaskFinished' start='10' end='167' sourcepath='org/apache/hadoop/mapreduce/jobhistory/TaskFinished.java' sourcefile='TaskFinished.java'><Message>At TaskFinished.java:[lines 10-167]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='adaa437a1ded598232276875b62e89d' rank='20' abbrev='RI' category='STYLE' priority='3' type='RI_REDUNDANT_INTERFACES' instanceOccurrenceMax='0'><ShortMessage>Class implements same interface as superclass</ShortMessage><LongMessage>Class org.apache.hadoop.mapreduce.jobhistory.TaskFinished$Builder implements same interface as superclass</LongMessage><Class classname='org.apache.hadoop.mapreduce.jobhistory.TaskFinished$Builder' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.jobhistory.TaskFinished$Builder' start='173' end='407' sourcepath='org/apache/hadoop/mapreduce/jobhistory/TaskFinished.java' sourcefile='TaskFinished.java'><Message>At TaskFinished.java:[lines 173-407]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.jobhistory.TaskFinished$Builder</Message></Class><Class role='INTERFACE_TYPE' classname='org.apache.avro.data.RecordBuilder'><SourceLine classname='org.apache.avro.data.RecordBuilder' sourcepath='org/apache/avro/data/RecordBuilder.java' sourcefile='RecordBuilder.java'><Message>In RecordBuilder.java</Message></SourceLine><Message>Interface org.apache.avro.data.RecordBuilder</Message></Class><SourceLine synthetic='true' classname='org.apache.hadoop.mapreduce.jobhistory.TaskFinished$Builder' start='173' end='407' sourcepath='org/apache/hadoop/mapreduce/jobhistory/TaskFinished.java' sourcefile='TaskFinished.java'><Message>At TaskFinished.java:[lines 173-407]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='151c15422d82b5a83a7dac54a2e796a7' rank='20' abbrev='Dm' category='PERFORMANCE' priority='3' type='DM_STRING_TOSTRING' instanceOccurrenceMax='0'><ShortMessage>Method invokes toString() method on a String</ShortMessage><LongMessage>org.apache.hadoop.mapreduce.jobhistory.TaskFinishedEvent.getTaskStatus() invokes toString() method on a String</LongMessage><Class classname='org.apache.hadoop.mapreduce.jobhistory.TaskFinishedEvent' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.jobhistory.TaskFinishedEvent' start='45' end='162' sourcepath='org/apache/hadoop/mapreduce/jobhistory/TaskFinishedEvent.java' sourcefile='TaskFinishedEvent.java'><Message>At TaskFinishedEvent.java:[lines 45-162]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.jobhistory.TaskFinishedEvent</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapreduce.jobhistory.TaskFinishedEvent' signature='()Ljava/lang/String;' name='getTaskStatus' primary='true'><SourceLine endBytecode='49' classname='org.apache.hadoop.mapreduce.jobhistory.TaskFinishedEvent' start='139' end='139' sourcepath='org/apache/hadoop/mapreduce/jobhistory/TaskFinishedEvent.java' sourcefile='TaskFinishedEvent.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapreduce.jobhistory.TaskFinishedEvent.getTaskStatus()</Message></Method><SourceLine endBytecode='4' classname='org.apache.hadoop.mapreduce.jobhistory.TaskFinishedEvent' start='139' end='139' sourcepath='org/apache/hadoop/mapreduce/jobhistory/TaskFinishedEvent.java' sourcefile='TaskFinishedEvent.java' startBytecode='4' primary='true'><Message>At TaskFinishedEvent.java:[line 139]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='851e1924abcf094ed9761c50686411f5' rank='20' abbrev='RI' category='STYLE' priority='3' type='RI_REDUNDANT_INTERFACES' instanceOccurrenceMax='0'><ShortMessage>Class implements same interface as superclass</ShortMessage><LongMessage>Class org.apache.hadoop.mapreduce.jobhistory.TaskStarted implements same interface as superclass</LongMessage><Class classname='org.apache.hadoop.mapreduce.jobhistory.TaskStarted' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.jobhistory.TaskStarted' start='10' end='129' sourcepath='org/apache/hadoop/mapreduce/jobhistory/TaskStarted.java' sourcefile='TaskStarted.java'><Message>At TaskStarted.java:[lines 10-129]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.jobhistory.TaskStarted</Message></Class><Class role='INTERFACE_TYPE' classname='org.apache.avro.specific.SpecificRecord'><SourceLine classname='org.apache.avro.specific.SpecificRecord' sourcepath='org/apache/avro/specific/SpecificRecord.java' sourcefile='SpecificRecord.java'><Message>In SpecificRecord.java</Message></SourceLine><Message>Interface org.apache.avro.specific.SpecificRecord</Message></Class><SourceLine synthetic='true' classname='org.apache.hadoop.mapreduce.jobhistory.TaskStarted' start='10' end='129' sourcepath='org/apache/hadoop/mapreduce/jobhistory/TaskStarted.java' sourcefile='TaskStarted.java'><Message>At TaskStarted.java:[lines 10-129]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='d47298a8bb02098771dad42a58bcdf74' rank='20' abbrev='RI' category='STYLE' priority='3' type='RI_REDUNDANT_INTERFACES' instanceOccurrenceMax='0'><ShortMessage>Class implements same interface as superclass</ShortMessage><LongMessage>Class org.apache.hadoop.mapreduce.jobhistory.TaskStarted$Builder implements same interface as superclass</LongMessage><Class classname='org.apache.hadoop.mapreduce.jobhistory.TaskStarted$Builder' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.jobhistory.TaskStarted$Builder' start='135' end='299' sourcepath='org/apache/hadoop/mapreduce/jobhistory/TaskStarted.java' sourcefile='TaskStarted.java'><Message>At TaskStarted.java:[lines 135-299]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.jobhistory.TaskStarted$Builder</Message></Class><Class role='INTERFACE_TYPE' classname='org.apache.avro.data.RecordBuilder'><SourceLine classname='org.apache.avro.data.RecordBuilder' sourcepath='org/apache/avro/data/RecordBuilder.java' sourcefile='RecordBuilder.java'><Message>In RecordBuilder.java</Message></SourceLine><Message>Interface org.apache.avro.data.RecordBuilder</Message></Class><SourceLine synthetic='true' classname='org.apache.hadoop.mapreduce.jobhistory.TaskStarted$Builder' start='135' end='299' sourcepath='org/apache/hadoop/mapreduce/jobhistory/TaskStarted.java' sourcefile='TaskStarted.java'><Message>At TaskStarted.java:[lines 135-299]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='1dfa7e8cfd8b46865c69e34d29ce3e9d' rank='20' abbrev='RI' category='STYLE' priority='3' type='RI_REDUNDANT_INTERFACES' instanceOccurrenceMax='0'><ShortMessage>Class implements same interface as superclass</ShortMessage><LongMessage>Class org.apache.hadoop.mapreduce.jobhistory.TaskUpdated implements same interface as superclass</LongMessage><Class classname='org.apache.hadoop.mapreduce.jobhistory.TaskUpdated' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.jobhistory.TaskUpdated' start='10' end='91' sourcepath='org/apache/hadoop/mapreduce/jobhistory/TaskUpdated.java' sourcefile='TaskUpdated.java'><Message>At TaskUpdated.java:[lines 10-91]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.jobhistory.TaskUpdated</Message></Class><Class role='INTERFACE_TYPE' classname='org.apache.avro.specific.SpecificRecord'><SourceLine classname='org.apache.avro.specific.SpecificRecord' sourcepath='org/apache/avro/specific/SpecificRecord.java' sourcefile='SpecificRecord.java'><Message>In SpecificRecord.java</Message></SourceLine><Message>Interface org.apache.avro.specific.SpecificRecord</Message></Class><SourceLine synthetic='true' classname='org.apache.hadoop.mapreduce.jobhistory.TaskUpdated' start='10' end='91' sourcepath='org/apache/hadoop/mapreduce/jobhistory/TaskUpdated.java' sourcefile='TaskUpdated.java'><Message>At TaskUpdated.java:[lines 10-91]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='16eabb7d5aaa1ecd104bf7712878050a' rank='20' abbrev='RI' category='STYLE' priority='3' type='RI_REDUNDANT_INTERFACES' instanceOccurrenceMax='0'><ShortMessage>Class implements same interface as superclass</ShortMessage><LongMessage>Class org.apache.hadoop.mapreduce.jobhistory.TaskUpdated$Builder implements same interface as superclass</LongMessage><Class classname='org.apache.hadoop.mapreduce.jobhistory.TaskUpdated$Builder' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.jobhistory.TaskUpdated$Builder' start='97' end='191' sourcepath='org/apache/hadoop/mapreduce/jobhistory/TaskUpdated.java' sourcefile='TaskUpdated.java'><Message>At TaskUpdated.java:[lines 97-191]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.jobhistory.TaskUpdated$Builder</Message></Class><Class role='INTERFACE_TYPE' classname='org.apache.avro.data.RecordBuilder'><SourceLine classname='org.apache.avro.data.RecordBuilder' sourcepath='org/apache/avro/data/RecordBuilder.java' sourcefile='RecordBuilder.java'><Message>In RecordBuilder.java</Message></SourceLine><Message>Interface org.apache.avro.data.RecordBuilder</Message></Class><SourceLine synthetic='true' classname='org.apache.hadoop.mapreduce.jobhistory.TaskUpdated$Builder' start='97' end='191' sourcepath='org/apache/hadoop/mapreduce/jobhistory/TaskUpdated.java' sourcefile='TaskUpdated.java'><Message>At TaskUpdated.java:[lines 97-191]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='edb55b96d121838c4a8250b5531efc9c' cweid='396' rank='20' abbrev='REC' category='STYLE' priority='3' type='REC_CATCH_EXCEPTION' instanceOccurrenceMax='0'><ShortMessage>Exception is caught when Exception is not thrown</ShortMessage><LongMessage>Exception is caught when Exception is not thrown in org.apache.hadoop.mapreduce.lib.aggregate.UserDefinedValueAggregatorDescriptor.createInstance(String)</LongMessage><Class classname='org.apache.hadoop.mapreduce.lib.aggregate.UserDefinedValueAggregatorDescriptor' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.lib.aggregate.UserDefinedValueAggregatorDescriptor' start='45' end='121' sourcepath='org/apache/hadoop/mapreduce/lib/aggregate/UserDefinedValueAggregatorDescriptor.java' sourcefile='UserDefinedValueAggregatorDescriptor.java'><Message>At UserDefinedValueAggregatorDescriptor.java:[lines 45-121]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.lib.aggregate.UserDefinedValueAggregatorDescriptor</Message></Class><Method isStatic='true' classname='org.apache.hadoop.mapreduce.lib.aggregate.UserDefinedValueAggregatorDescriptor' signature='(Ljava/lang/String;)Ljava/lang/Object;' name='createInstance' primary='true'><SourceLine endBytecode='244' classname='org.apache.hadoop.mapreduce.lib.aggregate.UserDefinedValueAggregatorDescriptor' start='55' end='65' sourcepath='org/apache/hadoop/mapreduce/lib/aggregate/UserDefinedValueAggregatorDescriptor.java' sourcefile='UserDefinedValueAggregatorDescriptor.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapreduce.lib.aggregate.UserDefinedValueAggregatorDescriptor.createInstance(String)</Message></Method><SourceLine endBytecode='44' classname='org.apache.hadoop.mapreduce.lib.aggregate.UserDefinedValueAggregatorDescriptor' start='62' end='62' sourcepath='org/apache/hadoop/mapreduce/lib/aggregate/UserDefinedValueAggregatorDescriptor.java' sourcefile='UserDefinedValueAggregatorDescriptor.java' startBytecode='44' primary='true'><Message>At UserDefinedValueAggregatorDescriptor.java:[line 62]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='cb0fee93f1c40840f3314f3f90b8f270' cweid='476' rank='20' abbrev='RCN' category='STYLE' priority='3' type='RCN_REDUNDANT_NULLCHECK_OF_NONNULL_VALUE' instanceOccurrenceMax='0'><ShortMessage>Redundant nullcheck of value known to be non-null</ShortMessage><LongMessage>Redundant nullcheck of e, which is known to be non-null in org.apache.hadoop.mapreduce.lib.aggregate.ValueAggregatorBaseDescriptor.generateKeyValPairs(Object, Object)</LongMessage><Class classname='org.apache.hadoop.mapreduce.lib.aggregate.ValueAggregatorBaseDescriptor' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.lib.aggregate.ValueAggregatorBaseDescriptor' start='36' end='165' sourcepath='org/apache/hadoop/mapreduce/lib/aggregate/ValueAggregatorBaseDescriptor.java' sourcefile='ValueAggregatorBaseDescriptor.java'><Message>At ValueAggregatorBaseDescriptor.java:[lines 36-165]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.lib.aggregate.ValueAggregatorBaseDescriptor</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapreduce.lib.aggregate.ValueAggregatorBaseDescriptor' signature='(Ljava/lang/Object;Ljava/lang/Object;)Ljava/util/ArrayList;' name='generateKeyValPairs' primary='true'><SourceLine endBytecode='281' classname='org.apache.hadoop.mapreduce.lib.aggregate.ValueAggregatorBaseDescriptor' start='142' end='155' sourcepath='org/apache/hadoop/mapreduce/lib/aggregate/ValueAggregatorBaseDescriptor.java' sourcefile='ValueAggregatorBaseDescriptor.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapreduce.lib.aggregate.ValueAggregatorBaseDescriptor.generateKeyValPairs(Object, Object)</Message></Method><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='28' name='e' register='6'><Message>Value loaded from e</Message></LocalVariable><Method isStatic='true' role='METHOD_RETURN_VALUE_OF' classname='org.apache.hadoop.mapreduce.lib.aggregate.ValueAggregatorBaseDescriptor' signature='(Ljava/lang/String;Ljava/lang/String;Lorg/apache/hadoop/io/Text;)Ljava/util/Map$Entry;' name='generateEntry'><SourceLine endBytecode='116' classname='org.apache.hadoop.mapreduce.lib.aggregate.ValueAggregatorBaseDescriptor' start='91' end='92' sourcepath='org/apache/hadoop/mapreduce/lib/aggregate/ValueAggregatorBaseDescriptor.java' sourcefile='ValueAggregatorBaseDescriptor.java' startBytecode='0'></SourceLine><Message>Return value of org.apache.hadoop.mapreduce.lib.aggregate.ValueAggregatorBaseDescriptor.generateEntry(String, String, Text) of type java.util.Map$Entry</Message></Method><SourceLine role='SOURCE_REDUNDANT_NULL_CHECK' endBytecode='30' classname='org.apache.hadoop.mapreduce.lib.aggregate.ValueAggregatorBaseDescriptor' start='146' end='146' sourcepath='org/apache/hadoop/mapreduce/lib/aggregate/ValueAggregatorBaseDescriptor.java' sourcefile='ValueAggregatorBaseDescriptor.java' startBytecode='30' primary='true'><Message>Redundant null check at ValueAggregatorBaseDescriptor.java:[line 146]</Message></SourceLine><SourceLine role='SOURCE_LINE_ANOTHER_INSTANCE' endBytecode='63' classname='org.apache.hadoop.mapreduce.lib.aggregate.ValueAggregatorBaseDescriptor' start='151' end='151' sourcepath='org/apache/hadoop/mapreduce/lib/aggregate/ValueAggregatorBaseDescriptor.java' sourcefile='ValueAggregatorBaseDescriptor.java' startBytecode='63'><Message>Another occurrence at ValueAggregatorBaseDescriptor.java:[line 151]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='c1dcb2c180830475530b4872772b8c8' cweid='382' rank='19' abbrev='Dm' category='BAD_PRACTICE' priority='3' type='DM_EXIT' instanceOccurrenceMax='0'><ShortMessage>Method invokes System.exit(...)</ShortMessage><LongMessage>org.apache.hadoop.mapreduce.lib.aggregate.ValueAggregatorJob.createValueAggregatorJob(Configuration, String[]) invokes System.exit(...), which shuts down the entire virtual machine</LongMessage><Class classname='org.apache.hadoop.mapreduce.lib.aggregate.ValueAggregatorJob' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.lib.aggregate.ValueAggregatorJob' start='85' end='221' sourcepath='org/apache/hadoop/mapreduce/lib/aggregate/ValueAggregatorJob.java' sourcefile='ValueAggregatorJob.java'><Message>At ValueAggregatorJob.java:[lines 85-221]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.lib.aggregate.ValueAggregatorJob</Message></Class><Method isStatic='true' classname='org.apache.hadoop.mapreduce.lib.aggregate.ValueAggregatorJob' signature='(Lorg/apache/hadoop/conf/Configuration;[Ljava/lang/String;)Lorg/apache/hadoop/mapreduce/Job;' name='createValueAggregatorJob' primary='true'><SourceLine endBytecode='687' classname='org.apache.hadoop.mapreduce.lib.aggregate.ValueAggregatorJob' start='122' end='187' sourcepath='org/apache/hadoop/mapreduce/lib/aggregate/ValueAggregatorJob.java' sourcefile='ValueAggregatorJob.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapreduce.lib.aggregate.ValueAggregatorJob.createValueAggregatorJob(Configuration, String[])</Message></Method><SourceLine endBytecode='36' classname='org.apache.hadoop.mapreduce.lib.aggregate.ValueAggregatorJob' start='130' end='130' sourcepath='org/apache/hadoop/mapreduce/lib/aggregate/ValueAggregatorJob.java' sourcefile='ValueAggregatorJob.java' startBytecode='36' primary='true'><Message>At ValueAggregatorJob.java:[line 130]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='cc62f7c45baef403dabaea28b07c2cf0' cweid='218' rank='18' abbrev='MS' category='MALICIOUS_CODE' priority='2' type='MS_PKGPROTECT' instanceOccurrenceMax='0'><ShortMessage>Field should be package protected</ShortMessage><LongMessage>org.apache.hadoop.mapreduce.lib.aggregate.ValueAggregatorJobBase.aggregatorDescriptorList should be package protected</LongMessage><Class classname='org.apache.hadoop.mapreduce.lib.aggregate.ValueAggregatorJobBase' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.lib.aggregate.ValueAggregatorJobBase' start='35' end='88' sourcepath='org/apache/hadoop/mapreduce/lib/aggregate/ValueAggregatorJobBase.java' sourcefile='ValueAggregatorJobBase.java'><Message>At ValueAggregatorJobBase.java:[lines 35-88]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.lib.aggregate.ValueAggregatorJobBase</Message></Class><Field isStatic='true' classname='org.apache.hadoop.mapreduce.lib.aggregate.ValueAggregatorJobBase' signature='Ljava/util/ArrayList;' name='aggregatorDescriptorList' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.lib.aggregate.ValueAggregatorJobBase' sourcepath='org/apache/hadoop/mapreduce/lib/aggregate/ValueAggregatorJobBase.java' sourcefile='ValueAggregatorJobBase.java'><Message>In ValueAggregatorJobBase.java</Message></SourceLine><Message>Field org.apache.hadoop.mapreduce.lib.aggregate.ValueAggregatorJobBase.aggregatorDescriptorList</Message></Field><SourceLine endBytecode='1' classname='org.apache.hadoop.mapreduce.lib.aggregate.ValueAggregatorJobBase' start='43' end='43' sourcepath='org/apache/hadoop/mapreduce/lib/aggregate/ValueAggregatorJobBase.java' sourcefile='ValueAggregatorJobBase.java' startBytecode='1' primary='true'><Message>At ValueAggregatorJobBase.java:[line 43]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='fc5295a9c0cf9cd70ffac29d1423bb02' rank='20' abbrev='UwF' category='STYLE' priority='3' type='UWF_FIELD_NOT_INITIALIZED_IN_CONSTRUCTOR' instanceOccurrenceMax='0'><ShortMessage>Field not initialized in constructor but dereferenced without null check</ShortMessage><LongMessage>Chain.rConf not initialized in constructor and dereferenced in org.apache.hadoop.mapreduce.lib.chain.Chain.addReducer(TaskInputOutputContext, Chain$ChainBlockingQueue)</LongMessage><Class classname='org.apache.hadoop.mapreduce.lib.chain.Chain' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.lib.chain.Chain' start='50' end='861' sourcepath='org/apache/hadoop/mapreduce/lib/chain/Chain.java' sourcefile='Chain.java'><Message>At Chain.java:[lines 50-861]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.lib.chain.Chain</Message></Class><Field isStatic='false' classname='org.apache.hadoop.mapreduce.lib.chain.Chain' signature='Lorg/apache/hadoop/conf/Configuration;' name='rConf' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.lib.chain.Chain' sourcepath='org/apache/hadoop/mapreduce/lib/chain/Chain.java' sourcefile='Chain.java'><Message>In Chain.java</Message></SourceLine><Message>Field org.apache.hadoop.mapreduce.lib.chain.Chain.rConf</Message></Field><Method isStatic='false' classname='org.apache.hadoop.mapreduce.lib.chain.Chain' signature='(Lorg/apache/hadoop/mapreduce/TaskInputOutputContext;Lorg/apache/hadoop/mapreduce/lib/chain/Chain$ChainBlockingQueue;)V' name='addReducer' primary='true'><SourceLine endBytecode='262' classname='org.apache.hadoop.mapreduce.lib.chain.Chain' start='495' end='505' sourcepath='org/apache/hadoop/mapreduce/lib/chain/Chain.java' sourcefile='Chain.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapreduce.lib.chain.Chain.addReducer(TaskInputOutputContext, Chain$ChainBlockingQueue)</Message></Method><SourceLine endBytecode='8' classname='org.apache.hadoop.mapreduce.lib.chain.Chain' start='495' end='495' sourcepath='org/apache/hadoop/mapreduce/lib/chain/Chain.java' sourcefile='Chain.java' startBytecode='8' primary='true'><Message>At Chain.java:[line 495]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='f8f93c5b79e3208785acdb2d53164039' rank='20' abbrev='UwF' category='STYLE' priority='3' type='UWF_FIELD_NOT_INITIALIZED_IN_CONSTRUCTOR' instanceOccurrenceMax='0'><ShortMessage>Field not initialized in constructor but dereferenced without null check</ShortMessage><LongMessage>Chain.reducer not initialized in constructor and dereferenced in org.apache.hadoop.mapreduce.lib.chain.Chain.runReducer(TaskInputOutputContext)</LongMessage><Class classname='org.apache.hadoop.mapreduce.lib.chain.Chain' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.lib.chain.Chain' start='50' end='861' sourcepath='org/apache/hadoop/mapreduce/lib/chain/Chain.java' sourcefile='Chain.java'><Message>At Chain.java:[lines 50-861]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.lib.chain.Chain</Message></Class><Field isStatic='false' classname='org.apache.hadoop.mapreduce.lib.chain.Chain' signature='Lorg/apache/hadoop/mapreduce/Reducer;' name='reducer' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.lib.chain.Chain' sourcepath='org/apache/hadoop/mapreduce/lib/chain/Chain.java' sourcefile='Chain.java'><Message>In Chain.java</Message></SourceLine><Message>Field org.apache.hadoop.mapreduce.lib.chain.Chain.reducer</Message></Field><Method isStatic='false' classname='org.apache.hadoop.mapreduce.lib.chain.Chain' signature='(Lorg/apache/hadoop/mapreduce/TaskInputOutputContext;)V' name='runReducer' primary='true'><SourceLine endBytecode='152' classname='org.apache.hadoop.mapreduce.lib.chain.Chain' start='479' end='485' sourcepath='org/apache/hadoop/mapreduce/lib/chain/Chain.java' sourcefile='Chain.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapreduce.lib.chain.Chain.runReducer(TaskInputOutputContext)</Message></Method><SourceLine endBytecode='28' classname='org.apache.hadoop.mapreduce.lib.chain.Chain' start='483' end='483' sourcepath='org/apache/hadoop/mapreduce/lib/chain/Chain.java' sourcefile='Chain.java' startBytecode='28' primary='true'><Message>At Chain.java:[line 483]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='d9c430d5dbb5c951f3fd3f0ce116f4f7' rank='17' abbrev='No' category='MT_CORRECTNESS' priority='3' type='NO_NOTIFY_NOT_NOTIFYALL' instanceOccurrenceMax='0'><ShortMessage>Using notify() rather than notifyAll()</ShortMessage><LongMessage>Using notify rather than notifyAll in org.apache.hadoop.mapreduce.lib.chain.Chain$ChainBlockingQueue.dequeue()</LongMessage><Class classname='org.apache.hadoop.mapreduce.lib.chain.Chain$ChainBlockingQueue' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.lib.chain.Chain$ChainBlockingQueue' start='870' end='904' sourcepath='org/apache/hadoop/mapreduce/lib/chain/Chain.java' sourcefile='Chain.java'><Message>At Chain.java:[lines 870-904]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.lib.chain.Chain$ChainBlockingQueue</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapreduce.lib.chain.Chain$ChainBlockingQueue' signature='()Ljava/lang/Object;' name='dequeue' primary='true'><SourceLine endBytecode='163' classname='org.apache.hadoop.mapreduce.lib.chain.Chain$ChainBlockingQueue' start='889' end='898' sourcepath='org/apache/hadoop/mapreduce/lib/chain/Chain.java' sourcefile='Chain.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapreduce.lib.chain.Chain$ChainBlockingQueue.dequeue()</Message></Method><SourceLine endBytecode='40' classname='org.apache.hadoop.mapreduce.lib.chain.Chain$ChainBlockingQueue' start='897' end='897' sourcepath='org/apache/hadoop/mapreduce/lib/chain/Chain.java' sourcefile='Chain.java' startBytecode='40' primary='true'><Message>At Chain.java:[line 897]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='96fb03a6600845db74082a5c9d5ced9d' rank='17' abbrev='No' category='MT_CORRECTNESS' priority='3' type='NO_NOTIFY_NOT_NOTIFYALL' instanceOccurrenceMax='0'><ShortMessage>Using notify() rather than notifyAll()</ShortMessage><LongMessage>Using notify rather than notifyAll in org.apache.hadoop.mapreduce.lib.chain.Chain$ChainBlockingQueue.enqueue(Object)</LongMessage><Class classname='org.apache.hadoop.mapreduce.lib.chain.Chain$ChainBlockingQueue' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.lib.chain.Chain$ChainBlockingQueue' start='870' end='904' sourcepath='org/apache/hadoop/mapreduce/lib/chain/Chain.java' sourcefile='Chain.java'><Message>At Chain.java:[lines 870-904]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.lib.chain.Chain$ChainBlockingQueue</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapreduce.lib.chain.Chain$ChainBlockingQueue' signature='(Ljava/lang/Object;)V' name='enqueue' primary='true'><SourceLine endBytecode='153' classname='org.apache.hadoop.mapreduce.lib.chain.Chain$ChainBlockingQueue' start='878' end='886' sourcepath='org/apache/hadoop/mapreduce/lib/chain/Chain.java' sourcefile='Chain.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapreduce.lib.chain.Chain$ChainBlockingQueue.enqueue(Object)</Message></Method><SourceLine endBytecode='35' classname='org.apache.hadoop.mapreduce.lib.chain.Chain$ChainBlockingQueue' start='885' end='885' sourcepath='org/apache/hadoop/mapreduce/lib/chain/Chain.java' sourcefile='Chain.java' startBytecode='35' primary='true'><Message>At Chain.java:[line 885]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='824ab258f49ad2ff4ce3bd9006588c9b' rank='20' abbrev='SIC' category='PERFORMANCE' priority='3' type='SIC_INNER_SHOULD_BE_STATIC_NEEDS_THIS' instanceOccurrenceMax='0'><ShortMessage>Could be refactored into a static inner class</ShortMessage><LongMessage>The class org.apache.hadoop.mapreduce.lib.chain.Chain$ChainBlockingQueue could be refactored into a _static_ inner class</LongMessage><Class classname='org.apache.hadoop.mapreduce.lib.chain.Chain$ChainBlockingQueue' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.lib.chain.Chain$ChainBlockingQueue' start='870' end='904' sourcepath='org/apache/hadoop/mapreduce/lib/chain/Chain.java' sourcefile='Chain.java'><Message>At Chain.java:[lines 870-904]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.lib.chain.Chain$ChainBlockingQueue</Message></Class><SourceLine synthetic='true' classname='org.apache.hadoop.mapreduce.lib.chain.Chain$ChainBlockingQueue' start='870' end='904' sourcepath='org/apache/hadoop/mapreduce/lib/chain/Chain.java' sourcefile='Chain.java'><Message>At Chain.java:[lines 870-904]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='fb71854e8ab7f4323cd9d9e12658c469' cweid='440' rank='10' abbrev='DMI' category='CORRECTNESS' priority='3' type='DMI_BIGDECIMAL_CONSTRUCTED_FROM_DOUBLE' instanceOccurrenceMax='0'><ShortMessage>BigDecimal constructed from double that isn't represented precisely</ShortMessage><LongMessage>BigDecimal constructed from 4.9407E-320 in org.apache.hadoop.mapreduce.lib.db.BigDecimalSplitter.&lt;static initializer for BigDecimalSplitter&gt;()</LongMessage><Class classname='org.apache.hadoop.mapreduce.lib.db.BigDecimalSplitter' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.lib.db.BigDecimalSplitter' start='41' end='148' sourcepath='org/apache/hadoop/mapreduce/lib/db/BigDecimalSplitter.java' sourcefile='BigDecimalSplitter.java'><Message>At BigDecimalSplitter.java:[lines 41-148]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.lib.db.BigDecimalSplitter</Message></Class><Method isStatic='true' classname='org.apache.hadoop.mapreduce.lib.db.BigDecimalSplitter' signature='()V' name='&lt;clinit&gt;' primary='true'><SourceLine endBytecode='53' classname='org.apache.hadoop.mapreduce.lib.db.BigDecimalSplitter' start='42' end='97' sourcepath='org/apache/hadoop/mapreduce/lib/db/BigDecimalSplitter.java' sourcefile='BigDecimalSplitter.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapreduce.lib.db.BigDecimalSplitter.&lt;static initializer for BigDecimalSplitter&gt;()</Message></Method><Method isStatic='false' role='METHOD_CALLED' classname='java.math.BigDecimal' signature='(D)V' name='&lt;init&gt;'><SourceLine endBytecode='36' classname='java.math.BigDecimal' start='875' end='876' sourcepath='java/math/BigDecimal.java' sourcefile='BigDecimal.java' startBytecode='0'></SourceLine><Message>Called method new java.math.BigDecimal(double)</Message></Method><Method isStatic='true' role='METHOD_ALTERNATIVE_TARGET' classname='java.math.BigDecimal' signature='(D)Ljava/math/BigDecimal;' name='valueOf'><SourceLine endBytecode='35' classname='java.math.BigDecimal' start='1277' end='1277' sourcepath='java/math/BigDecimal.java' sourcefile='BigDecimal.java' startBytecode='0'></SourceLine><Message>Did you intend to invoke java.math.BigDecimal.valueOf(double)</Message></Method><String value='4.9407E-320'><Message>Value 4.9407E-320</Message></String><String value='4.940656458412465441765687928682213723650598026143247644255856825006755072702087518652998363616359923797965646954457177309266567103559397963987747960107818781263007131903114045278458171678489821036887186360569987307230500063874091535649843873124733972731696151400317153853980741262385655911710266585566867681870395603106249319452715914924553293054565444011274801297099995419319894090804165633245247571478690147267801593552386115501348035264934720193790268107107491703332226844753335720832431936092382893458368060106011506169809753078342277318329247904982524730776375927247874656084778203734469699533647017972677717585125660551199131504891101451037862738167250955837389733598993664809941164205702637090279242767544565229087538682506419718265533447265625E-320'><Message>Value 4.940656458412465441765687928682213723650598026143247644255856825006755072702087518652998363616359923797965646954457177309266567103559397963987747960107818781263007131903114045278458171678489821036887186360569987307230500063874091535649843873124733972731696151400317153853980741262385655911710266585566867681870395603106249319452715914924553293054565444011274801297099995419319894090804165633245247571478690147267801593552386115501348035264934720193790268107107491703332226844753335720832431936092382893458368060106011506169809753078342277318329247904982524730776375927247874656084778203734469699533647017972677717585125660551199131504891101451037862738167250955837389733598993664809941164205702637090279242767544565229087538682506419718265533447265625E-320</Message></String><SourceLine endBytecode='15' classname='org.apache.hadoop.mapreduce.lib.db.BigDecimalSplitter' start='97' end='97' sourcepath='org/apache/hadoop/mapreduce/lib/db/BigDecimalSplitter.java' sourcefile='BigDecimalSplitter.java' startBytecode='15' primary='true'><Message>At BigDecimalSplitter.java:[line 97]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='c8c79c0936b00d25dd207646502d2417' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from org.apache.hadoop.mapreduce.InputSplit to org.apache.hadoop.mapreduce.lib.db.DBInputFormat$DBInputSplit in org.apache.hadoop.mapreduce.lib.db.DBInputFormat.createRecordReader(InputSplit, TaskAttemptContext)</LongMessage><Class classname='org.apache.hadoop.mapreduce.lib.db.DBInputFormat' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.lib.db.DBInputFormat' start='61' end='373' sourcepath='org/apache/hadoop/mapreduce/lib/db/DBInputFormat.java' sourcefile='DBInputFormat.java'><Message>At DBInputFormat.java:[lines 61-373]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.lib.db.DBInputFormat</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapreduce.lib.db.DBInputFormat' signature='(Lorg/apache/hadoop/mapreduce/InputSplit;Lorg/apache/hadoop/mapreduce/TaskAttemptContext;)Lorg/apache/hadoop/mapreduce/RecordReader;' name='createRecordReader' primary='true'><SourceLine endBytecode='6' classname='org.apache.hadoop.mapreduce.lib.db.DBInputFormat' start='246' end='246' sourcepath='org/apache/hadoop/mapreduce/lib/db/DBInputFormat.java' sourcefile='DBInputFormat.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapreduce.lib.db.DBInputFormat.createRecordReader(InputSplit, TaskAttemptContext)</Message></Method><Type role='TYPE_FOUND' descriptor='Lorg/apache/hadoop/mapreduce/InputSplit;'><SourceLine classname='org.apache.hadoop.mapreduce.InputSplit' start='44' end='75' sourcepath='org/apache/hadoop/mapreduce/InputSplit.java' sourcefile='InputSplit.java'><Message>At InputSplit.java:[lines 44-75]</Message></SourceLine><Message>Actual type org.apache.hadoop.mapreduce.InputSplit</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/mapreduce/lib/db/DBInputFormat$DBInputSplit;'><SourceLine classname='org.apache.hadoop.mapreduce.lib.db.DBInputFormat$DBInputSplit' start='90' end='146' sourcepath='org/apache/hadoop/mapreduce/lib/db/DBInputFormat.java' sourcefile='DBInputFormat.java'><Message>At DBInputFormat.java:[lines 90-146]</Message></SourceLine><Message>Expected org.apache.hadoop.mapreduce.lib.db.DBInputFormat$DBInputSplit</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='1' name='split' register='1'><Message>Value loaded from split</Message></LocalVariable><SourceLine endBytecode='2' classname='org.apache.hadoop.mapreduce.lib.db.DBInputFormat' start='246' end='246' sourcepath='org/apache/hadoop/mapreduce/lib/db/DBInputFormat.java' sourcefile='DBInputFormat.java' startBytecode='2' primary='true'><Message>At DBInputFormat.java:[line 246]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='e00e3bcf709495667c54c95ef727ecbf' cweid='89' rank='15' abbrev='SQL' category='SECURITY' priority='3' type='SQL_NONCONSTANT_STRING_PASSED_TO_EXECUTE' instanceOccurrenceMax='0'><ShortMessage>Nonconstant string passed to execute or addBatch method on an SQL statement</ShortMessage><LongMessage>org.apache.hadoop.mapreduce.lib.db.DBInputFormat.getSplits(JobContext) passes a nonconstant String to an execute or addBatch method on an SQL statement</LongMessage><Class classname='org.apache.hadoop.mapreduce.lib.db.DBInputFormat' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.lib.db.DBInputFormat' start='61' end='373' sourcepath='org/apache/hadoop/mapreduce/lib/db/DBInputFormat.java' sourcefile='DBInputFormat.java'><Message>At DBInputFormat.java:[lines 61-373]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.lib.db.DBInputFormat</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapreduce.lib.db.DBInputFormat' signature='(Lorg/apache/hadoop/mapreduce/JobContext;)Ljava/util/List;' name='getSplits' primary='true'><SourceLine endBytecode='123' classname='org.apache.hadoop.mapreduce.lib.db.DBInputFormat' start='252' end='296' sourcepath='org/apache/hadoop/mapreduce/lib/db/DBInputFormat.java' sourcefile='DBInputFormat.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapreduce.lib.db.DBInputFormat.getSplits(JobContext)</Message></Method><SourceLine endBytecode='19' classname='org.apache.hadoop.mapreduce.lib.db.DBInputFormat' start='257' end='257' sourcepath='org/apache/hadoop/mapreduce/lib/db/DBInputFormat.java' sourcefile='DBInputFormat.java' startBytecode='19' primary='true'><Message>At DBInputFormat.java:[line 257]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='5a79e4a2495d5b7d911e3ab8d51a423e' rank='20' abbrev='Dm' category='I18N' priority='3' type='DM_CONVERT_CASE' instanceOccurrenceMax='0'><ShortMessage>Consider using Locale parameterized version of invoked method</ShortMessage><LongMessage>Use of non-localized String.toUpperCase() or String.toLowerCase() in org.apache.hadoop.mapreduce.lib.db.DBOutputFormat.getRecordWriter(TaskAttemptContext)</LongMessage><Class classname='org.apache.hadoop.mapreduce.lib.db.DBOutputFormat' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.lib.db.DBOutputFormat' start='51' end='247' sourcepath='org/apache/hadoop/mapreduce/lib/db/DBOutputFormat.java' sourcefile='DBOutputFormat.java'><Message>At DBOutputFormat.java:[lines 51-247]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.lib.db.DBOutputFormat</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapreduce.lib.db.DBOutputFormat' signature='(Lorg/apache/hadoop/mapreduce/TaskAttemptContext;)Lorg/apache/hadoop/mapreduce/RecordWriter;' name='getRecordWriter' primary='true'><SourceLine endBytecode='342' classname='org.apache.hadoop.mapreduce.lib.db.DBOutputFormat' start='178' end='197' sourcepath='org/apache/hadoop/mapreduce/lib/db/DBOutputFormat.java' sourcefile='DBOutputFormat.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapreduce.lib.db.DBOutputFormat.getRecordWriter(TaskAttemptContext)</Message></Method><SourceLine endBytecode='65' classname='org.apache.hadoop.mapreduce.lib.db.DBOutputFormat' start='191' end='191' sourcepath='org/apache/hadoop/mapreduce/lib/db/DBOutputFormat.java' sourcefile='DBOutputFormat.java' startBytecode='65' primary='true'><Message>At DBOutputFormat.java:[line 191]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='1d6190a13774973aa71539f06738c20a' cweid='396' rank='20' abbrev='REC' category='STYLE' priority='3' type='REC_CATCH_EXCEPTION' instanceOccurrenceMax='0'><ShortMessage>Exception is caught when Exception is not thrown</ShortMessage><LongMessage>Exception is caught when Exception is not thrown in org.apache.hadoop.mapreduce.lib.db.DBOutputFormat.getRecordWriter(TaskAttemptContext)</LongMessage><Class classname='org.apache.hadoop.mapreduce.lib.db.DBOutputFormat' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.lib.db.DBOutputFormat' start='51' end='247' sourcepath='org/apache/hadoop/mapreduce/lib/db/DBOutputFormat.java' sourcefile='DBOutputFormat.java'><Message>At DBOutputFormat.java:[lines 51-247]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.lib.db.DBOutputFormat</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapreduce.lib.db.DBOutputFormat' signature='(Lorg/apache/hadoop/mapreduce/TaskAttemptContext;)Lorg/apache/hadoop/mapreduce/RecordWriter;' name='getRecordWriter' primary='true'><SourceLine endBytecode='342' classname='org.apache.hadoop.mapreduce.lib.db.DBOutputFormat' start='178' end='197' sourcepath='org/apache/hadoop/mapreduce/lib/db/DBOutputFormat.java' sourcefile='DBOutputFormat.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapreduce.lib.db.DBOutputFormat.getRecordWriter(TaskAttemptContext)</Message></Method><SourceLine endBytecode='100' classname='org.apache.hadoop.mapreduce.lib.db.DBOutputFormat' start='196' end='196' sourcepath='org/apache/hadoop/mapreduce/lib/db/DBOutputFormat.java' sourcefile='DBOutputFormat.java' startBytecode='100' primary='true'><Message>At DBOutputFormat.java:[line 196]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='a4b86a64376c54e9b03b94e44fa46d2a' cweid='89' rank='15' abbrev='SQL' category='SECURITY' priority='3' type='SQL_PREPARED_STATEMENT_GENERATED_FROM_NONCONSTANT_STRING' instanceOccurrenceMax='0'><ShortMessage>A prepared statement is generated from a nonconstant String</ShortMessage><LongMessage>A prepared statement is generated from a nonconstant String in org.apache.hadoop.mapreduce.lib.db.DBOutputFormat.getRecordWriter(TaskAttemptContext) </LongMessage><Class classname='org.apache.hadoop.mapreduce.lib.db.DBOutputFormat' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.lib.db.DBOutputFormat' start='51' end='247' sourcepath='org/apache/hadoop/mapreduce/lib/db/DBOutputFormat.java' sourcefile='DBOutputFormat.java'><Message>At DBOutputFormat.java:[lines 51-247]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.lib.db.DBOutputFormat</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapreduce.lib.db.DBOutputFormat' signature='(Lorg/apache/hadoop/mapreduce/TaskAttemptContext;)Lorg/apache/hadoop/mapreduce/RecordWriter;' name='getRecordWriter' primary='true'><SourceLine endBytecode='51' classname='org.apache.hadoop.mapreduce.lib.db.DBOutputFormat' start='178' end='197' sourcepath='org/apache/hadoop/mapreduce/lib/db/DBOutputFormat.java' sourcefile='DBOutputFormat.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapreduce.lib.db.DBOutputFormat.getRecordWriter(TaskAttemptContext)</Message></Method><SourceLine endBytecode='80' classname='org.apache.hadoop.mapreduce.lib.db.DBOutputFormat' start='193' end='193' sourcepath='org/apache/hadoop/mapreduce/lib/db/DBOutputFormat.java' sourcefile='DBOutputFormat.java' startBytecode='80' primary='true'><Message>At DBOutputFormat.java:[line 193]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='9f3dafd59a0cf701f7c593e67ea8373' cweid='374' rank='18' abbrev='EI2' category='MALICIOUS_CODE' priority='2' type='EI_EXPOSE_REP2' instanceOccurrenceMax='0'><ShortMessage>May expose internal representation by incorporating reference to mutable object</ShortMessage><LongMessage>new org.apache.hadoop.mapreduce.lib.db.DBRecordReader(DBInputFormat$DBInputSplit, Class, Configuration, Connection, DBConfiguration, String, String[], String) may expose internal representation by storing an externally mutable object into DBRecordReader.fieldNames</LongMessage><Class classname='org.apache.hadoop.mapreduce.lib.db.DBRecordReader' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.lib.db.DBRecordReader' start='54' end='275' sourcepath='org/apache/hadoop/mapreduce/lib/db/DBRecordReader.java' sourcefile='DBRecordReader.java'><Message>At DBRecordReader.java:[lines 54-275]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.lib.db.DBRecordReader</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapreduce.lib.db.DBRecordReader' signature='(Lorg/apache/hadoop/mapreduce/lib/db/DBInputFormat$DBInputSplit;Ljava/lang/Class;Lorg/apache/hadoop/conf/Configuration;Ljava/sql/Connection;Lorg/apache/hadoop/mapreduce/lib/db/DBConfiguration;Ljava/lang/String;[Ljava/lang/String;Ljava/lang/String;)V' name='&lt;init&gt;' primary='true'><SourceLine endBytecode='271' classname='org.apache.hadoop.mapreduce.lib.db.DBRecordReader' start='95' end='104' sourcepath='org/apache/hadoop/mapreduce/lib/db/DBRecordReader.java' sourcefile='DBRecordReader.java' startBytecode='0'></SourceLine><Message>In method new org.apache.hadoop.mapreduce.lib.db.DBRecordReader(DBInputFormat$DBInputSplit, Class, Configuration, Connection, DBConfiguration, String, String[], String)</Message></Method><Field isStatic='false' classname='org.apache.hadoop.mapreduce.lib.db.DBRecordReader' signature='[Ljava/lang/String;' name='fieldNames' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.lib.db.DBRecordReader' sourcepath='org/apache/hadoop/mapreduce/lib/db/DBRecordReader.java' sourcefile='DBRecordReader.java'><Message>In DBRecordReader.java</Message></SourceLine><Message>Field org.apache.hadoop.mapreduce.lib.db.DBRecordReader.fieldNames</Message></Field><LocalVariable role='LOCAL_VARIABLE_NAMED' pc='60' name='fields' register='7'><Message>Local variable named fields</Message></LocalVariable><SourceLine endBytecode='60' classname='org.apache.hadoop.mapreduce.lib.db.DBRecordReader' start='102' end='102' sourcepath='org/apache/hadoop/mapreduce/lib/db/DBRecordReader.java' sourcefile='DBRecordReader.java' startBytecode='60' primary='true'><Message>At DBRecordReader.java:[line 102]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='e7938220777d47f0df29e455b878d755' cweid='89' rank='15' abbrev='SQL' category='SECURITY' priority='3' type='SQL_PREPARED_STATEMENT_GENERATED_FROM_NONCONSTANT_STRING' instanceOccurrenceMax='0'><ShortMessage>A prepared statement is generated from a nonconstant String</ShortMessage><LongMessage>A prepared statement is generated from a nonconstant String in org.apache.hadoop.mapreduce.lib.db.DBRecordReader.nextKeyValue() </LongMessage><Class classname='org.apache.hadoop.mapreduce.lib.db.DBRecordReader' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.lib.db.DBRecordReader' start='54' end='275' sourcepath='org/apache/hadoop/mapreduce/lib/db/DBRecordReader.java' sourcefile='DBRecordReader.java'><Message>At DBRecordReader.java:[lines 54-275]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.lib.db.DBRecordReader</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapreduce.lib.db.DBRecordReader' signature='()Z' name='nextKeyValue' primary='true'><SourceLine endBytecode='60' classname='org.apache.hadoop.mapreduce.lib.db.DBRecordReader' start='220' end='242' sourcepath='org/apache/hadoop/mapreduce/lib/db/DBRecordReader.java' sourcefile='DBRecordReader.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapreduce.lib.db.DBRecordReader.nextKeyValue()</Message></Method><SourceLine endBytecode='47' classname='org.apache.hadoop.mapreduce.lib.db.DBRecordReader' start='228' end='228' sourcepath='org/apache/hadoop/mapreduce/lib/db/DBRecordReader.java' sourcefile='DBRecordReader.java' startBytecode='47' primary='true'><Message>At DBRecordReader.java:[line 228]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='53e94e45768bc191af0a413079997ec9' rank='20' abbrev='RI' category='STYLE' priority='3' type='RI_REDUNDANT_INTERFACES' instanceOccurrenceMax='0'><ShortMessage>Class implements same interface as superclass</ShortMessage><LongMessage>Class org.apache.hadoop.mapreduce.lib.db.DataDrivenDBInputFormat implements same interface as superclass</LongMessage><Class classname='org.apache.hadoop.mapreduce.lib.db.DataDrivenDBInputFormat' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.lib.db.DataDrivenDBInputFormat' start='61' end='330' sourcepath='org/apache/hadoop/mapreduce/lib/db/DataDrivenDBInputFormat.java' sourcefile='DataDrivenDBInputFormat.java'><Message>At DataDrivenDBInputFormat.java:[lines 61-330]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.lib.db.DataDrivenDBInputFormat</Message></Class><Class role='INTERFACE_TYPE' classname='org.apache.hadoop.conf.Configurable'><SourceLine classname='org.apache.hadoop.conf.Configurable' sourcepath='org/apache/hadoop/conf/Configurable.java' sourcefile='Configurable.java'><Message>In Configurable.java</Message></SourceLine><Message>Interface org.apache.hadoop.conf.Configurable</Message></Class><SourceLine synthetic='true' classname='org.apache.hadoop.mapreduce.lib.db.DataDrivenDBInputFormat' start='61' end='330' sourcepath='org/apache/hadoop/mapreduce/lib/db/DataDrivenDBInputFormat.java' sourcefile='DataDrivenDBInputFormat.java'><Message>At DataDrivenDBInputFormat.java:[lines 61-330]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='c670b4274814912f9886b1fa251ffb06' cweid='89' rank='15' abbrev='SQL' category='SECURITY' priority='3' type='SQL_NONCONSTANT_STRING_PASSED_TO_EXECUTE' instanceOccurrenceMax='0'><ShortMessage>Nonconstant string passed to execute or addBatch method on an SQL statement</ShortMessage><LongMessage>org.apache.hadoop.mapreduce.lib.db.DataDrivenDBInputFormat.getSplits(JobContext) passes a nonconstant String to an execute or addBatch method on an SQL statement</LongMessage><Class classname='org.apache.hadoop.mapreduce.lib.db.DataDrivenDBInputFormat' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.lib.db.DataDrivenDBInputFormat' start='61' end='330' sourcepath='org/apache/hadoop/mapreduce/lib/db/DataDrivenDBInputFormat.java' sourcefile='DataDrivenDBInputFormat.java'><Message>At DataDrivenDBInputFormat.java:[lines 61-330]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.lib.db.DataDrivenDBInputFormat</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapreduce.lib.db.DataDrivenDBInputFormat' signature='(Lorg/apache/hadoop/mapreduce/JobContext;)Ljava/util/List;' name='getSplits' primary='true'><SourceLine endBytecode='191' classname='org.apache.hadoop.mapreduce.lib.db.DataDrivenDBInputFormat' start='170' end='224' sourcepath='org/apache/hadoop/mapreduce/lib/db/DataDrivenDBInputFormat.java' sourcefile='DataDrivenDBInputFormat.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapreduce.lib.db.DataDrivenDBInputFormat.getSplits(JobContext)</Message></Method><SourceLine endBytecode='68' classname='org.apache.hadoop.mapreduce.lib.db.DataDrivenDBInputFormat' start='185' end='185' sourcepath='org/apache/hadoop/mapreduce/lib/db/DataDrivenDBInputFormat.java' sourcefile='DataDrivenDBInputFormat.java' startBytecode='68' primary='true'><Message>At DataDrivenDBInputFormat.java:[line 185]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='1d4d150feb45f1cb834bb79e067c1a67' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST_OF_RETURN_VALUE' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast of return value from method</ShortMessage><LongMessage>Unchecked/unconfirmed cast from org.apache.hadoop.mapreduce.lib.db.DBInputFormat$DBInputSplit to org.apache.hadoop.mapreduce.lib.db.DataDrivenDBInputFormat$DataDrivenDBInputSplit of return value in org.apache.hadoop.mapreduce.lib.db.DataDrivenDBRecordReader.getSelectQuery()</LongMessage><Class classname='org.apache.hadoop.mapreduce.lib.db.DataDrivenDBRecordReader' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.lib.db.DataDrivenDBRecordReader' start='59' end='136' sourcepath='org/apache/hadoop/mapreduce/lib/db/DataDrivenDBRecordReader.java' sourcefile='DataDrivenDBRecordReader.java'><Message>At DataDrivenDBRecordReader.java:[lines 59-136]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.lib.db.DataDrivenDBRecordReader</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapreduce.lib.db.DataDrivenDBRecordReader' signature='()Ljava/lang/String;' name='getSelectQuery' primary='true'><SourceLine endBytecode='154' classname='org.apache.hadoop.mapreduce.lib.db.DataDrivenDBRecordReader' start='80' end='136' sourcepath='org/apache/hadoop/mapreduce/lib/db/DataDrivenDBRecordReader.java' sourcefile='DataDrivenDBRecordReader.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapreduce.lib.db.DataDrivenDBRecordReader.getSelectQuery()</Message></Method><Type role='TYPE_FOUND' descriptor='Lorg/apache/hadoop/mapreduce/lib/db/DBInputFormat$DBInputSplit;'><SourceLine classname='org.apache.hadoop.mapreduce.lib.db.DBInputFormat$DBInputSplit' start='90' end='146' sourcepath='org/apache/hadoop/mapreduce/lib/db/DBInputFormat.java' sourcefile='DBInputFormat.java'><Message>At DBInputFormat.java:[lines 90-146]</Message></SourceLine><Message>Actual type org.apache.hadoop.mapreduce.lib.db.DBInputFormat$DBInputSplit</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/mapreduce/lib/db/DataDrivenDBInputFormat$DataDrivenDBInputSplit;'><SourceLine classname='org.apache.hadoop.mapreduce.lib.db.DataDrivenDBInputFormat$DataDrivenDBInputSplit' start='84' end='122' sourcepath='org/apache/hadoop/mapreduce/lib/db/DataDrivenDBInputFormat.java' sourcefile='DataDrivenDBInputFormat.java'><Message>At DataDrivenDBInputFormat.java:[lines 84-122]</Message></SourceLine><Message>Expected org.apache.hadoop.mapreduce.lib.db.DataDrivenDBInputFormat$DataDrivenDBInputSplit</Message></Type><SourceLine endBytecode='12' classname='org.apache.hadoop.mapreduce.lib.db.DataDrivenDBRecordReader' start='82' end='82' sourcepath='org/apache/hadoop/mapreduce/lib/db/DataDrivenDBRecordReader.java' sourcefile='DataDrivenDBRecordReader.java' startBytecode='12' primary='true'><Message>At DataDrivenDBRecordReader.java:[line 82]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='c4b030aae6057d8c53136ffcf26ccd38' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST_OF_RETURN_VALUE' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast of return value from method</ShortMessage><LongMessage>Unchecked/unconfirmed cast from java.util.Date to java.sql.Timestamp of return value in org.apache.hadoop.mapreduce.lib.db.DateSplitter.split(Configuration, ResultSet, String)</LongMessage><Class classname='org.apache.hadoop.mapreduce.lib.db.DateSplitter' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.lib.db.DateSplitter' start='46' end='176' sourcepath='org/apache/hadoop/mapreduce/lib/db/DateSplitter.java' sourcefile='DateSplitter.java'><Message>At DateSplitter.java:[lines 46-176]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.lib.db.DateSplitter</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapreduce.lib.db.DateSplitter' signature='(Lorg/apache/hadoop/conf/Configuration;Ljava/sql/ResultSet;Ljava/lang/String;)Ljava/util/List;' name='split' primary='true'><SourceLine endBytecode='242' classname='org.apache.hadoop.mapreduce.lib.db.DateSplitter' start='56' end='126' sourcepath='org/apache/hadoop/mapreduce/lib/db/DateSplitter.java' sourcefile='DateSplitter.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapreduce.lib.db.DateSplitter.split(Configuration, ResultSet, String)</Message></Method><Type role='TYPE_FOUND' descriptor='Ljava/util/Date;'><SourceLine classname='java.util.Date' start='131' end='1374' sourcepath='java/util/Date.java' sourcefile='Date.java'><Message>At Date.java:[lines 131-1374]</Message></SourceLine><Message>Actual type java.util.Date</Message></Type><Type role='TYPE_EXPECTED' descriptor='Ljava/sql/Timestamp;'><SourceLine classname='java.sql.Timestamp' start='72' end='617' sourcepath='java/sql/Timestamp.java' sourcefile='Timestamp.java'><Message>At Timestamp.java:[lines 72-617]</Message></SourceLine><Message>Expected java.sql.Timestamp</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='318' name='endDate' register='20'><Message>Value loaded from endDate</Message></LocalVariable><SourceLine endBytecode='320' classname='org.apache.hadoop.mapreduce.lib.db.DateSplitter' start='100' end='100' sourcepath='org/apache/hadoop/mapreduce/lib/db/DateSplitter.java' sourcefile='DateSplitter.java' startBytecode='320' primary='true'><Message>At DateSplitter.java:[line 100]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='99f75f5de775ba2ba8cb12e35c32e67e' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST_OF_RETURN_VALUE' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast of return value from method</ShortMessage><LongMessage>Unchecked/unconfirmed cast from java.util.Date to java.sql.Timestamp of return value in org.apache.hadoop.mapreduce.lib.db.DateSplitter.split(Configuration, ResultSet, String)</LongMessage><Class classname='org.apache.hadoop.mapreduce.lib.db.DateSplitter' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.lib.db.DateSplitter' start='46' end='176' sourcepath='org/apache/hadoop/mapreduce/lib/db/DateSplitter.java' sourcefile='DateSplitter.java'><Message>At DateSplitter.java:[lines 46-176]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.lib.db.DateSplitter</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapreduce.lib.db.DateSplitter' signature='(Lorg/apache/hadoop/conf/Configuration;Ljava/sql/ResultSet;Ljava/lang/String;)Ljava/util/List;' name='split' primary='true'><SourceLine endBytecode='242' classname='org.apache.hadoop.mapreduce.lib.db.DateSplitter' start='56' end='126' sourcepath='org/apache/hadoop/mapreduce/lib/db/DateSplitter.java' sourcefile='DateSplitter.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapreduce.lib.db.DateSplitter.split(Configuration, ResultSet, String)</Message></Method><Type role='TYPE_FOUND' descriptor='Ljava/util/Date;'><SourceLine classname='java.util.Date' start='131' end='1374' sourcepath='java/util/Date.java' sourcefile='Date.java'><Message>At Date.java:[lines 131-1374]</Message></SourceLine><Message>Actual type java.util.Date</Message></Type><Type role='TYPE_EXPECTED' descriptor='Ljava/sql/Timestamp;'><SourceLine classname='java.sql.Timestamp' start='72' end='617' sourcepath='java/sql/Timestamp.java' sourcefile='Timestamp.java'><Message>At Timestamp.java:[lines 72-617]</Message></SourceLine><Message>Expected java.sql.Timestamp</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='232' name='startDate' register='16'><Message>Value loaded from startDate</Message></LocalVariable><SourceLine endBytecode='234' classname='org.apache.hadoop.mapreduce.lib.db.DateSplitter' start='86' end='86' sourcepath='org/apache/hadoop/mapreduce/lib/db/DateSplitter.java' sourcefile='DateSplitter.java' startBytecode='234' primary='true'><Message>At DateSplitter.java:[line 86]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='d6ca865c578d17eee46b28ce8a9d625a' cweid='563' rank='20' abbrev='DLS' category='STYLE' priority='3' type='DLS_DEAD_LOCAL_STORE' instanceOccurrenceMax='0'><ShortMessage>Dead store to local variable</ShortMessage><LongMessage>Dead store to start in org.apache.hadoop.mapreduce.lib.db.DateSplitter.split(Configuration, ResultSet, String)</LongMessage><Class classname='org.apache.hadoop.mapreduce.lib.db.DateSplitter' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.lib.db.DateSplitter' start='46' end='176' sourcepath='org/apache/hadoop/mapreduce/lib/db/DateSplitter.java' sourcefile='DateSplitter.java'><Message>At DateSplitter.java:[lines 46-176]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.lib.db.DateSplitter</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapreduce.lib.db.DateSplitter' signature='(Lorg/apache/hadoop/conf/Configuration;Ljava/sql/ResultSet;Ljava/lang/String;)Ljava/util/List;' name='split' primary='true'><SourceLine endBytecode='242' classname='org.apache.hadoop.mapreduce.lib.db.DateSplitter' start='56' end='126' sourcepath='org/apache/hadoop/mapreduce/lib/db/DateSplitter.java' sourcefile='DateSplitter.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapreduce.lib.db.DateSplitter.split(Configuration, ResultSet, String)</Message></Method><LocalVariable role='LOCAL_VARIABLE_NAMED' pc='478' name='start' register='14'><Message>Local variable named start</Message></LocalVariable><SourceLine endBytecode='476' classname='org.apache.hadoop.mapreduce.lib.db.DateSplitter' start='116' end='116' sourcepath='org/apache/hadoop/mapreduce/lib/db/DateSplitter.java' sourcefile='DateSplitter.java' startBytecode='476' primary='true'><Message>At DateSplitter.java:[line 116]</Message></SourceLine><Property name='edu.umd.cs.findbugs.detect.DeadLocalStoreProperty.COPY_VALUE' value='true'></Property><Property name='edu.umd.cs.findbugs.detect.DeadLocalStoreProperty.KILLED_BY_SUBSEQUENT_STORE' value='true'></Property><Property name='edu.umd.cs.findbugs.detect.DeadLocalStoreProperty.LOCAL_NAME' value='start'></Property></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='760537ba4f2ac4f4ef00b9a209547b04' rank='20' abbrev='DP' category='MALICIOUS_CODE' priority='3' type='DP_DO_INSIDE_DO_PRIVILEGED' instanceOccurrenceMax='0'><ShortMessage>Method invoked that should be only be invoked inside a doPrivileged block</ShortMessage><LongMessage>Invocation of reflect.Method.setAccessible(boolean), which should be invoked from within a doPrivileged block, in org.apache.hadoop.mapreduce.lib.db.OracleDBRecordReader.setSessionTimeZone(Configuration, Connection)</LongMessage><Class classname='org.apache.hadoop.mapreduce.lib.db.OracleDBRecordReader' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.lib.db.OracleDBRecordReader' start='42' end='144' sourcepath='org/apache/hadoop/mapreduce/lib/db/OracleDBRecordReader.java' sourcefile='OracleDBRecordReader.java'><Message>At OracleDBRecordReader.java:[lines 42-144]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.lib.db.OracleDBRecordReader</Message></Class><Method isStatic='true' classname='org.apache.hadoop.mapreduce.lib.db.OracleDBRecordReader' signature='(Lorg/apache/hadoop/conf/Configuration;Ljava/sql/Connection;)V' name='setSessionTimeZone' primary='true'><SourceLine endBytecode='486' classname='org.apache.hadoop.mapreduce.lib.db.OracleDBRecordReader' start='114' end='144' sourcepath='org/apache/hadoop/mapreduce/lib/db/OracleDBRecordReader.java' sourcefile='OracleDBRecordReader.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapreduce.lib.db.OracleDBRecordReader.setSessionTimeZone(Configuration, Connection)</Message></Method><Method isStatic='false' role='METHOD_CALLED' classname='java.lang.reflect.Method' signature='(Z)V' name='setAccessible'><SourceLine classname='java.lang.reflect.Method' sourcepath='java/lang/reflect/Method.java' sourcefile='Method.java'></SourceLine><Message>Called method reflect.Method.setAccessible(boolean)</Message></Method><SourceLine endBytecode='77' classname='org.apache.hadoop.mapreduce.lib.db.OracleDBRecordReader' start='128' end='128' sourcepath='org/apache/hadoop/mapreduce/lib/db/OracleDBRecordReader.java' sourcefile='OracleDBRecordReader.java' startBytecode='77' primary='true'><Message>At OracleDBRecordReader.java:[line 128]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='1952e5a41321f168d66fd19f0a885759' cweid='396' rank='20' abbrev='REC' category='STYLE' priority='3' type='REC_CATCH_EXCEPTION' instanceOccurrenceMax='0'><ShortMessage>Exception is caught when Exception is not thrown</ShortMessage><LongMessage>Exception is caught when Exception is not thrown in org.apache.hadoop.mapreduce.lib.db.OracleDBRecordReader.setSessionTimeZone(Configuration, Connection)</LongMessage><Class classname='org.apache.hadoop.mapreduce.lib.db.OracleDBRecordReader' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.lib.db.OracleDBRecordReader' start='42' end='144' sourcepath='org/apache/hadoop/mapreduce/lib/db/OracleDBRecordReader.java' sourcefile='OracleDBRecordReader.java'><Message>At OracleDBRecordReader.java:[lines 42-144]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.lib.db.OracleDBRecordReader</Message></Class><Method isStatic='true' classname='org.apache.hadoop.mapreduce.lib.db.OracleDBRecordReader' signature='(Lorg/apache/hadoop/conf/Configuration;Ljava/sql/Connection;)V' name='setSessionTimeZone' primary='true'><SourceLine endBytecode='486' classname='org.apache.hadoop.mapreduce.lib.db.OracleDBRecordReader' start='114' end='144' sourcepath='org/apache/hadoop/mapreduce/lib/db/OracleDBRecordReader.java' sourcefile='OracleDBRecordReader.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapreduce.lib.db.OracleDBRecordReader.setSessionTimeZone(Configuration, Connection)</Message></Method><SourceLine endBytecode='124' classname='org.apache.hadoop.mapreduce.lib.db.OracleDBRecordReader' start='131' end='131' sourcepath='org/apache/hadoop/mapreduce/lib/db/OracleDBRecordReader.java' sourcefile='OracleDBRecordReader.java' startBytecode='124' primary='true'><Message>At OracleDBRecordReader.java:[line 131]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='7a8ba3aa3ee45068690b65fcfe8cdb43' rank='20' abbrev='RI' category='STYLE' priority='3' type='RI_REDUNDANT_INTERFACES' instanceOccurrenceMax='0'><ShortMessage>Class implements same interface as superclass</ShortMessage><LongMessage>Class org.apache.hadoop.mapreduce.lib.db.OracleDataDrivenDBInputFormat implements same interface as superclass</LongMessage><Class classname='org.apache.hadoop.mapreduce.lib.db.OracleDataDrivenDBInputFormat' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.lib.db.OracleDataDrivenDBInputFormat' start='54' end='87' sourcepath='org/apache/hadoop/mapreduce/lib/db/OracleDataDrivenDBInputFormat.java' sourcefile='OracleDataDrivenDBInputFormat.java'><Message>At OracleDataDrivenDBInputFormat.java:[lines 54-87]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.lib.db.OracleDataDrivenDBInputFormat</Message></Class><Class role='INTERFACE_TYPE' classname='org.apache.hadoop.conf.Configurable'><SourceLine classname='org.apache.hadoop.conf.Configurable' sourcepath='org/apache/hadoop/conf/Configurable.java' sourcefile='Configurable.java'><Message>In Configurable.java</Message></SourceLine><Message>Interface org.apache.hadoop.conf.Configurable</Message></Class><SourceLine synthetic='true' classname='org.apache.hadoop.mapreduce.lib.db.OracleDataDrivenDBInputFormat' start='54' end='87' sourcepath='org/apache/hadoop/mapreduce/lib/db/OracleDataDrivenDBInputFormat.java' sourcefile='OracleDataDrivenDBInputFormat.java'><Message>At OracleDataDrivenDBInputFormat.java:[lines 54-87]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='b6f9a8ff2d6fcf8cea12d066107b43cb' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.mapreduce.lib.fieldsel.FieldSelectionHelper.emptyText isn't final but should be</LongMessage><Class classname='org.apache.hadoop.mapreduce.lib.fieldsel.FieldSelectionHelper' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.lib.fieldsel.FieldSelectionHelper' start='62' end='231' sourcepath='org/apache/hadoop/mapreduce/lib/fieldsel/FieldSelectionHelper.java' sourcefile='FieldSelectionHelper.java'><Message>At FieldSelectionHelper.java:[lines 62-231]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.lib.fieldsel.FieldSelectionHelper</Message></Class><Field isStatic='true' classname='org.apache.hadoop.mapreduce.lib.fieldsel.FieldSelectionHelper' signature='Lorg/apache/hadoop/io/Text;' name='emptyText' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.lib.fieldsel.FieldSelectionHelper' sourcepath='org/apache/hadoop/mapreduce/lib/fieldsel/FieldSelectionHelper.java' sourcefile='FieldSelectionHelper.java'><Message>In FieldSelectionHelper.java</Message></SourceLine><Message>Field org.apache.hadoop.mapreduce.lib.fieldsel.FieldSelectionHelper.emptyText</Message></Field><SourceLine endBytecode='9' classname='org.apache.hadoop.mapreduce.lib.fieldsel.FieldSelectionHelper' start='62' end='62' sourcepath='org/apache/hadoop/mapreduce/lib/fieldsel/FieldSelectionHelper.java' sourcefile='FieldSelectionHelper.java' startBytecode='9' primary='true'><Message>At FieldSelectionHelper.java:[line 62]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='575d1f57815cfdf4241dacd5c2d2d77e' cweid='476' rank='19' abbrev='NP' category='STYLE' priority='3' type='NP_LOAD_OF_KNOWN_NULL_VALUE' instanceOccurrenceMax='0'><ShortMessage>Load of known null value</ShortMessage><LongMessage>Load of known null value in org.apache.hadoop.mapreduce.lib.fieldsel.FieldSelectionHelper.selectFields(String[], List, int, String)</LongMessage><Class classname='org.apache.hadoop.mapreduce.lib.fieldsel.FieldSelectionHelper' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.lib.fieldsel.FieldSelectionHelper' start='62' end='231' sourcepath='org/apache/hadoop/mapreduce/lib/fieldsel/FieldSelectionHelper.java' sourcefile='FieldSelectionHelper.java'><Message>At FieldSelectionHelper.java:[lines 62-231]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.lib.fieldsel.FieldSelectionHelper</Message></Class><Method isStatic='true' classname='org.apache.hadoop.mapreduce.lib.fieldsel.FieldSelectionHelper' signature='([Ljava/lang/String;Ljava/util/List;ILjava/lang/String;)Ljava/lang/String;' name='selectFields' primary='true'><SourceLine endBytecode='85' classname='org.apache.hadoop.mapreduce.lib.fieldsel.FieldSelectionHelper' start='122' end='150' sourcepath='org/apache/hadoop/mapreduce/lib/fieldsel/FieldSelectionHelper.java' sourcefile='FieldSelectionHelper.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapreduce.lib.fieldsel.FieldSelectionHelper.selectFields(String[], List, int, String)</Message></Method><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='19' name='sb' register='6'><Message>Value loaded from sb</Message></LocalVariable><SourceLine endBytecode='22' classname='org.apache.hadoop.mapreduce.lib.fieldsel.FieldSelectionHelper' start='126' end='126' sourcepath='org/apache/hadoop/mapreduce/lib/fieldsel/FieldSelectionHelper.java' sourcefile='FieldSelectionHelper.java' startBytecode='22' primary='true'><Message>At FieldSelectionHelper.java:[line 126]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='c4077a1b16c09a73615858864cb4507c' cweid='476' rank='20' abbrev='RCN' category='STYLE' priority='3' type='RCN_REDUNDANT_NULLCHECK_OF_NULL_VALUE' instanceOccurrenceMax='0'><ShortMessage>Redundant nullcheck of value known to be null</ShortMessage><LongMessage>Redundant nullcheck of sb which is known to be null in org.apache.hadoop.mapreduce.lib.fieldsel.FieldSelectionHelper.selectFields(String[], List, int, String)</LongMessage><Class classname='org.apache.hadoop.mapreduce.lib.fieldsel.FieldSelectionHelper' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.lib.fieldsel.FieldSelectionHelper' start='62' end='231' sourcepath='org/apache/hadoop/mapreduce/lib/fieldsel/FieldSelectionHelper.java' sourcefile='FieldSelectionHelper.java'><Message>At FieldSelectionHelper.java:[lines 62-231]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.lib.fieldsel.FieldSelectionHelper</Message></Class><Method isStatic='true' classname='org.apache.hadoop.mapreduce.lib.fieldsel.FieldSelectionHelper' signature='([Ljava/lang/String;Ljava/util/List;ILjava/lang/String;)Ljava/lang/String;' name='selectFields' primary='true'><SourceLine endBytecode='435' classname='org.apache.hadoop.mapreduce.lib.fieldsel.FieldSelectionHelper' start='122' end='150' sourcepath='org/apache/hadoop/mapreduce/lib/fieldsel/FieldSelectionHelper.java' sourcefile='FieldSelectionHelper.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapreduce.lib.fieldsel.FieldSelectionHelper.selectFields(String[], List, int, String)</Message></Method><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='22' name='sb' register='6'><Message>Value loaded from sb</Message></LocalVariable><SourceLine role='SOURCE_REDUNDANT_NULL_CHECK' endBytecode='24' classname='org.apache.hadoop.mapreduce.lib.fieldsel.FieldSelectionHelper' start='126' end='126' sourcepath='org/apache/hadoop/mapreduce/lib/fieldsel/FieldSelectionHelper.java' sourcefile='FieldSelectionHelper.java' startBytecode='24' primary='true'><Message>Redundant null check at FieldSelectionHelper.java:[line 126]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='5e7ac00d6154088f66f0c01d36451536' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from org.apache.hadoop.mapreduce.InputSplit to org.apache.hadoop.mapreduce.lib.input.CombineFileSplit in org.apache.hadoop.mapreduce.lib.input.CombineFileRecordReader.initialize(InputSplit, TaskAttemptContext)</LongMessage><Class classname='org.apache.hadoop.mapreduce.lib.input.CombineFileRecordReader' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.lib.input.CombineFileRecordReader' start='41' end='164' sourcepath='org/apache/hadoop/mapreduce/lib/input/CombineFileRecordReader.java' sourcefile='CombineFileRecordReader.java'><Message>At CombineFileRecordReader.java:[lines 41-164]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.lib.input.CombineFileRecordReader</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapreduce.lib.input.CombineFileRecordReader' signature='(Lorg/apache/hadoop/mapreduce/InputSplit;Lorg/apache/hadoop/mapreduce/TaskAttemptContext;)V' name='initialize' primary='true'><SourceLine endBytecode='16' classname='org.apache.hadoop.mapreduce.lib.input.CombineFileRecordReader' start='56' end='61' sourcepath='org/apache/hadoop/mapreduce/lib/input/CombineFileRecordReader.java' sourcefile='CombineFileRecordReader.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapreduce.lib.input.CombineFileRecordReader.initialize(InputSplit, TaskAttemptContext)</Message></Method><Type role='TYPE_FOUND' descriptor='Lorg/apache/hadoop/mapreduce/InputSplit;'><SourceLine classname='org.apache.hadoop.mapreduce.InputSplit' start='44' end='75' sourcepath='org/apache/hadoop/mapreduce/InputSplit.java' sourcefile='InputSplit.java'><Message>At InputSplit.java:[lines 44-75]</Message></SourceLine><Message>Actual type org.apache.hadoop.mapreduce.InputSplit</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/mapreduce/lib/input/CombineFileSplit;'><SourceLine classname='org.apache.hadoop.mapreduce.lib.input.CombineFileSplit' start='59' end='198' sourcepath='org/apache/hadoop/mapreduce/lib/input/CombineFileSplit.java' sourcefile='CombineFileSplit.java'><Message>At CombineFileSplit.java:[lines 59-198]</Message></SourceLine><Message>Expected org.apache.hadoop.mapreduce.lib.input.CombineFileSplit</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='1' name='split' register='1'><Message>Value loaded from split</Message></LocalVariable><SourceLine endBytecode='2' classname='org.apache.hadoop.mapreduce.lib.input.CombineFileRecordReader' start='56' end='56' sourcepath='org/apache/hadoop/mapreduce/lib/input/CombineFileRecordReader.java' sourcefile='CombineFileRecordReader.java' startBytecode='2' primary='true'><Message>At CombineFileRecordReader.java:[line 56]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='bf7f4fb1aece4abdc77892600327ed0' cweid='396' rank='20' abbrev='REC' category='STYLE' priority='3' type='REC_CATCH_EXCEPTION' instanceOccurrenceMax='0'><ShortMessage>Exception is caught when Exception is not thrown</ShortMessage><LongMessage>Exception is caught when Exception is not thrown in org.apache.hadoop.mapreduce.lib.input.CombineFileRecordReader.initNextRecordReader()</LongMessage><Class classname='org.apache.hadoop.mapreduce.lib.input.CombineFileRecordReader' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.lib.input.CombineFileRecordReader' start='41' end='164' sourcepath='org/apache/hadoop/mapreduce/lib/input/CombineFileRecordReader.java' sourcefile='CombineFileRecordReader.java'><Message>At CombineFileRecordReader.java:[lines 41-164]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.lib.input.CombineFileRecordReader</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapreduce.lib.input.CombineFileRecordReader' signature='()Z' name='initNextRecordReader' primary='true'><SourceLine endBytecode='415' classname='org.apache.hadoop.mapreduce.lib.input.CombineFileRecordReader' start='129' end='164' sourcepath='org/apache/hadoop/mapreduce/lib/input/CombineFileRecordReader.java' sourcefile='CombineFileRecordReader.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapreduce.lib.input.CombineFileRecordReader.initNextRecordReader()</Message></Method><SourceLine endBytecode='204' classname='org.apache.hadoop.mapreduce.lib.input.CombineFileRecordReader' start='160' end='160' sourcepath='org/apache/hadoop/mapreduce/lib/input/CombineFileRecordReader.java' sourcefile='CombineFileRecordReader.java' startBytecode='204' primary='true'><Message>At CombineFileRecordReader.java:[line 160]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='325c30d97353687d06e26d6da1ddaf56' cweid='374' rank='18' abbrev='EI' category='MALICIOUS_CODE' priority='2' type='EI_EXPOSE_REP' instanceOccurrenceMax='0'><ShortMessage>May expose internal representation by returning reference to mutable object</ShortMessage><LongMessage>org.apache.hadoop.mapreduce.lib.input.CombineFileSplit.getLengths() may expose internal representation by returning CombineFileSplit.lengths</LongMessage><Class classname='org.apache.hadoop.mapreduce.lib.input.CombineFileSplit' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.lib.input.CombineFileSplit' start='59' end='198' sourcepath='org/apache/hadoop/mapreduce/lib/input/CombineFileSplit.java' sourcefile='CombineFileSplit.java'><Message>At CombineFileSplit.java:[lines 59-198]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.lib.input.CombineFileSplit</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapreduce.lib.input.CombineFileSplit' signature='()[J' name='getLengths' primary='true'><SourceLine endBytecode='46' classname='org.apache.hadoop.mapreduce.lib.input.CombineFileSplit' start='108' end='108' sourcepath='org/apache/hadoop/mapreduce/lib/input/CombineFileSplit.java' sourcefile='CombineFileSplit.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapreduce.lib.input.CombineFileSplit.getLengths()</Message></Method><Field isStatic='false' classname='org.apache.hadoop.mapreduce.lib.input.CombineFileSplit' signature='[J' name='lengths' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.lib.input.CombineFileSplit' sourcepath='org/apache/hadoop/mapreduce/lib/input/CombineFileSplit.java' sourcefile='CombineFileSplit.java'><Message>In CombineFileSplit.java</Message></SourceLine><Message>Field org.apache.hadoop.mapreduce.lib.input.CombineFileSplit.lengths</Message></Field><SourceLine endBytecode='4' classname='org.apache.hadoop.mapreduce.lib.input.CombineFileSplit' start='108' end='108' sourcepath='org/apache/hadoop/mapreduce/lib/input/CombineFileSplit.java' sourcefile='CombineFileSplit.java' startBytecode='4' primary='true'><Message>At CombineFileSplit.java:[line 108]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='d56e09a25e1abee756257fb834799368' cweid='374' rank='18' abbrev='EI' category='MALICIOUS_CODE' priority='2' type='EI_EXPOSE_REP' instanceOccurrenceMax='0'><ShortMessage>May expose internal representation by returning reference to mutable object</ShortMessage><LongMessage>org.apache.hadoop.mapreduce.lib.input.CombineFileSplit.getLocations() may expose internal representation by returning CombineFileSplit.locations</LongMessage><Class classname='org.apache.hadoop.mapreduce.lib.input.CombineFileSplit' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.lib.input.CombineFileSplit' start='59' end='198' sourcepath='org/apache/hadoop/mapreduce/lib/input/CombineFileSplit.java' sourcefile='CombineFileSplit.java'><Message>At CombineFileSplit.java:[lines 59-198]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.lib.input.CombineFileSplit</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapreduce.lib.input.CombineFileSplit' signature='()[Ljava/lang/String;' name='getLocations' primary='true'><SourceLine endBytecode='46' classname='org.apache.hadoop.mapreduce.lib.input.CombineFileSplit' start='138' end='138' sourcepath='org/apache/hadoop/mapreduce/lib/input/CombineFileSplit.java' sourcefile='CombineFileSplit.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapreduce.lib.input.CombineFileSplit.getLocations()</Message></Method><Field isStatic='false' classname='org.apache.hadoop.mapreduce.lib.input.CombineFileSplit' signature='[Ljava/lang/String;' name='locations' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.lib.input.CombineFileSplit' sourcepath='org/apache/hadoop/mapreduce/lib/input/CombineFileSplit.java' sourcefile='CombineFileSplit.java'><Message>In CombineFileSplit.java</Message></SourceLine><Message>Field org.apache.hadoop.mapreduce.lib.input.CombineFileSplit.locations</Message></Field><SourceLine endBytecode='4' classname='org.apache.hadoop.mapreduce.lib.input.CombineFileSplit' start='138' end='138' sourcepath='org/apache/hadoop/mapreduce/lib/input/CombineFileSplit.java' sourcefile='CombineFileSplit.java' startBytecode='4' primary='true'><Message>At CombineFileSplit.java:[line 138]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='7526c7380a67c6408f44c43d48877dd9' cweid='374' rank='18' abbrev='EI' category='MALICIOUS_CODE' priority='2' type='EI_EXPOSE_REP' instanceOccurrenceMax='0'><ShortMessage>May expose internal representation by returning reference to mutable object</ShortMessage><LongMessage>org.apache.hadoop.mapreduce.lib.input.CombineFileSplit.getPaths() may expose internal representation by returning CombineFileSplit.paths</LongMessage><Class classname='org.apache.hadoop.mapreduce.lib.input.CombineFileSplit' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.lib.input.CombineFileSplit' start='59' end='198' sourcepath='org/apache/hadoop/mapreduce/lib/input/CombineFileSplit.java' sourcefile='CombineFileSplit.java'><Message>At CombineFileSplit.java:[lines 59-198]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.lib.input.CombineFileSplit</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapreduce.lib.input.CombineFileSplit' signature='()[Lorg/apache/hadoop/fs/Path;' name='getPaths' primary='true'><SourceLine endBytecode='46' classname='org.apache.hadoop.mapreduce.lib.input.CombineFileSplit' start='133' end='133' sourcepath='org/apache/hadoop/mapreduce/lib/input/CombineFileSplit.java' sourcefile='CombineFileSplit.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapreduce.lib.input.CombineFileSplit.getPaths()</Message></Method><Field isStatic='false' classname='org.apache.hadoop.mapreduce.lib.input.CombineFileSplit' signature='[Lorg/apache/hadoop/fs/Path;' name='paths' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.lib.input.CombineFileSplit' sourcepath='org/apache/hadoop/mapreduce/lib/input/CombineFileSplit.java' sourcefile='CombineFileSplit.java'><Message>In CombineFileSplit.java</Message></SourceLine><Message>Field org.apache.hadoop.mapreduce.lib.input.CombineFileSplit.paths</Message></Field><SourceLine endBytecode='4' classname='org.apache.hadoop.mapreduce.lib.input.CombineFileSplit' start='133' end='133' sourcepath='org/apache/hadoop/mapreduce/lib/input/CombineFileSplit.java' sourcefile='CombineFileSplit.java' startBytecode='4' primary='true'><Message>At CombineFileSplit.java:[line 133]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='cac1701db4ac60e07cf4735c5ce22ca6' cweid='374' rank='18' abbrev='EI' category='MALICIOUS_CODE' priority='2' type='EI_EXPOSE_REP' instanceOccurrenceMax='0'><ShortMessage>May expose internal representation by returning reference to mutable object</ShortMessage><LongMessage>org.apache.hadoop.mapreduce.lib.input.CombineFileSplit.getStartOffsets() may expose internal representation by returning CombineFileSplit.startoffset</LongMessage><Class classname='org.apache.hadoop.mapreduce.lib.input.CombineFileSplit' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.lib.input.CombineFileSplit' start='59' end='198' sourcepath='org/apache/hadoop/mapreduce/lib/input/CombineFileSplit.java' sourcefile='CombineFileSplit.java'><Message>At CombineFileSplit.java:[lines 59-198]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.lib.input.CombineFileSplit</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapreduce.lib.input.CombineFileSplit' signature='()[J' name='getStartOffsets' primary='true'><SourceLine endBytecode='46' classname='org.apache.hadoop.mapreduce.lib.input.CombineFileSplit' start='103' end='103' sourcepath='org/apache/hadoop/mapreduce/lib/input/CombineFileSplit.java' sourcefile='CombineFileSplit.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapreduce.lib.input.CombineFileSplit.getStartOffsets()</Message></Method><Field isStatic='false' classname='org.apache.hadoop.mapreduce.lib.input.CombineFileSplit' signature='[J' name='startoffset' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.lib.input.CombineFileSplit' sourcepath='org/apache/hadoop/mapreduce/lib/input/CombineFileSplit.java' sourcefile='CombineFileSplit.java'><Message>In CombineFileSplit.java</Message></SourceLine><Message>Field org.apache.hadoop.mapreduce.lib.input.CombineFileSplit.startoffset</Message></Field><SourceLine endBytecode='4' classname='org.apache.hadoop.mapreduce.lib.input.CombineFileSplit' start='103' end='103' sourcepath='org/apache/hadoop/mapreduce/lib/input/CombineFileSplit.java' sourcefile='CombineFileSplit.java' startBytecode='4' primary='true'><Message>At CombineFileSplit.java:[line 103]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='7699780d54fc900a70d67375be660d15' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from org.apache.hadoop.mapreduce.InputSplit to org.apache.hadoop.mapreduce.lib.input.CombineFileSplit in org.apache.hadoop.mapreduce.lib.input.CombineSequenceFileInputFormat.createRecordReader(InputSplit, TaskAttemptContext)</LongMessage><Class classname='org.apache.hadoop.mapreduce.lib.input.CombineSequenceFileInputFormat' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.lib.input.CombineSequenceFileInputFormat' start='37' end='42' sourcepath='org/apache/hadoop/mapreduce/lib/input/CombineSequenceFileInputFormat.java' sourcefile='CombineSequenceFileInputFormat.java'><Message>At CombineSequenceFileInputFormat.java:[lines 37-42]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.lib.input.CombineSequenceFileInputFormat</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapreduce.lib.input.CombineSequenceFileInputFormat' signature='(Lorg/apache/hadoop/mapreduce/InputSplit;Lorg/apache/hadoop/mapreduce/TaskAttemptContext;)Lorg/apache/hadoop/mapreduce/RecordReader;' name='createRecordReader' primary='true'><SourceLine endBytecode='7' classname='org.apache.hadoop.mapreduce.lib.input.CombineSequenceFileInputFormat' start='42' end='42' sourcepath='org/apache/hadoop/mapreduce/lib/input/CombineSequenceFileInputFormat.java' sourcefile='CombineSequenceFileInputFormat.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapreduce.lib.input.CombineSequenceFileInputFormat.createRecordReader(InputSplit, TaskAttemptContext)</Message></Method><Type role='TYPE_FOUND' descriptor='Lorg/apache/hadoop/mapreduce/InputSplit;'><SourceLine classname='org.apache.hadoop.mapreduce.InputSplit' start='44' end='75' sourcepath='org/apache/hadoop/mapreduce/InputSplit.java' sourcefile='InputSplit.java'><Message>At InputSplit.java:[lines 44-75]</Message></SourceLine><Message>Actual type org.apache.hadoop.mapreduce.InputSplit</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/mapreduce/lib/input/CombineFileSplit;'><SourceLine classname='org.apache.hadoop.mapreduce.lib.input.CombineFileSplit' start='59' end='198' sourcepath='org/apache/hadoop/mapreduce/lib/input/CombineFileSplit.java' sourcefile='CombineFileSplit.java'><Message>At CombineFileSplit.java:[lines 59-198]</Message></SourceLine><Message>Expected org.apache.hadoop.mapreduce.lib.input.CombineFileSplit</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='4' name='split' register='1'><Message>Value loaded from split</Message></LocalVariable><SourceLine endBytecode='5' classname='org.apache.hadoop.mapreduce.lib.input.CombineSequenceFileInputFormat' start='42' end='42' sourcepath='org/apache/hadoop/mapreduce/lib/input/CombineSequenceFileInputFormat.java' sourcefile='CombineSequenceFileInputFormat.java' startBytecode='5' primary='true'><Message>At CombineSequenceFileInputFormat.java:[line 42]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='641a6a53aa6c3be0de5e29e2e61bf7a5' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from org.apache.hadoop.mapreduce.InputSplit to org.apache.hadoop.mapreduce.lib.input.CombineFileSplit in org.apache.hadoop.mapreduce.lib.input.CombineTextInputFormat.createRecordReader(InputSplit, TaskAttemptContext)</LongMessage><Class classname='org.apache.hadoop.mapreduce.lib.input.CombineTextInputFormat' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.lib.input.CombineTextInputFormat' start='39' end='43' sourcepath='org/apache/hadoop/mapreduce/lib/input/CombineTextInputFormat.java' sourcefile='CombineTextInputFormat.java'><Message>At CombineTextInputFormat.java:[lines 39-43]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.lib.input.CombineTextInputFormat</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapreduce.lib.input.CombineTextInputFormat' signature='(Lorg/apache/hadoop/mapreduce/InputSplit;Lorg/apache/hadoop/mapreduce/TaskAttemptContext;)Lorg/apache/hadoop/mapreduce/RecordReader;' name='createRecordReader' primary='true'><SourceLine endBytecode='7' classname='org.apache.hadoop.mapreduce.lib.input.CombineTextInputFormat' start='43' end='43' sourcepath='org/apache/hadoop/mapreduce/lib/input/CombineTextInputFormat.java' sourcefile='CombineTextInputFormat.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapreduce.lib.input.CombineTextInputFormat.createRecordReader(InputSplit, TaskAttemptContext)</Message></Method><Type role='TYPE_FOUND' descriptor='Lorg/apache/hadoop/mapreduce/InputSplit;'><SourceLine classname='org.apache.hadoop.mapreduce.InputSplit' start='44' end='75' sourcepath='org/apache/hadoop/mapreduce/InputSplit.java' sourcefile='InputSplit.java'><Message>At InputSplit.java:[lines 44-75]</Message></SourceLine><Message>Actual type org.apache.hadoop.mapreduce.InputSplit</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/mapreduce/lib/input/CombineFileSplit;'><SourceLine classname='org.apache.hadoop.mapreduce.lib.input.CombineFileSplit' start='59' end='198' sourcepath='org/apache/hadoop/mapreduce/lib/input/CombineFileSplit.java' sourcefile='CombineFileSplit.java'><Message>At CombineFileSplit.java:[lines 59-198]</Message></SourceLine><Message>Expected org.apache.hadoop.mapreduce.lib.input.CombineFileSplit</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='4' name='split' register='1'><Message>Value loaded from split</Message></LocalVariable><SourceLine endBytecode='5' classname='org.apache.hadoop.mapreduce.lib.input.CombineTextInputFormat' start='43' end='43' sourcepath='org/apache/hadoop/mapreduce/lib/input/CombineTextInputFormat.java' sourcefile='CombineTextInputFormat.java' startBytecode='5' primary='true'><Message>At CombineTextInputFormat.java:[line 43]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='676fc6e31cda66d6bfabd18540352ff9' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from org.apache.hadoop.mapreduce.InputSplit to org.apache.hadoop.mapreduce.lib.input.TaggedInputSplit in new org.apache.hadoop.mapreduce.lib.input.DelegatingRecordReader(InputSplit, TaskAttemptContext)</LongMessage><Class classname='org.apache.hadoop.mapreduce.lib.input.DelegatingRecordReader' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.lib.input.DelegatingRecordReader' start='50' end='89' sourcepath='org/apache/hadoop/mapreduce/lib/input/DelegatingRecordReader.java' sourcefile='DelegatingRecordReader.java'><Message>At DelegatingRecordReader.java:[lines 50-89]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.lib.input.DelegatingRecordReader</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapreduce.lib.input.DelegatingRecordReader' signature='(Lorg/apache/hadoop/mapreduce/InputSplit;Lorg/apache/hadoop/mapreduce/TaskAttemptContext;)V' name='&lt;init&gt;' primary='true'><SourceLine endBytecode='19' classname='org.apache.hadoop.mapreduce.lib.input.DelegatingRecordReader' start='50' end='59' sourcepath='org/apache/hadoop/mapreduce/lib/input/DelegatingRecordReader.java' sourcefile='DelegatingRecordReader.java' startBytecode='0'></SourceLine><Message>In method new org.apache.hadoop.mapreduce.lib.input.DelegatingRecordReader(InputSplit, TaskAttemptContext)</Message></Method><Type role='TYPE_FOUND' descriptor='Lorg/apache/hadoop/mapreduce/InputSplit;'><SourceLine classname='org.apache.hadoop.mapreduce.InputSplit' start='44' end='75' sourcepath='org/apache/hadoop/mapreduce/InputSplit.java' sourcefile='InputSplit.java'><Message>At InputSplit.java:[lines 44-75]</Message></SourceLine><Message>Actual type org.apache.hadoop.mapreduce.InputSplit</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/mapreduce/lib/input/TaggedInputSplit;'><SourceLine classname='org.apache.hadoop.mapreduce.lib.input.TaggedInputSplit' start='58' end='162' sourcepath='org/apache/hadoop/mapreduce/lib/input/TaggedInputSplit.java' sourcefile='TaggedInputSplit.java'><Message>At TaggedInputSplit.java:[lines 58-162]</Message></SourceLine><Message>Expected org.apache.hadoop.mapreduce.lib.input.TaggedInputSplit</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='4' name='split' register='1'><Message>Value loaded from split</Message></LocalVariable><SourceLine endBytecode='5' classname='org.apache.hadoop.mapreduce.lib.input.DelegatingRecordReader' start='53' end='53' sourcepath='org/apache/hadoop/mapreduce/lib/input/DelegatingRecordReader.java' sourcefile='DelegatingRecordReader.java' startBytecode='5' primary='true'><Message>At DelegatingRecordReader.java:[line 53]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='7146f1bad1bc65eba51e8ac615ddcc29' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from org.apache.hadoop.mapreduce.InputSplit to org.apache.hadoop.mapreduce.lib.input.TaggedInputSplit in org.apache.hadoop.mapreduce.lib.input.DelegatingRecordReader.initialize(InputSplit, TaskAttemptContext)</LongMessage><Class classname='org.apache.hadoop.mapreduce.lib.input.DelegatingRecordReader' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.lib.input.DelegatingRecordReader' start='50' end='89' sourcepath='org/apache/hadoop/mapreduce/lib/input/DelegatingRecordReader.java' sourcefile='DelegatingRecordReader.java'><Message>At DelegatingRecordReader.java:[lines 50-89]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.lib.input.DelegatingRecordReader</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapreduce.lib.input.DelegatingRecordReader' signature='(Lorg/apache/hadoop/mapreduce/InputSplit;Lorg/apache/hadoop/mapreduce/TaskAttemptContext;)V' name='initialize' primary='true'><SourceLine endBytecode='7' classname='org.apache.hadoop.mapreduce.lib.input.DelegatingRecordReader' start='84' end='85' sourcepath='org/apache/hadoop/mapreduce/lib/input/DelegatingRecordReader.java' sourcefile='DelegatingRecordReader.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapreduce.lib.input.DelegatingRecordReader.initialize(InputSplit, TaskAttemptContext)</Message></Method><Type role='TYPE_FOUND' descriptor='Lorg/apache/hadoop/mapreduce/InputSplit;'><SourceLine classname='org.apache.hadoop.mapreduce.InputSplit' start='44' end='75' sourcepath='org/apache/hadoop/mapreduce/InputSplit.java' sourcefile='InputSplit.java'><Message>At InputSplit.java:[lines 44-75]</Message></SourceLine><Message>Actual type org.apache.hadoop.mapreduce.InputSplit</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/mapreduce/lib/input/TaggedInputSplit;'><SourceLine classname='org.apache.hadoop.mapreduce.lib.input.TaggedInputSplit' start='58' end='162' sourcepath='org/apache/hadoop/mapreduce/lib/input/TaggedInputSplit.java' sourcefile='TaggedInputSplit.java'><Message>At TaggedInputSplit.java:[lines 58-162]</Message></SourceLine><Message>Expected org.apache.hadoop.mapreduce.lib.input.TaggedInputSplit</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='4' name='split' register='1'><Message>Value loaded from split</Message></LocalVariable><SourceLine endBytecode='5' classname='org.apache.hadoop.mapreduce.lib.input.DelegatingRecordReader' start='84' end='84' sourcepath='org/apache/hadoop/mapreduce/lib/input/DelegatingRecordReader.java' sourcefile='DelegatingRecordReader.java' startBytecode='5' primary='true'><Message>At DelegatingRecordReader.java:[line 84]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='e5a3131db2e1f233ff24c3275a038299' cweid='374' rank='18' abbrev='EI' category='MALICIOUS_CODE' priority='2' type='EI_EXPOSE_REP' instanceOccurrenceMax='0'><ShortMessage>May expose internal representation by returning reference to mutable object</ShortMessage><LongMessage>org.apache.hadoop.mapreduce.lib.input.FileSplit.getLocationInfo() may expose internal representation by returning FileSplit.hostInfos</LongMessage><Class classname='org.apache.hadoop.mapreduce.lib.input.FileSplit' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.lib.input.FileSplit' start='48' end='133' sourcepath='org/apache/hadoop/mapreduce/lib/input/FileSplit.java' sourcefile='FileSplit.java'><Message>At FileSplit.java:[lines 48-133]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.lib.input.FileSplit</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapreduce.lib.input.FileSplit' signature='()[Lorg/apache/hadoop/mapred/SplitLocationInfo;' name='getLocationInfo' primary='true'><SourceLine endBytecode='46' classname='org.apache.hadoop.mapreduce.lib.input.FileSplit' start='133' end='133' sourcepath='org/apache/hadoop/mapreduce/lib/input/FileSplit.java' sourcefile='FileSplit.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapreduce.lib.input.FileSplit.getLocationInfo()</Message></Method><Field isStatic='false' classname='org.apache.hadoop.mapreduce.lib.input.FileSplit' signature='[Lorg/apache/hadoop/mapred/SplitLocationInfo;' name='hostInfos' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.lib.input.FileSplit' sourcepath='org/apache/hadoop/mapreduce/lib/input/FileSplit.java' sourcefile='FileSplit.java'><Message>In FileSplit.java</Message></SourceLine><Message>Field org.apache.hadoop.mapreduce.lib.input.FileSplit.hostInfos</Message></Field><SourceLine endBytecode='4' classname='org.apache.hadoop.mapreduce.lib.input.FileSplit' start='133' end='133' sourcepath='org/apache/hadoop/mapreduce/lib/input/FileSplit.java' sourcefile='FileSplit.java' startBytecode='4' primary='true'><Message>At FileSplit.java:[line 133]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='f12a50f4cfd729836cacac4b3f96ca9f' cweid='374' rank='18' abbrev='EI' category='MALICIOUS_CODE' priority='2' type='EI_EXPOSE_REP' instanceOccurrenceMax='0'><ShortMessage>May expose internal representation by returning reference to mutable object</ShortMessage><LongMessage>org.apache.hadoop.mapreduce.lib.input.FileSplit.getLocations() may expose internal representation by returning FileSplit.hosts</LongMessage><Class classname='org.apache.hadoop.mapreduce.lib.input.FileSplit' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.lib.input.FileSplit' start='48' end='133' sourcepath='org/apache/hadoop/mapreduce/lib/input/FileSplit.java' sourcefile='FileSplit.java'><Message>At FileSplit.java:[lines 48-133]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.lib.input.FileSplit</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapreduce.lib.input.FileSplit' signature='()[Ljava/lang/String;' name='getLocations' primary='true'><SourceLine endBytecode='75' classname='org.apache.hadoop.mapreduce.lib.input.FileSplit' start='123' end='126' sourcepath='org/apache/hadoop/mapreduce/lib/input/FileSplit.java' sourcefile='FileSplit.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapreduce.lib.input.FileSplit.getLocations()</Message></Method><Field isStatic='false' classname='org.apache.hadoop.mapreduce.lib.input.FileSplit' signature='[Ljava/lang/String;' name='hosts' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.lib.input.FileSplit' sourcepath='org/apache/hadoop/mapreduce/lib/input/FileSplit.java' sourcefile='FileSplit.java'><Message>In FileSplit.java</Message></SourceLine><Message>Field org.apache.hadoop.mapreduce.lib.input.FileSplit.hosts</Message></Field><SourceLine endBytecode='16' classname='org.apache.hadoop.mapreduce.lib.input.FileSplit' start='126' end='126' sourcepath='org/apache/hadoop/mapreduce/lib/input/FileSplit.java' sourcefile='FileSplit.java' startBytecode='16' primary='true'><Message>At FileSplit.java:[line 126]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='93541a29c7966d5edfb24cfd05835694' cweid='374' rank='18' abbrev='EI2' category='MALICIOUS_CODE' priority='2' type='EI_EXPOSE_REP2' instanceOccurrenceMax='0'><ShortMessage>May expose internal representation by incorporating reference to mutable object</ShortMessage><LongMessage>new org.apache.hadoop.mapreduce.lib.input.FileSplit(Path, long, long, String[]) may expose internal representation by storing an externally mutable object into FileSplit.hosts</LongMessage><Class classname='org.apache.hadoop.mapreduce.lib.input.FileSplit' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.lib.input.FileSplit' start='48' end='133' sourcepath='org/apache/hadoop/mapreduce/lib/input/FileSplit.java' sourcefile='FileSplit.java'><Message>At FileSplit.java:[lines 48-133]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.lib.input.FileSplit</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapreduce.lib.input.FileSplit' signature='(Lorg/apache/hadoop/fs/Path;JJ[Ljava/lang/String;)V' name='&lt;init&gt;' primary='true'><SourceLine endBytecode='128' classname='org.apache.hadoop.mapreduce.lib.input.FileSplit' start='57' end='62' sourcepath='org/apache/hadoop/mapreduce/lib/input/FileSplit.java' sourcefile='FileSplit.java' startBytecode='0'></SourceLine><Message>In method new org.apache.hadoop.mapreduce.lib.input.FileSplit(Path, long, long, String[])</Message></Method><Field isStatic='false' classname='org.apache.hadoop.mapreduce.lib.input.FileSplit' signature='[Ljava/lang/String;' name='hosts' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.lib.input.FileSplit' sourcepath='org/apache/hadoop/mapreduce/lib/input/FileSplit.java' sourcefile='FileSplit.java'><Message>In FileSplit.java</Message></SourceLine><Message>Field org.apache.hadoop.mapreduce.lib.input.FileSplit.hosts</Message></Field><LocalVariable role='LOCAL_VARIABLE_NAMED' pc='23' name='hosts' register='6'><Message>Local variable named hosts</Message></LocalVariable><SourceLine endBytecode='23' classname='org.apache.hadoop.mapreduce.lib.input.FileSplit' start='61' end='61' sourcepath='org/apache/hadoop/mapreduce/lib/input/FileSplit.java' sourcefile='FileSplit.java' startBytecode='23' primary='true'><Message>At FileSplit.java:[line 61]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='be9f2ca5b3f992ffc6706fe577974b95' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from org.apache.hadoop.mapreduce.InputSplit to org.apache.hadoop.mapreduce.lib.input.FileSplit in org.apache.hadoop.mapreduce.lib.input.FixedLengthRecordReader.initialize(InputSplit, TaskAttemptContext)</LongMessage><Class classname='org.apache.hadoop.mapreduce.lib.input.FixedLengthRecordReader' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.lib.input.FixedLengthRecordReader' start='48' end='217' sourcepath='org/apache/hadoop/mapreduce/lib/input/FixedLengthRecordReader.java' sourcefile='FixedLengthRecordReader.java'><Message>At FixedLengthRecordReader.java:[lines 48-217]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.lib.input.FixedLengthRecordReader</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapreduce.lib.input.FixedLengthRecordReader' signature='(Lorg/apache/hadoop/mapreduce/InputSplit;Lorg/apache/hadoop/mapreduce/TaskAttemptContext;)V' name='initialize' primary='true'><SourceLine endBytecode='17' classname='org.apache.hadoop.mapreduce.lib.input.FixedLengthRecordReader' start='75' end='79' sourcepath='org/apache/hadoop/mapreduce/lib/input/FixedLengthRecordReader.java' sourcefile='FixedLengthRecordReader.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapreduce.lib.input.FixedLengthRecordReader.initialize(InputSplit, TaskAttemptContext)</Message></Method><Type role='TYPE_FOUND' descriptor='Lorg/apache/hadoop/mapreduce/InputSplit;'><SourceLine classname='org.apache.hadoop.mapreduce.InputSplit' start='44' end='75' sourcepath='org/apache/hadoop/mapreduce/InputSplit.java' sourcefile='InputSplit.java'><Message>At InputSplit.java:[lines 44-75]</Message></SourceLine><Message>Actual type org.apache.hadoop.mapreduce.InputSplit</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/mapreduce/lib/input/FileSplit;'><SourceLine classname='org.apache.hadoop.mapreduce.lib.input.FileSplit' start='48' end='133' sourcepath='org/apache/hadoop/mapreduce/lib/input/FileSplit.java' sourcefile='FileSplit.java'><Message>At FileSplit.java:[lines 48-133]</Message></SourceLine><Message>Expected org.apache.hadoop.mapreduce.lib.input.FileSplit</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='0' name='genericSplit' register='1'><Message>Value loaded from genericSplit</Message></LocalVariable><SourceLine endBytecode='1' classname='org.apache.hadoop.mapreduce.lib.input.FixedLengthRecordReader' start='75' end='75' sourcepath='org/apache/hadoop/mapreduce/lib/input/FixedLengthRecordReader.java' sourcefile='FixedLengthRecordReader.java' startBytecode='1' primary='true'><Message>At FixedLengthRecordReader.java:[line 75]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='5a5494f9e3be2566c9a8400354d36be5' cweid='366' rank='20' abbrev='IS' category='MT_CORRECTNESS' priority='3' type='IS2_INCONSISTENT_SYNC' instanceOccurrenceMax='0'><ShortMessage>Inconsistent synchronization</ShortMessage><LongMessage>Inconsistent synchronization of org.apache.hadoop.mapreduce.lib.input.FixedLengthRecordReader.key; locked 75% of time</LongMessage><Class classname='org.apache.hadoop.mapreduce.lib.input.FixedLengthRecordReader' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.lib.input.FixedLengthRecordReader' start='48' end='217' sourcepath='org/apache/hadoop/mapreduce/lib/input/FixedLengthRecordReader.java' sourcefile='FixedLengthRecordReader.java'><Message>At FixedLengthRecordReader.java:[lines 48-217]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.lib.input.FixedLengthRecordReader</Message></Class><Field isStatic='false' classname='org.apache.hadoop.mapreduce.lib.input.FixedLengthRecordReader' signature='Lorg/apache/hadoop/io/LongWritable;' name='key' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.lib.input.FixedLengthRecordReader' sourcepath='org/apache/hadoop/mapreduce/lib/input/FixedLengthRecordReader.java' sourcefile='FixedLengthRecordReader.java'><Message>In FixedLengthRecordReader.java</Message></SourceLine><Message>Field org.apache.hadoop.mapreduce.lib.input.FixedLengthRecordReader.key</Message></Field><Int role='INT_SYNC_PERCENT' value='75'><Message>Synchronized 75% of the time</Message></Int><SourceLine role='SOURCE_LINE_UNSYNC_ACCESS' endBytecode='1' classname='org.apache.hadoop.mapreduce.lib.input.FixedLengthRecordReader' start='173' end='173' sourcepath='org/apache/hadoop/mapreduce/lib/input/FixedLengthRecordReader.java' sourcefile='FixedLengthRecordReader.java' startBytecode='1' primary='true'><Message>Unsynchronized access at FixedLengthRecordReader.java:[line 173]</Message></SourceLine><SourceLine role='SOURCE_LINE_SYNC_ACCESS' endBytecode='1' classname='org.apache.hadoop.mapreduce.lib.input.FixedLengthRecordReader' start='129' end='129' sourcepath='org/apache/hadoop/mapreduce/lib/input/FixedLengthRecordReader.java' sourcefile='FixedLengthRecordReader.java' startBytecode='1'><Message>Synchronized access at FixedLengthRecordReader.java:[line 129]</Message></SourceLine><SourceLine role='SOURCE_LINE_SYNC_ACCESS' endBytecode='15' classname='org.apache.hadoop.mapreduce.lib.input.FixedLengthRecordReader' start='130' end='130' sourcepath='org/apache/hadoop/mapreduce/lib/input/FixedLengthRecordReader.java' sourcefile='FixedLengthRecordReader.java' startBytecode='15'><Message>Synchronized access at FixedLengthRecordReader.java:[line 130]</Message></SourceLine><SourceLine role='SOURCE_LINE_SYNC_ACCESS' endBytecode='73' classname='org.apache.hadoop.mapreduce.lib.input.FixedLengthRecordReader' start='139' end='139' sourcepath='org/apache/hadoop/mapreduce/lib/input/FixedLengthRecordReader.java' sourcefile='FixedLengthRecordReader.java' startBytecode='73'><Message>Synchronized access at FixedLengthRecordReader.java:[line 139]</Message></SourceLine><Property name='edu.umd.cs.findbugs.detect.InconsistentSyncWarningProperty.ONLY_UNSYNC_IN_GETTERS' value='true'></Property></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='f499683a399685086c8a1586b041785c' cweid='366' rank='20' abbrev='IS' category='MT_CORRECTNESS' priority='3' type='IS2_INCONSISTENT_SYNC' instanceOccurrenceMax='0'><ShortMessage>Inconsistent synchronization</ShortMessage><LongMessage>Inconsistent synchronization of org.apache.hadoop.mapreduce.lib.input.FixedLengthRecordReader.pos; locked 80% of time</LongMessage><Class classname='org.apache.hadoop.mapreduce.lib.input.FixedLengthRecordReader' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.lib.input.FixedLengthRecordReader' start='48' end='217' sourcepath='org/apache/hadoop/mapreduce/lib/input/FixedLengthRecordReader.java' sourcefile='FixedLengthRecordReader.java'><Message>At FixedLengthRecordReader.java:[lines 48-217]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.lib.input.FixedLengthRecordReader</Message></Class><Field isStatic='false' classname='org.apache.hadoop.mapreduce.lib.input.FixedLengthRecordReader' signature='J' name='pos' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.lib.input.FixedLengthRecordReader' sourcepath='org/apache/hadoop/mapreduce/lib/input/FixedLengthRecordReader.java' sourcefile='FixedLengthRecordReader.java'><Message>In FixedLengthRecordReader.java</Message></SourceLine><Message>Field org.apache.hadoop.mapreduce.lib.input.FixedLengthRecordReader.pos</Message></Field><Int role='INT_SYNC_PERCENT' value='80'><Message>Synchronized 80% of the time</Message></Int><SourceLine role='SOURCE_LINE_UNSYNC_ACCESS' endBytecode='1' classname='org.apache.hadoop.mapreduce.lib.input.FixedLengthRecordReader' start='207' end='207' sourcepath='org/apache/hadoop/mapreduce/lib/input/FixedLengthRecordReader.java' sourcefile='FixedLengthRecordReader.java' startBytecode='1' primary='true'><Message>Unsynchronized access at FixedLengthRecordReader.java:[line 207]</Message></SourceLine><SourceLine role='SOURCE_LINE_SYNC_ACCESS' endBytecode='29' classname='org.apache.hadoop.mapreduce.lib.input.FixedLengthRecordReader' start='215' end='215' sourcepath='org/apache/hadoop/mapreduce/lib/input/FixedLengthRecordReader.java' sourcefile='FixedLengthRecordReader.java' startBytecode='29'><Message>Synchronized access at FixedLengthRecordReader.java:[line 215]</Message></SourceLine><SourceLine role='SOURCE_LINE_SYNC_ACCESS' endBytecode='77' classname='org.apache.hadoop.mapreduce.lib.input.FixedLengthRecordReader' start='139' end='139' sourcepath='org/apache/hadoop/mapreduce/lib/input/FixedLengthRecordReader.java' sourcefile='FixedLengthRecordReader.java' startBytecode='77'><Message>Synchronized access at FixedLengthRecordReader.java:[line 139]</Message></SourceLine><SourceLine role='SOURCE_LINE_SYNC_ACCESS' endBytecode='147' classname='org.apache.hadoop.mapreduce.lib.input.FixedLengthRecordReader' start='153' end='153' sourcepath='org/apache/hadoop/mapreduce/lib/input/FixedLengthRecordReader.java' sourcefile='FixedLengthRecordReader.java' startBytecode='147'><Message>Synchronized access at FixedLengthRecordReader.java:[line 153]</Message></SourceLine><SourceLine role='SOURCE_LINE_SYNC_ACCESS' endBytecode='154' classname='org.apache.hadoop.mapreduce.lib.input.FixedLengthRecordReader' start='153' end='153' sourcepath='org/apache/hadoop/mapreduce/lib/input/FixedLengthRecordReader.java' sourcefile='FixedLengthRecordReader.java' startBytecode='154'><Message>Synchronized access at FixedLengthRecordReader.java:[line 153]</Message></SourceLine><SourceLine role='SOURCE_LINE_SYNC_ACCESS' endBytecode='313' classname='org.apache.hadoop.mapreduce.lib.input.FixedLengthRecordReader' start='124' end='124' sourcepath='org/apache/hadoop/mapreduce/lib/input/FixedLengthRecordReader.java' sourcefile='FixedLengthRecordReader.java' startBytecode='313'><Message>Synchronized access at FixedLengthRecordReader.java:[line 124]</Message></SourceLine><Property name='edu.umd.cs.findbugs.detect.InconsistentSyncWarningProperty.ONLY_UNSYNC_IN_GETTERS' value='true'></Property></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='15f81b23a1eada2002922d5f917b43a2' cweid='366' rank='20' abbrev='IS' category='MT_CORRECTNESS' priority='3' type='IS2_INCONSISTENT_SYNC' instanceOccurrenceMax='0'><ShortMessage>Inconsistent synchronization</ShortMessage><LongMessage>Inconsistent synchronization of org.apache.hadoop.mapreduce.lib.input.FixedLengthRecordReader.value; locked 80% of time</LongMessage><Class classname='org.apache.hadoop.mapreduce.lib.input.FixedLengthRecordReader' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.lib.input.FixedLengthRecordReader' start='48' end='217' sourcepath='org/apache/hadoop/mapreduce/lib/input/FixedLengthRecordReader.java' sourcefile='FixedLengthRecordReader.java'><Message>At FixedLengthRecordReader.java:[lines 48-217]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.lib.input.FixedLengthRecordReader</Message></Class><Field isStatic='false' classname='org.apache.hadoop.mapreduce.lib.input.FixedLengthRecordReader' signature='Lorg/apache/hadoop/io/BytesWritable;' name='value' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.lib.input.FixedLengthRecordReader' sourcepath='org/apache/hadoop/mapreduce/lib/input/FixedLengthRecordReader.java' sourcefile='FixedLengthRecordReader.java'><Message>In FixedLengthRecordReader.java</Message></SourceLine><Message>Field org.apache.hadoop.mapreduce.lib.input.FixedLengthRecordReader.value</Message></Field><Int role='INT_SYNC_PERCENT' value='80'><Message>Synchronized 80% of the time</Message></Int><SourceLine role='SOURCE_LINE_UNSYNC_ACCESS' endBytecode='1' classname='org.apache.hadoop.mapreduce.lib.input.FixedLengthRecordReader' start='178' end='178' sourcepath='org/apache/hadoop/mapreduce/lib/input/FixedLengthRecordReader.java' sourcefile='FixedLengthRecordReader.java' startBytecode='1' primary='true'><Message>Unsynchronized access at FixedLengthRecordReader.java:[line 178]</Message></SourceLine><SourceLine role='SOURCE_LINE_SYNC_ACCESS' endBytecode='19' classname='org.apache.hadoop.mapreduce.lib.input.FixedLengthRecordReader' start='132' end='132' sourcepath='org/apache/hadoop/mapreduce/lib/input/FixedLengthRecordReader.java' sourcefile='FixedLengthRecordReader.java' startBytecode='19'><Message>Synchronized access at FixedLengthRecordReader.java:[line 132]</Message></SourceLine><SourceLine role='SOURCE_LINE_SYNC_ACCESS' endBytecode='45' classname='org.apache.hadoop.mapreduce.lib.input.FixedLengthRecordReader' start='136' end='136' sourcepath='org/apache/hadoop/mapreduce/lib/input/FixedLengthRecordReader.java' sourcefile='FixedLengthRecordReader.java' startBytecode='45'><Message>Synchronized access at FixedLengthRecordReader.java:[line 136]</Message></SourceLine><SourceLine role='SOURCE_LINE_SYNC_ACCESS' endBytecode='56' classname='org.apache.hadoop.mapreduce.lib.input.FixedLengthRecordReader' start='137' end='137' sourcepath='org/apache/hadoop/mapreduce/lib/input/FixedLengthRecordReader.java' sourcefile='FixedLengthRecordReader.java' startBytecode='56'><Message>Synchronized access at FixedLengthRecordReader.java:[line 137]</Message></SourceLine><SourceLine role='SOURCE_LINE_SYNC_ACCESS' endBytecode='39' classname='org.apache.hadoop.mapreduce.lib.input.FixedLengthRecordReader' start='133' end='133' sourcepath='org/apache/hadoop/mapreduce/lib/input/FixedLengthRecordReader.java' sourcefile='FixedLengthRecordReader.java' startBytecode='39'><Message>Synchronized access at FixedLengthRecordReader.java:[line 133]</Message></SourceLine><Property name='edu.umd.cs.findbugs.detect.InconsistentSyncWarningProperty.ONLY_UNSYNC_IN_GETTERS' value='true'></Property></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='e91f0166b619f739b380de770fd8671e' cweid='366' rank='20' abbrev='IS' category='MT_CORRECTNESS' priority='3' type='IS2_INCONSISTENT_SYNC' instanceOccurrenceMax='0'><ShortMessage>Inconsistent synchronization</ShortMessage><LongMessage>Inconsistent synchronization of org.apache.hadoop.mapreduce.lib.input.KeyValueLineRecordReader.key; locked 75% of time</LongMessage><Class classname='org.apache.hadoop.mapreduce.lib.input.KeyValueLineRecordReader' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.lib.input.KeyValueLineRecordReader' start='37' end='132' sourcepath='org/apache/hadoop/mapreduce/lib/input/KeyValueLineRecordReader.java' sourcefile='KeyValueLineRecordReader.java'><Message>At KeyValueLineRecordReader.java:[lines 37-132]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.lib.input.KeyValueLineRecordReader</Message></Class><Field isStatic='false' classname='org.apache.hadoop.mapreduce.lib.input.KeyValueLineRecordReader' signature='Lorg/apache/hadoop/io/Text;' name='key' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.lib.input.KeyValueLineRecordReader' sourcepath='org/apache/hadoop/mapreduce/lib/input/KeyValueLineRecordReader.java' sourcefile='KeyValueLineRecordReader.java'><Message>In KeyValueLineRecordReader.java</Message></SourceLine><Message>Field org.apache.hadoop.mapreduce.lib.input.KeyValueLineRecordReader.key</Message></Field><Int role='INT_SYNC_PERCENT' value='75'><Message>Synchronized 75% of the time</Message></Int><SourceLine role='SOURCE_LINE_UNSYNC_ACCESS' endBytecode='1' classname='org.apache.hadoop.mapreduce.lib.input.KeyValueLineRecordReader' start='119' end='119' sourcepath='org/apache/hadoop/mapreduce/lib/input/KeyValueLineRecordReader.java' sourcefile='KeyValueLineRecordReader.java' startBytecode='1' primary='true'><Message>Unsynchronized access at KeyValueLineRecordReader.java:[line 119]</Message></SourceLine><SourceLine role='SOURCE_LINE_SYNC_ACCESS' endBytecode='53' classname='org.apache.hadoop.mapreduce.lib.input.KeyValueLineRecordReader' start='107' end='107' sourcepath='org/apache/hadoop/mapreduce/lib/input/KeyValueLineRecordReader.java' sourcefile='KeyValueLineRecordReader.java' startBytecode='53'><Message>Synchronized access at KeyValueLineRecordReader.java:[line 107]</Message></SourceLine><SourceLine role='SOURCE_LINE_SYNC_ACCESS' endBytecode='67' classname='org.apache.hadoop.mapreduce.lib.input.KeyValueLineRecordReader' start='108' end='108' sourcepath='org/apache/hadoop/mapreduce/lib/input/KeyValueLineRecordReader.java' sourcefile='KeyValueLineRecordReader.java' startBytecode='67'><Message>Synchronized access at KeyValueLineRecordReader.java:[line 108]</Message></SourceLine><SourceLine role='SOURCE_LINE_SYNC_ACCESS' endBytecode='100' classname='org.apache.hadoop.mapreduce.lib.input.KeyValueLineRecordReader' start='114' end='114' sourcepath='org/apache/hadoop/mapreduce/lib/input/KeyValueLineRecordReader.java' sourcefile='KeyValueLineRecordReader.java' startBytecode='100'><Message>Synchronized access at KeyValueLineRecordReader.java:[line 114]</Message></SourceLine><Property name='edu.umd.cs.findbugs.detect.InconsistentSyncWarningProperty.ONLY_UNSYNC_IN_GETTERS' value='true'></Property></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='1be9b3bd722a7a276d028986056f2c64' cweid='366' rank='20' abbrev='IS' category='MT_CORRECTNESS' priority='3' type='IS2_INCONSISTENT_SYNC' instanceOccurrenceMax='0'><ShortMessage>Inconsistent synchronization</ShortMessage><LongMessage>Inconsistent synchronization of org.apache.hadoop.mapreduce.lib.input.KeyValueLineRecordReader.value; locked 75% of time</LongMessage><Class classname='org.apache.hadoop.mapreduce.lib.input.KeyValueLineRecordReader' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.lib.input.KeyValueLineRecordReader' start='37' end='132' sourcepath='org/apache/hadoop/mapreduce/lib/input/KeyValueLineRecordReader.java' sourcefile='KeyValueLineRecordReader.java'><Message>At KeyValueLineRecordReader.java:[lines 37-132]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.lib.input.KeyValueLineRecordReader</Message></Class><Field isStatic='false' classname='org.apache.hadoop.mapreduce.lib.input.KeyValueLineRecordReader' signature='Lorg/apache/hadoop/io/Text;' name='value' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.lib.input.KeyValueLineRecordReader' sourcepath='org/apache/hadoop/mapreduce/lib/input/KeyValueLineRecordReader.java' sourcefile='KeyValueLineRecordReader.java'><Message>In KeyValueLineRecordReader.java</Message></SourceLine><Message>Field org.apache.hadoop.mapreduce.lib.input.KeyValueLineRecordReader.value</Message></Field><Int role='INT_SYNC_PERCENT' value='75'><Message>Synchronized 75% of the time</Message></Int><SourceLine role='SOURCE_LINE_UNSYNC_ACCESS' endBytecode='1' classname='org.apache.hadoop.mapreduce.lib.input.KeyValueLineRecordReader' start='123' end='123' sourcepath='org/apache/hadoop/mapreduce/lib/input/KeyValueLineRecordReader.java' sourcefile='KeyValueLineRecordReader.java' startBytecode='1' primary='true'><Message>Unsynchronized access at KeyValueLineRecordReader.java:[line 123]</Message></SourceLine><SourceLine role='SOURCE_LINE_SYNC_ACCESS' endBytecode='71' classname='org.apache.hadoop.mapreduce.lib.input.KeyValueLineRecordReader' start='110' end='110' sourcepath='org/apache/hadoop/mapreduce/lib/input/KeyValueLineRecordReader.java' sourcefile='KeyValueLineRecordReader.java' startBytecode='71'><Message>Synchronized access at KeyValueLineRecordReader.java:[line 110]</Message></SourceLine><SourceLine role='SOURCE_LINE_SYNC_ACCESS' endBytecode='104' classname='org.apache.hadoop.mapreduce.lib.input.KeyValueLineRecordReader' start='114' end='114' sourcepath='org/apache/hadoop/mapreduce/lib/input/KeyValueLineRecordReader.java' sourcefile='KeyValueLineRecordReader.java' startBytecode='104'><Message>Synchronized access at KeyValueLineRecordReader.java:[line 114]</Message></SourceLine><SourceLine role='SOURCE_LINE_SYNC_ACCESS' endBytecode='85' classname='org.apache.hadoop.mapreduce.lib.input.KeyValueLineRecordReader' start='111' end='111' sourcepath='org/apache/hadoop/mapreduce/lib/input/KeyValueLineRecordReader.java' sourcefile='KeyValueLineRecordReader.java' startBytecode='85'><Message>Synchronized access at KeyValueLineRecordReader.java:[line 111]</Message></SourceLine><Property name='edu.umd.cs.findbugs.detect.InconsistentSyncWarningProperty.ONLY_UNSYNC_IN_GETTERS' value='true'></Property></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='b4ac5922400ccbd7d0ff38c09ffa3bff' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from org.apache.hadoop.mapreduce.InputSplit to org.apache.hadoop.mapreduce.lib.input.FileSplit in org.apache.hadoop.mapreduce.lib.input.LineRecordReader.initialize(InputSplit, TaskAttemptContext)</LongMessage><Class classname='org.apache.hadoop.mapreduce.lib.input.LineRecordReader' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.lib.input.LineRecordReader' start='47' end='247' sourcepath='org/apache/hadoop/mapreduce/lib/input/LineRecordReader.java' sourcefile='LineRecordReader.java'><Message>At LineRecordReader.java:[lines 47-247]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.lib.input.LineRecordReader</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapreduce.lib.input.LineRecordReader' signature='(Lorg/apache/hadoop/mapreduce/InputSplit;Lorg/apache/hadoop/mapreduce/TaskAttemptContext;)V' name='initialize' primary='true'><SourceLine endBytecode='176' classname='org.apache.hadoop.mapreduce.lib.input.LineRecordReader' start='77' end='127' sourcepath='org/apache/hadoop/mapreduce/lib/input/LineRecordReader.java' sourcefile='LineRecordReader.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapreduce.lib.input.LineRecordReader.initialize(InputSplit, TaskAttemptContext)</Message></Method><Type role='TYPE_FOUND' descriptor='Lorg/apache/hadoop/mapreduce/InputSplit;'><SourceLine classname='org.apache.hadoop.mapreduce.InputSplit' start='44' end='75' sourcepath='org/apache/hadoop/mapreduce/InputSplit.java' sourcefile='InputSplit.java'><Message>At InputSplit.java:[lines 44-75]</Message></SourceLine><Message>Actual type org.apache.hadoop.mapreduce.InputSplit</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/mapreduce/lib/input/FileSplit;'><SourceLine classname='org.apache.hadoop.mapreduce.lib.input.FileSplit' start='48' end='133' sourcepath='org/apache/hadoop/mapreduce/lib/input/FileSplit.java' sourcefile='FileSplit.java'><Message>At FileSplit.java:[lines 48-133]</Message></SourceLine><Message>Expected org.apache.hadoop.mapreduce.lib.input.FileSplit</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='0' name='genericSplit' register='1'><Message>Value loaded from genericSplit</Message></LocalVariable><SourceLine endBytecode='1' classname='org.apache.hadoop.mapreduce.lib.input.LineRecordReader' start='77' end='77' sourcepath='org/apache/hadoop/mapreduce/lib/input/LineRecordReader.java' sourcefile='LineRecordReader.java' startBytecode='1' primary='true'><Message>At LineRecordReader.java:[line 77]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='d05b550c2e279d24223834deabc2c8d5' cweid='374' rank='18' abbrev='EI2' category='MALICIOUS_CODE' priority='2' type='EI_EXPOSE_REP2' instanceOccurrenceMax='0'><ShortMessage>May expose internal representation by incorporating reference to mutable object</ShortMessage><LongMessage>new org.apache.hadoop.mapreduce.lib.input.LineRecordReader(byte[]) may expose internal representation by storing an externally mutable object into LineRecordReader.recordDelimiterBytes</LongMessage><Class classname='org.apache.hadoop.mapreduce.lib.input.LineRecordReader' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.lib.input.LineRecordReader' start='47' end='247' sourcepath='org/apache/hadoop/mapreduce/lib/input/LineRecordReader.java' sourcefile='LineRecordReader.java'><Message>At LineRecordReader.java:[lines 47-247]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.lib.input.LineRecordReader</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapreduce.lib.input.LineRecordReader' signature='([B)V' name='&lt;init&gt;' primary='true'><SourceLine endBytecode='69' classname='org.apache.hadoop.mapreduce.lib.input.LineRecordReader' start='71' end='73' sourcepath='org/apache/hadoop/mapreduce/lib/input/LineRecordReader.java' sourcefile='LineRecordReader.java' startBytecode='0'></SourceLine><Message>In method new org.apache.hadoop.mapreduce.lib.input.LineRecordReader(byte[])</Message></Method><Field isStatic='false' classname='org.apache.hadoop.mapreduce.lib.input.LineRecordReader' signature='[B' name='recordDelimiterBytes' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.lib.input.LineRecordReader' sourcepath='org/apache/hadoop/mapreduce/lib/input/LineRecordReader.java' sourcefile='LineRecordReader.java'><Message>In LineRecordReader.java</Message></SourceLine><Message>Field org.apache.hadoop.mapreduce.lib.input.LineRecordReader.recordDelimiterBytes</Message></Field><LocalVariable role='LOCAL_VARIABLE_NAMED' pc='6' name='recordDelimiter' register='1'><Message>Local variable named recordDelimiter</Message></LocalVariable><SourceLine endBytecode='6' classname='org.apache.hadoop.mapreduce.lib.input.LineRecordReader' start='72' end='72' sourcepath='org/apache/hadoop/mapreduce/lib/input/LineRecordReader.java' sourcefile='LineRecordReader.java' startBytecode='6' primary='true'><Message>At LineRecordReader.java:[line 72]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='c53508fcbbaa9edffa818ee463a04cf9' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from org.apache.hadoop.mapreduce.InputSplit to org.apache.hadoop.mapreduce.lib.input.FileSplit in org.apache.hadoop.mapreduce.lib.input.SequenceFileAsBinaryInputFormat$SequenceFileAsBinaryRecordReader.initialize(InputSplit, TaskAttemptContext)</LongMessage><Class classname='org.apache.hadoop.mapreduce.lib.input.SequenceFileAsBinaryInputFormat$SequenceFileAsBinaryRecordReader' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.lib.input.SequenceFileAsBinaryInputFormat$SequenceFileAsBinaryRecordReader' start='56' end='149' sourcepath='org/apache/hadoop/mapreduce/lib/input/SequenceFileAsBinaryInputFormat.java' sourcefile='SequenceFileAsBinaryInputFormat.java'><Message>At SequenceFileAsBinaryInputFormat.java:[lines 56-149]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.lib.input.SequenceFileAsBinaryInputFormat$SequenceFileAsBinaryRecordReader</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapreduce.lib.input.SequenceFileAsBinaryInputFormat$SequenceFileAsBinaryRecordReader' signature='(Lorg/apache/hadoop/mapreduce/InputSplit;Lorg/apache/hadoop/mapreduce/TaskAttemptContext;)V' name='initialize' primary='true'><SourceLine endBytecode='62' classname='org.apache.hadoop.mapreduce.lib.input.SequenceFileAsBinaryInputFormat$SequenceFileAsBinaryRecordReader' start='69' end='80' sourcepath='org/apache/hadoop/mapreduce/lib/input/SequenceFileAsBinaryInputFormat.java' sourcefile='SequenceFileAsBinaryInputFormat.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapreduce.lib.input.SequenceFileAsBinaryInputFormat$SequenceFileAsBinaryRecordReader.initialize(InputSplit, TaskAttemptContext)</Message></Method><Type role='TYPE_FOUND' descriptor='Lorg/apache/hadoop/mapreduce/InputSplit;'><SourceLine classname='org.apache.hadoop.mapreduce.InputSplit' start='44' end='75' sourcepath='org/apache/hadoop/mapreduce/InputSplit.java' sourcefile='InputSplit.java'><Message>At InputSplit.java:[lines 44-75]</Message></SourceLine><Message>Actual type org.apache.hadoop.mapreduce.InputSplit</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/mapreduce/lib/input/FileSplit;'><SourceLine classname='org.apache.hadoop.mapreduce.lib.input.FileSplit' start='48' end='133' sourcepath='org/apache/hadoop/mapreduce/lib/input/FileSplit.java' sourcefile='FileSplit.java'><Message>At FileSplit.java:[lines 48-133]</Message></SourceLine><Message>Expected org.apache.hadoop.mapreduce.lib.input.FileSplit</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='0' name='split' register='1'><Message>Value loaded from split</Message></LocalVariable><SourceLine endBytecode='1' classname='org.apache.hadoop.mapreduce.lib.input.SequenceFileAsBinaryInputFormat$SequenceFileAsBinaryRecordReader' start='69' end='69' sourcepath='org/apache/hadoop/mapreduce/lib/input/SequenceFileAsBinaryInputFormat.java' sourcefile='SequenceFileAsBinaryInputFormat.java' startBytecode='1' primary='true'><Message>At SequenceFileAsBinaryInputFormat.java:[line 69]</Message></SourceLine><SourceLine role='SOURCE_LINE_ANOTHER_INSTANCE' endBytecode='42' classname='org.apache.hadoop.mapreduce.lib.input.SequenceFileAsBinaryInputFormat$SequenceFileAsBinaryRecordReader' start='73' end='73' sourcepath='org/apache/hadoop/mapreduce/lib/input/SequenceFileAsBinaryInputFormat.java' sourcefile='SequenceFileAsBinaryInputFormat.java' startBytecode='42'><Message>Another occurrence at SequenceFileAsBinaryInputFormat.java:[line 73]</Message></SourceLine><SourceLine role='SOURCE_LINE_ANOTHER_INSTANCE' endBytecode='57' classname='org.apache.hadoop.mapreduce.lib.input.SequenceFileAsBinaryInputFormat$SequenceFileAsBinaryRecordReader' start='74' end='74' sourcepath='org/apache/hadoop/mapreduce/lib/input/SequenceFileAsBinaryInputFormat.java' sourcefile='SequenceFileAsBinaryInputFormat.java' startBytecode='57'><Message>Another occurrence at SequenceFileAsBinaryInputFormat.java:[line 74]</Message></SourceLine><SourceLine role='SOURCE_LINE_ANOTHER_INSTANCE' endBytecode='79' classname='org.apache.hadoop.mapreduce.lib.input.SequenceFileAsBinaryInputFormat$SequenceFileAsBinaryRecordReader' start='75' end='75' sourcepath='org/apache/hadoop/mapreduce/lib/input/SequenceFileAsBinaryInputFormat.java' sourcefile='SequenceFileAsBinaryInputFormat.java' startBytecode='79'><Message>Another occurrence at SequenceFileAsBinaryInputFormat.java:[line 75]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='16c72d706104775d3d6bb4b851d6cd71' cweid='366' rank='20' abbrev='IS' category='MT_CORRECTNESS' priority='3' type='IS2_INCONSISTENT_SYNC' instanceOccurrenceMax='0'><ShortMessage>Inconsistent synchronization</ShortMessage><LongMessage>Inconsistent synchronization of org.apache.hadoop.mapreduce.lib.input.SequenceFileAsBinaryInputFormat$SequenceFileAsBinaryRecordReader.key; locked 75% of time</LongMessage><Class classname='org.apache.hadoop.mapreduce.lib.input.SequenceFileAsBinaryInputFormat$SequenceFileAsBinaryRecordReader' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.lib.input.SequenceFileAsBinaryInputFormat$SequenceFileAsBinaryRecordReader' start='56' end='149' sourcepath='org/apache/hadoop/mapreduce/lib/input/SequenceFileAsBinaryInputFormat.java' sourcefile='SequenceFileAsBinaryInputFormat.java'><Message>At SequenceFileAsBinaryInputFormat.java:[lines 56-149]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.lib.input.SequenceFileAsBinaryInputFormat$SequenceFileAsBinaryRecordReader</Message></Class><Field isStatic='false' classname='org.apache.hadoop.mapreduce.lib.input.SequenceFileAsBinaryInputFormat$SequenceFileAsBinaryRecordReader' signature='Lorg/apache/hadoop/io/BytesWritable;' name='key' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.lib.input.SequenceFileAsBinaryInputFormat$SequenceFileAsBinaryRecordReader' sourcepath='org/apache/hadoop/mapreduce/lib/input/SequenceFileAsBinaryInputFormat.java' sourcefile='SequenceFileAsBinaryInputFormat.java'><Message>In SequenceFileAsBinaryInputFormat.java</Message></SourceLine><Message>Field org.apache.hadoop.mapreduce.lib.input.SequenceFileAsBinaryInputFormat$SequenceFileAsBinaryRecordReader.key</Message></Field><Int role='INT_SYNC_PERCENT' value='75'><Message>Synchronized 75% of the time</Message></Int><SourceLine role='SOURCE_LINE_UNSYNC_ACCESS' endBytecode='1' classname='org.apache.hadoop.mapreduce.lib.input.SequenceFileAsBinaryInputFormat$SequenceFileAsBinaryRecordReader' start='85' end='85' sourcepath='org/apache/hadoop/mapreduce/lib/input/SequenceFileAsBinaryInputFormat.java' sourcefile='SequenceFileAsBinaryInputFormat.java' startBytecode='1' primary='true'><Message>Unsynchronized access at SequenceFileAsBinaryInputFormat.java:[line 85]</Message></SourceLine><SourceLine role='SOURCE_LINE_SYNC_ACCESS' endBytecode='43' classname='org.apache.hadoop.mapreduce.lib.input.SequenceFileAsBinaryInputFormat$SequenceFileAsBinaryRecordReader' start='121' end='121' sourcepath='org/apache/hadoop/mapreduce/lib/input/SequenceFileAsBinaryInputFormat.java' sourcefile='SequenceFileAsBinaryInputFormat.java' startBytecode='43'><Message>Synchronized access at SequenceFileAsBinaryInputFormat.java:[line 121]</Message></SourceLine><SourceLine role='SOURCE_LINE_SYNC_ACCESS' endBytecode='79' classname='org.apache.hadoop.mapreduce.lib.input.SequenceFileAsBinaryInputFormat$SequenceFileAsBinaryRecordReader' start='127' end='127' sourcepath='org/apache/hadoop/mapreduce/lib/input/SequenceFileAsBinaryInputFormat.java' sourcefile='SequenceFileAsBinaryInputFormat.java' startBytecode='79'><Message>Synchronized access at SequenceFileAsBinaryInputFormat.java:[line 127]</Message></SourceLine><SourceLine role='SOURCE_LINE_SYNC_ACCESS' endBytecode='57' classname='org.apache.hadoop.mapreduce.lib.input.SequenceFileAsBinaryInputFormat$SequenceFileAsBinaryRecordReader' start='122' end='122' sourcepath='org/apache/hadoop/mapreduce/lib/input/SequenceFileAsBinaryInputFormat.java' sourcefile='SequenceFileAsBinaryInputFormat.java' startBytecode='57'><Message>Synchronized access at SequenceFileAsBinaryInputFormat.java:[line 122]</Message></SourceLine><Property name='edu.umd.cs.findbugs.detect.InconsistentSyncWarningProperty.ONLY_UNSYNC_IN_GETTERS' value='true'></Property></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='712fa65885c24746bc1c24a7218dcbb8' cweid='366' rank='20' abbrev='IS' category='MT_CORRECTNESS' priority='3' type='IS2_INCONSISTENT_SYNC' instanceOccurrenceMax='0'><ShortMessage>Inconsistent synchronization</ShortMessage><LongMessage>Inconsistent synchronization of org.apache.hadoop.mapreduce.lib.input.SequenceFileAsBinaryInputFormat$SequenceFileAsBinaryRecordReader.value; locked 75% of time</LongMessage><Class classname='org.apache.hadoop.mapreduce.lib.input.SequenceFileAsBinaryInputFormat$SequenceFileAsBinaryRecordReader' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.lib.input.SequenceFileAsBinaryInputFormat$SequenceFileAsBinaryRecordReader' start='56' end='149' sourcepath='org/apache/hadoop/mapreduce/lib/input/SequenceFileAsBinaryInputFormat.java' sourcefile='SequenceFileAsBinaryInputFormat.java'><Message>At SequenceFileAsBinaryInputFormat.java:[lines 56-149]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.lib.input.SequenceFileAsBinaryInputFormat$SequenceFileAsBinaryRecordReader</Message></Class><Field isStatic='false' classname='org.apache.hadoop.mapreduce.lib.input.SequenceFileAsBinaryInputFormat$SequenceFileAsBinaryRecordReader' signature='Lorg/apache/hadoop/io/BytesWritable;' name='value' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.lib.input.SequenceFileAsBinaryInputFormat$SequenceFileAsBinaryRecordReader' sourcepath='org/apache/hadoop/mapreduce/lib/input/SequenceFileAsBinaryInputFormat.java' sourcefile='SequenceFileAsBinaryInputFormat.java'><Message>In SequenceFileAsBinaryInputFormat.java</Message></SourceLine><Message>Field org.apache.hadoop.mapreduce.lib.input.SequenceFileAsBinaryInputFormat$SequenceFileAsBinaryRecordReader.value</Message></Field><Int role='INT_SYNC_PERCENT' value='75'><Message>Synchronized 75% of the time</Message></Int><SourceLine role='SOURCE_LINE_UNSYNC_ACCESS' endBytecode='1' classname='org.apache.hadoop.mapreduce.lib.input.SequenceFileAsBinaryInputFormat$SequenceFileAsBinaryRecordReader' start='91' end='91' sourcepath='org/apache/hadoop/mapreduce/lib/input/SequenceFileAsBinaryInputFormat.java' sourcefile='SequenceFileAsBinaryInputFormat.java' startBytecode='1' primary='true'><Message>Unsynchronized access at SequenceFileAsBinaryInputFormat.java:[line 91]</Message></SourceLine><SourceLine role='SOURCE_LINE_SYNC_ACCESS' endBytecode='61' classname='org.apache.hadoop.mapreduce.lib.input.SequenceFileAsBinaryInputFormat$SequenceFileAsBinaryRecordReader' start='124' end='124' sourcepath='org/apache/hadoop/mapreduce/lib/input/SequenceFileAsBinaryInputFormat.java' sourcefile='SequenceFileAsBinaryInputFormat.java' startBytecode='61'><Message>Synchronized access at SequenceFileAsBinaryInputFormat.java:[line 124]</Message></SourceLine><SourceLine role='SOURCE_LINE_SYNC_ACCESS' endBytecode='75' classname='org.apache.hadoop.mapreduce.lib.input.SequenceFileAsBinaryInputFormat$SequenceFileAsBinaryRecordReader' start='125' end='125' sourcepath='org/apache/hadoop/mapreduce/lib/input/SequenceFileAsBinaryInputFormat.java' sourcefile='SequenceFileAsBinaryInputFormat.java' startBytecode='75'><Message>Synchronized access at SequenceFileAsBinaryInputFormat.java:[line 125]</Message></SourceLine><SourceLine role='SOURCE_LINE_SYNC_ACCESS' endBytecode='134' classname='org.apache.hadoop.mapreduce.lib.input.SequenceFileAsBinaryInputFormat$SequenceFileAsBinaryRecordReader' start='131' end='131' sourcepath='org/apache/hadoop/mapreduce/lib/input/SequenceFileAsBinaryInputFormat.java' sourcefile='SequenceFileAsBinaryInputFormat.java' startBytecode='134'><Message>Synchronized access at SequenceFileAsBinaryInputFormat.java:[line 131]</Message></SourceLine><Property name='edu.umd.cs.findbugs.detect.InconsistentSyncWarningProperty.ONLY_UNSYNC_IN_GETTERS' value='true'></Property></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='125fc4c8bc72da75d6b50ddf66b9d585' cweid='366' rank='20' abbrev='IS' category='MT_CORRECTNESS' priority='3' type='IS2_INCONSISTENT_SYNC' instanceOccurrenceMax='0'><ShortMessage>Inconsistent synchronization</ShortMessage><LongMessage>Inconsistent synchronization of org.apache.hadoop.mapreduce.lib.input.SequenceFileAsTextRecordReader.key; locked 75% of time</LongMessage><Class classname='org.apache.hadoop.mapreduce.lib.input.SequenceFileAsTextRecordReader' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.lib.input.SequenceFileAsTextRecordReader' start='37' end='94' sourcepath='org/apache/hadoop/mapreduce/lib/input/SequenceFileAsTextRecordReader.java' sourcefile='SequenceFileAsTextRecordReader.java'><Message>At SequenceFileAsTextRecordReader.java:[lines 37-94]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.lib.input.SequenceFileAsTextRecordReader</Message></Class><Field isStatic='false' classname='org.apache.hadoop.mapreduce.lib.input.SequenceFileAsTextRecordReader' signature='Lorg/apache/hadoop/io/Text;' name='key' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.lib.input.SequenceFileAsTextRecordReader' sourcepath='org/apache/hadoop/mapreduce/lib/input/SequenceFileAsTextRecordReader.java' sourcefile='SequenceFileAsTextRecordReader.java'><Message>In SequenceFileAsTextRecordReader.java</Message></SourceLine><Message>Field org.apache.hadoop.mapreduce.lib.input.SequenceFileAsTextRecordReader.key</Message></Field><Int role='INT_SYNC_PERCENT' value='75'><Message>Synchronized 75% of the time</Message></Int><SourceLine role='SOURCE_LINE_UNSYNC_ACCESS' endBytecode='1' classname='org.apache.hadoop.mapreduce.lib.input.SequenceFileAsTextRecordReader' start='62' end='62' sourcepath='org/apache/hadoop/mapreduce/lib/input/SequenceFileAsTextRecordReader.java' sourcefile='SequenceFileAsTextRecordReader.java' startBytecode='1' primary='true'><Message>Unsynchronized access at SequenceFileAsTextRecordReader.java:[line 62]</Message></SourceLine><SourceLine role='SOURCE_LINE_SYNC_ACCESS' endBytecode='13' classname='org.apache.hadoop.mapreduce.lib.input.SequenceFileAsTextRecordReader' start='77' end='77' sourcepath='org/apache/hadoop/mapreduce/lib/input/SequenceFileAsTextRecordReader.java' sourcefile='SequenceFileAsTextRecordReader.java' startBytecode='13'><Message>Synchronized access at SequenceFileAsTextRecordReader.java:[line 77]</Message></SourceLine><SourceLine role='SOURCE_LINE_SYNC_ACCESS' endBytecode='49' classname='org.apache.hadoop.mapreduce.lib.input.SequenceFileAsTextRecordReader' start='83' end='83' sourcepath='org/apache/hadoop/mapreduce/lib/input/SequenceFileAsTextRecordReader.java' sourcefile='SequenceFileAsTextRecordReader.java' startBytecode='49'><Message>Synchronized access at SequenceFileAsTextRecordReader.java:[line 83]</Message></SourceLine><SourceLine role='SOURCE_LINE_SYNC_ACCESS' endBytecode='27' classname='org.apache.hadoop.mapreduce.lib.input.SequenceFileAsTextRecordReader' start='78' end='78' sourcepath='org/apache/hadoop/mapreduce/lib/input/SequenceFileAsTextRecordReader.java' sourcefile='SequenceFileAsTextRecordReader.java' startBytecode='27'><Message>Synchronized access at SequenceFileAsTextRecordReader.java:[line 78]</Message></SourceLine><Property name='edu.umd.cs.findbugs.detect.InconsistentSyncWarningProperty.ONLY_UNSYNC_IN_GETTERS' value='true'></Property></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='e6c1ad7649ebb1b64cc8da88794374ea' cweid='366' rank='20' abbrev='IS' category='MT_CORRECTNESS' priority='3' type='IS2_INCONSISTENT_SYNC' instanceOccurrenceMax='0'><ShortMessage>Inconsistent synchronization</ShortMessage><LongMessage>Inconsistent synchronization of org.apache.hadoop.mapreduce.lib.input.SequenceFileAsTextRecordReader.value; locked 75% of time</LongMessage><Class classname='org.apache.hadoop.mapreduce.lib.input.SequenceFileAsTextRecordReader' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.lib.input.SequenceFileAsTextRecordReader' start='37' end='94' sourcepath='org/apache/hadoop/mapreduce/lib/input/SequenceFileAsTextRecordReader.java' sourcefile='SequenceFileAsTextRecordReader.java'><Message>At SequenceFileAsTextRecordReader.java:[lines 37-94]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.lib.input.SequenceFileAsTextRecordReader</Message></Class><Field isStatic='false' classname='org.apache.hadoop.mapreduce.lib.input.SequenceFileAsTextRecordReader' signature='Lorg/apache/hadoop/io/Text;' name='value' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.lib.input.SequenceFileAsTextRecordReader' sourcepath='org/apache/hadoop/mapreduce/lib/input/SequenceFileAsTextRecordReader.java' sourcefile='SequenceFileAsTextRecordReader.java'><Message>In SequenceFileAsTextRecordReader.java</Message></SourceLine><Message>Field org.apache.hadoop.mapreduce.lib.input.SequenceFileAsTextRecordReader.value</Message></Field><Int role='INT_SYNC_PERCENT' value='75'><Message>Synchronized 75% of the time</Message></Int><SourceLine role='SOURCE_LINE_UNSYNC_ACCESS' endBytecode='1' classname='org.apache.hadoop.mapreduce.lib.input.SequenceFileAsTextRecordReader' start='68' end='68' sourcepath='org/apache/hadoop/mapreduce/lib/input/SequenceFileAsTextRecordReader.java' sourcefile='SequenceFileAsTextRecordReader.java' startBytecode='1' primary='true'><Message>Unsynchronized access at SequenceFileAsTextRecordReader.java:[line 68]</Message></SourceLine><SourceLine role='SOURCE_LINE_SYNC_ACCESS' endBytecode='31' classname='org.apache.hadoop.mapreduce.lib.input.SequenceFileAsTextRecordReader' start='80' end='80' sourcepath='org/apache/hadoop/mapreduce/lib/input/SequenceFileAsTextRecordReader.java' sourcefile='SequenceFileAsTextRecordReader.java' startBytecode='31'><Message>Synchronized access at SequenceFileAsTextRecordReader.java:[line 80]</Message></SourceLine><SourceLine role='SOURCE_LINE_SYNC_ACCESS' endBytecode='45' classname='org.apache.hadoop.mapreduce.lib.input.SequenceFileAsTextRecordReader' start='81' end='81' sourcepath='org/apache/hadoop/mapreduce/lib/input/SequenceFileAsTextRecordReader.java' sourcefile='SequenceFileAsTextRecordReader.java' startBytecode='45'><Message>Synchronized access at SequenceFileAsTextRecordReader.java:[line 81]</Message></SourceLine><SourceLine role='SOURCE_LINE_SYNC_ACCESS' endBytecode='69' classname='org.apache.hadoop.mapreduce.lib.input.SequenceFileAsTextRecordReader' start='84' end='84' sourcepath='org/apache/hadoop/mapreduce/lib/input/SequenceFileAsTextRecordReader.java' sourcefile='SequenceFileAsTextRecordReader.java' startBytecode='69'><Message>Synchronized access at SequenceFileAsTextRecordReader.java:[line 84]</Message></SourceLine><Property name='edu.umd.cs.findbugs.detect.InconsistentSyncWarningProperty.ONLY_UNSYNC_IN_GETTERS' value='true'></Property></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='3baf1bd64fe9b5f893161f04bda04435' cweid='366' rank='20' abbrev='IS' category='MT_CORRECTNESS' priority='3' type='IS2_INCONSISTENT_SYNC' instanceOccurrenceMax='0'><ShortMessage>Inconsistent synchronization</ShortMessage><LongMessage>Inconsistent synchronization of org.apache.hadoop.mapreduce.lib.input.SequenceFileInputFilter$FilterRecordReader.key; locked 66% of time</LongMessage><Class classname='org.apache.hadoop.mapreduce.lib.input.SequenceFileInputFilter$FilterRecordReader' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.lib.input.SequenceFileInputFilter$FilterRecordReader' start='298' end='323' sourcepath='org/apache/hadoop/mapreduce/lib/input/SequenceFileInputFilter.java' sourcefile='SequenceFileInputFilter.java'><Message>At SequenceFileInputFilter.java:[lines 298-323]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.lib.input.SequenceFileInputFilter$FilterRecordReader</Message></Class><Field isStatic='false' classname='org.apache.hadoop.mapreduce.lib.input.SequenceFileInputFilter$FilterRecordReader' signature='Ljava/lang/Object;' name='key' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.lib.input.SequenceFileInputFilter$FilterRecordReader' sourcepath='org/apache/hadoop/mapreduce/lib/input/SequenceFileInputFilter.java' sourcefile='SequenceFileInputFilter.java'><Message>In SequenceFileInputFilter.java</Message></SourceLine><Message>Field org.apache.hadoop.mapreduce.lib.input.SequenceFileInputFilter$FilterRecordReader.key</Message></Field><Int role='INT_SYNC_PERCENT' value='66'><Message>Synchronized 66% of the time</Message></Int><SourceLine role='SOURCE_LINE_UNSYNC_ACCESS' endBytecode='1' classname='org.apache.hadoop.mapreduce.lib.input.SequenceFileInputFilter$FilterRecordReader' start='318' end='318' sourcepath='org/apache/hadoop/mapreduce/lib/input/SequenceFileInputFilter.java' sourcefile='SequenceFileInputFilter.java' startBytecode='1' primary='true'><Message>Unsynchronized access at SequenceFileInputFilter.java:[line 318]</Message></SourceLine><SourceLine role='SOURCE_LINE_SYNC_ACCESS' endBytecode='12' classname='org.apache.hadoop.mapreduce.lib.input.SequenceFileInputFilter$FilterRecordReader' start='307' end='307' sourcepath='org/apache/hadoop/mapreduce/lib/input/SequenceFileInputFilter.java' sourcefile='SequenceFileInputFilter.java' startBytecode='12'><Message>Synchronized access at SequenceFileInputFilter.java:[line 307]</Message></SourceLine><SourceLine role='SOURCE_LINE_SYNC_ACCESS' endBytecode='20' classname='org.apache.hadoop.mapreduce.lib.input.SequenceFileInputFilter$FilterRecordReader' start='308' end='308' sourcepath='org/apache/hadoop/mapreduce/lib/input/SequenceFileInputFilter.java' sourcefile='SequenceFileInputFilter.java' startBytecode='20'><Message>Synchronized access at SequenceFileInputFilter.java:[line 308]</Message></SourceLine><Property name='edu.umd.cs.findbugs.detect.InconsistentSyncWarningProperty.ONLY_UNSYNC_IN_GETTERS' value='true'></Property></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='b56d7b72e7d71dbb5e30e855784419f' cweid='366' rank='20' abbrev='IS' category='MT_CORRECTNESS' priority='3' type='IS2_INCONSISTENT_SYNC' instanceOccurrenceMax='0'><ShortMessage>Inconsistent synchronization</ShortMessage><LongMessage>Inconsistent synchronization of org.apache.hadoop.mapreduce.lib.input.SequenceFileInputFilter$FilterRecordReader.value; locked 50% of time</LongMessage><Class classname='org.apache.hadoop.mapreduce.lib.input.SequenceFileInputFilter$FilterRecordReader' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.lib.input.SequenceFileInputFilter$FilterRecordReader' start='298' end='323' sourcepath='org/apache/hadoop/mapreduce/lib/input/SequenceFileInputFilter.java' sourcefile='SequenceFileInputFilter.java'><Message>At SequenceFileInputFilter.java:[lines 298-323]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.lib.input.SequenceFileInputFilter$FilterRecordReader</Message></Class><Field isStatic='false' classname='org.apache.hadoop.mapreduce.lib.input.SequenceFileInputFilter$FilterRecordReader' signature='Ljava/lang/Object;' name='value' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.lib.input.SequenceFileInputFilter$FilterRecordReader' sourcepath='org/apache/hadoop/mapreduce/lib/input/SequenceFileInputFilter.java' sourcefile='SequenceFileInputFilter.java'><Message>In SequenceFileInputFilter.java</Message></SourceLine><Message>Field org.apache.hadoop.mapreduce.lib.input.SequenceFileInputFilter$FilterRecordReader.value</Message></Field><Int role='INT_SYNC_PERCENT' value='50'><Message>Synchronized 50% of the time</Message></Int><SourceLine role='SOURCE_LINE_UNSYNC_ACCESS' endBytecode='1' classname='org.apache.hadoop.mapreduce.lib.input.SequenceFileInputFilter$FilterRecordReader' start='323' end='323' sourcepath='org/apache/hadoop/mapreduce/lib/input/SequenceFileInputFilter.java' sourcefile='SequenceFileInputFilter.java' startBytecode='1' primary='true'><Message>Unsynchronized access at SequenceFileInputFilter.java:[line 323]</Message></SourceLine><SourceLine role='SOURCE_LINE_SYNC_ACCESS' endBytecode='36' classname='org.apache.hadoop.mapreduce.lib.input.SequenceFileInputFilter$FilterRecordReader' start='309' end='309' sourcepath='org/apache/hadoop/mapreduce/lib/input/SequenceFileInputFilter.java' sourcefile='SequenceFileInputFilter.java' startBytecode='36'><Message>Synchronized access at SequenceFileInputFilter.java:[line 309]</Message></SourceLine><Property name='edu.umd.cs.findbugs.detect.InconsistentSyncWarningProperty.ONLY_UNSYNC_IN_GETTERS' value='true'></Property></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='fa0655c045ca306344c82b9982630dcd' cweid='396' rank='20' abbrev='REC' category='STYLE' priority='3' type='REC_CATCH_EXCEPTION' instanceOccurrenceMax='0'><ShortMessage>Exception is caught when Exception is not thrown</ShortMessage><LongMessage>Exception is caught when Exception is not thrown in org.apache.hadoop.mapreduce.lib.input.SequenceFileInputFilter$MD5Filter.accept(Object)</LongMessage><Class classname='org.apache.hadoop.mapreduce.lib.input.SequenceFileInputFilter$MD5Filter' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.lib.input.SequenceFileInputFilter$MD5Filter' start='207' end='285' sourcepath='org/apache/hadoop/mapreduce/lib/input/SequenceFileInputFilter.java' sourcefile='SequenceFileInputFilter.java'><Message>At SequenceFileInputFilter.java:[lines 207-285]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.lib.input.SequenceFileInputFilter$MD5Filter</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapreduce.lib.input.SequenceFileInputFilter$MD5Filter' signature='(Ljava/lang/Object;)Z' name='accept' primary='true'><SourceLine endBytecode='289' classname='org.apache.hadoop.mapreduce.lib.input.SequenceFileInputFilter$MD5Filter' start='252' end='267' sourcepath='org/apache/hadoop/mapreduce/lib/input/SequenceFileInputFilter.java' sourcefile='SequenceFileInputFilter.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapreduce.lib.input.SequenceFileInputFilter$MD5Filter.accept(Object)</Message></Method><SourceLine endBytecode='86' classname='org.apache.hadoop.mapreduce.lib.input.SequenceFileInputFilter$MD5Filter' start='263' end='263' sourcepath='org/apache/hadoop/mapreduce/lib/input/SequenceFileInputFilter.java' sourcefile='SequenceFileInputFilter.java' startBytecode='86' primary='true'><Message>At SequenceFileInputFilter.java:[line 263]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='4e06e69d95b3d18a066474ae1a6d645f' rank='20' abbrev='UwF' category='STYLE' priority='3' type='UWF_FIELD_NOT_INITIALIZED_IN_CONSTRUCTOR' instanceOccurrenceMax='0'><ShortMessage>Field not initialized in constructor but dereferenced without null check</ShortMessage><LongMessage>SequenceFileInputFilter$RegexFilter.p not initialized in constructor and dereferenced in org.apache.hadoop.mapreduce.lib.input.SequenceFileInputFilter$RegexFilter.accept(Object)</LongMessage><Class classname='org.apache.hadoop.mapreduce.lib.input.SequenceFileInputFilter$RegexFilter' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.lib.input.SequenceFileInputFilter$RegexFilter' start='120' end='145' sourcepath='org/apache/hadoop/mapreduce/lib/input/SequenceFileInputFilter.java' sourcefile='SequenceFileInputFilter.java'><Message>At SequenceFileInputFilter.java:[lines 120-145]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.lib.input.SequenceFileInputFilter$RegexFilter</Message></Class><Field isStatic='false' classname='org.apache.hadoop.mapreduce.lib.input.SequenceFileInputFilter$RegexFilter' signature='Ljava/util/regex/Pattern;' name='p' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.lib.input.SequenceFileInputFilter$RegexFilter' sourcepath='org/apache/hadoop/mapreduce/lib/input/SequenceFileInputFilter.java' sourcefile='SequenceFileInputFilter.java'><Message>In SequenceFileInputFilter.java</Message></SourceLine><Message>Field org.apache.hadoop.mapreduce.lib.input.SequenceFileInputFilter$RegexFilter.p</Message></Field><Method isStatic='false' classname='org.apache.hadoop.mapreduce.lib.input.SequenceFileInputFilter$RegexFilter' signature='(Ljava/lang/Object;)Z' name='accept' primary='true'><SourceLine endBytecode='66' classname='org.apache.hadoop.mapreduce.lib.input.SequenceFileInputFilter$RegexFilter' start='145' end='145' sourcepath='org/apache/hadoop/mapreduce/lib/input/SequenceFileInputFilter.java' sourcefile='SequenceFileInputFilter.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapreduce.lib.input.SequenceFileInputFilter$RegexFilter.accept(Object)</Message></Method><SourceLine endBytecode='8' classname='org.apache.hadoop.mapreduce.lib.input.SequenceFileInputFilter$RegexFilter' start='145' end='145' sourcepath='org/apache/hadoop/mapreduce/lib/input/SequenceFileInputFilter.java' sourcefile='SequenceFileInputFilter.java' startBytecode='8' primary='true'><Message>At SequenceFileInputFilter.java:[line 145]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='4f4cb288ac833fb0ad683c9644efa393' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from org.apache.hadoop.mapreduce.InputSplit to org.apache.hadoop.mapreduce.lib.input.FileSplit in org.apache.hadoop.mapreduce.lib.input.SequenceFileRecordReader.initialize(InputSplit, TaskAttemptContext)</LongMessage><Class classname='org.apache.hadoop.mapreduce.lib.input.SequenceFileRecordReader' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.lib.input.SequenceFileRecordReader' start='37' end='105' sourcepath='org/apache/hadoop/mapreduce/lib/input/SequenceFileRecordReader.java' sourcefile='SequenceFileRecordReader.java'><Message>At SequenceFileRecordReader.java:[lines 37-105]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.lib.input.SequenceFileRecordReader</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapreduce.lib.input.SequenceFileRecordReader' signature='(Lorg/apache/hadoop/mapreduce/InputSplit;Lorg/apache/hadoop/mapreduce/TaskAttemptContext;)V' name='initialize' primary='true'><SourceLine endBytecode='59' classname='org.apache.hadoop.mapreduce.lib.input.SequenceFileRecordReader' start='50' end='63' sourcepath='org/apache/hadoop/mapreduce/lib/input/SequenceFileRecordReader.java' sourcefile='SequenceFileRecordReader.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapreduce.lib.input.SequenceFileRecordReader.initialize(InputSplit, TaskAttemptContext)</Message></Method><Type role='TYPE_FOUND' descriptor='Lorg/apache/hadoop/mapreduce/InputSplit;'><SourceLine classname='org.apache.hadoop.mapreduce.InputSplit' start='44' end='75' sourcepath='org/apache/hadoop/mapreduce/InputSplit.java' sourcefile='InputSplit.java'><Message>At InputSplit.java:[lines 44-75]</Message></SourceLine><Message>Actual type org.apache.hadoop.mapreduce.InputSplit</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/mapreduce/lib/input/FileSplit;'><SourceLine classname='org.apache.hadoop.mapreduce.lib.input.FileSplit' start='48' end='133' sourcepath='org/apache/hadoop/mapreduce/lib/input/FileSplit.java' sourcefile='FileSplit.java'><Message>At FileSplit.java:[lines 48-133]</Message></SourceLine><Message>Expected org.apache.hadoop.mapreduce.lib.input.FileSplit</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='0' name='split' register='1'><Message>Value loaded from split</Message></LocalVariable><SourceLine endBytecode='1' classname='org.apache.hadoop.mapreduce.lib.input.SequenceFileRecordReader' start='50' end='50' sourcepath='org/apache/hadoop/mapreduce/lib/input/SequenceFileRecordReader.java' sourcefile='SequenceFileRecordReader.java' startBytecode='1' primary='true'><Message>At SequenceFileRecordReader.java:[line 50]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='53fa83559d468105d077bdba963dab94' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from java.io.DataInput to java.io.DataInputStream in org.apache.hadoop.mapreduce.lib.input.TaggedInputSplit.readFields(DataInput)</LongMessage><Class classname='org.apache.hadoop.mapreduce.lib.input.TaggedInputSplit' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.lib.input.TaggedInputSplit' start='58' end='162' sourcepath='org/apache/hadoop/mapreduce/lib/input/TaggedInputSplit.java' sourcefile='TaggedInputSplit.java'><Message>At TaggedInputSplit.java:[lines 58-162]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.lib.input.TaggedInputSplit</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapreduce.lib.input.TaggedInputSplit' signature='(Ljava/io/DataInput;)V' name='readFields' primary='true'><SourceLine endBytecode='45' classname='org.apache.hadoop.mapreduce.lib.input.TaggedInputSplit' start='120' end='129' sourcepath='org/apache/hadoop/mapreduce/lib/input/TaggedInputSplit.java' sourcefile='TaggedInputSplit.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapreduce.lib.input.TaggedInputSplit.readFields(DataInput)</Message></Method><Type role='TYPE_FOUND' descriptor='Ljava/io/DataInput;'><SourceLine classname='java.io.DataInput' sourcepath='java/io/DataInput.java' sourcefile='DataInput.java'><Message>In DataInput.java</Message></SourceLine><Message>Actual type java.io.DataInput</Message></Type><Type role='TYPE_EXPECTED' descriptor='Ljava/io/DataInputStream;'><SourceLine classname='java.io.DataInputStream' start='52' end='661' sourcepath='java/io/DataInputStream.java' sourcefile='DataInputStream.java'><Message>At DataInputStream.java:[lines 52-661]</Message></SourceLine><Message>Expected java.io.DataInputStream</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='67' name='in' register='1'><Message>Value loaded from in</Message></LocalVariable><SourceLine endBytecode='68' classname='org.apache.hadoop.mapreduce.lib.input.TaggedInputSplit' start='127' end='127' sourcepath='org/apache/hadoop/mapreduce/lib/input/TaggedInputSplit.java' sourcefile='TaggedInputSplit.java' startBytecode='68' primary='true'><Message>At TaggedInputSplit.java:[line 127]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='242d187b0f9636c2e1fd89ee7de9400c' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from java.io.DataOutput to java.io.DataOutputStream in org.apache.hadoop.mapreduce.lib.input.TaggedInputSplit.write(DataOutput)</LongMessage><Class classname='org.apache.hadoop.mapreduce.lib.input.TaggedInputSplit' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.lib.input.TaggedInputSplit' start='58' end='162' sourcepath='org/apache/hadoop/mapreduce/lib/input/TaggedInputSplit.java' sourcefile='TaggedInputSplit.java'><Message>At TaggedInputSplit.java:[lines 58-162]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.lib.input.TaggedInputSplit</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapreduce.lib.input.TaggedInputSplit' signature='(Ljava/io/DataOutput;)V' name='write' primary='true'><SourceLine endBytecode='37' classname='org.apache.hadoop.mapreduce.lib.input.TaggedInputSplit' start='142' end='150' sourcepath='org/apache/hadoop/mapreduce/lib/input/TaggedInputSplit.java' sourcefile='TaggedInputSplit.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapreduce.lib.input.TaggedInputSplit.write(DataOutput)</Message></Method><Type role='TYPE_FOUND' descriptor='Ljava/io/DataOutput;'><SourceLine classname='java.io.DataOutput' sourcepath='java/io/DataOutput.java' sourcefile='DataOutput.java'><Message>In DataOutput.java</Message></SourceLine><Message>Actual type java.io.DataOutput</Message></Type><Type role='TYPE_EXPECTED' descriptor='Ljava/io/DataOutputStream;'><SourceLine classname='java.io.DataOutputStream' start='48' end='414' sourcepath='java/io/DataOutputStream.java' sourcefile='DataOutputStream.java'><Message>At DataOutputStream.java:[lines 48-414]</Message></SourceLine><Message>Expected java.io.DataOutputStream</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='58' name='out' register='1'><Message>Value loaded from out</Message></LocalVariable><SourceLine endBytecode='59' classname='org.apache.hadoop.mapreduce.lib.input.TaggedInputSplit' start='148' end='148' sourcepath='org/apache/hadoop/mapreduce/lib/input/TaggedInputSplit.java' sourcefile='TaggedInputSplit.java' startBytecode='59' primary='true'><Message>At TaggedInputSplit.java:[line 148]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='c6caef9b21c5376ec3fa36c51c1a3b24' cweid='366' rank='20' abbrev='IS' category='MT_CORRECTNESS' priority='3' type='IS2_INCONSISTENT_SYNC' instanceOccurrenceMax='0'><ShortMessage>Inconsistent synchronization</ShortMessage><LongMessage>Inconsistent synchronization of org.apache.hadoop.mapreduce.lib.jobcontrol.ControlledJob.dependingJobs; locked 87% of time</LongMessage><Class classname='org.apache.hadoop.mapreduce.lib.jobcontrol.ControlledJob' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.lib.jobcontrol.ControlledJob' start='52' end='343' sourcepath='org/apache/hadoop/mapreduce/lib/jobcontrol/ControlledJob.java' sourcefile='ControlledJob.java'><Message>At ControlledJob.java:[lines 52-343]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.lib.jobcontrol.ControlledJob</Message></Class><Field isStatic='false' classname='org.apache.hadoop.mapreduce.lib.jobcontrol.ControlledJob' signature='Ljava/util/List;' name='dependingJobs' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.lib.jobcontrol.ControlledJob' sourcepath='org/apache/hadoop/mapreduce/lib/jobcontrol/ControlledJob.java' sourcefile='ControlledJob.java'><Message>In ControlledJob.java</Message></SourceLine><Message>Field org.apache.hadoop.mapreduce.lib.jobcontrol.ControlledJob.dependingJobs</Message></Field><Int role='INT_SYNC_PERCENT' value='87'><Message>Synchronized 87% of the time</Message></Int><SourceLine role='SOURCE_LINE_UNSYNC_ACCESS' endBytecode='1' classname='org.apache.hadoop.mapreduce.lib.jobcontrol.ControlledJob' start='199' end='199' sourcepath='org/apache/hadoop/mapreduce/lib/jobcontrol/ControlledJob.java' sourcefile='ControlledJob.java' startBytecode='1' primary='true'><Message>Unsynchronized access at ControlledJob.java:[line 199]</Message></SourceLine><SourceLine role='SOURCE_LINE_SYNC_ACCESS' endBytecode='11' classname='org.apache.hadoop.mapreduce.lib.jobcontrol.ControlledJob' start='212' end='212' sourcepath='org/apache/hadoop/mapreduce/lib/jobcontrol/ControlledJob.java' sourcefile='ControlledJob.java' startBytecode='11'><Message>Synchronized access at ControlledJob.java:[line 212]</Message></SourceLine><SourceLine role='SOURCE_LINE_SYNC_ACCESS' endBytecode='29' classname='org.apache.hadoop.mapreduce.lib.jobcontrol.ControlledJob' start='215' end='215' sourcepath='org/apache/hadoop/mapreduce/lib/jobcontrol/ControlledJob.java' sourcefile='ControlledJob.java' startBytecode='29'><Message>Synchronized access at ControlledJob.java:[line 215]</Message></SourceLine><SourceLine role='SOURCE_LINE_SYNC_ACCESS' endBytecode='25' classname='org.apache.hadoop.mapreduce.lib.jobcontrol.ControlledJob' start='213' end='213' sourcepath='org/apache/hadoop/mapreduce/lib/jobcontrol/ControlledJob.java' sourcefile='ControlledJob.java' startBytecode='25'><Message>Synchronized access at ControlledJob.java:[line 213]</Message></SourceLine><SourceLine role='SOURCE_LINE_SYNC_ACCESS' endBytecode='30' classname='org.apache.hadoop.mapreduce.lib.jobcontrol.ControlledJob' start='288' end='288' sourcepath='org/apache/hadoop/mapreduce/lib/jobcontrol/ControlledJob.java' sourcefile='ControlledJob.java' startBytecode='30'><Message>Synchronized access at ControlledJob.java:[line 288]</Message></SourceLine><SourceLine role='SOURCE_LINE_SYNC_ACCESS' endBytecode='37' classname='org.apache.hadoop.mapreduce.lib.jobcontrol.ControlledJob' start='288' end='288' sourcepath='org/apache/hadoop/mapreduce/lib/jobcontrol/ControlledJob.java' sourcefile='ControlledJob.java' startBytecode='37'><Message>Synchronized access at ControlledJob.java:[line 288]</Message></SourceLine><SourceLine role='SOURCE_LINE_SYNC_ACCESS' endBytecode='63' classname='org.apache.hadoop.mapreduce.lib.jobcontrol.ControlledJob' start='293' end='293' sourcepath='org/apache/hadoop/mapreduce/lib/jobcontrol/ControlledJob.java' sourcefile='ControlledJob.java' startBytecode='63'><Message>Synchronized access at ControlledJob.java:[line 293]</Message></SourceLine><SourceLine role='SOURCE_LINE_SYNC_ACCESS' endBytecode='80' classname='org.apache.hadoop.mapreduce.lib.jobcontrol.ControlledJob' start='295' end='295' sourcepath='org/apache/hadoop/mapreduce/lib/jobcontrol/ControlledJob.java' sourcefile='ControlledJob.java' startBytecode='80'><Message>Synchronized access at ControlledJob.java:[line 295]</Message></SourceLine><SourceLine role='SOURCE_LINE_SYNC_ACCESS' endBytecode='110' classname='org.apache.hadoop.mapreduce.lib.jobcontrol.ControlledJob' start='100' end='100' sourcepath='org/apache/hadoop/mapreduce/lib/jobcontrol/ControlledJob.java' sourcefile='ControlledJob.java' startBytecode='110'><Message>Synchronized access at ControlledJob.java:[line 100]</Message></SourceLine><SourceLine role='SOURCE_LINE_SYNC_ACCESS' endBytecode='117' classname='org.apache.hadoop.mapreduce.lib.jobcontrol.ControlledJob' start='100' end='100' sourcepath='org/apache/hadoop/mapreduce/lib/jobcontrol/ControlledJob.java' sourcefile='ControlledJob.java' startBytecode='117'><Message>Synchronized access at ControlledJob.java:[line 100]</Message></SourceLine><SourceLine role='SOURCE_LINE_SYNC_ACCESS' endBytecode='150' classname='org.apache.hadoop.mapreduce.lib.jobcontrol.ControlledJob' start='103' end='103' sourcepath='org/apache/hadoop/mapreduce/lib/jobcontrol/ControlledJob.java' sourcefile='ControlledJob.java' startBytecode='150'><Message>Synchronized access at ControlledJob.java:[line 103]</Message></SourceLine><SourceLine role='SOURCE_LINE_SYNC_ACCESS' endBytecode='171' classname='org.apache.hadoop.mapreduce.lib.jobcontrol.ControlledJob' start='105' end='105' sourcepath='org/apache/hadoop/mapreduce/lib/jobcontrol/ControlledJob.java' sourcefile='ControlledJob.java' startBytecode='171'><Message>Synchronized access at ControlledJob.java:[line 105]</Message></SourceLine><SourceLine role='SOURCE_LINE_SYNC_ACCESS' endBytecode='200' classname='org.apache.hadoop.mapreduce.lib.jobcontrol.ControlledJob' start='107' end='107' sourcepath='org/apache/hadoop/mapreduce/lib/jobcontrol/ControlledJob.java' sourcefile='ControlledJob.java' startBytecode='200'><Message>Synchronized access at ControlledJob.java:[line 107]</Message></SourceLine><Property name='edu.umd.cs.findbugs.detect.InconsistentSyncWarningProperty.ONLY_UNSYNC_IN_GETTERS' value='true'></Property></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='6b7a73872c9083ff1434bcd56d0cad4' cweid='366' rank='20' abbrev='IS' category='MT_CORRECTNESS' priority='3' type='IS2_INCONSISTENT_SYNC' instanceOccurrenceMax='0'><ShortMessage>Inconsistent synchronization</ShortMessage><LongMessage>Inconsistent synchronization of org.apache.hadoop.mapreduce.lib.jobcontrol.ControlledJob.job; locked 80% of time</LongMessage><Class classname='org.apache.hadoop.mapreduce.lib.jobcontrol.ControlledJob' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.lib.jobcontrol.ControlledJob' start='52' end='343' sourcepath='org/apache/hadoop/mapreduce/lib/jobcontrol/ControlledJob.java' sourcefile='ControlledJob.java'><Message>At ControlledJob.java:[lines 52-343]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.lib.jobcontrol.ControlledJob</Message></Class><Field isStatic='false' classname='org.apache.hadoop.mapreduce.lib.jobcontrol.ControlledJob' signature='Lorg/apache/hadoop/mapreduce/Job;' name='job' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.lib.jobcontrol.ControlledJob' sourcepath='org/apache/hadoop/mapreduce/lib/jobcontrol/ControlledJob.java' sourcefile='ControlledJob.java'><Message>In ControlledJob.java</Message></SourceLine><Message>Field org.apache.hadoop.mapreduce.lib.jobcontrol.ControlledJob.job</Message></Field><Int role='INT_SYNC_PERCENT' value='80'><Message>Synchronized 80% of the time</Message></Int><SourceLine role='SOURCE_LINE_UNSYNC_ACCESS' endBytecode='1' classname='org.apache.hadoop.mapreduce.lib.jobcontrol.ControlledJob' start='238' end='238' sourcepath='org/apache/hadoop/mapreduce/lib/jobcontrol/ControlledJob.java' sourcefile='ControlledJob.java' startBytecode='1' primary='true'><Message>Unsynchronized access at ControlledJob.java:[line 238]</Message></SourceLine><SourceLine role='SOURCE_LINE_UNSYNC_ACCESS' endBytecode='1' classname='org.apache.hadoop.mapreduce.lib.jobcontrol.ControlledJob' start='125' end='125' sourcepath='org/apache/hadoop/mapreduce/lib/jobcontrol/ControlledJob.java' sourcefile='ControlledJob.java' startBytecode='1'><Message>Unsynchronized access at ControlledJob.java:[line 125]</Message></SourceLine><SourceLine role='SOURCE_LINE_UNSYNC_ACCESS' endBytecode='1' classname='org.apache.hadoop.mapreduce.lib.jobcontrol.ControlledJob' start='117' end='117' sourcepath='org/apache/hadoop/mapreduce/lib/jobcontrol/ControlledJob.java' sourcefile='ControlledJob.java' startBytecode='1'><Message>Unsynchronized access at ControlledJob.java:[line 117]</Message></SourceLine><SourceLine role='SOURCE_LINE_SYNC_ACCESS' endBytecode='1' classname='org.apache.hadoop.mapreduce.lib.jobcontrol.ControlledJob' start='258' end='258' sourcepath='org/apache/hadoop/mapreduce/lib/jobcontrol/ControlledJob.java' sourcefile='ControlledJob.java' startBytecode='1'><Message>Synchronized access at ControlledJob.java:[line 258]</Message></SourceLine><SourceLine role='SOURCE_LINE_SYNC_ACCESS' endBytecode='11' classname='org.apache.hadoop.mapreduce.lib.jobcontrol.ControlledJob' start='259' end='259' sourcepath='org/apache/hadoop/mapreduce/lib/jobcontrol/ControlledJob.java' sourcefile='ControlledJob.java' startBytecode='11'><Message>Synchronized access at ControlledJob.java:[line 259]</Message></SourceLine><SourceLine role='SOURCE_LINE_SYNC_ACCESS' endBytecode='63' classname='org.apache.hadoop.mapreduce.lib.jobcontrol.ControlledJob' start='270' end='270' sourcepath='org/apache/hadoop/mapreduce/lib/jobcontrol/ControlledJob.java' sourcefile='ControlledJob.java' startBytecode='63'><Message>Synchronized access at ControlledJob.java:[line 270]</Message></SourceLine><SourceLine role='SOURCE_LINE_SYNC_ACCESS' endBytecode='70' classname='org.apache.hadoop.mapreduce.lib.jobcontrol.ControlledJob' start='271' end='271' sourcepath='org/apache/hadoop/mapreduce/lib/jobcontrol/ControlledJob.java' sourcefile='ControlledJob.java' startBytecode='70'><Message>Synchronized access at ControlledJob.java:[line 271]</Message></SourceLine><SourceLine role='SOURCE_LINE_SYNC_ACCESS' endBytecode='2' classname='org.apache.hadoop.mapreduce.lib.jobcontrol.ControlledJob' start='162' end='162' sourcepath='org/apache/hadoop/mapreduce/lib/jobcontrol/ControlledJob.java' sourcefile='ControlledJob.java' startBytecode='2'><Message>Synchronized access at ControlledJob.java:[line 162]</Message></SourceLine><SourceLine role='SOURCE_LINE_SYNC_ACCESS' endBytecode='1' classname='org.apache.hadoop.mapreduce.lib.jobcontrol.ControlledJob' start='154' end='154' sourcepath='org/apache/hadoop/mapreduce/lib/jobcontrol/ControlledJob.java' sourcefile='ControlledJob.java' startBytecode='1'><Message>Synchronized access at ControlledJob.java:[line 154]</Message></SourceLine><SourceLine role='SOURCE_LINE_SYNC_ACCESS' endBytecode='1' classname='org.apache.hadoop.mapreduce.lib.jobcontrol.ControlledJob' start='147' end='147' sourcepath='org/apache/hadoop/mapreduce/lib/jobcontrol/ControlledJob.java' sourcefile='ControlledJob.java' startBytecode='1'><Message>Synchronized access at ControlledJob.java:[line 147]</Message></SourceLine><SourceLine role='SOURCE_LINE_SYNC_ACCESS' endBytecode='1' classname='org.apache.hadoop.mapreduce.lib.jobcontrol.ControlledJob' start='243' end='243' sourcepath='org/apache/hadoop/mapreduce/lib/jobcontrol/ControlledJob.java' sourcefile='ControlledJob.java' startBytecode='1'><Message>Synchronized access at ControlledJob.java:[line 243]</Message></SourceLine><SourceLine role='SOURCE_LINE_SYNC_ACCESS' endBytecode='18' classname='org.apache.hadoop.mapreduce.lib.jobcontrol.ControlledJob' start='244' end='244' sourcepath='org/apache/hadoop/mapreduce/lib/jobcontrol/ControlledJob.java' sourcefile='ControlledJob.java' startBytecode='18'><Message>Synchronized access at ControlledJob.java:[line 244]</Message></SourceLine><SourceLine role='SOURCE_LINE_SYNC_ACCESS' endBytecode='1' classname='org.apache.hadoop.mapreduce.lib.jobcontrol.ControlledJob' start='322' end='322' sourcepath='org/apache/hadoop/mapreduce/lib/jobcontrol/ControlledJob.java' sourcefile='ControlledJob.java' startBytecode='1'><Message>Synchronized access at ControlledJob.java:[line 322]</Message></SourceLine><SourceLine role='SOURCE_LINE_SYNC_ACCESS' endBytecode='73' classname='org.apache.hadoop.mapreduce.lib.jobcontrol.ControlledJob' start='336' end='336' sourcepath='org/apache/hadoop/mapreduce/lib/jobcontrol/ControlledJob.java' sourcefile='ControlledJob.java' startBytecode='73'><Message>Synchronized access at ControlledJob.java:[line 336]</Message></SourceLine><SourceLine role='SOURCE_LINE_SYNC_ACCESS' endBytecode='24' classname='org.apache.hadoop.mapreduce.lib.jobcontrol.ControlledJob' start='325' end='325' sourcepath='org/apache/hadoop/mapreduce/lib/jobcontrol/ControlledJob.java' sourcefile='ControlledJob.java' startBytecode='24'><Message>Synchronized access at ControlledJob.java:[line 325]</Message></SourceLine><SourceLine role='SOURCE_LINE_SYNC_ACCESS' endBytecode='15' classname='org.apache.hadoop.mapreduce.lib.jobcontrol.ControlledJob' start='94' end='94' sourcepath='org/apache/hadoop/mapreduce/lib/jobcontrol/ControlledJob.java' sourcefile='ControlledJob.java' startBytecode='15'><Message>Synchronized access at ControlledJob.java:[line 94]</Message></SourceLine><SourceLine role='SOURCE_LINE_SYNC_ACCESS' endBytecode='75' classname='org.apache.hadoop.mapreduce.lib.jobcontrol.ControlledJob' start='97' end='97' sourcepath='org/apache/hadoop/mapreduce/lib/jobcontrol/ControlledJob.java' sourcefile='ControlledJob.java' startBytecode='75'><Message>Synchronized access at ControlledJob.java:[line 97]</Message></SourceLine><Property name='edu.umd.cs.findbugs.detect.InconsistentSyncWarningProperty.ONLY_UNSYNC_IN_GETTERS' value='true'></Property></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='2b1defe8ef89bbacc56539f4c07c1d7b' cweid='396' rank='20' abbrev='REC' category='STYLE' priority='3' type='REC_CATCH_EXCEPTION' instanceOccurrenceMax='0'><ShortMessage>Exception is caught when Exception is not thrown</ShortMessage><LongMessage>Exception is caught when Exception is not thrown in org.apache.hadoop.mapreduce.lib.jobcontrol.ControlledJob.submit()</LongMessage><Class classname='org.apache.hadoop.mapreduce.lib.jobcontrol.ControlledJob' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.lib.jobcontrol.ControlledJob' start='52' end='343' sourcepath='org/apache/hadoop/mapreduce/lib/jobcontrol/ControlledJob.java' sourcefile='ControlledJob.java'><Message>At ControlledJob.java:[lines 52-343]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.lib.jobcontrol.ControlledJob</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapreduce.lib.jobcontrol.ControlledJob' signature='()V' name='submit' primary='true'><SourceLine endBytecode='362' classname='org.apache.hadoop.mapreduce.lib.jobcontrol.ControlledJob' start='322' end='343' sourcepath='org/apache/hadoop/mapreduce/lib/jobcontrol/ControlledJob.java' sourcefile='ControlledJob.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapreduce.lib.jobcontrol.ControlledJob.submit()</Message></Method><SourceLine endBytecode='89' classname='org.apache.hadoop.mapreduce.lib.jobcontrol.ControlledJob' start='338' end='338' sourcepath='org/apache/hadoop/mapreduce/lib/jobcontrol/ControlledJob.java' sourcefile='ControlledJob.java' startBytecode='89' primary='true'><Message>At ControlledJob.java:[line 338]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='d8724a25c557c88c741525d75bcbad52' cweid='391' rank='19' abbrev='DE' category='BAD_PRACTICE' priority='3' type='DE_MIGHT_IGNORE' instanceOccurrenceMax='0'><ShortMessage>Method might ignore exception</ShortMessage><LongMessage>org.apache.hadoop.mapreduce.lib.jobcontrol.JobControl.run() might ignore java.lang.Exception</LongMessage><Class classname='org.apache.hadoop.mapreduce.lib.jobcontrol.JobControl' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.lib.jobcontrol.JobControl' start='58' end='353' sourcepath='org/apache/hadoop/mapreduce/lib/jobcontrol/JobControl.java' sourcefile='JobControl.java'><Message>At JobControl.java:[lines 58-353]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.lib.jobcontrol.JobControl</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapreduce.lib.jobcontrol.JobControl' signature='()V' name='run' primary='true'><SourceLine endBytecode='632' classname='org.apache.hadoop.mapreduce.lib.jobcontrol.JobControl' start='214' end='276' sourcepath='org/apache/hadoop/mapreduce/lib/jobcontrol/JobControl.java' sourcefile='JobControl.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapreduce.lib.jobcontrol.JobControl.run()</Message></Method><Class role='CLASS_EXCEPTION' classname='java.lang.Exception'><SourceLine classname='java.lang.Exception' start='54' end='123' sourcepath='java/lang/Exception.java' sourcefile='Exception.java'><Message>At Exception.java:[lines 54-123]</Message></SourceLine><Message>Exception class java.lang.Exception</Message></Class><SourceLine endBytecode='47' classname='org.apache.hadoop.mapreduce.lib.jobcontrol.JobControl' start='224' end='224' sourcepath='org/apache/hadoop/mapreduce/lib/jobcontrol/JobControl.java' sourcefile='JobControl.java' startBytecode='47' primary='true'><Message>At JobControl.java:[line 224]</Message></SourceLine><SourceLine endBytecode='47' classname='org.apache.hadoop.mapreduce.lib.jobcontrol.JobControl' start='224' end='224' sourcepath='org/apache/hadoop/mapreduce/lib/jobcontrol/JobControl.java' sourcefile='JobControl.java' startBytecode='47' primary='true'><Message>At JobControl.java:[line 224]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='de776b4df29110dd5787d6fa53d30adf' rank='20' abbrev='UwF' category='STYLE' priority='3' type='UWF_FIELD_NOT_INITIALIZED_IN_CONSTRUCTOR' instanceOccurrenceMax='0'><ShortMessage>Field not initialized in constructor but dereferenced without null check</ShortMessage><LongMessage>CompositeInputFormat.root not initialized in constructor and dereferenced in org.apache.hadoop.mapreduce.lib.join.CompositeInputFormat.createRecordReader(InputSplit, TaskAttemptContext)</LongMessage><Class classname='org.apache.hadoop.mapreduce.lib.join.CompositeInputFormat' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.lib.join.CompositeInputFormat' start='65' end='193' sourcepath='org/apache/hadoop/mapreduce/lib/join/CompositeInputFormat.java' sourcefile='CompositeInputFormat.java'><Message>At CompositeInputFormat.java:[lines 65-193]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.lib.join.CompositeInputFormat</Message></Class><Field isStatic='false' classname='org.apache.hadoop.mapreduce.lib.join.CompositeInputFormat' signature='Lorg/apache/hadoop/mapreduce/lib/join/Parser$Node;' name='root' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.lib.join.CompositeInputFormat' sourcepath='org/apache/hadoop/mapreduce/lib/join/CompositeInputFormat.java' sourcefile='CompositeInputFormat.java'><Message>In CompositeInputFormat.java</Message></SourceLine><Message>Field org.apache.hadoop.mapreduce.lib.join.CompositeInputFormat.root</Message></Field><Method isStatic='false' classname='org.apache.hadoop.mapreduce.lib.join.CompositeInputFormat' signature='(Lorg/apache/hadoop/mapreduce/InputSplit;Lorg/apache/hadoop/mapreduce/TaskAttemptContext;)Lorg/apache/hadoop/mapreduce/RecordReader;' name='createRecordReader' primary='true'><SourceLine endBytecode='103' classname='org.apache.hadoop.mapreduce.lib.join.CompositeInputFormat' start='142' end='143' sourcepath='org/apache/hadoop/mapreduce/lib/join/CompositeInputFormat.java' sourcefile='CompositeInputFormat.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapreduce.lib.join.CompositeInputFormat.createRecordReader(InputSplit, TaskAttemptContext)</Message></Method><SourceLine endBytecode='16' classname='org.apache.hadoop.mapreduce.lib.join.CompositeInputFormat' start='143' end='143' sourcepath='org/apache/hadoop/mapreduce/lib/join/CompositeInputFormat.java' sourcefile='CompositeInputFormat.java' startBytecode='16' primary='true'><Message>At CompositeInputFormat.java:[line 143]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='dd4914628180acb248fcfa3df82d8960' rank='20' abbrev='UwF' category='STYLE' priority='3' type='UWF_FIELD_NOT_INITIALIZED_IN_CONSTRUCTOR' instanceOccurrenceMax='0'><ShortMessage>Field not initialized in constructor but dereferenced without null check</ShortMessage><LongMessage>CompositeInputFormat.root not initialized in constructor and dereferenced in org.apache.hadoop.mapreduce.lib.join.CompositeInputFormat.getSplits(JobContext)</LongMessage><Class classname='org.apache.hadoop.mapreduce.lib.join.CompositeInputFormat' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.lib.join.CompositeInputFormat' start='65' end='193' sourcepath='org/apache/hadoop/mapreduce/lib/join/CompositeInputFormat.java' sourcefile='CompositeInputFormat.java'><Message>At CompositeInputFormat.java:[lines 65-193]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.lib.join.CompositeInputFormat</Message></Class><Field isStatic='false' classname='org.apache.hadoop.mapreduce.lib.join.CompositeInputFormat' signature='Lorg/apache/hadoop/mapreduce/lib/join/Parser$Node;' name='root' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.lib.join.CompositeInputFormat' sourcepath='org/apache/hadoop/mapreduce/lib/join/CompositeInputFormat.java' sourcefile='CompositeInputFormat.java'><Message>In CompositeInputFormat.java</Message></SourceLine><Message>Field org.apache.hadoop.mapreduce.lib.join.CompositeInputFormat.root</Message></Field><Method isStatic='false' classname='org.apache.hadoop.mapreduce.lib.join.CompositeInputFormat' signature='(Lorg/apache/hadoop/mapreduce/JobContext;)Ljava/util/List;' name='getSplits' primary='true'><SourceLine endBytecode='110' classname='org.apache.hadoop.mapreduce.lib.join.CompositeInputFormat' start='127' end='129' sourcepath='org/apache/hadoop/mapreduce/lib/join/CompositeInputFormat.java' sourcefile='CompositeInputFormat.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapreduce.lib.join.CompositeInputFormat.getSplits(JobContext)</Message></Method><SourceLine endBytecode='29' classname='org.apache.hadoop.mapreduce.lib.join.CompositeInputFormat' start='129' end='129' sourcepath='org/apache/hadoop/mapreduce/lib/join/CompositeInputFormat.java' sourcefile='CompositeInputFormat.java' startBytecode='29' primary='true'><Message>At CompositeInputFormat.java:[line 129]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='5e0da061bc1d64294e498b119b0ac8c8' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from java.io.DataInput to java.io.DataInputStream in org.apache.hadoop.mapreduce.lib.join.CompositeInputSplit.readFields(DataInput)</LongMessage><Class classname='org.apache.hadoop.mapreduce.lib.join.CompositeInputSplit' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.lib.join.CompositeInputSplit' start='46' end='165' sourcepath='org/apache/hadoop/mapreduce/lib/join/CompositeInputSplit.java' sourcefile='CompositeInputSplit.java'><Message>At CompositeInputSplit.java:[lines 46-165]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.lib.join.CompositeInputSplit</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapreduce.lib.join.CompositeInputSplit' signature='(Ljava/io/DataInput;)V' name='readFields' primary='true'><SourceLine endBytecode='85' classname='org.apache.hadoop.mapreduce.lib.join.CompositeInputSplit' start='145' end='165' sourcepath='org/apache/hadoop/mapreduce/lib/join/CompositeInputSplit.java' sourcefile='CompositeInputSplit.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapreduce.lib.join.CompositeInputSplit.readFields(DataInput)</Message></Method><Type role='TYPE_FOUND' descriptor='Ljava/io/DataInput;'><SourceLine classname='java.io.DataInput' sourcepath='java/io/DataInput.java' sourcefile='DataInput.java'><Message>In DataInput.java</Message></SourceLine><Message>Actual type java.io.DataInput</Message></Type><Type role='TYPE_EXPECTED' descriptor='Ljava/io/DataInputStream;'><SourceLine classname='java.io.DataInputStream' start='52' end='661' sourcepath='java/io/DataInputStream.java' sourcefile='DataInputStream.java'><Message>At DataInputStream.java:[lines 52-661]</Message></SourceLine><Message>Expected java.io.DataInputStream</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='118' name='in' register='1'><Message>Value loaded from in</Message></LocalVariable><SourceLine endBytecode='119' classname='org.apache.hadoop.mapreduce.lib.join.CompositeInputSplit' start='159' end='159' sourcepath='org/apache/hadoop/mapreduce/lib/join/CompositeInputSplit.java' sourcefile='CompositeInputSplit.java' startBytecode='119' primary='true'><Message>At CompositeInputSplit.java:[line 159]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='8a992284c296f51d30f99a26ead81495' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from java.io.DataOutput to java.io.DataOutputStream in org.apache.hadoop.mapreduce.lib.join.CompositeInputSplit.write(DataOutput)</LongMessage><Class classname='org.apache.hadoop.mapreduce.lib.join.CompositeInputSplit' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.lib.join.CompositeInputSplit' start='46' end='165' sourcepath='org/apache/hadoop/mapreduce/lib/join/CompositeInputSplit.java' sourcefile='CompositeInputSplit.java'><Message>At CompositeInputSplit.java:[lines 46-165]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.lib.join.CompositeInputSplit</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapreduce.lib.join.CompositeInputSplit' signature='(Ljava/io/DataOutput;)V' name='write' primary='true'><SourceLine endBytecode='63' classname='org.apache.hadoop.mapreduce.lib.join.CompositeInputSplit' start='125' end='136' sourcepath='org/apache/hadoop/mapreduce/lib/join/CompositeInputSplit.java' sourcefile='CompositeInputSplit.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapreduce.lib.join.CompositeInputSplit.write(DataOutput)</Message></Method><Type role='TYPE_FOUND' descriptor='Ljava/io/DataOutput;'><SourceLine classname='java.io.DataOutput' sourcepath='java/io/DataOutput.java' sourcefile='DataOutput.java'><Message>In DataOutput.java</Message></SourceLine><Message>Actual type java.io.DataOutput</Message></Type><Type role='TYPE_EXPECTED' descriptor='Ljava/io/DataOutputStream;'><SourceLine classname='java.io.DataOutputStream' start='48' end='414' sourcepath='java/io/DataOutputStream.java' sourcefile='DataOutputStream.java'><Message>At DataOutputStream.java:[lines 48-414]</Message></SourceLine><Message>Expected java.io.DataOutputStream</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='101' name='out' register='1'><Message>Value loaded from out</Message></LocalVariable><SourceLine endBytecode='102' classname='org.apache.hadoop.mapreduce.lib.join.CompositeInputSplit' start='133' end='133' sourcepath='org/apache/hadoop/mapreduce/lib/join/CompositeInputSplit.java' sourcefile='CompositeInputSplit.java' startBytecode='102' primary='true'><Message>At CompositeInputSplit.java:[line 133]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='8dd54148dbc312ee1cd3523efe077059' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from org.apache.hadoop.mapreduce.InputSplit to org.apache.hadoop.mapreduce.lib.join.CompositeInputSplit in org.apache.hadoop.mapreduce.lib.join.CompositeRecordReader.initialize(InputSplit, TaskAttemptContext)</LongMessage><Class classname='org.apache.hadoop.mapreduce.lib.join.CompositeRecordReader' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.lib.join.CompositeRecordReader' start='43' end='494' sourcepath='org/apache/hadoop/mapreduce/lib/join/CompositeRecordReader.java' sourcefile='CompositeRecordReader.java'><Message>At CompositeRecordReader.java:[lines 43-494]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.lib.join.CompositeRecordReader</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapreduce.lib.join.CompositeRecordReader' signature='(Lorg/apache/hadoop/mapreduce/InputSplit;Lorg/apache/hadoop/mapreduce/TaskAttemptContext;)V' name='initialize' primary='true'><SourceLine endBytecode='92' classname='org.apache.hadoop.mapreduce.lib.join.CompositeRecordReader' start='98' end='132' sourcepath='org/apache/hadoop/mapreduce/lib/join/CompositeRecordReader.java' sourcefile='CompositeRecordReader.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapreduce.lib.join.CompositeRecordReader.initialize(InputSplit, TaskAttemptContext)</Message></Method><Type role='TYPE_FOUND' descriptor='Lorg/apache/hadoop/mapreduce/InputSplit;'><SourceLine classname='org.apache.hadoop.mapreduce.InputSplit' start='44' end='75' sourcepath='org/apache/hadoop/mapreduce/InputSplit.java' sourcefile='InputSplit.java'><Message>At InputSplit.java:[lines 44-75]</Message></SourceLine><Message>Actual type org.apache.hadoop.mapreduce.InputSplit</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/mapreduce/lib/join/CompositeInputSplit;'><SourceLine classname='org.apache.hadoop.mapreduce.lib.join.CompositeInputSplit' start='46' end='165' sourcepath='org/apache/hadoop/mapreduce/lib/join/CompositeInputSplit.java' sourcefile='CompositeInputSplit.java'><Message>At CompositeInputSplit.java:[lines 46-165]</Message></SourceLine><Message>Expected org.apache.hadoop.mapreduce.lib.join.CompositeInputSplit</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='24' name='split' register='1'><Message>Value loaded from split</Message></LocalVariable><SourceLine endBytecode='25' classname='org.apache.hadoop.mapreduce.lib.join.CompositeRecordReader' start='100' end='100' sourcepath='org/apache/hadoop/mapreduce/lib/join/CompositeRecordReader.java' sourcefile='CompositeRecordReader.java' startBytecode='25' primary='true'><Message>At CompositeRecordReader.java:[line 100]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='f59707e17cf2e75b74ccafa7504b7b7f' rank='19' abbrev='Eq' category='BAD_PRACTICE' priority='3' type='EQ_COMPARETO_USE_OBJECT_EQUALS' instanceOccurrenceMax='0'><ShortMessage>Class defines compareTo(...) and uses Object.equals()</ShortMessage><LongMessage>org.apache.hadoop.mapreduce.lib.join.CompositeRecordReader defines compareTo(Object) and uses Object.equals()</LongMessage><Class classname='org.apache.hadoop.mapreduce.lib.join.CompositeRecordReader' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.lib.join.CompositeRecordReader' start='43' end='494' sourcepath='org/apache/hadoop/mapreduce/lib/join/CompositeRecordReader.java' sourcefile='CompositeRecordReader.java'><Message>At CompositeRecordReader.java:[lines 43-494]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.lib.join.CompositeRecordReader</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapreduce.lib.join.CompositeRecordReader' signature='(Ljava/lang/Object;)I' name='compareTo' primary='true'><SourceLine endBytecode='68' classname='org.apache.hadoop.mapreduce.lib.join.CompositeRecordReader' start='43' end='43' sourcepath='org/apache/hadoop/mapreduce/lib/join/CompositeRecordReader.java' sourcefile='CompositeRecordReader.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapreduce.lib.join.CompositeRecordReader.compareTo(Object)</Message></Method><SourceLine synthetic='true' endBytecode='68' classname='org.apache.hadoop.mapreduce.lib.join.CompositeRecordReader' start='43' end='43' sourcepath='org/apache/hadoop/mapreduce/lib/join/CompositeRecordReader.java' sourcefile='CompositeRecordReader.java' startBytecode='0'><Message>At CompositeRecordReader.java:[line 43]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='65ce78af74bfb8376e09d96bd55474ab' cweid='218' rank='18' abbrev='MS' category='MALICIOUS_CODE' priority='2' type='MS_MUTABLE_COLLECTION_PKGPROTECT' instanceOccurrenceMax='0'><ShortMessage>Field is a mutable collection which should be package protected</ShortMessage><LongMessage>org.apache.hadoop.mapreduce.lib.join.Parser$Node.rrCstrMap is a mutable collection which should be package protected</LongMessage><Class classname='org.apache.hadoop.mapreduce.lib.join.Parser$Node' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.lib.join.Parser$Node' start='207' end='265' sourcepath='org/apache/hadoop/mapreduce/lib/join/Parser.java' sourcefile='Parser.java'><Message>At Parser.java:[lines 207-265]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.lib.join.Parser$Node</Message></Class><Field isStatic='true' classname='org.apache.hadoop.mapreduce.lib.join.Parser$Node' signature='Ljava/util/Map;' name='rrCstrMap' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.lib.join.Parser$Node' sourcepath='org/apache/hadoop/mapreduce/lib/join/Parser.java' sourcefile='Parser.java'><Message>In Parser.java</Message></SourceLine><Message>Field org.apache.hadoop.mapreduce.lib.join.Parser$Node.rrCstrMap</Message></Field><SourceLine endBytecode='29' classname='org.apache.hadoop.mapreduce.lib.join.Parser$Node' start='225' end='225' sourcepath='org/apache/hadoop/mapreduce/lib/join/Parser.java' sourcefile='Parser.java' startBytecode='29' primary='true'><Message>At Parser.java:[line 225]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='37d10adff41e33abec38d2e6157f55f7' rank='20' abbrev='UwF' category='STYLE' priority='3' type='UWF_FIELD_NOT_INITIALIZED_IN_CONSTRUCTOR' instanceOccurrenceMax='0'><ShortMessage>Field not initialized in constructor but dereferenced without null check</ShortMessage><LongMessage>StreamBackedIterator.inbuf not initialized in constructor and dereferenced in org.apache.hadoop.mapreduce.lib.join.StreamBackedIterator.hasNext()</LongMessage><Class classname='org.apache.hadoop.mapreduce.lib.join.StreamBackedIterator' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.lib.join.StreamBackedIterator' start='49' end='102' sourcepath='org/apache/hadoop/mapreduce/lib/join/StreamBackedIterator.java' sourcefile='StreamBackedIterator.java'><Message>At StreamBackedIterator.java:[lines 49-102]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.lib.join.StreamBackedIterator</Message></Class><Field isStatic='false' classname='org.apache.hadoop.mapreduce.lib.join.StreamBackedIterator' signature='Lorg/apache/hadoop/mapreduce/lib/join/StreamBackedIterator$ReplayableByteInputStream;' name='inbuf' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.lib.join.StreamBackedIterator' sourcepath='org/apache/hadoop/mapreduce/lib/join/StreamBackedIterator.java' sourcefile='StreamBackedIterator.java'><Message>In StreamBackedIterator.java</Message></SourceLine><Message>Field org.apache.hadoop.mapreduce.lib.join.StreamBackedIterator.inbuf</Message></Field><Method isStatic='false' classname='org.apache.hadoop.mapreduce.lib.join.StreamBackedIterator' signature='()Z' name='hasNext' primary='true'><SourceLine endBytecode='93' classname='org.apache.hadoop.mapreduce.lib.join.StreamBackedIterator' start='57' end='57' sourcepath='org/apache/hadoop/mapreduce/lib/join/StreamBackedIterator.java' sourcefile='StreamBackedIterator.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapreduce.lib.join.StreamBackedIterator.hasNext()</Message></Method><SourceLine endBytecode='11' classname='org.apache.hadoop.mapreduce.lib.join.StreamBackedIterator' start='57' end='57' sourcepath='org/apache/hadoop/mapreduce/lib/join/StreamBackedIterator.java' sourcefile='StreamBackedIterator.java' startBytecode='11' primary='true'><Message>At StreamBackedIterator.java:[line 57]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='542875fc5c41eb572dfa2521ed6cbdd1' rank='20' abbrev='UwF' category='STYLE' priority='3' type='UWF_FIELD_NOT_INITIALIZED_IN_CONSTRUCTOR' instanceOccurrenceMax='0'><ShortMessage>Field not initialized in constructor but dereferenced without null check</ShortMessage><LongMessage>StreamBackedIterator.inbuf not initialized in constructor and dereferenced in org.apache.hadoop.mapreduce.lib.join.StreamBackedIterator.next(Writable)</LongMessage><Class classname='org.apache.hadoop.mapreduce.lib.join.StreamBackedIterator' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.lib.join.StreamBackedIterator' start='49' end='102' sourcepath='org/apache/hadoop/mapreduce/lib/join/StreamBackedIterator.java' sourcefile='StreamBackedIterator.java'><Message>At StreamBackedIterator.java:[lines 49-102]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.lib.join.StreamBackedIterator</Message></Class><Field isStatic='false' classname='org.apache.hadoop.mapreduce.lib.join.StreamBackedIterator' signature='Lorg/apache/hadoop/mapreduce/lib/join/StreamBackedIterator$ReplayableByteInputStream;' name='inbuf' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.lib.join.StreamBackedIterator' sourcepath='org/apache/hadoop/mapreduce/lib/join/StreamBackedIterator.java' sourcefile='StreamBackedIterator.java'><Message>In StreamBackedIterator.java</Message></SourceLine><Message>Field org.apache.hadoop.mapreduce.lib.join.StreamBackedIterator.inbuf</Message></Field><Method isStatic='false' classname='org.apache.hadoop.mapreduce.lib.join.StreamBackedIterator' signature='(Lorg/apache/hadoop/io/Writable;)Z' name='next' primary='true'><SourceLine endBytecode='133' classname='org.apache.hadoop.mapreduce.lib.join.StreamBackedIterator' start='61' end='66' sourcepath='org/apache/hadoop/mapreduce/lib/join/StreamBackedIterator.java' sourcefile='StreamBackedIterator.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapreduce.lib.join.StreamBackedIterator.next(Writable)</Message></Method><SourceLine endBytecode='12' classname='org.apache.hadoop.mapreduce.lib.join.StreamBackedIterator' start='62' end='62' sourcepath='org/apache/hadoop/mapreduce/lib/join/StreamBackedIterator.java' sourcefile='StreamBackedIterator.java' startBytecode='12' primary='true'><Message>At StreamBackedIterator.java:[line 62]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='ec561da0f5168596e6d7a54121a4d554' rank='20' abbrev='UwF' category='STYLE' priority='3' type='UWF_FIELD_NOT_INITIALIZED_IN_CONSTRUCTOR' instanceOccurrenceMax='0'><ShortMessage>Field not initialized in constructor but dereferenced without null check</ShortMessage><LongMessage>StreamBackedIterator.inbuf not initialized in constructor and dereferenced in org.apache.hadoop.mapreduce.lib.join.StreamBackedIterator.replay(Writable)</LongMessage><Class classname='org.apache.hadoop.mapreduce.lib.join.StreamBackedIterator' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.lib.join.StreamBackedIterator' start='49' end='102' sourcepath='org/apache/hadoop/mapreduce/lib/join/StreamBackedIterator.java' sourcefile='StreamBackedIterator.java'><Message>At StreamBackedIterator.java:[lines 49-102]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.lib.join.StreamBackedIterator</Message></Class><Field isStatic='false' classname='org.apache.hadoop.mapreduce.lib.join.StreamBackedIterator' signature='Lorg/apache/hadoop/mapreduce/lib/join/StreamBackedIterator$ReplayableByteInputStream;' name='inbuf' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.lib.join.StreamBackedIterator' sourcepath='org/apache/hadoop/mapreduce/lib/join/StreamBackedIterator.java' sourcefile='StreamBackedIterator.java'><Message>In StreamBackedIterator.java</Message></SourceLine><Message>Field org.apache.hadoop.mapreduce.lib.join.StreamBackedIterator.inbuf</Message></Field><Method isStatic='false' classname='org.apache.hadoop.mapreduce.lib.join.StreamBackedIterator' signature='(Lorg/apache/hadoop/io/Writable;)Z' name='replay' primary='true'><SourceLine endBytecode='136' classname='org.apache.hadoop.mapreduce.lib.join.StreamBackedIterator' start='70' end='74' sourcepath='org/apache/hadoop/mapreduce/lib/join/StreamBackedIterator.java' sourcefile='StreamBackedIterator.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapreduce.lib.join.StreamBackedIterator.replay(Writable)</Message></Method><SourceLine endBytecode='4' classname='org.apache.hadoop.mapreduce.lib.join.StreamBackedIterator' start='70' end='70' sourcepath='org/apache/hadoop/mapreduce/lib/join/StreamBackedIterator.java' sourcefile='StreamBackedIterator.java' startBytecode='4' primary='true'><Message>At StreamBackedIterator.java:[line 70]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='50fdf65a222ec5e79f44ded7a704ac1b' cweid='374' rank='18' abbrev='EI2' category='MALICIOUS_CODE' priority='2' type='EI_EXPOSE_REP2' instanceOccurrenceMax='0'><ShortMessage>May expose internal representation by incorporating reference to mutable object</ShortMessage><LongMessage>new org.apache.hadoop.mapreduce.lib.join.TupleWritable(Writable[]) may expose internal representation by storing an externally mutable object into TupleWritable.values</LongMessage><Class classname='org.apache.hadoop.mapreduce.lib.join.TupleWritable' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.lib.join.TupleWritable' start='47' end='297' sourcepath='org/apache/hadoop/mapreduce/lib/join/TupleWritable.java' sourcefile='TupleWritable.java'><Message>At TupleWritable.java:[lines 47-297]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.lib.join.TupleWritable</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapreduce.lib.join.TupleWritable' signature='([Lorg/apache/hadoop/io/Writable;)V' name='&lt;init&gt;' primary='true'><SourceLine endBytecode='86' classname='org.apache.hadoop.mapreduce.lib.join.TupleWritable' start='65' end='68' sourcepath='org/apache/hadoop/mapreduce/lib/join/TupleWritable.java' sourcefile='TupleWritable.java' startBytecode='0'></SourceLine><Message>In method new org.apache.hadoop.mapreduce.lib.join.TupleWritable(Writable[])</Message></Method><Field isStatic='false' classname='org.apache.hadoop.mapreduce.lib.join.TupleWritable' signature='[Lorg/apache/hadoop/io/Writable;' name='values' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.lib.join.TupleWritable' sourcepath='org/apache/hadoop/mapreduce/lib/join/TupleWritable.java' sourcefile='TupleWritable.java'><Message>In TupleWritable.java</Message></SourceLine><Message>Field org.apache.hadoop.mapreduce.lib.join.TupleWritable.values</Message></Field><LocalVariable role='LOCAL_VARIABLE_NAMED' pc='19' name='vals' register='1'><Message>Local variable named vals</Message></LocalVariable><SourceLine endBytecode='19' classname='org.apache.hadoop.mapreduce.lib.join.TupleWritable' start='67' end='67' sourcepath='org/apache/hadoop/mapreduce/lib/join/TupleWritable.java' sourcefile='TupleWritable.java' startBytecode='19' primary='true'><Message>At TupleWritable.java:[line 67]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='c25f61e92e091f316340212b825a95d2' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.mapreduce.lib.map.MultithreadedMapper.MAP_CLASS isn't final but should be</LongMessage><Class classname='org.apache.hadoop.mapreduce.lib.map.MultithreadedMapper' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.lib.map.MultithreadedMapper' start='61' end='159' sourcepath='org/apache/hadoop/mapreduce/lib/map/MultithreadedMapper.java' sourcefile='MultithreadedMapper.java'><Message>At MultithreadedMapper.java:[lines 61-159]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.lib.map.MultithreadedMapper</Message></Class><Field isStatic='true' classname='org.apache.hadoop.mapreduce.lib.map.MultithreadedMapper' signature='Ljava/lang/String;' name='MAP_CLASS' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.lib.map.MultithreadedMapper' sourcepath='org/apache/hadoop/mapreduce/lib/map/MultithreadedMapper.java' sourcefile='MultithreadedMapper.java'><Message>In MultithreadedMapper.java</Message></SourceLine><Message>Field org.apache.hadoop.mapreduce.lib.map.MultithreadedMapper.MAP_CLASS</Message></Field><SourceLine endBytecode='15' classname='org.apache.hadoop.mapreduce.lib.map.MultithreadedMapper' start='67' end='67' sourcepath='org/apache/hadoop/mapreduce/lib/map/MultithreadedMapper.java' sourcefile='MultithreadedMapper.java' startBytecode='15' primary='true'><Message>At MultithreadedMapper.java:[line 67]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='f72d2aa292b0e8db744e04ad84b4c6cd' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.mapreduce.lib.map.MultithreadedMapper.NUM_THREADS isn't final but should be</LongMessage><Class classname='org.apache.hadoop.mapreduce.lib.map.MultithreadedMapper' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.lib.map.MultithreadedMapper' start='61' end='159' sourcepath='org/apache/hadoop/mapreduce/lib/map/MultithreadedMapper.java' sourcefile='MultithreadedMapper.java'><Message>At MultithreadedMapper.java:[lines 61-159]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.lib.map.MultithreadedMapper</Message></Class><Field isStatic='true' classname='org.apache.hadoop.mapreduce.lib.map.MultithreadedMapper' signature='Ljava/lang/String;' name='NUM_THREADS' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.lib.map.MultithreadedMapper' sourcepath='org/apache/hadoop/mapreduce/lib/map/MultithreadedMapper.java' sourcefile='MultithreadedMapper.java'><Message>In MultithreadedMapper.java</Message></SourceLine><Message>Field org.apache.hadoop.mapreduce.lib.map.MultithreadedMapper.NUM_THREADS</Message></Field><SourceLine endBytecode='10' classname='org.apache.hadoop.mapreduce.lib.map.MultithreadedMapper' start='66' end='66' sourcepath='org/apache/hadoop/mapreduce/lib/map/MultithreadedMapper.java' sourcefile='MultithreadedMapper.java' startBytecode='10' primary='true'><Message>At MultithreadedMapper.java:[line 66]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='fb1dcd94c4b96da942cf96e029f00661' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.mapreduce.lib.map.RegexMapper.GROUP isn't final but should be</LongMessage><Class classname='org.apache.hadoop.mapreduce.lib.map.RegexMapper' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.lib.map.RegexMapper' start='34' end='57' sourcepath='org/apache/hadoop/mapreduce/lib/map/RegexMapper.java' sourcefile='RegexMapper.java'><Message>At RegexMapper.java:[lines 34-57]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.lib.map.RegexMapper</Message></Class><Field isStatic='true' classname='org.apache.hadoop.mapreduce.lib.map.RegexMapper' signature='Ljava/lang/String;' name='GROUP' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.lib.map.RegexMapper' sourcepath='org/apache/hadoop/mapreduce/lib/map/RegexMapper.java' sourcefile='RegexMapper.java'><Message>In RegexMapper.java</Message></SourceLine><Message>Field org.apache.hadoop.mapreduce.lib.map.RegexMapper.GROUP</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.mapreduce.lib.map.RegexMapper' start='39' end='39' sourcepath='org/apache/hadoop/mapreduce/lib/map/RegexMapper.java' sourcefile='RegexMapper.java' startBytecode='7' primary='true'><Message>At RegexMapper.java:[line 39]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='7a7aa73dd04f90c4bb310c9889ed360b' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.mapreduce.lib.map.RegexMapper.PATTERN isn't final but should be</LongMessage><Class classname='org.apache.hadoop.mapreduce.lib.map.RegexMapper' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.lib.map.RegexMapper' start='34' end='57' sourcepath='org/apache/hadoop/mapreduce/lib/map/RegexMapper.java' sourcefile='RegexMapper.java'><Message>At RegexMapper.java:[lines 34-57]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.lib.map.RegexMapper</Message></Class><Field isStatic='true' classname='org.apache.hadoop.mapreduce.lib.map.RegexMapper' signature='Ljava/lang/String;' name='PATTERN' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.lib.map.RegexMapper' sourcepath='org/apache/hadoop/mapreduce/lib/map/RegexMapper.java' sourcefile='RegexMapper.java'><Message>In RegexMapper.java</Message></SourceLine><Message>Field org.apache.hadoop.mapreduce.lib.map.RegexMapper.PATTERN</Message></Field><SourceLine endBytecode='2' classname='org.apache.hadoop.mapreduce.lib.map.RegexMapper' start='38' end='38' sourcepath='org/apache/hadoop/mapreduce/lib/map/RegexMapper.java' sourcefile='RegexMapper.java' startBytecode='2' primary='true'><Message>At RegexMapper.java:[line 38]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='4b42a3140ff45fc815177c803c6a0d81' rank='20' abbrev='UwF' category='STYLE' priority='3' type='UWF_FIELD_NOT_INITIALIZED_IN_CONSTRUCTOR' instanceOccurrenceMax='0'><ShortMessage>Field not initialized in constructor but dereferenced without null check</ShortMessage><LongMessage>RegexMapper.pattern not initialized in constructor and dereferenced in org.apache.hadoop.mapreduce.lib.map.RegexMapper.map(Object, Text, Mapper$Context)</LongMessage><Class classname='org.apache.hadoop.mapreduce.lib.map.RegexMapper' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.lib.map.RegexMapper' start='34' end='57' sourcepath='org/apache/hadoop/mapreduce/lib/map/RegexMapper.java' sourcefile='RegexMapper.java'><Message>At RegexMapper.java:[lines 34-57]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.lib.map.RegexMapper</Message></Class><Field isStatic='false' classname='org.apache.hadoop.mapreduce.lib.map.RegexMapper' signature='Ljava/util/regex/Pattern;' name='pattern' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.lib.map.RegexMapper' sourcepath='org/apache/hadoop/mapreduce/lib/map/RegexMapper.java' sourcefile='RegexMapper.java'><Message>In RegexMapper.java</Message></SourceLine><Message>Field org.apache.hadoop.mapreduce.lib.map.RegexMapper.pattern</Message></Field><Method isStatic='false' classname='org.apache.hadoop.mapreduce.lib.map.RegexMapper' signature='(Ljava/lang/Object;Lorg/apache/hadoop/io/Text;Lorg/apache/hadoop/mapreduce/Mapper$Context;)V' name='map' primary='true'><SourceLine endBytecode='220' classname='org.apache.hadoop.mapreduce.lib.map.RegexMapper' start='52' end='57' sourcepath='org/apache/hadoop/mapreduce/lib/map/RegexMapper.java' sourcefile='RegexMapper.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapreduce.lib.map.RegexMapper.map(Object, Text, Mapper$Context)</Message></Method><SourceLine endBytecode='12' classname='org.apache.hadoop.mapreduce.lib.map.RegexMapper' start='53' end='53' sourcepath='org/apache/hadoop/mapreduce/lib/map/RegexMapper.java' sourcefile='RegexMapper.java' startBytecode='12' primary='true'><Message>At RegexMapper.java:[line 53]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='8a7e2d6ae7444cb7a71b32a03fecfd55' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.mapreduce.lib.output.LazyOutputFormat.OUTPUT_FORMAT isn't final but should be</LongMessage><Class classname='org.apache.hadoop.mapreduce.lib.output.LazyOutputFormat' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.lib.output.LazyOutputFormat' start='42' end='92' sourcepath='org/apache/hadoop/mapreduce/lib/output/LazyOutputFormat.java' sourcefile='LazyOutputFormat.java'><Message>At LazyOutputFormat.java:[lines 42-92]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.lib.output.LazyOutputFormat</Message></Class><Field isStatic='true' classname='org.apache.hadoop.mapreduce.lib.output.LazyOutputFormat' signature='Ljava/lang/String;' name='OUTPUT_FORMAT' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.lib.output.LazyOutputFormat' sourcepath='org/apache/hadoop/mapreduce/lib/output/LazyOutputFormat.java' sourcefile='LazyOutputFormat.java'><Message>In LazyOutputFormat.java</Message></SourceLine><Message>Field org.apache.hadoop.mapreduce.lib.output.LazyOutputFormat.OUTPUT_FORMAT</Message></Field><SourceLine endBytecode='2' classname='org.apache.hadoop.mapreduce.lib.output.LazyOutputFormat' start='43' end='43' sourcepath='org/apache/hadoop/mapreduce/lib/output/LazyOutputFormat.java' sourcefile='LazyOutputFormat.java' startBytecode='2' primary='true'><Message>At LazyOutputFormat.java:[line 43]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='735346c67cb852d2e98481cbb1fe09c4' rank='20' abbrev='SIC' category='PERFORMANCE' priority='3' type='SIC_INNER_SHOULD_BE_STATIC_ANON' instanceOccurrenceMax='0'><ShortMessage>Could be refactored into a named static inner class</ShortMessage><LongMessage>The class org.apache.hadoop.mapreduce.lib.output.MapFileOutputFormat$1 could be refactored into a named _static_ inner class</LongMessage><Class role='CLASS_ANONYMOUS' classname='org.apache.hadoop.mapreduce.lib.output.MapFileOutputFormat$1'><SourceLine classname='org.apache.hadoop.mapreduce.lib.output.MapFileOutputFormat$1' start='76' end='84' sourcepath='org/apache/hadoop/mapreduce/lib/output/MapFileOutputFormat.java' sourcefile='MapFileOutputFormat.java'><Message>At MapFileOutputFormat.java:[lines 76-84]</Message></SourceLine><Message>Anonymous class org.apache.hadoop.mapreduce.lib.output.MapFileOutputFormat$1</Message></Class><Class classname='org.apache.hadoop.mapreduce.lib.output.MapFileOutputFormat' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.lib.output.MapFileOutputFormat' start='49' end='124' sourcepath='org/apache/hadoop/mapreduce/lib/output/MapFileOutputFormat.java' sourcefile='MapFileOutputFormat.java'><Message>At MapFileOutputFormat.java:[lines 49-124]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.lib.output.MapFileOutputFormat</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapreduce.lib.output.MapFileOutputFormat' signature='(Lorg/apache/hadoop/mapreduce/TaskAttemptContext;)Lorg/apache/hadoop/mapreduce/RecordWriter;' name='getRecordWriter' primary='true'><SourceLine endBytecode='327' classname='org.apache.hadoop.mapreduce.lib.output.MapFileOutputFormat' start='54' end='76' sourcepath='org/apache/hadoop/mapreduce/lib/output/MapFileOutputFormat.java' sourcefile='MapFileOutputFormat.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapreduce.lib.output.MapFileOutputFormat.getRecordWriter(TaskAttemptContext)</Message></Method><SourceLine endBytecode='112' classname='org.apache.hadoop.mapreduce.lib.output.MapFileOutputFormat' start='76' end='76' sourcepath='org/apache/hadoop/mapreduce/lib/output/MapFileOutputFormat.java' sourcefile='MapFileOutputFormat.java' startBytecode='112' primary='true'><Message>At MapFileOutputFormat.java:[line 76]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='4c39c00ede4d8c7f005d5f11922b2095' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.mapreduce.lib.output.SequenceFileAsBinaryOutputFormat.KEY_CLASS isn't final but should be</LongMessage><Class classname='org.apache.hadoop.mapreduce.lib.output.SequenceFileAsBinaryOutputFormat' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.lib.output.SequenceFileAsBinaryOutputFormat' start='43' end='164' sourcepath='org/apache/hadoop/mapreduce/lib/output/SequenceFileAsBinaryOutputFormat.java' sourcefile='SequenceFileAsBinaryOutputFormat.java'><Message>At SequenceFileAsBinaryOutputFormat.java:[lines 43-164]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.lib.output.SequenceFileAsBinaryOutputFormat</Message></Class><Field isStatic='true' classname='org.apache.hadoop.mapreduce.lib.output.SequenceFileAsBinaryOutputFormat' signature='Ljava/lang/String;' name='KEY_CLASS' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.lib.output.SequenceFileAsBinaryOutputFormat' sourcepath='org/apache/hadoop/mapreduce/lib/output/SequenceFileAsBinaryOutputFormat.java' sourcefile='SequenceFileAsBinaryOutputFormat.java'><Message>In SequenceFileAsBinaryOutputFormat.java</Message></SourceLine><Message>Field org.apache.hadoop.mapreduce.lib.output.SequenceFileAsBinaryOutputFormat.KEY_CLASS</Message></Field><SourceLine endBytecode='2' classname='org.apache.hadoop.mapreduce.lib.output.SequenceFileAsBinaryOutputFormat' start='45' end='45' sourcepath='org/apache/hadoop/mapreduce/lib/output/SequenceFileAsBinaryOutputFormat.java' sourcefile='SequenceFileAsBinaryOutputFormat.java' startBytecode='2' primary='true'><Message>At SequenceFileAsBinaryOutputFormat.java:[line 45]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='3d5bebef4a7b96718815d632048a8cca' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.mapreduce.lib.output.SequenceFileAsBinaryOutputFormat.VALUE_CLASS isn't final but should be</LongMessage><Class classname='org.apache.hadoop.mapreduce.lib.output.SequenceFileAsBinaryOutputFormat' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.lib.output.SequenceFileAsBinaryOutputFormat' start='43' end='164' sourcepath='org/apache/hadoop/mapreduce/lib/output/SequenceFileAsBinaryOutputFormat.java' sourcefile='SequenceFileAsBinaryOutputFormat.java'><Message>At SequenceFileAsBinaryOutputFormat.java:[lines 43-164]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.lib.output.SequenceFileAsBinaryOutputFormat</Message></Class><Field isStatic='true' classname='org.apache.hadoop.mapreduce.lib.output.SequenceFileAsBinaryOutputFormat' signature='Ljava/lang/String;' name='VALUE_CLASS' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.lib.output.SequenceFileAsBinaryOutputFormat' sourcepath='org/apache/hadoop/mapreduce/lib/output/SequenceFileAsBinaryOutputFormat.java' sourcefile='SequenceFileAsBinaryOutputFormat.java'><Message>In SequenceFileAsBinaryOutputFormat.java</Message></SourceLine><Message>Field org.apache.hadoop.mapreduce.lib.output.SequenceFileAsBinaryOutputFormat.VALUE_CLASS</Message></Field><SourceLine endBytecode='7' classname='org.apache.hadoop.mapreduce.lib.output.SequenceFileAsBinaryOutputFormat' start='46' end='46' sourcepath='org/apache/hadoop/mapreduce/lib/output/SequenceFileAsBinaryOutputFormat.java' sourcefile='SequenceFileAsBinaryOutputFormat.java' startBytecode='7' primary='true'><Message>At SequenceFileAsBinaryOutputFormat.java:[line 46]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='7b7b36ea9ca9ad5eecf709f2d65a1200' rank='20' abbrev='SIC' category='PERFORMANCE' priority='3' type='SIC_INNER_SHOULD_BE_STATIC_ANON' instanceOccurrenceMax='0'><ShortMessage>Could be refactored into a named static inner class</ShortMessage><LongMessage>The class org.apache.hadoop.mapreduce.lib.output.SequenceFileAsBinaryOutputFormat$1 could be refactored into a named _static_ inner class</LongMessage><Class role='CLASS_ANONYMOUS' classname='org.apache.hadoop.mapreduce.lib.output.SequenceFileAsBinaryOutputFormat$1'><SourceLine classname='org.apache.hadoop.mapreduce.lib.output.SequenceFileAsBinaryOutputFormat$1' start='140' end='152' sourcepath='org/apache/hadoop/mapreduce/lib/output/SequenceFileAsBinaryOutputFormat.java' sourcefile='SequenceFileAsBinaryOutputFormat.java'><Message>At SequenceFileAsBinaryOutputFormat.java:[lines 140-152]</Message></SourceLine><Message>Anonymous class org.apache.hadoop.mapreduce.lib.output.SequenceFileAsBinaryOutputFormat$1</Message></Class><Class classname='org.apache.hadoop.mapreduce.lib.output.SequenceFileAsBinaryOutputFormat' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.lib.output.SequenceFileAsBinaryOutputFormat' start='43' end='164' sourcepath='org/apache/hadoop/mapreduce/lib/output/SequenceFileAsBinaryOutputFormat.java' sourcefile='SequenceFileAsBinaryOutputFormat.java'><Message>At SequenceFileAsBinaryOutputFormat.java:[lines 43-164]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.lib.output.SequenceFileAsBinaryOutputFormat</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapreduce.lib.output.SequenceFileAsBinaryOutputFormat' signature='(Lorg/apache/hadoop/mapreduce/TaskAttemptContext;)Lorg/apache/hadoop/mapreduce/RecordWriter;' name='getRecordWriter' primary='true'><SourceLine endBytecode='101' classname='org.apache.hadoop.mapreduce.lib.output.SequenceFileAsBinaryOutputFormat' start='136' end='140' sourcepath='org/apache/hadoop/mapreduce/lib/output/SequenceFileAsBinaryOutputFormat.java' sourcefile='SequenceFileAsBinaryOutputFormat.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapreduce.lib.output.SequenceFileAsBinaryOutputFormat.getRecordWriter(TaskAttemptContext)</Message></Method><SourceLine endBytecode='20' classname='org.apache.hadoop.mapreduce.lib.output.SequenceFileAsBinaryOutputFormat' start='140' end='140' sourcepath='org/apache/hadoop/mapreduce/lib/output/SequenceFileAsBinaryOutputFormat.java' sourcefile='SequenceFileAsBinaryOutputFormat.java' startBytecode='20' primary='true'><Message>At SequenceFileAsBinaryOutputFormat.java:[line 140]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='d200a3b06460636fcc7912436372d0a7' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.mapreduce.lib.output.TextOutputFormat.SEPARATOR isn't final but should be</LongMessage><Class classname='org.apache.hadoop.mapreduce.lib.output.TextOutputFormat' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.lib.output.TextOutputFormat' start='44' end='132' sourcepath='org/apache/hadoop/mapreduce/lib/output/TextOutputFormat.java' sourcefile='TextOutputFormat.java'><Message>At TextOutputFormat.java:[lines 44-132]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.lib.output.TextOutputFormat</Message></Class><Field isStatic='true' classname='org.apache.hadoop.mapreduce.lib.output.TextOutputFormat' signature='Ljava/lang/String;' name='SEPARATOR' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.lib.output.TextOutputFormat' sourcepath='org/apache/hadoop/mapreduce/lib/output/TextOutputFormat.java' sourcefile='TextOutputFormat.java'><Message>In TextOutputFormat.java</Message></SourceLine><Message>Field org.apache.hadoop.mapreduce.lib.output.TextOutputFormat.SEPARATOR</Message></Field><SourceLine endBytecode='2' classname='org.apache.hadoop.mapreduce.lib.output.TextOutputFormat' start='45' end='45' sourcepath='org/apache/hadoop/mapreduce/lib/output/TextOutputFormat.java' sourcefile='TextOutputFormat.java' startBytecode='2' primary='true'><Message>At TextOutputFormat.java:[line 45]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='283ea8c05f8fcd508d8914ace9237ad8' cweid='218' rank='20' abbrev='MS' category='MALICIOUS_CODE' priority='3' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.mapreduce.lib.output.TextOutputFormat.SEPERATOR isn't final but should be</LongMessage><Class classname='org.apache.hadoop.mapreduce.lib.output.TextOutputFormat' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.lib.output.TextOutputFormat' start='44' end='132' sourcepath='org/apache/hadoop/mapreduce/lib/output/TextOutputFormat.java' sourcefile='TextOutputFormat.java'><Message>At TextOutputFormat.java:[lines 44-132]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.lib.output.TextOutputFormat</Message></Class><Field isStatic='true' classname='org.apache.hadoop.mapreduce.lib.output.TextOutputFormat' signature='Ljava/lang/String;' name='SEPERATOR' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.lib.output.TextOutputFormat' sourcepath='org/apache/hadoop/mapreduce/lib/output/TextOutputFormat.java' sourcefile='TextOutputFormat.java'><Message>In TextOutputFormat.java</Message></SourceLine><Message>Field org.apache.hadoop.mapreduce.lib.output.TextOutputFormat.SEPERATOR</Message></Field><SourceLine endBytecode='8' classname='org.apache.hadoop.mapreduce.lib.output.TextOutputFormat' start='50' end='50' sourcepath='org/apache/hadoop/mapreduce/lib/output/TextOutputFormat.java' sourcefile='TextOutputFormat.java' startBytecode='8' primary='true'><Message>At TextOutputFormat.java:[line 50]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='1275ca5e7571cf85040347019ac180e1' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.mapreduce.lib.partition.KeyFieldBasedComparator.COMPARATOR_OPTIONS isn't final but should be</LongMessage><Class classname='org.apache.hadoop.mapreduce.lib.partition.KeyFieldBasedComparator' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.lib.partition.KeyFieldBasedComparator' start='55' end='371' sourcepath='org/apache/hadoop/mapreduce/lib/partition/KeyFieldBasedComparator.java' sourcefile='KeyFieldBasedComparator.java'><Message>At KeyFieldBasedComparator.java:[lines 55-371]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.lib.partition.KeyFieldBasedComparator</Message></Class><Field isStatic='true' classname='org.apache.hadoop.mapreduce.lib.partition.KeyFieldBasedComparator' signature='Ljava/lang/String;' name='COMPARATOR_OPTIONS' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.lib.partition.KeyFieldBasedComparator' sourcepath='org/apache/hadoop/mapreduce/lib/partition/KeyFieldBasedComparator.java' sourcefile='KeyFieldBasedComparator.java'><Message>In KeyFieldBasedComparator.java</Message></SourceLine><Message>Field org.apache.hadoop.mapreduce.lib.partition.KeyFieldBasedComparator.COMPARATOR_OPTIONS</Message></Field><SourceLine endBytecode='2' classname='org.apache.hadoop.mapreduce.lib.partition.KeyFieldBasedComparator' start='56' end='56' sourcepath='org/apache/hadoop/mapreduce/lib/partition/KeyFieldBasedComparator.java' sourcefile='KeyFieldBasedComparator.java' startBytecode='2' primary='true'><Message>At KeyFieldBasedComparator.java:[line 56]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='1dcb461b43382e6885703323aca2f54c' rank='20' abbrev='RI' category='STYLE' priority='3' type='RI_REDUNDANT_INTERFACES' instanceOccurrenceMax='0'><ShortMessage>Class implements same interface as superclass</ShortMessage><LongMessage>Class org.apache.hadoop.mapreduce.lib.partition.KeyFieldBasedComparator implements same interface as superclass</LongMessage><Class classname='org.apache.hadoop.mapreduce.lib.partition.KeyFieldBasedComparator' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.lib.partition.KeyFieldBasedComparator' start='55' end='371' sourcepath='org/apache/hadoop/mapreduce/lib/partition/KeyFieldBasedComparator.java' sourcefile='KeyFieldBasedComparator.java'><Message>At KeyFieldBasedComparator.java:[lines 55-371]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.lib.partition.KeyFieldBasedComparator</Message></Class><Class role='INTERFACE_TYPE' classname='org.apache.hadoop.conf.Configurable'><SourceLine classname='org.apache.hadoop.conf.Configurable' sourcepath='org/apache/hadoop/conf/Configurable.java' sourcefile='Configurable.java'><Message>In Configurable.java</Message></SourceLine><Message>Interface org.apache.hadoop.conf.Configurable</Message></Class><SourceLine synthetic='true' classname='org.apache.hadoop.mapreduce.lib.partition.KeyFieldBasedComparator' start='55' end='371' sourcepath='org/apache/hadoop/mapreduce/lib/partition/KeyFieldBasedComparator.java' sourcefile='KeyFieldBasedComparator.java'><Message>At KeyFieldBasedComparator.java:[lines 55-371]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='cb98b3d22dc6acec65aa11226b51f2ee' rank='20' abbrev='Se' category='BAD_PRACTICE' priority='3' type='SE_COMPARATOR_SHOULD_BE_SERIALIZABLE' instanceOccurrenceMax='0'><ShortMessage>Comparator doesn't implement Serializable</ShortMessage><LongMessage>org.apache.hadoop.mapreduce.lib.partition.KeyFieldBasedComparator implements Comparator but not Serializable</LongMessage><Class classname='org.apache.hadoop.mapreduce.lib.partition.KeyFieldBasedComparator' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.lib.partition.KeyFieldBasedComparator' start='55' end='371' sourcepath='org/apache/hadoop/mapreduce/lib/partition/KeyFieldBasedComparator.java' sourcefile='KeyFieldBasedComparator.java'><Message>At KeyFieldBasedComparator.java:[lines 55-371]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.lib.partition.KeyFieldBasedComparator</Message></Class><SourceLine synthetic='true' classname='org.apache.hadoop.mapreduce.lib.partition.KeyFieldBasedComparator' start='55' end='371' sourcepath='org/apache/hadoop/mapreduce/lib/partition/KeyFieldBasedComparator.java' sourcefile='KeyFieldBasedComparator.java'><Message>At KeyFieldBasedComparator.java:[lines 55-371]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='396cf3f507450ab4f2ff7d36d46674d2' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.mapreduce.lib.partition.KeyFieldBasedPartitioner.PARTITIONER_OPTIONS isn't final but should be</LongMessage><Class classname='org.apache.hadoop.mapreduce.lib.partition.KeyFieldBasedPartitioner' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.lib.partition.KeyFieldBasedPartitioner' start='51' end='154' sourcepath='org/apache/hadoop/mapreduce/lib/partition/KeyFieldBasedPartitioner.java' sourcefile='KeyFieldBasedPartitioner.java'><Message>At KeyFieldBasedPartitioner.java:[lines 51-154]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.lib.partition.KeyFieldBasedPartitioner</Message></Class><Field isStatic='true' classname='org.apache.hadoop.mapreduce.lib.partition.KeyFieldBasedPartitioner' signature='Ljava/lang/String;' name='PARTITIONER_OPTIONS' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.lib.partition.KeyFieldBasedPartitioner' sourcepath='org/apache/hadoop/mapreduce/lib/partition/KeyFieldBasedPartitioner.java' sourcefile='KeyFieldBasedPartitioner.java'><Message>In KeyFieldBasedPartitioner.java</Message></SourceLine><Message>Field org.apache.hadoop.mapreduce.lib.partition.KeyFieldBasedPartitioner.PARTITIONER_OPTIONS</Message></Field><SourceLine endBytecode='13' classname='org.apache.hadoop.mapreduce.lib.partition.KeyFieldBasedPartitioner' start='56' end='56' sourcepath='org/apache/hadoop/mapreduce/lib/partition/KeyFieldBasedPartitioner.java' sourcefile='KeyFieldBasedPartitioner.java' startBytecode='13' primary='true'><Message>At KeyFieldBasedPartitioner.java:[line 56]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='f0b4c6114b515381b11e9e86af1a2e1d' rank='20' abbrev='UPM' category='PERFORMANCE' priority='3' type='UPM_UNCALLED_PRIVATE_METHOD' instanceOccurrenceMax='0'><ShortMessage>Private method is never called</ShortMessage><LongMessage>Private method org.apache.hadoop.mapreduce.lib.partition.KeyFieldHelper.printKey(KeyFieldHelper$KeyDescription) is never called</LongMessage><Class classname='org.apache.hadoop.mapreduce.lib.partition.KeyFieldHelper' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.lib.partition.KeyFieldHelper' start='41' end='295' sourcepath='org/apache/hadoop/mapreduce/lib/partition/KeyFieldHelper.java' sourcefile='KeyFieldHelper.java'><Message>At KeyFieldHelper.java:[lines 41-295]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.lib.partition.KeyFieldHelper</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapreduce.lib.partition.KeyFieldHelper' signature='(Lorg/apache/hadoop/mapreduce/lib/partition/KeyFieldHelper$KeyDescription;)V' name='printKey' primary='true'><SourceLine endBytecode='256' classname='org.apache.hadoop.mapreduce.lib.partition.KeyFieldHelper' start='288' end='295' sourcepath='org/apache/hadoop/mapreduce/lib/partition/KeyFieldHelper.java' sourcefile='KeyFieldHelper.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapreduce.lib.partition.KeyFieldHelper.printKey(KeyFieldHelper$KeyDescription)</Message></Method><SourceLine synthetic='true' endBytecode='256' classname='org.apache.hadoop.mapreduce.lib.partition.KeyFieldHelper' start='288' end='295' sourcepath='org/apache/hadoop/mapreduce/lib/partition/KeyFieldHelper.java' sourcefile='KeyFieldHelper.java' startBytecode='0'><Message>At KeyFieldHelper.java:[lines 288-295]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='94bfc9ed424077954183042b7cfb08e5' rank='20' abbrev='UwF' category='STYLE' priority='3' type='UWF_FIELD_NOT_INITIALIZED_IN_CONSTRUCTOR' instanceOccurrenceMax='0'><ShortMessage>Field not initialized in constructor but dereferenced without null check</ShortMessage><LongMessage>KeyFieldHelper.keyFieldSeparator not initialized in constructor and dereferenced in org.apache.hadoop.mapreduce.lib.partition.KeyFieldHelper.getEndOffset(byte[], int, int, int[], KeyFieldHelper$KeyDescription)</LongMessage><Class classname='org.apache.hadoop.mapreduce.lib.partition.KeyFieldHelper' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.lib.partition.KeyFieldHelper' start='41' end='295' sourcepath='org/apache/hadoop/mapreduce/lib/partition/KeyFieldHelper.java' sourcefile='KeyFieldHelper.java'><Message>At KeyFieldHelper.java:[lines 41-295]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.lib.partition.KeyFieldHelper</Message></Class><Field isStatic='false' classname='org.apache.hadoop.mapreduce.lib.partition.KeyFieldHelper' signature='[B' name='keyFieldSeparator' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.lib.partition.KeyFieldHelper' sourcepath='org/apache/hadoop/mapreduce/lib/partition/KeyFieldHelper.java' sourcefile='KeyFieldHelper.java'><Message>In KeyFieldHelper.java</Message></SourceLine><Message>Field org.apache.hadoop.mapreduce.lib.partition.KeyFieldHelper.keyFieldSeparator</Message></Field><Method isStatic='false' classname='org.apache.hadoop.mapreduce.lib.partition.KeyFieldHelper' signature='([BII[ILorg/apache/hadoop/mapreduce/lib/partition/KeyFieldHelper$KeyDescription;)I' name='getEndOffset' primary='true'><SourceLine endBytecode='294' classname='org.apache.hadoop.mapreduce.lib.partition.KeyFieldHelper' start='137' end='156' sourcepath='org/apache/hadoop/mapreduce/lib/partition/KeyFieldHelper.java' sourcefile='KeyFieldHelper.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapreduce.lib.partition.KeyFieldHelper.getEndOffset(byte[], int, int, int[], KeyFieldHelper$KeyDescription)</Message></Method><SourceLine endBytecode='51' classname='org.apache.hadoop.mapreduce.lib.partition.KeyFieldHelper' start='146' end='146' sourcepath='org/apache/hadoop/mapreduce/lib/partition/KeyFieldHelper.java' sourcefile='KeyFieldHelper.java' startBytecode='51' primary='true'><Message>At KeyFieldHelper.java:[line 146]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='e108ad3a288900e2e638b10f2603545b' rank='20' abbrev='UwF' category='STYLE' priority='3' type='UWF_FIELD_NOT_INITIALIZED_IN_CONSTRUCTOR' instanceOccurrenceMax='0'><ShortMessage>Field not initialized in constructor but dereferenced without null check</ShortMessage><LongMessage>KeyFieldHelper.keyFieldSeparator not initialized in constructor and dereferenced in org.apache.hadoop.mapreduce.lib.partition.KeyFieldHelper.getStartOffset(byte[], int, int, int[], KeyFieldHelper$KeyDescription)</LongMessage><Class classname='org.apache.hadoop.mapreduce.lib.partition.KeyFieldHelper' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.lib.partition.KeyFieldHelper' start='41' end='295' sourcepath='org/apache/hadoop/mapreduce/lib/partition/KeyFieldHelper.java' sourcefile='KeyFieldHelper.java'><Message>At KeyFieldHelper.java:[lines 41-295]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.lib.partition.KeyFieldHelper</Message></Class><Field isStatic='false' classname='org.apache.hadoop.mapreduce.lib.partition.KeyFieldHelper' signature='[B' name='keyFieldSeparator' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.lib.partition.KeyFieldHelper' sourcepath='org/apache/hadoop/mapreduce/lib/partition/KeyFieldHelper.java' sourcefile='KeyFieldHelper.java'><Message>In KeyFieldHelper.java</Message></SourceLine><Message>Field org.apache.hadoop.mapreduce.lib.partition.KeyFieldHelper.keyFieldSeparator</Message></Field><Method isStatic='false' classname='org.apache.hadoop.mapreduce.lib.partition.KeyFieldHelper' signature='([BII[ILorg/apache/hadoop/mapreduce/lib/partition/KeyFieldHelper$KeyDescription;)I' name='getStartOffset' primary='true'><SourceLine endBytecode='237' classname='org.apache.hadoop.mapreduce.lib.partition.KeyFieldHelper' start='122' end='131' sourcepath='org/apache/hadoop/mapreduce/lib/partition/KeyFieldHelper.java' sourcefile='KeyFieldHelper.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapreduce.lib.partition.KeyFieldHelper.getStartOffset(byte[], int, int, int[], KeyFieldHelper$KeyDescription)</Message></Method><SourceLine endBytecode='39' classname='org.apache.hadoop.mapreduce.lib.partition.KeyFieldHelper' start='125' end='125' sourcepath='org/apache/hadoop/mapreduce/lib/partition/KeyFieldHelper.java' sourcefile='KeyFieldHelper.java' startBytecode='39' primary='true'><Message>At KeyFieldHelper.java:[line 125]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='a98786ce9fc5d32b19a8659ed8240780' rank='19' abbrev='Nm' category='BAD_PRACTICE' priority='3' type='NM_METHOD_NAMING_CONVENTION' instanceOccurrenceMax='0'><ShortMessage>Method names should start with a lower case letter</ShortMessage><LongMessage>The method name org.apache.hadoop.mapreduce.lib.partition.TotalOrderPartitioner.LeafTrieNodeFactory(int, BinaryComparable[], int, int) doesn't start with a lower case letter</LongMessage><Class classname='org.apache.hadoop.mapreduce.lib.partition.TotalOrderPartitioner' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.lib.partition.TotalOrderPartitioner' start='62' end='411' sourcepath='org/apache/hadoop/mapreduce/lib/partition/TotalOrderPartitioner.java' sourcefile='TotalOrderPartitioner.java'><Message>At TotalOrderPartitioner.java:[lines 62-411]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.lib.partition.TotalOrderPartitioner</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapreduce.lib.partition.TotalOrderPartitioner' signature='(I[Lorg/apache/hadoop/io/BinaryComparable;II)Lorg/apache/hadoop/mapreduce/lib/partition/TotalOrderPartitioner$TrieNode;' name='LeafTrieNodeFactory' primary='true'><SourceLine endBytecode='191' classname='org.apache.hadoop.mapreduce.lib.partition.TotalOrderPartitioner' start='226' end='234' sourcepath='org/apache/hadoop/mapreduce/lib/partition/TotalOrderPartitioner.java' sourcefile='TotalOrderPartitioner.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapreduce.lib.partition.TotalOrderPartitioner.LeafTrieNodeFactory(int, BinaryComparable[], int, int)</Message></Method><SourceLine synthetic='true' endBytecode='191' classname='org.apache.hadoop.mapreduce.lib.partition.TotalOrderPartitioner' start='226' end='234' sourcepath='org/apache/hadoop/mapreduce/lib/partition/TotalOrderPartitioner.java' sourcefile='TotalOrderPartitioner.java' startBytecode='0'><Message>At TotalOrderPartitioner.java:[lines 226-234]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='a4345379af41c4f3d31019fa0520a40e' rank='20' abbrev='PZLA' category='STYLE' priority='3' type='PZLA_PREFER_ZERO_LENGTH_ARRAYS' instanceOccurrenceMax='0'><ShortMessage>Consider returning a zero length array rather than null</ShortMessage><LongMessage>Should org.apache.hadoop.mapreduce.security.TokenCache.getSecretKey(Credentials, Text) return a zero length array rather than null?</LongMessage><Class classname='org.apache.hadoop.mapreduce.security.TokenCache' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.security.TokenCache' start='52' end='272' sourcepath='org/apache/hadoop/mapreduce/security/TokenCache.java' sourcefile='TokenCache.java'><Message>At TokenCache.java:[lines 52-272]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.security.TokenCache</Message></Class><Method isStatic='true' classname='org.apache.hadoop.mapreduce.security.TokenCache' signature='(Lorg/apache/hadoop/security/Credentials;Lorg/apache/hadoop/io/Text;)[B' name='getSecretKey' primary='true'><SourceLine endBytecode='80' classname='org.apache.hadoop.mapreduce.security.TokenCache' start='63' end='65' sourcepath='org/apache/hadoop/mapreduce/security/TokenCache.java' sourcefile='TokenCache.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapreduce.security.TokenCache.getSecretKey(Credentials, Text)</Message></Method><SourceLine endBytecode='5' classname='org.apache.hadoop.mapreduce.security.TokenCache' start='64' end='64' sourcepath='org/apache/hadoop/mapreduce/security/TokenCache.java' sourcefile='TokenCache.java' startBytecode='5' primary='true'><Message>At TokenCache.java:[line 64]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='d09b23b4bd77df7954159041e6746440' cweid='374' rank='18' abbrev='EI' category='MALICIOUS_CODE' priority='2' type='EI_EXPOSE_REP' instanceOccurrenceMax='0'><ShortMessage>May expose internal representation by returning reference to mutable object</ShortMessage><LongMessage>org.apache.hadoop.mapreduce.split.JobSplit$SplitMetaInfo.getLocations() may expose internal representation by returning JobSplit$SplitMetaInfo.locations</LongMessage><Class classname='org.apache.hadoop.mapreduce.split.JobSplit$SplitMetaInfo' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.split.JobSplit$SplitMetaInfo' start='73' end='140' sourcepath='org/apache/hadoop/mapreduce/split/JobSplit.java' sourcefile='JobSplit.java'><Message>At JobSplit.java:[lines 73-140]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.split.JobSplit$SplitMetaInfo</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapreduce.split.JobSplit$SplitMetaInfo' signature='()[Ljava/lang/String;' name='getLocations' primary='true'><SourceLine endBytecode='46' classname='org.apache.hadoop.mapreduce.split.JobSplit$SplitMetaInfo' start='93' end='93' sourcepath='org/apache/hadoop/mapreduce/split/JobSplit.java' sourcefile='JobSplit.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapreduce.split.JobSplit$SplitMetaInfo.getLocations()</Message></Method><Field isStatic='false' classname='org.apache.hadoop.mapreduce.split.JobSplit$SplitMetaInfo' signature='[Ljava/lang/String;' name='locations' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.split.JobSplit$SplitMetaInfo' sourcepath='org/apache/hadoop/mapreduce/split/JobSplit.java' sourcefile='JobSplit.java'><Message>In JobSplit.java</Message></SourceLine><Message>Field org.apache.hadoop.mapreduce.split.JobSplit$SplitMetaInfo.locations</Message></Field><SourceLine endBytecode='4' classname='org.apache.hadoop.mapreduce.split.JobSplit$SplitMetaInfo' start='93' end='93' sourcepath='org/apache/hadoop/mapreduce/split/JobSplit.java' sourcefile='JobSplit.java' startBytecode='4' primary='true'><Message>At JobSplit.java:[line 93]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='699391fa03a00dccf08d7948bb4bfc92' cweid='374' rank='18' abbrev='EI2' category='MALICIOUS_CODE' priority='2' type='EI_EXPOSE_REP2' instanceOccurrenceMax='0'><ShortMessage>May expose internal representation by incorporating reference to mutable object</ShortMessage><LongMessage>new org.apache.hadoop.mapreduce.split.JobSplit$SplitMetaInfo(String[], long, long) may expose internal representation by storing an externally mutable object into JobSplit$SplitMetaInfo.locations</LongMessage><Class classname='org.apache.hadoop.mapreduce.split.JobSplit$SplitMetaInfo' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.split.JobSplit$SplitMetaInfo' start='73' end='140' sourcepath='org/apache/hadoop/mapreduce/split/JobSplit.java' sourcefile='JobSplit.java'><Message>At JobSplit.java:[lines 73-140]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.split.JobSplit$SplitMetaInfo</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapreduce.split.JobSplit$SplitMetaInfo' signature='([Ljava/lang/String;JJ)V' name='&lt;init&gt;' primary='true'><SourceLine endBytecode='108' classname='org.apache.hadoop.mapreduce.split.JobSplit$SplitMetaInfo' start='76' end='80' sourcepath='org/apache/hadoop/mapreduce/split/JobSplit.java' sourcefile='JobSplit.java' startBytecode='0'></SourceLine><Message>In method new org.apache.hadoop.mapreduce.split.JobSplit$SplitMetaInfo(String[], long, long)</Message></Method><Field isStatic='false' classname='org.apache.hadoop.mapreduce.split.JobSplit$SplitMetaInfo' signature='[Ljava/lang/String;' name='locations' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.split.JobSplit$SplitMetaInfo' sourcepath='org/apache/hadoop/mapreduce/split/JobSplit.java' sourcefile='JobSplit.java'><Message>In JobSplit.java</Message></SourceLine><Message>Field org.apache.hadoop.mapreduce.split.JobSplit$SplitMetaInfo.locations</Message></Field><LocalVariable role='LOCAL_VARIABLE_NAMED' pc='6' name='locations' register='1'><Message>Local variable named locations</Message></LocalVariable><SourceLine endBytecode='6' classname='org.apache.hadoop.mapreduce.split.JobSplit$SplitMetaInfo' start='77' end='77' sourcepath='org/apache/hadoop/mapreduce/split/JobSplit.java' sourcefile='JobSplit.java' startBytecode='6' primary='true'><Message>At JobSplit.java:[line 77]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='91322606b80b61e91358c8bf866959c' cweid='374' rank='18' abbrev='EI2' category='MALICIOUS_CODE' priority='2' type='EI_EXPOSE_REP2' instanceOccurrenceMax='0'><ShortMessage>May expose internal representation by incorporating reference to mutable object</ShortMessage><LongMessage>org.apache.hadoop.mapreduce.split.JobSplit$SplitMetaInfo.setInputDataLocations(String[]) may expose internal representation by storing an externally mutable object into JobSplit$SplitMetaInfo.locations</LongMessage><Class classname='org.apache.hadoop.mapreduce.split.JobSplit$SplitMetaInfo' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.split.JobSplit$SplitMetaInfo' start='73' end='140' sourcepath='org/apache/hadoop/mapreduce/split/JobSplit.java' sourcefile='JobSplit.java'><Message>At JobSplit.java:[lines 73-140]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.split.JobSplit$SplitMetaInfo</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapreduce.split.JobSplit$SplitMetaInfo' signature='([Ljava/lang/String;)V' name='setInputDataLocations' primary='true'><SourceLine endBytecode='61' classname='org.apache.hadoop.mapreduce.split.JobSplit$SplitMetaInfo' start='105' end='106' sourcepath='org/apache/hadoop/mapreduce/split/JobSplit.java' sourcefile='JobSplit.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapreduce.split.JobSplit$SplitMetaInfo.setInputDataLocations(String[])</Message></Method><Field isStatic='false' classname='org.apache.hadoop.mapreduce.split.JobSplit$SplitMetaInfo' signature='[Ljava/lang/String;' name='locations' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.split.JobSplit$SplitMetaInfo' sourcepath='org/apache/hadoop/mapreduce/split/JobSplit.java' sourcefile='JobSplit.java'><Message>In JobSplit.java</Message></SourceLine><Message>Field org.apache.hadoop.mapreduce.split.JobSplit$SplitMetaInfo.locations</Message></Field><LocalVariable role='LOCAL_VARIABLE_NAMED' pc='2' name='locations' register='1'><Message>Local variable named locations</Message></LocalVariable><SourceLine endBytecode='2' classname='org.apache.hadoop.mapreduce.split.JobSplit$SplitMetaInfo' start='105' end='105' sourcepath='org/apache/hadoop/mapreduce/split/JobSplit.java' sourcefile='JobSplit.java' startBytecode='2' primary='true'><Message>At JobSplit.java:[line 105]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='ae3ec7a7a80661ade62c754e0bc49cc0' cweid='374' rank='18' abbrev='EI' category='MALICIOUS_CODE' priority='2' type='EI_EXPOSE_REP' instanceOccurrenceMax='0'><ShortMessage>May expose internal representation by returning reference to mutable object</ShortMessage><LongMessage>org.apache.hadoop.mapreduce.split.JobSplit$TaskSplitMetaInfo.getLocations() may expose internal representation by returning JobSplit$TaskSplitMetaInfo.locations</LongMessage><Class classname='org.apache.hadoop.mapreduce.split.JobSplit$TaskSplitMetaInfo' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.split.JobSplit$TaskSplitMetaInfo' start='151' end='186' sourcepath='org/apache/hadoop/mapreduce/split/JobSplit.java' sourcefile='JobSplit.java'><Message>At JobSplit.java:[lines 151-186]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.split.JobSplit$TaskSplitMetaInfo</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapreduce.split.JobSplit$TaskSplitMetaInfo' signature='()[Ljava/lang/String;' name='getLocations' primary='true'><SourceLine endBytecode='46' classname='org.apache.hadoop.mapreduce.split.JobSplit$TaskSplitMetaInfo' start='183' end='183' sourcepath='org/apache/hadoop/mapreduce/split/JobSplit.java' sourcefile='JobSplit.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapreduce.split.JobSplit$TaskSplitMetaInfo.getLocations()</Message></Method><Field isStatic='false' classname='org.apache.hadoop.mapreduce.split.JobSplit$TaskSplitMetaInfo' signature='[Ljava/lang/String;' name='locations' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.split.JobSplit$TaskSplitMetaInfo' sourcepath='org/apache/hadoop/mapreduce/split/JobSplit.java' sourcefile='JobSplit.java'><Message>In JobSplit.java</Message></SourceLine><Message>Field org.apache.hadoop.mapreduce.split.JobSplit$TaskSplitMetaInfo.locations</Message></Field><SourceLine endBytecode='4' classname='org.apache.hadoop.mapreduce.split.JobSplit$TaskSplitMetaInfo' start='183' end='183' sourcepath='org/apache/hadoop/mapreduce/split/JobSplit.java' sourcefile='JobSplit.java' startBytecode='4' primary='true'><Message>At JobSplit.java:[line 183]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='af6fb06e35aa81e152389411f167babd' cweid='374' rank='18' abbrev='EI2' category='MALICIOUS_CODE' priority='2' type='EI_EXPOSE_REP2' instanceOccurrenceMax='0'><ShortMessage>May expose internal representation by incorporating reference to mutable object</ShortMessage><LongMessage>new org.apache.hadoop.mapreduce.split.JobSplit$TaskSplitMetaInfo(JobSplit$TaskSplitIndex, String[], long) may expose internal representation by storing an externally mutable object into JobSplit$TaskSplitMetaInfo.locations</LongMessage><Class classname='org.apache.hadoop.mapreduce.split.JobSplit$TaskSplitMetaInfo' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.split.JobSplit$TaskSplitMetaInfo' start='151' end='186' sourcepath='org/apache/hadoop/mapreduce/split/JobSplit.java' sourcefile='JobSplit.java'><Message>At JobSplit.java:[lines 151-186]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.split.JobSplit$TaskSplitMetaInfo</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapreduce.split.JobSplit$TaskSplitMetaInfo' signature='(Lorg/apache/hadoop/mapreduce/split/JobSplit$TaskSplitIndex;[Ljava/lang/String;J)V' name='&lt;init&gt;' primary='true'><SourceLine endBytecode='107' classname='org.apache.hadoop.mapreduce.split.JobSplit$TaskSplitMetaInfo' start='156' end='160' sourcepath='org/apache/hadoop/mapreduce/split/JobSplit.java' sourcefile='JobSplit.java' startBytecode='0'></SourceLine><Message>In method new org.apache.hadoop.mapreduce.split.JobSplit$TaskSplitMetaInfo(JobSplit$TaskSplitIndex, String[], long)</Message></Method><Field isStatic='false' classname='org.apache.hadoop.mapreduce.split.JobSplit$TaskSplitMetaInfo' signature='[Ljava/lang/String;' name='locations' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.split.JobSplit$TaskSplitMetaInfo' sourcepath='org/apache/hadoop/mapreduce/split/JobSplit.java' sourcefile='JobSplit.java'><Message>In JobSplit.java</Message></SourceLine><Message>Field org.apache.hadoop.mapreduce.split.JobSplit$TaskSplitMetaInfo.locations</Message></Field><LocalVariable role='LOCAL_VARIABLE_NAMED' pc='11' name='locations' register='2'><Message>Local variable named locations</Message></LocalVariable><SourceLine endBytecode='11' classname='org.apache.hadoop.mapreduce.split.JobSplit$TaskSplitMetaInfo' start='158' end='158' sourcepath='org/apache/hadoop/mapreduce/split/JobSplit.java' sourcefile='JobSplit.java' startBytecode='11' primary='true'><Message>At JobSplit.java:[line 158]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='c275b72f62559bf2beaf7a634865dc9b' rank='20' abbrev='PZLA' category='STYLE' priority='3' type='PZLA_PREFER_ZERO_LENGTH_ARRAYS' instanceOccurrenceMax='0'><ShortMessage>Consider returning a zero length array rather than null</ShortMessage><LongMessage>Should org.apache.hadoop.mapreduce.task.JobContextImpl.toTimestampStrs(long[]) return a zero length array rather than null?</LongMessage><Class classname='org.apache.hadoop.mapreduce.task.JobContextImpl' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.task.JobContextImpl' start='63' end='461' sourcepath='org/apache/hadoop/mapreduce/task/JobContextImpl.java' sourcefile='JobContextImpl.java'><Message>At JobContextImpl.java:[lines 63-461]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.task.JobContextImpl</Message></Class><Method isStatic='true' classname='org.apache.hadoop.mapreduce.task.JobContextImpl' signature='([J)[Ljava/lang/String;' name='toTimestampStrs' primary='true'><SourceLine endBytecode='141' classname='org.apache.hadoop.mapreduce.task.JobContextImpl' start='363' end='370' sourcepath='org/apache/hadoop/mapreduce/task/JobContextImpl.java' sourcefile='JobContextImpl.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapreduce.task.JobContextImpl.toTimestampStrs(long[])</Message></Method><SourceLine endBytecode='5' classname='org.apache.hadoop.mapreduce.task.JobContextImpl' start='364' end='364' sourcepath='org/apache/hadoop/mapreduce/task/JobContextImpl.java' sourcefile='JobContextImpl.java' startBytecode='5' primary='true'><Message>At JobContextImpl.java:[line 364]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='f1e25174fa17bfc215348d011debe7b9' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from org.apache.hadoop.mapreduce.TaskAttemptID to org.apache.hadoop.mapred.TaskAttemptID in org.apache.hadoop.mapreduce.task.reduce.EventFetcher.getMapCompletionEvents()</LongMessage><Class classname='org.apache.hadoop.mapreduce.task.reduce.EventFetcher' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.task.reduce.EventFetcher' start='29' end='149' sourcepath='org/apache/hadoop/mapreduce/task/reduce/EventFetcher.java' sourcefile='EventFetcher.java'><Message>At EventFetcher.java:[lines 29-149]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.task.reduce.EventFetcher</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapreduce.task.reduce.EventFetcher' signature='()I' name='getMapCompletionEvents' primary='true'><SourceLine endBytecode='86' classname='org.apache.hadoop.mapreduce.task.reduce.EventFetcher' start='116' end='149' sourcepath='org/apache/hadoop/mapreduce/task/reduce/EventFetcher.java' sourcefile='EventFetcher.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapreduce.task.reduce.EventFetcher.getMapCompletionEvents()</Message></Method><Type role='TYPE_FOUND' descriptor='Lorg/apache/hadoop/mapreduce/TaskAttemptID;'><SourceLine classname='org.apache.hadoop.mapreduce.TaskAttemptID' start='48' end='201' sourcepath='org/apache/hadoop/mapreduce/TaskAttemptID.java' sourcefile='TaskAttemptID.java'><Message>At TaskAttemptID.java:[lines 48-201]</Message></SourceLine><Message>Actual type org.apache.hadoop.mapreduce.TaskAttemptID</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/mapred/TaskAttemptID;'><SourceLine classname='org.apache.hadoop.mapred.TaskAttemptID' start='48' end='193' sourcepath='org/apache/hadoop/mapred/TaskAttemptID.java' sourcefile='TaskAttemptID.java'><Message>At TaskAttemptID.java:[lines 48-193]</Message></SourceLine><Message>Expected org.apache.hadoop.mapred.TaskAttemptID</Message></Type><Field isStatic='false' role='FIELD_VALUE_OF' classname='org.apache.hadoop.mapreduce.task.reduce.EventFetcher' signature='Lorg/apache/hadoop/mapreduce/TaskAttemptID;' name='reduce' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.task.reduce.EventFetcher' sourcepath='org/apache/hadoop/mapreduce/task/reduce/EventFetcher.java' sourcefile='EventFetcher.java'><Message>In EventFetcher.java</Message></SourceLine><Message>Value loaded from field org.apache.hadoop.mapreduce.task.reduce.EventFetcher.reduce</Message></Field><SourceLine endBytecode='30' classname='org.apache.hadoop.mapreduce.task.reduce.EventFetcher' start='122' end='122' sourcepath='org/apache/hadoop/mapreduce/task/reduce/EventFetcher.java' sourcefile='EventFetcher.java' startBytecode='30' primary='true'><Message>At EventFetcher.java:[line 122]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='ece5c98393b16c677072a8ba8036a3c8' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST_OF_RETURN_VALUE' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast of return value from method</ShortMessage><LongMessage>Unchecked/unconfirmed cast from org.apache.hadoop.mapreduce.JobID to org.apache.hadoop.mapred.JobID of return value in org.apache.hadoop.mapreduce.task.reduce.EventFetcher.getMapCompletionEvents()</LongMessage><Class classname='org.apache.hadoop.mapreduce.task.reduce.EventFetcher' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.task.reduce.EventFetcher' start='29' end='149' sourcepath='org/apache/hadoop/mapreduce/task/reduce/EventFetcher.java' sourcefile='EventFetcher.java'><Message>At EventFetcher.java:[lines 29-149]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.task.reduce.EventFetcher</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapreduce.task.reduce.EventFetcher' signature='()I' name='getMapCompletionEvents' primary='true'><SourceLine endBytecode='86' classname='org.apache.hadoop.mapreduce.task.reduce.EventFetcher' start='116' end='149' sourcepath='org/apache/hadoop/mapreduce/task/reduce/EventFetcher.java' sourcefile='EventFetcher.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapreduce.task.reduce.EventFetcher.getMapCompletionEvents()</Message></Method><Type role='TYPE_FOUND' descriptor='Lorg/apache/hadoop/mapreduce/JobID;'><SourceLine classname='org.apache.hadoop.mapreduce.JobID' start='47' end='156' sourcepath='org/apache/hadoop/mapreduce/JobID.java' sourcefile='JobID.java'><Message>At JobID.java:[lines 47-156]</Message></SourceLine><Message>Actual type org.apache.hadoop.mapreduce.JobID</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/mapred/JobID;'><SourceLine classname='org.apache.hadoop.mapred.JobID' start='53' end='118' sourcepath='org/apache/hadoop/mapred/JobID.java' sourcefile='JobID.java'><Message>At JobID.java:[lines 53-118]</Message></SourceLine><Message>Expected org.apache.hadoop.mapred.JobID</Message></Type><SourceLine endBytecode='15' classname='org.apache.hadoop.mapreduce.task.reduce.EventFetcher' start='122' end='122' sourcepath='org/apache/hadoop/mapreduce/task/reduce/EventFetcher.java' sourcefile='EventFetcher.java' startBytecode='15' primary='true'><Message>At EventFetcher.java:[line 122]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='412b855213e5b1e0334375beb19f1af1' rank='20' abbrev='PZLA' category='STYLE' priority='3' type='PZLA_PREFER_ZERO_LENGTH_ARRAYS' instanceOccurrenceMax='0'><ShortMessage>Consider returning a zero length array rather than null</ShortMessage><LongMessage>Should org.apache.hadoop.mapreduce.task.reduce.Fetcher.copyMapOutput(MapHost, DataInputStream, Set, boolean) return a zero length array rather than null?</LongMessage><Class classname='org.apache.hadoop.mapreduce.task.reduce.Fetcher' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.task.reduce.Fetcher' start='57' end='749' sourcepath='org/apache/hadoop/mapreduce/task/reduce/Fetcher.java' sourcefile='Fetcher.java'><Message>At Fetcher.java:[lines 57-749]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.task.reduce.Fetcher</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapreduce.task.reduce.Fetcher' signature='(Lorg/apache/hadoop/mapreduce/task/reduce/MapHost;Ljava/io/DataInputStream;Ljava/util/Set;Z)[Lorg/apache/hadoop/mapreduce/TaskAttemptID;' name='copyMapOutput' primary='true'><SourceLine endBytecode='1398' classname='org.apache.hadoop.mapreduce.task.reduce.Fetcher' start='491' end='599' sourcepath='org/apache/hadoop/mapreduce/task/reduce/Fetcher.java' sourcefile='Fetcher.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapreduce.task.reduce.Fetcher.copyMapOutput(MapHost, DataInputStream, Set, boolean)</Message></Method><SourceLine endBytecode='518' classname='org.apache.hadoop.mapreduce.task.reduce.Fetcher' start='572' end='572' sourcepath='org/apache/hadoop/mapreduce/task/reduce/Fetcher.java' sourcefile='Fetcher.java' startBytecode='518' primary='true'><Message>At Fetcher.java:[line 572]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='949f6eb656240785f3e4ed4efc1c0ce3' rank='20' abbrev='ST' category='STYLE' priority='3' type='ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD' instanceOccurrenceMax='0'><ShortMessage>Write to static field from instance method</ShortMessage><LongMessage>Write to static field org.apache.hadoop.mapreduce.task.reduce.Fetcher.nextId from instance method new org.apache.hadoop.mapreduce.task.reduce.Fetcher(JobConf, TaskAttemptID, ShuffleSchedulerImpl, MergeManager, Reporter, ShuffleClientMetrics, ExceptionReporter, SecretKey)</LongMessage><Class classname='org.apache.hadoop.mapreduce.task.reduce.Fetcher' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.task.reduce.Fetcher' start='57' end='749' sourcepath='org/apache/hadoop/mapreduce/task/reduce/Fetcher.java' sourcefile='Fetcher.java'><Message>At Fetcher.java:[lines 57-749]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.task.reduce.Fetcher</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapreduce.task.reduce.Fetcher' signature='(Lorg/apache/hadoop/mapred/JobConf;Lorg/apache/hadoop/mapreduce/TaskAttemptID;Lorg/apache/hadoop/mapreduce/task/reduce/ShuffleSchedulerImpl;Lorg/apache/hadoop/mapreduce/task/reduce/MergeManager;Lorg/apache/hadoop/mapred/Reporter;Lorg/apache/hadoop/mapreduce/task/reduce/ShuffleClientMetrics;Lorg/apache/hadoop/mapreduce/task/reduce/ExceptionReporter;Ljavax/crypto/SecretKey;)V' name='&lt;init&gt;' primary='true'><SourceLine endBytecode='190' classname='org.apache.hadoop.mapreduce.task.reduce.Fetcher' start='116' end='118' sourcepath='org/apache/hadoop/mapreduce/task/reduce/Fetcher.java' sourcefile='Fetcher.java' startBytecode='0'></SourceLine><Message>In method new org.apache.hadoop.mapreduce.task.reduce.Fetcher(JobConf, TaskAttemptID, ShuffleSchedulerImpl, MergeManager, Reporter, ShuffleClientMetrics, ExceptionReporter, SecretKey)</Message></Method><Field isStatic='true' classname='org.apache.hadoop.mapreduce.task.reduce.Fetcher' signature='I' name='nextId' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.task.reduce.Fetcher' sourcepath='org/apache/hadoop/mapreduce/task/reduce/Fetcher.java' sourcefile='Fetcher.java'><Message>In Fetcher.java</Message></SourceLine><Message>Field org.apache.hadoop.mapreduce.task.reduce.Fetcher.nextId</Message></Field><SourceLine endBytecode='20' classname='org.apache.hadoop.mapreduce.task.reduce.Fetcher' start='116' end='116' sourcepath='org/apache/hadoop/mapreduce/task/reduce/Fetcher.java' sourcefile='Fetcher.java' startBytecode='20' primary='true'><Message>At Fetcher.java:[line 116]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='853b9afcbd02a232d6de70dac117c97d' cweid='374' rank='18' abbrev='EI2' category='MALICIOUS_CODE' priority='2' type='EI_EXPOSE_REP2' instanceOccurrenceMax='0'><ShortMessage>May expose internal representation by incorporating reference to mutable object</ShortMessage><LongMessage>new org.apache.hadoop.mapreduce.task.reduce.InMemoryReader(MergeManagerImpl, TaskAttemptID, byte[], int, int, Configuration) may expose internal representation by storing an externally mutable object into InMemoryReader.buffer</LongMessage><Class classname='org.apache.hadoop.mapreduce.task.reduce.InMemoryReader' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.task.reduce.InMemoryReader' start='40' end='146' sourcepath='org/apache/hadoop/mapreduce/task/reduce/InMemoryReader.java' sourcefile='InMemoryReader.java'><Message>At InMemoryReader.java:[lines 40-146]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.task.reduce.InMemoryReader</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapreduce.task.reduce.InMemoryReader' signature='(Lorg/apache/hadoop/mapreduce/task/reduce/MergeManagerImpl;Lorg/apache/hadoop/mapreduce/TaskAttemptID;[BIILorg/apache/hadoop/conf/Configuration;)V' name='&lt;init&gt;' primary='true'><SourceLine endBytecode='246' classname='org.apache.hadoop.mapreduce.task.reduce.InMemoryReader' start='47' end='56' sourcepath='org/apache/hadoop/mapreduce/task/reduce/InMemoryReader.java' sourcefile='InMemoryReader.java' startBytecode='0'></SourceLine><Message>In method new org.apache.hadoop.mapreduce.task.reduce.InMemoryReader(MergeManagerImpl, TaskAttemptID, byte[], int, int, Configuration)</Message></Method><Field isStatic='false' classname='org.apache.hadoop.mapreduce.task.reduce.InMemoryReader' signature='[B' name='buffer' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.task.reduce.InMemoryReader' sourcepath='org/apache/hadoop/mapreduce/task/reduce/InMemoryReader.java' sourcefile='InMemoryReader.java'><Message>In InMemoryReader.java</Message></SourceLine><Message>Field org.apache.hadoop.mapreduce.task.reduce.InMemoryReader.buffer</Message></Field><LocalVariable role='LOCAL_VARIABLE_NAMED' pc='38' name='data' register='3'><Message>Local variable named data</Message></LocalVariable><SourceLine endBytecode='38' classname='org.apache.hadoop.mapreduce.task.reduce.InMemoryReader' start='51' end='51' sourcepath='org/apache/hadoop/mapreduce/task/reduce/InMemoryReader.java' sourcefile='InMemoryReader.java' startBytecode='38' primary='true'><Message>At InMemoryReader.java:[line 51]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='38d6ec7521e2c381e5e9621d92f1b224' cweid='366' rank='20' abbrev='IS' category='MT_CORRECTNESS' priority='3' type='IS2_INCONSISTENT_SYNC' instanceOccurrenceMax='0'><ShortMessage>Inconsistent synchronization</ShortMessage><LongMessage>Inconsistent synchronization of org.apache.hadoop.mapreduce.task.reduce.MapHost.state; locked 87% of time</LongMessage><Class classname='org.apache.hadoop.mapreduce.task.reduce.MapHost' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.task.reduce.MapHost' start='39' end='105' sourcepath='org/apache/hadoop/mapreduce/task/reduce/MapHost.java' sourcefile='MapHost.java'><Message>At MapHost.java:[lines 39-105]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.task.reduce.MapHost</Message></Class><Field isStatic='false' classname='org.apache.hadoop.mapreduce.task.reduce.MapHost' signature='Lorg/apache/hadoop/mapreduce/task/reduce/MapHost$State;' name='state' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.task.reduce.MapHost' sourcepath='org/apache/hadoop/mapreduce/task/reduce/MapHost.java' sourcefile='MapHost.java'><Message>In MapHost.java</Message></SourceLine><Message>Field org.apache.hadoop.mapreduce.task.reduce.MapHost.state</Message></Field><Int role='INT_SYNC_PERCENT' value='87'><Message>Synchronized 87% of the time</Message></Int><SourceLine role='SOURCE_LINE_UNSYNC_ACCESS' endBytecode='1' classname='org.apache.hadoop.mapreduce.task.reduce.MapHost' start='50' end='50' sourcepath='org/apache/hadoop/mapreduce/task/reduce/MapHost.java' sourcefile='MapHost.java' startBytecode='1' primary='true'><Message>Unsynchronized access at MapHost.java:[line 50]</Message></SourceLine><SourceLine role='SOURCE_LINE_SYNC_ACCESS' endBytecode='4' classname='org.apache.hadoop.mapreduce.task.reduce.MapHost' start='104' end='104' sourcepath='org/apache/hadoop/mapreduce/task/reduce/MapHost.java' sourcefile='MapHost.java' startBytecode='4'><Message>Synchronized access at MapHost.java:[line 104]</Message></SourceLine><SourceLine role='SOURCE_LINE_SYNC_ACCESS' endBytecode='4' classname='org.apache.hadoop.mapreduce.task.reduce.MapHost' start='75' end='75' sourcepath='org/apache/hadoop/mapreduce/task/reduce/MapHost.java' sourcefile='MapHost.java' startBytecode='4'><Message>Synchronized access at MapHost.java:[line 75]</Message></SourceLine><SourceLine role='SOURCE_LINE_SYNC_ACCESS' endBytecode='12' classname='org.apache.hadoop.mapreduce.task.reduce.MapHost' start='63' end='63' sourcepath='org/apache/hadoop/mapreduce/task/reduce/MapHost.java' sourcefile='MapHost.java' startBytecode='12'><Message>Synchronized access at MapHost.java:[line 63]</Message></SourceLine><SourceLine role='SOURCE_LINE_SYNC_ACCESS' endBytecode='25' classname='org.apache.hadoop.mapreduce.task.reduce.MapHost' start='64' end='64' sourcepath='org/apache/hadoop/mapreduce/task/reduce/MapHost.java' sourcefile='MapHost.java' startBytecode='25'><Message>Synchronized access at MapHost.java:[line 64]</Message></SourceLine><SourceLine role='SOURCE_LINE_SYNC_ACCESS' endBytecode='26' classname='org.apache.hadoop.mapreduce.task.reduce.MapHost' start='90' end='90' sourcepath='org/apache/hadoop/mapreduce/task/reduce/MapHost.java' sourcefile='MapHost.java' startBytecode='26'><Message>Synchronized access at MapHost.java:[line 90]</Message></SourceLine><SourceLine role='SOURCE_LINE_SYNC_ACCESS' endBytecode='16' classname='org.apache.hadoop.mapreduce.task.reduce.MapHost' start='88' end='88' sourcepath='org/apache/hadoop/mapreduce/task/reduce/MapHost.java' sourcefile='MapHost.java' startBytecode='16'><Message>Synchronized access at MapHost.java:[line 88]</Message></SourceLine><SourceLine role='SOURCE_LINE_SYNC_ACCESS' endBytecode='30' classname='org.apache.hadoop.mapreduce.task.reduce.MapHost' start='92' end='92' sourcepath='org/apache/hadoop/mapreduce/task/reduce/MapHost.java' sourcefile='MapHost.java' startBytecode='30'><Message>Synchronized access at MapHost.java:[line 92]</Message></SourceLine><Property name='edu.umd.cs.findbugs.detect.InconsistentSyncWarningProperty.ONLY_UNSYNC_IN_GETTERS' value='true'></Property></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='39874f855365335bab9a07e008a060f7' rank='19' abbrev='Se' category='BAD_PRACTICE' priority='2' type='SE_COMPARATOR_SHOULD_BE_SERIALIZABLE' instanceOccurrenceMax='0'><ShortMessage>Comparator doesn't implement Serializable</ShortMessage><LongMessage>org.apache.hadoop.mapreduce.task.reduce.MapOutput$MapOutputComparator implements Comparator but not Serializable</LongMessage><Class classname='org.apache.hadoop.mapreduce.task.reduce.MapOutput$MapOutputComparator' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.task.reduce.MapOutput$MapOutputComparator' start='91' end='107' sourcepath='org/apache/hadoop/mapreduce/task/reduce/MapOutput.java' sourcefile='MapOutput.java'><Message>At MapOutput.java:[lines 91-107]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.task.reduce.MapOutput$MapOutputComparator</Message></Class><SourceLine synthetic='true' classname='org.apache.hadoop.mapreduce.task.reduce.MapOutput$MapOutputComparator' start='91' end='107' sourcepath='org/apache/hadoop/mapreduce/task/reduce/MapOutput.java' sourcefile='MapOutput.java'><Message>At MapOutput.java:[lines 91-107]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='6ed88b55d020a891a6e677fecaa9d7cc' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from org.apache.hadoop.fs.FileSystem to org.apache.hadoop.fs.LocalFileSystem in new org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl(TaskAttemptID, JobConf, FileSystem, LocalDirAllocator, Reporter, CompressionCodec, Class, Task$CombineOutputCollector, Counters$Counter, Counters$Counter, Counters$Counter, ExceptionReporter, Progress, MapOutputFile)</LongMessage><Class classname='org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl' start='68' end='828' sourcepath='org/apache/hadoop/mapreduce/task/reduce/MergeManagerImpl.java' sourcefile='MergeManagerImpl.java'><Message>At MergeManagerImpl.java:[lines 68-828]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl' signature='(Lorg/apache/hadoop/mapreduce/TaskAttemptID;Lorg/apache/hadoop/mapred/JobConf;Lorg/apache/hadoop/fs/FileSystem;Lorg/apache/hadoop/fs/LocalDirAllocator;Lorg/apache/hadoop/mapred/Reporter;Lorg/apache/hadoop/io/compress/CompressionCodec;Ljava/lang/Class;Lorg/apache/hadoop/mapred/Task$CombineOutputCollector;Lorg/apache/hadoop/mapred/Counters$Counter;Lorg/apache/hadoop/mapred/Counters$Counter;Lorg/apache/hadoop/mapred/Counters$Counter;Lorg/apache/hadoop/mapreduce/task/reduce/ExceptionReporter;Lorg/apache/hadoop/util/Progress;Lorg/apache/hadoop/mapred/MapOutputFile;)V' name='&lt;init&gt;' primary='true'><SourceLine endBytecode='281' classname='org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl' start='146' end='239' sourcepath='org/apache/hadoop/mapreduce/task/reduce/MergeManagerImpl.java' sourcefile='MergeManagerImpl.java' startBytecode='0'></SourceLine><Message>In method new org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl(TaskAttemptID, JobConf, FileSystem, LocalDirAllocator, Reporter, CompressionCodec, Class, Task$CombineOutputCollector, Counters$Counter, Counters$Counter, Counters$Counter, ExceptionReporter, Progress, MapOutputFile)</Message></Method><Type role='TYPE_FOUND' descriptor='Lorg/apache/hadoop/fs/FileSystem;'><SourceLine classname='org.apache.hadoop.fs.FileSystem' start='124' end='4296' sourcepath='org/apache/hadoop/fs/FileSystem.java' sourcefile='FileSystem.java'><Message>At FileSystem.java:[lines 124-4296]</Message></SourceLine><Message>Actual type org.apache.hadoop.fs.FileSystem</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/fs/LocalFileSystem;'><SourceLine classname='org.apache.hadoop.fs.LocalFileSystem' start='37' end='165' sourcepath='org/apache/hadoop/fs/LocalFileSystem.java' sourcefile='LocalFileSystem.java'><Message>At LocalFileSystem.java:[lines 37-165]</Message></SourceLine><Message>Expected org.apache.hadoop.fs.LocalFileSystem</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='135' name='localFS' register='3'><Message>Value loaded from localFS</Message></LocalVariable><SourceLine endBytecode='136' classname='org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl' start='163' end='163' sourcepath='org/apache/hadoop/mapreduce/task/reduce/MergeManagerImpl.java' sourcefile='MergeManagerImpl.java' startBytecode='136' primary='true'><Message>At MergeManagerImpl.java:[line 163]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='d8a3639bfcf57fec42006cbf45cd3cc5' rank='14' abbrev='SC' category='MT_CORRECTNESS' priority='2' type='SC_START_IN_CTOR' instanceOccurrenceMax='0'><ShortMessage>Constructor invokes Thread.start()</ShortMessage><LongMessage>new org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl(TaskAttemptID, JobConf, FileSystem, LocalDirAllocator, Reporter, CompressionCodec, Class, Task$CombineOutputCollector, Counters$Counter, Counters$Counter, Counters$Counter, ExceptionReporter, Progress, MapOutputFile) invokes org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl$IntermediateMemoryToMemoryMerger.start()</LongMessage><Class classname='org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl' start='68' end='828' sourcepath='org/apache/hadoop/mapreduce/task/reduce/MergeManagerImpl.java' sourcefile='MergeManagerImpl.java'><Message>At MergeManagerImpl.java:[lines 68-828]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl' signature='(Lorg/apache/hadoop/mapreduce/TaskAttemptID;Lorg/apache/hadoop/mapred/JobConf;Lorg/apache/hadoop/fs/FileSystem;Lorg/apache/hadoop/fs/LocalDirAllocator;Lorg/apache/hadoop/mapred/Reporter;Lorg/apache/hadoop/io/compress/CompressionCodec;Ljava/lang/Class;Lorg/apache/hadoop/mapred/Task$CombineOutputCollector;Lorg/apache/hadoop/mapred/Counters$Counter;Lorg/apache/hadoop/mapred/Counters$Counter;Lorg/apache/hadoop/mapred/Counters$Counter;Lorg/apache/hadoop/mapreduce/task/reduce/ExceptionReporter;Lorg/apache/hadoop/util/Progress;Lorg/apache/hadoop/mapred/MapOutputFile;)V' name='&lt;init&gt;' primary='true'><SourceLine endBytecode='1150' classname='org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl' start='146' end='239' sourcepath='org/apache/hadoop/mapreduce/task/reduce/MergeManagerImpl.java' sourcefile='MergeManagerImpl.java' startBytecode='0'></SourceLine><Message>In method new org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl(TaskAttemptID, JobConf, FileSystem, LocalDirAllocator, Reporter, CompressionCodec, Class, Task$CombineOutputCollector, Counters$Counter, Counters$Counter, Counters$Counter, ExceptionReporter, Progress, MapOutputFile)</Message></Method><Method isStatic='false' role='METHOD_CALLED' classname='org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl$IntermediateMemoryToMemoryMerger' signature='()V' name='start'><SourceLine classname='org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl$IntermediateMemoryToMemoryMerger' sourcepath='org/apache/hadoop/mapreduce/task/reduce/MergeManagerImpl.java' sourcefile='MergeManagerImpl.java'></SourceLine><Message>Called method org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl$IntermediateMemoryToMemoryMerger.start()</Message></Method><SourceLine endBytecode='535' classname='org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl' start='227' end='227' sourcepath='org/apache/hadoop/mapreduce/task/reduce/MergeManagerImpl.java' sourcefile='MergeManagerImpl.java' startBytecode='535' primary='true'><Message>At MergeManagerImpl.java:[line 227]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='6674dd57f5f77550b4ce08c40b2377b' rank='14' abbrev='SC' category='MT_CORRECTNESS' priority='2' type='SC_START_IN_CTOR' instanceOccurrenceMax='0'><ShortMessage>Constructor invokes Thread.start()</ShortMessage><LongMessage>new org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl(TaskAttemptID, JobConf, FileSystem, LocalDirAllocator, Reporter, CompressionCodec, Class, Task$CombineOutputCollector, Counters$Counter, Counters$Counter, Counters$Counter, ExceptionReporter, Progress, MapOutputFile) invokes org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl$OnDiskMerger.start()</LongMessage><Class classname='org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl' start='68' end='828' sourcepath='org/apache/hadoop/mapreduce/task/reduce/MergeManagerImpl.java' sourcefile='MergeManagerImpl.java'><Message>At MergeManagerImpl.java:[lines 68-828]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl' signature='(Lorg/apache/hadoop/mapreduce/TaskAttemptID;Lorg/apache/hadoop/mapred/JobConf;Lorg/apache/hadoop/fs/FileSystem;Lorg/apache/hadoop/fs/LocalDirAllocator;Lorg/apache/hadoop/mapred/Reporter;Lorg/apache/hadoop/io/compress/CompressionCodec;Ljava/lang/Class;Lorg/apache/hadoop/mapred/Task$CombineOutputCollector;Lorg/apache/hadoop/mapred/Counters$Counter;Lorg/apache/hadoop/mapred/Counters$Counter;Lorg/apache/hadoop/mapred/Counters$Counter;Lorg/apache/hadoop/mapreduce/task/reduce/ExceptionReporter;Lorg/apache/hadoop/util/Progress;Lorg/apache/hadoop/mapred/MapOutputFile;)V' name='&lt;init&gt;' primary='true'><SourceLine endBytecode='1150' classname='org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl' start='146' end='239' sourcepath='org/apache/hadoop/mapreduce/task/reduce/MergeManagerImpl.java' sourcefile='MergeManagerImpl.java' startBytecode='0'></SourceLine><Message>In method new org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl(TaskAttemptID, JobConf, FileSystem, LocalDirAllocator, Reporter, CompressionCodec, Class, Task$CombineOutputCollector, Counters$Counter, Counters$Counter, Counters$Counter, ExceptionReporter, Progress, MapOutputFile)</Message></Method><Method isStatic='false' role='METHOD_CALLED' classname='org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl$OnDiskMerger' signature='()V' name='start'><SourceLine classname='org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl$OnDiskMerger' sourcepath='org/apache/hadoop/mapreduce/task/reduce/MergeManagerImpl.java' sourcefile='MergeManagerImpl.java'></SourceLine><Message>Called method org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl$OnDiskMerger.start()</Message></Method><SourceLine endBytecode='578' classname='org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl' start='236' end='236' sourcepath='org/apache/hadoop/mapreduce/task/reduce/MergeManagerImpl.java' sourcefile='MergeManagerImpl.java' startBytecode='578' primary='true'><Message>At MergeManagerImpl.java:[line 236]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='7cad5e72ea7bfc8f0332464ef7727548' rank='14' abbrev='SC' category='MT_CORRECTNESS' priority='2' type='SC_START_IN_CTOR' instanceOccurrenceMax='0'><ShortMessage>Constructor invokes Thread.start()</ShortMessage><LongMessage>new org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl(TaskAttemptID, JobConf, FileSystem, LocalDirAllocator, Reporter, CompressionCodec, Class, Task$CombineOutputCollector, Counters$Counter, Counters$Counter, Counters$Counter, ExceptionReporter, Progress, MapOutputFile) invokes org.apache.hadoop.mapreduce.task.reduce.MergeThread.start()</LongMessage><Class classname='org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl' start='68' end='828' sourcepath='org/apache/hadoop/mapreduce/task/reduce/MergeManagerImpl.java' sourcefile='MergeManagerImpl.java'><Message>At MergeManagerImpl.java:[lines 68-828]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl' signature='(Lorg/apache/hadoop/mapreduce/TaskAttemptID;Lorg/apache/hadoop/mapred/JobConf;Lorg/apache/hadoop/fs/FileSystem;Lorg/apache/hadoop/fs/LocalDirAllocator;Lorg/apache/hadoop/mapred/Reporter;Lorg/apache/hadoop/io/compress/CompressionCodec;Ljava/lang/Class;Lorg/apache/hadoop/mapred/Task$CombineOutputCollector;Lorg/apache/hadoop/mapred/Counters$Counter;Lorg/apache/hadoop/mapred/Counters$Counter;Lorg/apache/hadoop/mapred/Counters$Counter;Lorg/apache/hadoop/mapreduce/task/reduce/ExceptionReporter;Lorg/apache/hadoop/util/Progress;Lorg/apache/hadoop/mapred/MapOutputFile;)V' name='&lt;init&gt;' primary='true'><SourceLine endBytecode='1150' classname='org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl' start='146' end='239' sourcepath='org/apache/hadoop/mapreduce/task/reduce/MergeManagerImpl.java' sourcefile='MergeManagerImpl.java' startBytecode='0'></SourceLine><Message>In method new org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl(TaskAttemptID, JobConf, FileSystem, LocalDirAllocator, Reporter, CompressionCodec, Class, Task$CombineOutputCollector, Counters$Counter, Counters$Counter, Counters$Counter, ExceptionReporter, Progress, MapOutputFile)</Message></Method><Method isStatic='false' role='METHOD_CALLED' classname='org.apache.hadoop.mapreduce.task.reduce.MergeThread' signature='()V' name='start'><SourceLine classname='org.apache.hadoop.mapreduce.task.reduce.MergeThread' sourcepath='org/apache/hadoop/mapreduce/task/reduce/MergeThread.java' sourcefile='MergeThread.java'></SourceLine><Message>Called method org.apache.hadoop.mapreduce.task.reduce.MergeThread.start()</Message></Method><SourceLine endBytecode='558' classname='org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl' start='233' end='233' sourcepath='org/apache/hadoop/mapreduce/task/reduce/MergeManagerImpl.java' sourcefile='MergeManagerImpl.java' startBytecode='558' primary='true'><Message>At MergeManagerImpl.java:[line 233]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='837be3730482fae391465324b3e3f54a' rank='19' abbrev='SnVI' category='BAD_PRACTICE' priority='3' type='SE_NO_SERIALVERSIONID' instanceOccurrenceMax='0'><ShortMessage>Class is Serializable, but doesn't define serialVersionUID</ShortMessage><LongMessage>org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl$CompressAwarePath is Serializable; consider declaring a serialVersionUID</LongMessage><Class classname='org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl$CompressAwarePath' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl$CompressAwarePath' start='839' end='874' sourcepath='org/apache/hadoop/mapreduce/task/reduce/MergeManagerImpl.java' sourcefile='MergeManagerImpl.java'><Message>At MergeManagerImpl.java:[lines 839-874]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl$CompressAwarePath</Message></Class><SourceLine synthetic='true' classname='org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl$CompressAwarePath' start='839' end='874' sourcepath='org/apache/hadoop/mapreduce/task/reduce/MergeManagerImpl.java' sourcefile='MergeManagerImpl.java'><Message>At MergeManagerImpl.java:[lines 839-874]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='7f298daa19976a1c08f31667f527db03' rank='20' abbrev='BC' category='STYLE' priority='3' type='BC_UNCONFIRMED_CAST' instanceOccurrenceMax='0'><ShortMessage>Unchecked/unconfirmed cast</ShortMessage><LongMessage>Unchecked/unconfirmed cast from org.apache.hadoop.mapreduce.TaskAttemptID to org.apache.hadoop.mapred.TaskAttemptID in org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl.checkAndInformMRAppMaster(int, TaskAttemptID, boolean, boolean, boolean)</LongMessage><Class classname='org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl' start='57' end='590' sourcepath='org/apache/hadoop/mapreduce/task/reduce/ShuffleSchedulerImpl.java' sourcefile='ShuffleSchedulerImpl.java'><Message>At ShuffleSchedulerImpl.java:[lines 57-590]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl' signature='(ILorg/apache/hadoop/mapreduce/TaskAttemptID;ZZZ)V' name='checkAndInformMRAppMaster' primary='true'><SourceLine endBytecode='31' classname='org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl' start='347' end='352' sourcepath='org/apache/hadoop/mapreduce/task/reduce/ShuffleSchedulerImpl.java' sourcefile='ShuffleSchedulerImpl.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl.checkAndInformMRAppMaster(int, TaskAttemptID, boolean, boolean, boolean)</Message></Method><Type role='TYPE_FOUND' descriptor='Lorg/apache/hadoop/mapreduce/TaskAttemptID;'><SourceLine classname='org.apache.hadoop.mapreduce.TaskAttemptID' start='48' end='201' sourcepath='org/apache/hadoop/mapreduce/TaskAttemptID.java' sourcefile='TaskAttemptID.java'><Message>At TaskAttemptID.java:[lines 48-201]</Message></SourceLine><Message>Actual type org.apache.hadoop.mapreduce.TaskAttemptID</Message></Type><Type role='TYPE_EXPECTED' descriptor='Lorg/apache/hadoop/mapred/TaskAttemptID;'><SourceLine classname='org.apache.hadoop.mapred.TaskAttemptID' start='48' end='193' sourcepath='org/apache/hadoop/mapred/TaskAttemptID.java' sourcefile='TaskAttemptID.java'><Message>At TaskAttemptID.java:[lines 48-193]</Message></SourceLine><Message>Expected org.apache.hadoop.mapred.TaskAttemptID</Message></Type><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='66' name='mapId' register='2'><Message>Value loaded from mapId</Message></LocalVariable><SourceLine endBytecode='67' classname='org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl' start='350' end='350' sourcepath='org/apache/hadoop/mapreduce/task/reduce/ShuffleSchedulerImpl.java' sourcefile='ShuffleSchedulerImpl.java' startBytecode='67' primary='true'><Message>At ShuffleSchedulerImpl.java:[line 350]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='197a698d39d574e8ef83f76770cc84bb' rank='14' abbrev='SC' category='MT_CORRECTNESS' priority='2' type='SC_START_IN_CTOR' instanceOccurrenceMax='0'><ShortMessage>Constructor invokes Thread.start()</ShortMessage><LongMessage>new org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl(JobConf, TaskStatus, TaskAttemptID, ExceptionReporter, Progress, Counters$Counter, Counters$Counter, Counters$Counter) invokes org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl$Referee.start()</LongMessage><Class classname='org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl' start='57' end='590' sourcepath='org/apache/hadoop/mapreduce/task/reduce/ShuffleSchedulerImpl.java' sourcefile='ShuffleSchedulerImpl.java'><Message>At ShuffleSchedulerImpl.java:[lines 57-590]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl' signature='(Lorg/apache/hadoop/mapred/JobConf;Lorg/apache/hadoop/mapred/TaskStatus;Lorg/apache/hadoop/mapreduce/TaskAttemptID;Lorg/apache/hadoop/mapreduce/task/reduce/ExceptionReporter;Lorg/apache/hadoop/util/Progress;Lorg/apache/hadoop/mapred/Counters$Counter;Lorg/apache/hadoop/mapred/Counters$Counter;Lorg/apache/hadoop/mapred/Counters$Counter;)V' name='&lt;init&gt;' primary='true'><SourceLine endBytecode='569' classname='org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl' start='119' end='146' sourcepath='org/apache/hadoop/mapreduce/task/reduce/ShuffleSchedulerImpl.java' sourcefile='ShuffleSchedulerImpl.java' startBytecode='0'></SourceLine><Message>In method new org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl(JobConf, TaskStatus, TaskAttemptID, ExceptionReporter, Progress, Counters$Counter, Counters$Counter, Counters$Counter)</Message></Method><Method isStatic='false' role='METHOD_CALLED' classname='org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl$Referee' signature='()V' name='start'><SourceLine classname='org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl$Referee' sourcepath='org/apache/hadoop/mapreduce/task/reduce/ShuffleSchedulerImpl.java' sourcefile='ShuffleSchedulerImpl.java'></SourceLine><Message>Called method org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl$Referee.start()</Message></Method><SourceLine endBytecode='235' classname='org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl' start='134' end='134' sourcepath='org/apache/hadoop/mapreduce/task/reduce/ShuffleSchedulerImpl.java' sourcefile='ShuffleSchedulerImpl.java' startBytecode='235' primary='true'><Message>At ShuffleSchedulerImpl.java:[line 134]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='b2eec1576a6f7171d2d98f6ac8e4d77' rank='17' abbrev='Wa' category='MT_CORRECTNESS' priority='3' type='WA_NOT_IN_LOOP' instanceOccurrenceMax='0'><ShortMessage>Wait not in loop </ShortMessage><LongMessage>Wait not in loop in org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl.waitUntilDone(int)</LongMessage><Class classname='org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl' start='57' end='590' sourcepath='org/apache/hadoop/mapreduce/task/reduce/ShuffleSchedulerImpl.java' sourcefile='ShuffleSchedulerImpl.java'><Message>At ShuffleSchedulerImpl.java:[lines 57-590]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl' signature='(I)Z' name='waitUntilDone' primary='true'><SourceLine endBytecode='121' classname='org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl' start='521' end='525' sourcepath='org/apache/hadoop/mapreduce/task/reduce/ShuffleSchedulerImpl.java' sourcefile='ShuffleSchedulerImpl.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl.waitUntilDone(int)</Message></Method><SourceLine endBytecode='10' classname='org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl' start='522' end='522' sourcepath='org/apache/hadoop/mapreduce/task/reduce/ShuffleSchedulerImpl.java' sourcefile='ShuffleSchedulerImpl.java' startBytecode='10' primary='true'><Message>At ShuffleSchedulerImpl.java:[line 522]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='5e0e3aacacdd8f69813784ccc0b47921' rank='16' abbrev='Eq' category='BAD_PRACTICE' priority='2' type='EQ_COMPARETO_USE_OBJECT_EQUALS' instanceOccurrenceMax='0'><ShortMessage>Class defines compareTo(...) and uses Object.equals()</ShortMessage><LongMessage>org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl$Penalty defines compareTo(Object) and uses Object.equals()</LongMessage><Class classname='org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl$Penalty' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl$Penalty' start='531' end='549' sourcepath='org/apache/hadoop/mapreduce/task/reduce/ShuffleSchedulerImpl.java' sourcefile='ShuffleSchedulerImpl.java'><Message>At ShuffleSchedulerImpl.java:[lines 531-549]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl$Penalty</Message></Class><Method isStatic='false' classname='org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl$Penalty' signature='(Ljava/lang/Object;)I' name='compareTo' primary='true'><SourceLine endBytecode='50' classname='org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl$Penalty' start='531' end='531' sourcepath='org/apache/hadoop/mapreduce/task/reduce/ShuffleSchedulerImpl.java' sourcefile='ShuffleSchedulerImpl.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl$Penalty.compareTo(Object)</Message></Method><SourceLine synthetic='true' endBytecode='50' classname='org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl$Penalty' start='531' end='531' sourcepath='org/apache/hadoop/mapreduce/task/reduce/ShuffleSchedulerImpl.java' sourcefile='ShuffleSchedulerImpl.java' startBytecode='0'><Message>At ShuffleSchedulerImpl.java:[line 531]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='69472b49c85765da9f2480882bc04622' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.mapreduce.tools.CLI.dataPattern isn't final but should be</LongMessage><Class classname='org.apache.hadoop.mapreduce.tools.CLI' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.tools.CLI' start='75' end='812' sourcepath='org/apache/hadoop/mapreduce/tools/CLI.java' sourcefile='CLI.java'><Message>At CLI.java:[lines 75-812]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.tools.CLI</Message></Class><Field isStatic='true' classname='org.apache.hadoop.mapreduce.tools.CLI' signature='Ljava/lang/String;' name='dataPattern' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.tools.CLI' sourcepath='org/apache/hadoop/mapreduce/tools/CLI.java' sourcefile='CLI.java'><Message>In CLI.java</Message></SourceLine><Message>Field org.apache.hadoop.mapreduce.tools.CLI.dataPattern</Message></Field><SourceLine endBytecode='47' classname='org.apache.hadoop.mapreduce.tools.CLI' start='777' end='777' sourcepath='org/apache/hadoop/mapreduce/tools/CLI.java' sourcefile='CLI.java' startBytecode='47' primary='true'><Message>At CLI.java:[line 777]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='59c9558ff5170651b4abff16f0af1944' cweid='218' rank='16' abbrev='MS' category='MALICIOUS_CODE' priority='1' type='MS_SHOULD_BE_FINAL' instanceOccurrenceMax='0'><ShortMessage>Field isn't final but should be</ShortMessage><LongMessage>org.apache.hadoop.mapreduce.tools.CLI.headerPattern isn't final but should be</LongMessage><Class classname='org.apache.hadoop.mapreduce.tools.CLI' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.tools.CLI' start='75' end='812' sourcepath='org/apache/hadoop/mapreduce/tools/CLI.java' sourcefile='CLI.java'><Message>At CLI.java:[lines 75-812]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.tools.CLI</Message></Class><Field isStatic='true' classname='org.apache.hadoop.mapreduce.tools.CLI' signature='Ljava/lang/String;' name='headerPattern' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.tools.CLI' sourcepath='org/apache/hadoop/mapreduce/tools/CLI.java' sourcefile='CLI.java'><Message>In CLI.java</Message></SourceLine><Message>Field org.apache.hadoop.mapreduce.tools.CLI.headerPattern</Message></Field><SourceLine endBytecode='41' classname='org.apache.hadoop.mapreduce.tools.CLI' start='774' end='774' sourcepath='org/apache/hadoop/mapreduce/tools/CLI.java' sourcefile='CLI.java' startBytecode='41' primary='true'><Message>At CLI.java:[line 774]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='ee73c73d6ef6dce3ccc34c5573036b88' cweid='476' rank='11' abbrev='NP' category='CORRECTNESS' priority='2' type='NP_GUARANTEED_DEREF_ON_EXCEPTION_PATH' instanceOccurrenceMax='0'><ShortMessage>Value is null and guaranteed to be dereferenced on exception path</ShortMessage><LongMessage>shexec is null guaranteed to be dereferenced in org.apache.hadoop.mapreduce.util.ProcessTree.sendSignal(String, int, String) on exception path</LongMessage><Class classname='org.apache.hadoop.mapreduce.util.ProcessTree' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.util.ProcessTree' start='36' end='324' sourcepath='org/apache/hadoop/mapreduce/util/ProcessTree.java' sourcefile='ProcessTree.java'><Message>At ProcessTree.java:[lines 36-324]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.util.ProcessTree</Message></Class><Method isStatic='true' classname='org.apache.hadoop.mapreduce.util.ProcessTree' signature='(Ljava/lang/String;ILjava/lang/String;)V' name='sendSignal' primary='true'><SourceLine endBytecode='698' classname='org.apache.hadoop.mapreduce.util.ProcessTree' start='125' end='141' sourcepath='org/apache/hadoop/mapreduce/util/ProcessTree.java' sourcefile='ProcessTree.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapreduce.util.ProcessTree.sendSignal(String, int, String)</Message></Method><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='2' name='shexec' register='3'><Message>Value loaded from shexec</Message></LocalVariable><SourceLine role='SOURCE_LINE_DEREF' endBytecode='401' classname='org.apache.hadoop.mapreduce.util.ProcessTree' start='138' end='138' sourcepath='org/apache/hadoop/mapreduce/util/ProcessTree.java' sourcefile='ProcessTree.java' startBytecode='401' primary='true'><Message>Dereferenced at ProcessTree.java:[line 138]</Message></SourceLine><SourceLine role='SOURCE_LINE_DEREF' endBytecode='350' classname='org.apache.hadoop.mapreduce.util.ProcessTree' start='135' end='135' sourcepath='org/apache/hadoop/mapreduce/util/ProcessTree.java' sourcefile='ProcessTree.java' startBytecode='350'><Message>Dereferenced at ProcessTree.java:[line 135]</Message></SourceLine><SourceLine role='SOURCE_LINE_NULL_VALUE' endBytecode='0' classname='org.apache.hadoop.mapreduce.util.ProcessTree' start='125' end='125' sourcepath='org/apache/hadoop/mapreduce/util/ProcessTree.java' sourcefile='ProcessTree.java' startBytecode='0'><Message>Null value at ProcessTree.java:[line 125]</Message></SourceLine><SourceLine role='SOURCE_LINE_KNOWN_NULL' endBytecode='3' classname='org.apache.hadoop.mapreduce.util.ProcessTree' start='127' end='127' sourcepath='org/apache/hadoop/mapreduce/util/ProcessTree.java' sourcefile='ProcessTree.java' startBytecode='3'><Message>Known null at ProcessTree.java:[line 127]</Message></SourceLine><Property name='edu.umd.cs.findbugs.detect.DoomedCodeWarningProperty.DOOMED_CODE' value='true'></Property><Property name='edu.umd.cs.findbugs.detect.NullDerefProperty.ALWAYS_ON_EXCEPTION_PATH' value='true'></Property><Property name='edu.umd.cs.findbugs.detect.NullDerefProperty.DEREFS_ARE_CLONED' value='true'></Property><Property name='edu.umd.cs.findbugs.detect.NullDerefProperty.LONG_RANGE_NULL_SOURCE' value='true'></Property></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='a17cc02a8339b8c4684ee13c5b8dc8c4' cweid='476' rank='11' abbrev='NP' category='CORRECTNESS' priority='2' type='NP_NULL_ON_SOME_PATH_EXCEPTION' instanceOccurrenceMax='0'><ShortMessage>Possible null pointer dereference in method on exception path</ShortMessage><LongMessage>Possible null pointer dereference of shexec in org.apache.hadoop.mapreduce.util.ProcessTree.isSetsidSupported() on exception path</LongMessage><Class classname='org.apache.hadoop.mapreduce.util.ProcessTree' primary='true'><SourceLine classname='org.apache.hadoop.mapreduce.util.ProcessTree' start='36' end='324' sourcepath='org/apache/hadoop/mapreduce/util/ProcessTree.java' sourcefile='ProcessTree.java'><Message>At ProcessTree.java:[lines 36-324]</Message></SourceLine><Message>In class org.apache.hadoop.mapreduce.util.ProcessTree</Message></Class><Method isStatic='true' classname='org.apache.hadoop.mapreduce.util.ProcessTree' signature='()Z' name='isSetsidSupported' primary='true'><SourceLine endBytecode='334' classname='org.apache.hadoop.mapreduce.util.ProcessTree' start='53' end='65' sourcepath='org/apache/hadoop/mapreduce/util/ProcessTree.java' sourcefile='ProcessTree.java' startBytecode='0'></SourceLine><Message>In method org.apache.hadoop.mapreduce.util.ProcessTree.isSetsidSupported()</Message></Method><LocalVariable role='LOCAL_VARIABLE_VALUE_OF' pc='4' name='shexec' register='0'><Message>Value loaded from shexec</Message></LocalVariable><SourceLine role='SOURCE_LINE_DEREF' endBytecode='138' classname='org.apache.hadoop.mapreduce.util.ProcessTree' start='63' end='63' sourcepath='org/apache/hadoop/mapreduce/util/ProcessTree.java' sourcefile='ProcessTree.java' startBytecode='138' primary='true'><Message>Dereferenced at ProcessTree.java:[line 63]</Message></SourceLine><SourceLine role='SOURCE_LINE_NULL_VALUE' endBytecode='0' classname='org.apache.hadoop.mapreduce.util.ProcessTree' start='53' end='53' sourcepath='org/apache/hadoop/mapreduce/util/ProcessTree.java' sourcefile='ProcessTree.java' startBytecode='0'><Message>Null value at ProcessTree.java:[line 53]</Message></SourceLine><SourceLine role='SOURCE_LINE_KNOWN_NULL' endBytecode='5' classname='org.apache.hadoop.mapreduce.util.ProcessTree' start='56' end='56' sourcepath='org/apache/hadoop/mapreduce/util/ProcessTree.java' sourcefile='ProcessTree.java' startBytecode='5'><Message>Known null at ProcessTree.java:[line 56]</Message></SourceLine><Property name='edu.umd.cs.findbugs.detect.DoomedCodeWarningProperty.DOOMED_CODE' value='true'></Property><Property name='edu.umd.cs.findbugs.detect.NullDerefProperty.ALWAYS_ON_EXCEPTION_PATH' value='true'></Property><Property name='edu.umd.cs.findbugs.detect.NullDerefProperty.DEREFS_ARE_CLONED' value='true'></Property><Property name='edu.umd.cs.findbugs.detect.NullDerefProperty.LONG_RANGE_NULL_SOURCE' value='true'></Property></BugInstance><BugCategory category='BAD_PRACTICE'><Description>Bad practice</Description></BugCategory><BugCategory category='MALICIOUS_CODE'><Description>Malicious code vulnerability</Description></BugCategory><BugCategory category='PERFORMANCE'><Description>Performance</Description></BugCategory><BugCategory category='CORRECTNESS'><Description>Correctness</Description></BugCategory><BugCategory category='STYLE'><Description>Dodgy code</Description></BugCategory><BugCategory category='SECURITY'><Description>Security</Description></BugCategory><BugCategory category='MT_CORRECTNESS'><Description>Multithreaded correctness</Description></BugCategory><BugCategory category='I18N'><Description>Internationalization</Description></BugCategory><BugPattern abbrev='UwF' category='STYLE' type='UWF_FIELD_NOT_INITIALIZED_IN_CONSTRUCTOR'><ShortDescription>Field not initialized in constructor but dereferenced without null check</ShortDescription><Details>

  &lt;p&gt; This field is never initialized within any constructor, and is therefore could be null after
the object is constructed. Elsewhere, it is loaded and dereferenced without a null check.
This could be a either an error or a questionable design, since
it means a null pointer exception will be generated if that field is dereferenced
before being initialized.
&lt;/p&gt;

    </Details></BugPattern><BugPattern abbrev='DLS' category='STYLE' type='DLS_DEAD_LOCAL_STORE'><ShortDescription>Dead store to local variable</ShortDescription><Details>

&lt;p&gt;
This instruction assigns a value to a local variable,
but the value is not read or used in any subsequent instruction.
Often, this indicates an error, because the value computed is never
used.
&lt;/p&gt;
&lt;p&gt;
Note that Sun's javac compiler often generates dead stores for
final local variables.  Because SpotBugs is a bytecode-based tool,
there is no easy way to eliminate these false positives.
&lt;/p&gt;

    </Details></BugPattern><BugPattern abbrev='Nm' category='BAD_PRACTICE' type='NM_SAME_SIMPLE_NAME_AS_INTERFACE'><ShortDescription>Class names shouldn't shadow simple name of implemented interface</ShortDescription><Details>

  &lt;p&gt; This class/interface has a simple name that is identical to that of an implemented/extended interface, except
that the interface is in a different package (e.g., &lt;code&gt;alpha.Foo&lt;/code&gt; extends &lt;code&gt;beta.Foo&lt;/code&gt;).
This can be exceptionally confusing, create lots of situations in which you have to look at import statements
to resolve references and creates many
opportunities to accidentally define methods that do not override methods in their superclasses.
&lt;/p&gt;

    </Details></BugPattern><BugPattern cweid='374' abbrev='EI2' category='MALICIOUS_CODE' type='EI_EXPOSE_REP2'><ShortDescription>May expose internal representation by incorporating reference to mutable object</ShortDescription><Details>

  &lt;p&gt; This code stores a reference to an externally mutable object into the
  internal representation of the object.&amp;nbsp;
   If instances
   are accessed by untrusted code, and unchecked changes to
   the mutable object would compromise security or other
   important properties, you will need to do something different.
  Storing a copy of the object is better approach in many situations.&lt;/p&gt;

    </Details></BugPattern><BugPattern abbrev='SC' category='MT_CORRECTNESS' type='SC_START_IN_CTOR'><ShortDescription>Constructor invokes Thread.start()</ShortDescription><Details>

  &lt;p&gt; The constructor starts a thread. This is likely to be wrong if
   the class is ever extended/subclassed, since the thread will be started
   before the subclass constructor is started.&lt;/p&gt;

    </Details></BugPattern><BugPattern abbrev='No' category='MT_CORRECTNESS' type='NO_NOTIFY_NOT_NOTIFYALL'><ShortDescription>Using notify() rather than notifyAll()</ShortDescription><Details>

  &lt;p&gt; This method calls &lt;code&gt;notify()&lt;/code&gt; rather than &lt;code&gt;notifyAll()&lt;/code&gt;.&amp;nbsp;
  Java monitors are often used for multiple conditions.&amp;nbsp; Calling &lt;code&gt;notify()&lt;/code&gt;
  only wakes up one thread, meaning that the thread woken up might not be the
  one waiting for the condition that the caller just satisfied.&lt;/p&gt;

    </Details></BugPattern><BugPattern cweid='89' abbrev='SQL' category='SECURITY' type='SQL_PREPARED_STATEMENT_GENERATED_FROM_NONCONSTANT_STRING'><ShortDescription>A prepared statement is generated from a nonconstant String</ShortDescription><Details>

  &lt;p&gt;The code creates an SQL prepared statement from a nonconstant String.
If unchecked, tainted data from a user is used in building this String, SQL injection could
be used to make the prepared statement do something unexpected and undesirable.
&lt;/p&gt;

    </Details></BugPattern><BugPattern abbrev='Nm' category='BAD_PRACTICE' type='NM_SAME_SIMPLE_NAME_AS_SUPERCLASS'><ShortDescription>Class names shouldn't shadow simple name of superclass</ShortDescription><Details>

  &lt;p&gt; This class has a simple name that is identical to that of its superclass, except
that its superclass is in a different package (e.g., &lt;code&gt;alpha.Foo&lt;/code&gt; extends &lt;code&gt;beta.Foo&lt;/code&gt;).
This can be exceptionally confusing, create lots of situations in which you have to look at import statements
to resolve references and creates many
opportunities to accidentally define methods that do not override methods in their superclasses.
&lt;/p&gt;

    </Details></BugPattern><BugPattern abbrev='SIC' category='PERFORMANCE' type='SIC_INNER_SHOULD_BE_STATIC_NEEDS_THIS'><ShortDescription>Could be refactored into a static inner class</ShortDescription><Details>

  &lt;p&gt; This class is an inner class, but does not use its embedded reference
  to the object which created it except during construction of the
inner object.&amp;nbsp; This reference makes the instances
  of the class larger, and may keep the reference to the creator object
  alive longer than necessary.&amp;nbsp; If possible, the class should be
  made into a &lt;em&gt;static&lt;/em&gt; inner class. Since the reference to the
   outer object is required during construction of the inner instance,
   the inner class will need to be refactored so as to
   pass a reference to the outer instance to the constructor
   for the inner class.&lt;/p&gt;

    </Details></BugPattern><BugPattern abbrev='MS' category='MALICIOUS_CODE' type='MS_SHOULD_BE_FINAL'><ShortDescription>Field isn't final but should be</ShortDescription><Details>

   &lt;p&gt;
This static field public but not final, and
could be changed by malicious code or
        by accident from another package.
        The field could be made final to avoid
        this vulnerability.&lt;/p&gt;

    </Details></BugPattern><BugPattern abbrev='Dm' category='PERFORMANCE' type='DM_STRING_TOSTRING'><ShortDescription>Method invokes toString() method on a String</ShortDescription><Details>

  &lt;p&gt; Calling &lt;code&gt;String.toString()&lt;/code&gt; is just a redundant operation.
  Just use the String.&lt;/p&gt;

    </Details></BugPattern><BugPattern abbrev='ICAST' category='STYLE' type='ICAST_INTEGER_MULTIPLY_CAST_TO_LONG'><ShortDescription>Result of integer multiplication cast to long</ShortDescription><Details>

&lt;p&gt;
This code performs integer multiply and then converts the result to a long,
as in:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;long convertDaysToMilliseconds(int days) { return 1000*3600*24*days; }
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;
If the multiplication is done using long arithmetic, you can avoid
the possibility that the result will overflow. For example, you
could fix the above code to:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;long convertDaysToMilliseconds(int days) { return 1000L*3600*24*days; }
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;
or
&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;static final long MILLISECONDS_PER_DAY = 24L*3600*1000;
long convertDaysToMilliseconds(int days) { return days * MILLISECONDS_PER_DAY; }
&lt;/code&gt;&lt;/pre&gt;

    </Details></BugPattern><BugPattern abbrev='Nm' category='BAD_PRACTICE' type='NM_METHOD_NAMING_CONVENTION'><ShortDescription>Method names should start with a lower case letter</ShortDescription><Details>

  &lt;p&gt;
Methods should be verbs, in mixed case with the first letter lowercase, with the first letter of each internal word capitalized.
&lt;/p&gt;

    </Details></BugPattern><BugPattern abbrev='UrF' category='PERFORMANCE' type='URF_UNREAD_FIELD'><ShortDescription>Unread field</ShortDescription><Details>

  &lt;p&gt; This field is never read.&amp;nbsp; Consider removing it from the class.&lt;/p&gt;

    </Details></BugPattern><BugPattern abbrev='RCN' category='STYLE' type='RCN_REDUNDANT_NULLCHECK_OF_NULL_VALUE'><ShortDescription>Redundant nullcheck of value known to be null</ShortDescription><Details>

&lt;p&gt; This method contains a redundant check of a known null value against
the constant null.&lt;/p&gt;

    </Details></BugPattern><BugPattern abbrev='BC' category='STYLE' type='BC_UNCONFIRMED_CAST'><ShortDescription>Unchecked/unconfirmed cast</ShortDescription><Details>

&lt;p&gt;
This cast is unchecked, and not all instances of the type casted from can be cast to
the type it is being cast to. Check that your program logic ensures that this
cast will not fail.
&lt;/p&gt;

    </Details></BugPattern><BugPattern cweid='396' abbrev='REC' category='STYLE' type='REC_CATCH_EXCEPTION'><ShortDescription>Exception is caught when Exception is not thrown</ShortDescription><Details>
  
  &lt;p&gt;
  This method uses a try-catch block that catches Exception objects, but Exception is not
  thrown within the try block, and RuntimeException is not explicitly caught.  It is a common bug pattern to
  say try { ... } catch (Exception e) { something } as a shorthand for catching a number of types of exception
  each of whose catch blocks is identical, but this construct also accidentally catches RuntimeException as well,
  masking potential bugs.
  &lt;/p&gt;
  &lt;p&gt;A better approach is to either explicitly catch the specific exceptions that are thrown,
  or to explicitly catch RuntimeException exception, rethrow it, and then catch all non-Runtime Exceptions, as shown below:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;try {
    ...
} catch (RuntimeException e) {
    throw e;
} catch (Exception e) {
    ... deal with all non-runtime exceptions ...
}
&lt;/code&gt;&lt;/pre&gt;
  
     </Details></BugPattern><BugPattern abbrev='RCN' category='STYLE' type='RCN_REDUNDANT_NULLCHECK_OF_NONNULL_VALUE'><ShortDescription>Redundant nullcheck of value known to be non-null</ShortDescription><Details>

&lt;p&gt; This method contains a redundant check of a known non-null value against
the constant null.&lt;/p&gt;

    </Details></BugPattern><BugPattern abbrev='MS' category='MALICIOUS_CODE' type='MS_PKGPROTECT'><ShortDescription>Field should be package protected</ShortDescription><Details>

  &lt;p&gt; A mutable static field could be changed by malicious code or
   by accident.
   The field could be made package protected to avoid
   this vulnerability.&lt;/p&gt;

    </Details></BugPattern><BugPattern abbrev='NP' category='CORRECTNESS' type='NP_NULL_ON_SOME_PATH_EXCEPTION'><ShortDescription>Possible null pointer dereference in method on exception path</ShortDescription><Details>

&lt;p&gt; A reference value which is null on some exception control path is
dereferenced here.&amp;nbsp; This may lead to a &lt;code&gt;NullPointerException&lt;/code&gt;
when the code is executed.&amp;nbsp;
Note that because SpotBugs currently does not prune infeasible exception paths,
this may be a false warning.&lt;/p&gt;

&lt;p&gt; Also note that SpotBugs considers the default case of a switch statement to
be an exception path, since the default case is often infeasible.&lt;/p&gt;

    </Details></BugPattern><BugPattern abbrev='Eq' category='BAD_PRACTICE' type='EQ_COMPARETO_USE_OBJECT_EQUALS'><ShortDescription>Class defines compareTo(...) and uses Object.equals()</ShortDescription><Details>

  &lt;p&gt; This class defines a &lt;code&gt;compareTo(...)&lt;/code&gt; method but inherits its
  &lt;code&gt;equals()&lt;/code&gt; method from &lt;code&gt;java.lang.Object&lt;/code&gt;.
    Generally, the value of compareTo should return zero if and only if
    equals returns true. If this is violated, weird and unpredictable
    failures will occur in classes such as PriorityQueue.
    In Java 5 the PriorityQueue.remove method uses the compareTo method,
    while in Java 6 it uses the equals method.&lt;/p&gt;

&lt;p&gt;From the JavaDoc for the compareTo method in the Comparable interface:
&lt;blockquote&gt;
It is strongly recommended, but not strictly required that &lt;code&gt;(x.compareTo(y)==0) == (x.equals(y))&lt;/code&gt;.
Generally speaking, any class that implements the Comparable interface and violates this condition
should clearly indicate this fact. The recommended language
is "Note: this class has a natural ordering that is inconsistent with equals."
&lt;/blockquote&gt;&lt;/p&gt;

    </Details></BugPattern><BugPattern abbrev='Nm' category='BAD_PRACTICE' type='NM_WRONG_PACKAGE_INTENTIONAL'><ShortDescription>Method doesn't override method in superclass due to wrong package for parameter</ShortDescription><Details>

  &lt;p&gt; The method in the subclass doesn't override a similar method in a superclass because the type of a parameter doesn't exactly match
the type of the corresponding parameter in the superclass. For example, if you have:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;import alpha.Foo;

public class A {
    public int f(Foo x) { return 17; }
}
----
import beta.Foo;

public class B extends A {
    public int f(Foo x) { return 42; }
    public int f(alpha.Foo x) { return 27; }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The &lt;code&gt;f(Foo)&lt;/code&gt; method defined in class &lt;code&gt;B&lt;/code&gt; doesn't
override the
&lt;code&gt;f(Foo)&lt;/code&gt; method defined in class &lt;code&gt;A&lt;/code&gt;, because the argument
types are &lt;code&gt;Foo&lt;/code&gt;'s from different packages.
&lt;/p&gt;

&lt;p&gt;In this case, the subclass does define a method with a signature identical to the method in the superclass,
so this is presumably understood. However, such methods are exceptionally confusing. You should strongly consider
removing or deprecating the method with the similar but not identical signature.
&lt;/p&gt;

    </Details></BugPattern><BugPattern abbrev='ST' category='STYLE' type='ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD'><ShortDescription>Write to static field from instance method</ShortDescription><Details>

  &lt;p&gt; This instance method writes to a static field. This is tricky to get
correct if multiple instances are being manipulated,
and generally bad practice.
&lt;/p&gt;

    </Details></BugPattern><BugPattern abbrev='BC' category='STYLE' type='BC_UNCONFIRMED_CAST_OF_RETURN_VALUE'><ShortDescription>Unchecked/unconfirmed cast of return value from method</ShortDescription><Details>

&lt;p&gt;
This code performs an unchecked cast of the return value of a method.
The code might be calling the method in such a way that the cast is guaranteed to be
safe, but SpotBugs is unable to verify that the cast is safe.  Check that your program logic ensures that this
cast will not fail.
&lt;/p&gt;

    </Details></BugPattern><BugPattern cweid='374' abbrev='EI' category='MALICIOUS_CODE' type='EI_EXPOSE_REP'><ShortDescription>May expose internal representation by returning reference to mutable object</ShortDescription><Details>

  &lt;p&gt; Returning a reference to a mutable object value stored in one of the object's fields
  exposes the internal representation of the object.&amp;nbsp;
   If instances
   are accessed by untrusted code, and unchecked changes to
   the mutable object would compromise security or other
   important properties, you will need to do something different.
  Returning a new copy of the object is better approach in many situations.&lt;/p&gt;

    </Details></BugPattern><BugPattern abbrev='SIC' category='PERFORMANCE' type='SIC_INNER_SHOULD_BE_STATIC_ANON'><ShortDescription>Could be refactored into a named static inner class</ShortDescription><Details>

  &lt;p&gt; This class is an inner class, but does not use its embedded reference
  to the object which created it.&amp;nbsp; This reference makes the instances
  of the class larger, and may keep the reference to the creator object
  alive longer than necessary.&amp;nbsp; If possible, the class should be
  made into a &lt;em&gt;static&lt;/em&gt; inner class. Since anonymous inner
classes cannot be marked as static, doing this will require refactoring
the inner class so that it is a named inner class.&lt;/p&gt;

    </Details></BugPattern><BugPattern abbrev='DLS' category='CORRECTNESS' type='DLS_DEAD_STORE_OF_CLASS_LITERAL'><ShortDescription>Dead store of class literal</ShortDescription><Details>

&lt;p&gt;
This instruction assigns a class literal to a variable and then never uses it.
&lt;a href="http://www.oracle.com/technetwork/java/javase/compatibility-137462.html#literal"&gt;The behavior of this differs in Java 1.4 and in Java 5.&lt;/a&gt;
In Java 1.4 and earlier, a reference to &lt;code&gt;Foo.class&lt;/code&gt; would force the static initializer
for &lt;code&gt;Foo&lt;/code&gt; to be executed, if it has not been executed already.
In Java 5 and later, it does not.
&lt;/p&gt;
&lt;p&gt;See Sun's &lt;a href="http://www.oracle.com/technetwork/java/javase/compatibility-137462.html#literal"&gt;article on Java SE compatibility&lt;/a&gt;
for more details and examples, and suggestions on how to force class initialization in Java 5.
&lt;/p&gt;

    </Details></BugPattern><BugPattern abbrev='FE' category='STYLE' type='FE_FLOATING_POINT_EQUALITY'><ShortDescription>Test for floating point equality</ShortDescription><Details>
   
    &lt;p&gt;
    This operation compares two floating point values for equality.
    Because floating point calculations may involve rounding,
   calculated float and double values may not be accurate.
    For values that must be precise, such as monetary values,
   consider using a fixed-precision type such as BigDecimal.
    For values that need not be precise, consider comparing for equality
    within some range, for example:
    &lt;code&gt;if ( Math.abs(x - y) &amp;lt; .0000001 )&lt;/code&gt;.
   See the Java Language Specification, section 4.2.4.
    &lt;/p&gt;
    
     </Details></BugPattern><BugPattern abbrev='Se' category='BAD_PRACTICE' type='SE_BAD_FIELD'><ShortDescription>Non-transient non-serializable instance field in serializable class</ShortDescription><Details>

&lt;p&gt; This Serializable class defines a non-primitive instance field which is neither transient,
Serializable, or &lt;code&gt;java.lang.Object&lt;/code&gt;, and does not appear to implement
the &lt;code&gt;Externalizable&lt;/code&gt; interface or the
&lt;code&gt;readObject()&lt;/code&gt; and &lt;code&gt;writeObject()&lt;/code&gt; methods.&amp;nbsp;
Objects of this class will not be deserialized correctly if a non-Serializable
object is stored in this field.&lt;/p&gt;

    </Details></BugPattern><BugPattern abbrev='Se' category='BAD_PRACTICE' type='SE_COMPARATOR_SHOULD_BE_SERIALIZABLE'><ShortDescription>Comparator doesn't implement Serializable</ShortDescription><Details>

  &lt;p&gt; This class implements the &lt;code&gt;Comparator&lt;/code&gt; interface. You
should consider whether or not it should also implement the &lt;code&gt;Serializable&lt;/code&gt;
interface. If a comparator is used to construct an ordered collection
such as a &lt;code&gt;TreeMap&lt;/code&gt;, then the &lt;code&gt;TreeMap&lt;/code&gt;
will be serializable only if the comparator is also serializable.
As most comparators have little or no state, making them serializable
is generally easy and good defensive programming.
&lt;/p&gt;

    </Details></BugPattern><BugPattern abbrev='UrF' category='STYLE' type='URF_UNREAD_PUBLIC_OR_PROTECTED_FIELD'><ShortDescription>Unread public/protected field</ShortDescription><Details>

  &lt;p&gt; This field is never read.&amp;nbsp;
The field is public or protected, so perhaps
    it is intended to be used with classes not seen as part of the analysis. If not,
consider removing it from the class.&lt;/p&gt;

    </Details></BugPattern><BugPattern abbrev='NP' category='STYLE' type='NP_LOAD_OF_KNOWN_NULL_VALUE'><ShortDescription>Load of known null value</ShortDescription><Details>

  &lt;p&gt; The variable referenced at this point is known to be null due to an earlier
   check against null. Although this is valid, it might be a mistake (perhaps you
intended to refer to a different variable, or perhaps the earlier check to see if the
variable is null should have been a check to see if it was non-null).
&lt;/p&gt;

    </Details></BugPattern><BugPattern abbrev='RI' category='STYLE' type='RI_REDUNDANT_INTERFACES'><ShortDescription>Class implements same interface as superclass</ShortDescription><Details>
   
    &lt;p&gt;
    This class declares that it implements an interface that is also implemented by a superclass.
    This is redundant because once a superclass implements an interface, all subclasses by default also
    implement this interface. It may point out that the inheritance hierarchy has changed since
    this class was created, and consideration should be given to the ownership of
    the interface's implementation.
    &lt;/p&gt;
    
     </Details></BugPattern><BugPattern abbrev='DP' category='MALICIOUS_CODE' type='DP_DO_INSIDE_DO_PRIVILEGED'><ShortDescription>Method invoked that should be only be invoked inside a doPrivileged block</ShortDescription><Details>

  &lt;p&gt; This code invokes a method that requires a security permission check.
  If this code will be granted security permissions, but might be invoked by code that does not
  have security permissions, then the invocation needs to occur inside a doPrivileged block.&lt;/p&gt;

    </Details></BugPattern><BugPattern abbrev='UPM' category='PERFORMANCE' type='UPM_UNCALLED_PRIVATE_METHOD'><ShortDescription>Private method is never called</ShortDescription><Details>

&lt;p&gt; This private method is never called. Although it is
possible that the method will be invoked through reflection,
it is more likely that the method is never used, and should be
removed.
&lt;/p&gt;

</Details></BugPattern><BugPattern abbrev='DMI' category='CORRECTNESS' type='DMI_BIGDECIMAL_CONSTRUCTED_FROM_DOUBLE'><ShortDescription>BigDecimal constructed from double that isn't represented precisely</ShortDescription><Details>
      
    &lt;p&gt;
This code creates a BigDecimal from a double value that doesn't translate well to a
decimal number.
For example, one might assume that writing new BigDecimal(0.1) in Java creates a BigDecimal which is exactly equal to 0.1 (an unscaled value of 1, with a scale of 1), but it is actually equal to 0.1000000000000000055511151231257827021181583404541015625.
You probably want to use the BigDecimal.valueOf(double d) method, which uses the String representation
of the double to create the BigDecimal (e.g., BigDecimal.valueOf(0.1) gives 0.1).
&lt;/p&gt;


    </Details></BugPattern><BugPattern abbrev='Nm' category='CORRECTNESS' type='NM_WRONG_PACKAGE'><ShortDescription>Method doesn't override method in superclass due to wrong package for parameter</ShortDescription><Details>

  &lt;p&gt; The method in the subclass doesn't override a similar method in a superclass because the type of a parameter doesn't exactly match
the type of the corresponding parameter in the superclass. For example, if you have:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;import alpha.Foo;

public class A {
    public int f(Foo x) { return 17; }
}
----
import beta.Foo;

public class B extends A {
    public int f(Foo x) { return 42; }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The &lt;code&gt;f(Foo)&lt;/code&gt; method defined in class &lt;code&gt;B&lt;/code&gt; doesn't
override the
&lt;code&gt;f(Foo)&lt;/code&gt; method defined in class &lt;code&gt;A&lt;/code&gt;, because the argument
types are &lt;code&gt;Foo&lt;/code&gt;'s from different packages.
&lt;/p&gt;

    </Details></BugPattern><BugPattern abbrev='Wa' category='MT_CORRECTNESS' type='WA_NOT_IN_LOOP'><ShortDescription>Wait not in loop </ShortDescription><Details>

  &lt;p&gt; This method contains a call to &lt;code&gt;java.lang.Object.wait()&lt;/code&gt;
  which is not in a loop.&amp;nbsp; If the monitor is used for multiple conditions,
  the condition the caller intended to wait for might not be the one
  that actually occurred.&lt;/p&gt;

    </Details></BugPattern><BugPattern abbrev='PZLA' category='STYLE' type='PZLA_PREFER_ZERO_LENGTH_ARRAYS'><ShortDescription>Consider returning a zero length array rather than null</ShortDescription><Details>

&lt;p&gt; It is often a better design to
return a length zero array rather than a null reference to indicate that there
are no results (i.e., an empty list of results).
This way, no explicit check for null is needed by clients of the method.&lt;/p&gt;

&lt;p&gt;On the other hand, using null to indicate
"there is no answer to this question" is probably appropriate.
For example, &lt;code&gt;File.listFiles()&lt;/code&gt; returns an empty list
if given a directory containing no files, and returns null if the file
is not a directory.&lt;/p&gt;

    </Details></BugPattern><BugPattern abbrev='MS' category='MALICIOUS_CODE' type='MS_MUTABLE_COLLECTION_PKGPROTECT'><ShortDescription>Field is a mutable collection which should be package protected</ShortDescription><Details>

 &lt;p&gt;A mutable collection instance is assigned to a final static field,
   thus can be changed by malicious code or by accident from another package.
   The field could be made package protected to avoid this vulnerability.
   Alternatively you may wrap this field into Collections.unmodifiableSet/List/Map/etc.
   to avoid this vulnerability.&lt;/p&gt;

    </Details></BugPattern><BugPattern cweid='89' abbrev='SQL' category='SECURITY' type='SQL_NONCONSTANT_STRING_PASSED_TO_EXECUTE'><ShortDescription>Nonconstant string passed to execute or addBatch method on an SQL statement</ShortDescription><Details>

  &lt;p&gt;The method invokes the execute or addBatch method on an SQL statement with a String that seems
to be dynamically generated. Consider using
a prepared statement instead. It is more efficient and less vulnerable to
SQL injection attacks.
&lt;/p&gt;

    </Details></BugPattern><BugPattern abbrev='DE' category='BAD_PRACTICE' type='DE_MIGHT_IGNORE'><ShortDescription>Method might ignore exception</ShortDescription><Details>

  &lt;p&gt; This method might ignore an exception.&amp;nbsp; In general, exceptions
  should be handled or reported in some way, or they should be thrown
  out of the method.&lt;/p&gt;

    </Details></BugPattern><BugPattern abbrev='IS' category='MT_CORRECTNESS' type='IS2_INCONSISTENT_SYNC'><ShortDescription>Inconsistent synchronization</ShortDescription><Details>

  &lt;p&gt; The fields of this class appear to be accessed inconsistently with respect
  to synchronization.&amp;nbsp; This bug report indicates that the bug pattern detector
  judged that
  &lt;/p&gt;
  &lt;ul&gt;
  &lt;li&gt; The class contains a mix of locked and unlocked accesses,&lt;/li&gt;
  &lt;li&gt; The class is &lt;b&gt;not&lt;/b&gt; annotated as javax.annotation.concurrent.NotThreadSafe,&lt;/li&gt;
  &lt;li&gt; At least one locked access was performed by one of the class's own methods, and&lt;/li&gt;
  &lt;li&gt; The number of unsynchronized field accesses (reads and writes) was no more than
       one third of all accesses, with writes being weighed twice as high as reads&lt;/li&gt;
  &lt;/ul&gt;

  &lt;p&gt; A typical bug matching this bug pattern is forgetting to synchronize
  one of the methods in a class that is intended to be thread-safe.&lt;/p&gt;

  &lt;p&gt; You can select the nodes labeled "Unsynchronized access" to show the
  code locations where the detector believed that a field was accessed
  without synchronization.&lt;/p&gt;

  &lt;p&gt; Note that there are various sources of inaccuracy in this detector;
  for example, the detector cannot statically detect all situations in which
  a lock is held.&amp;nbsp; Also, even when the detector is accurate in
  distinguishing locked vs. unlocked accesses, the code in question may still
  be correct.&lt;/p&gt;


    </Details></BugPattern><BugPattern cweid='382' abbrev='Dm' category='BAD_PRACTICE' type='DM_EXIT'><ShortDescription>Method invokes System.exit(...)</ShortDescription><Details>

  &lt;p&gt; Invoking System.exit shuts down the entire Java virtual machine. This
   should only been done when it is appropriate. Such calls make it
   hard or impossible for your code to be invoked by other code.
   Consider throwing a RuntimeException instead.&lt;/p&gt;

    </Details></BugPattern><BugPattern abbrev='SnVI' category='BAD_PRACTICE' type='SE_NO_SERIALVERSIONID'><ShortDescription>Class is Serializable, but doesn't define serialVersionUID</ShortDescription><Details>

  &lt;p&gt; This class implements the &lt;code&gt;Serializable&lt;/code&gt; interface, but does
  not define a &lt;code&gt;serialVersionUID&lt;/code&gt; field.&amp;nbsp;
  A change as simple as adding a reference to a .class object
    will add synthetic fields to the class,
   which will unfortunately change the implicit
   serialVersionUID (e.g., adding a reference to &lt;code&gt;String.class&lt;/code&gt;
   will generate a static field &lt;code&gt;class$java$lang$String&lt;/code&gt;).
   Also, different source code to bytecode compilers may use different
   naming conventions for synthetic variables generated for
   references to class objects or inner classes.
   To ensure interoperability of Serializable across versions,
   consider adding an explicit serialVersionUID.&lt;/p&gt;

    </Details></BugPattern><BugPattern abbrev='NP' category='CORRECTNESS' type='NP_GUARANTEED_DEREF_ON_EXCEPTION_PATH'><ShortDescription>Value is null and guaranteed to be dereferenced on exception path</ShortDescription><Details>
          
              &lt;p&gt;
              There is a statement or branch on an exception path
                that if executed guarantees that
              a value is null at this point, and that
              value that is guaranteed to be dereferenced
              (except on forward paths involving runtime exceptions).
              &lt;/p&gt;
          
      </Details></BugPattern><BugPattern abbrev='Nm' category='BAD_PRACTICE' type='NM_CONFUSING'><ShortDescription>Confusing method names</ShortDescription><Details>

  &lt;p&gt; The referenced methods have names that differ only by capitalization.&lt;/p&gt;

    </Details></BugPattern><BugPattern abbrev='Dm' category='I18N' type='DM_CONVERT_CASE'><ShortDescription>Consider using Locale parameterized version of invoked method</ShortDescription><Details>

  &lt;p&gt; A String is being converted to upper or lowercase, using the platform's default encoding. This may
      result in improper conversions when used with international characters. Use the &lt;/p&gt;
      &lt;ul&gt;
    &lt;li&gt;String.toUpperCase( Locale l )&lt;/li&gt;
    &lt;li&gt;String.toLowerCase( Locale l )&lt;/li&gt;
    &lt;/ul&gt;
      &lt;p&gt;versions instead.&lt;/p&gt;

    </Details></BugPattern><BugCode abbrev='BC'><Description>Bad casts of object references</Description></BugCode><BugCode cweid='391' abbrev='DE'><Description>Dropped or ignored exception</Description></BugCode><BugCode cweid='476' abbrev='NP'><Description>Null pointer dereference</Description></BugCode><BugCode abbrev='UwF'><Description>Unwritten field</Description></BugCode><BugCode abbrev='SnVI'><Description>Serializable class with no Version ID</Description></BugCode><BugCode cweid='563' abbrev='DLS'><Description>Dead local store</Description></BugCode><BugCode abbrev='Eq'><Description>Problems with implementation of equals()</Description></BugCode><BugCode abbrev='DP'><Description>Use doPrivileged</Description></BugCode><BugCode abbrev='EI2'><Description>Storing reference to mutable object</Description></BugCode><BugCode abbrev='SC'><Description>Constructor invokes Thread.start()</Description></BugCode><BugCode abbrev='UPM'><Description>Private method is never called</Description></BugCode><BugCode abbrev='PZLA'><Description>Prefer zero length arrays to null to indicate no results</Description></BugCode><BugCode abbrev='Nm'><Description>Confusing method name</Description></BugCode><BugCode abbrev='No'><Description>Using notify() rather than notifyAll()</Description></BugCode><BugCode abbrev='ST'><Description>Misuse of static fields</Description></BugCode><BugCode cweid='440' abbrev='DMI'><Description>Dubious method invocation</Description></BugCode><BugCode abbrev='EI'><Description>Method returning array may expose internal representation</Description></BugCode><BugCode cweid='218' abbrev='MS'><Description>Mutable static field</Description></BugCode><BugCode abbrev='UrF'><Description>Unread field</Description></BugCode><BugCode abbrev='Dm'><Description>Dubious method used</Description></BugCode><BugCode cweid='366' abbrev='IS'><Description>Inconsistent synchronization</Description></BugCode><BugCode abbrev='Wa'><Description>Wait not in loop</Description></BugCode><BugCode abbrev='SIC'><Description>Inner class could be made static</Description></BugCode><BugCode cweid='192' abbrev='ICAST'><Description>Casting from integer values</Description></BugCode><BugCode abbrev='SQL'><Description>Potential SQL Problem</Description></BugCode><BugCode abbrev='REC'><Description>RuntimeException capture</Description></BugCode><BugCode abbrev='Se'><Description>Incorrect definition of Serializable class</Description></BugCode><BugCode abbrev='RI'><Description>Redundant Interfaces</Description></BugCode><BugCode cweid='476' abbrev='RCN'><Description>Redundant comparison to null</Description></BugCode><BugCode abbrev='FE'><Description>Test for floating point equality</Description></BugCode><Errors missingClasses='0' errors='0'></Errors><FindBugsSummary num_packages='37' total_classes='907' priority_1='62' priority_2='83' priority_3='295' total_size='40899' clock_seconds='18.98' referenced_classes='1565' vm_version='25.222-b10' total_bugs='440' java_version='1.8.0_222' gc_seconds='0.87' alloc_mbytes='455.50' cpu_seconds='84.17' peak_mbytes='435.34' timestamp='Wed, 11 Sep 2019 10:43:05 +0200'><FileStats path='org/apache/hadoop/filecache/DistributedCache.java' size='39' bugHash='db225acbef2a30e8e1326303e5e434ba' bugCount='1'></FileStats><FileStats path='org/apache/hadoop/mapred/AMFeedback.java' size='23' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapred/BackupStore.java' size='369' bugHash='9ca7c1bf45a5a09b837306abaf32d501' bugCount='1'></FileStats><FileStats path='org/apache/hadoop/mapred/BasicTypeSorterBase.java' size='131' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapred/BufferSorter.java' size='7' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapred/CleanupQueue.java' size='70' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapred/Clock.java' size='5' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapred/ClusterStatus.java' size='195' bugHash='e8b682f492184410c90b633cf3ce83b8' bugCount='2'></FileStats><FileStats path='org/apache/hadoop/mapred/Counters.java' size='293' bugHash='c525f45814d853dffae39e02c28de804' bugCount='1'></FileStats><FileStats path='org/apache/hadoop/mapred/CumulativePeriodicStats.java' size='12' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapred/DeprecatedQueueConfigurationParser.java' size='61' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapred/FileAlreadyExistsException.java' size='8' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapred/FileInputFormat.java' size='358' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapred/FileOutputCommitter.java' size='89' bugHash='74eec2300ce0485d7d9b3fa627937efd' bugCount='5'></FileStats><FileStats path='org/apache/hadoop/mapred/FileOutputFormat.java' size='82' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapred/FileSplit.java' size='39' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapred/FixedLengthInputFormat.java' size='23' bugHash='480d77050543f0c88861cde7d6bddc45' bugCount='1'></FileStats><FileStats path='org/apache/hadoop/mapred/FixedLengthRecordReader.java' size='33' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapred/ID.java' size='7' bugHash='0af155bae558cf27d4730117b48bce1d' bugCount='1'></FileStats><FileStats path='org/apache/hadoop/mapred/IFile.java' size='247' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapred/IFileInputStream.java' size='119' bugHash='54af3c5a176762e79f22c37b005122b6' bugCount='1'></FileStats><FileStats path='org/apache/hadoop/mapred/IFileOutputStream.java' size='36' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapred/IndexCache.java' size='102' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapred/IndexRecord.java' size='12' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapred/InputFormat.java' size='3' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapred/InputSplit.java' size='3' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapred/InputSplitWithLocationInfo.java' size='2' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapred/InvalidFileTypeException.java' size='8' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapred/InvalidInputException.java' size='17' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapred/InvalidJobConfException.java' size='14' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapred/JVMId.java' size='89' bugHash='bd68de4b44a495317014a112e0fde453' bugCount='1'></FileStats><FileStats path='org/apache/hadoop/mapred/JobACLsManager.java' size='40' bugHash='73fb379be4fd858b5f2980f2e3a11b17' bugCount='1'></FileStats><FileStats path='org/apache/hadoop/mapred/JobClient.java' size='564' bugHash='b27ab845becdc7360983e0f593f31ecb' bugCount='7'></FileStats><FileStats path='org/apache/hadoop/mapred/JobConf.java' size='548' bugHash='8e1215f2d2ccdd9daf0098a94cdd17b5' bugCount='1'></FileStats><FileStats path='org/apache/hadoop/mapred/JobConfigurable.java' size='2' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapred/JobContext.java' size='3' bugHash='e8dcaab1369135bb14475b97b1ac5923' bugCount='1'></FileStats><FileStats path='org/apache/hadoop/mapred/JobContextImpl.java' size='15' bugHash='16279a6f26293e6b5f088ac71e1f4225' bugCount='1'></FileStats><FileStats path='org/apache/hadoop/mapred/JobEndNotifier.java' size='96' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapred/JobID.java' size='28' bugHash='f028b431d6b4e585a588f11bdd2181d5' bugCount='1'></FileStats><FileStats path='org/apache/hadoop/mapred/JobInProgress.java' size='33' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapred/JobInfo.java' size='30' bugHash='49fe37a50f4d65a1569121b408180fed' bugCount='1'></FileStats><FileStats path='org/apache/hadoop/mapred/JobPriority.java' size='22' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapred/JobProfile.java' size='67' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapred/JobQueueClient.java' size='135' bugHash='6d43f923b238a23b7ceb02cdc0bb25e9' bugCount='3'></FileStats><FileStats path='org/apache/hadoop/mapred/JobQueueInfo.java' size='54' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapred/JobStatus.java' size='154' bugHash='a3a76f9e879f96adf33f2b72cb0a35bf' bugCount='1'></FileStats><FileStats path='org/apache/hadoop/mapred/JobTracker.java' size='13' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapred/JvmContext.java' size='25' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapred/JvmTask.java' size='32' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapred/KeyValueLineRecordReader.java' size='47' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapred/KeyValueTextInputFormat.java' size='16' bugHash='231dd751d924e366c4f23a6e3f40a856' bugCount='1'></FileStats><FileStats path='org/apache/hadoop/mapred/LineRecordReader.java' size='157' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapred/LocatedFileStatusFetcher.java' size='228' bugHash='dfdaeb1118db26508bbf08312a0545d4' bugCount='1'></FileStats><FileStats path='org/apache/hadoop/mapred/MRConstants.java' size='10' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapred/MROutputFiles.java' size='49' bugHash='52776b08f04d49d4d008c1436fe44513' bugCount='1'></FileStats><FileStats path='org/apache/hadoop/mapred/MapFileOutputFormat.java' size='37' bugHash='d6f074fe2e74f371ccf9fe3957c6be94' bugCount='1'></FileStats><FileStats path='org/apache/hadoop/mapred/MapOutputCollector.java' size='21' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapred/MapOutputFile.java' size='26' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapred/MapReduceBase.java' size='7' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapred/MapRunnable.java' size='2' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapred/MapRunner.java' size='22' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapred/MapTask.java' size='1269' bugHash='391fbd3db3ab25f7abc518612b9515d7' bugCount='7'></FileStats><FileStats path='org/apache/hadoop/mapred/MapTaskCompletionEventsUpdate.java' size='27' bugHash='5ea9d72fe38d421dc8f0b083d8e005f0' bugCount='2'></FileStats><FileStats path='org/apache/hadoop/mapred/MapTaskStatus.java' size='39' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapred/Mapper.java' size='2' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapred/Master.java' size='26' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapred/MergeSorter.java' size='29' bugHash='d23c1818420b4298f9d7544163f46e9f' bugCount='4'></FileStats><FileStats path='org/apache/hadoop/mapred/Merger.java' size='408' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapred/MultiFileInputFormat.java' size='39' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapred/MultiFileSplit.java' size='27' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapred/Operation.java' size='33' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapred/OutputCollector.java' size='2' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapred/OutputCommitter.java' size='57' bugHash='a3f947f45d4df7a402b560ac929cd4c0' bugCount='17'></FileStats><FileStats path='org/apache/hadoop/mapred/OutputFormat.java' size='3' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapred/OutputLogFilter.java' size='8' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapred/Partitioner.java' size='2' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapred/PeriodicStatsAccumulator.java' size='60' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapred/ProgressSplitsBlock.java' size='37' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapred/Queue.java' size='145' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapred/QueueACL.java' size='17' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapred/QueueAclsInfo.java' size='9' bugHash='f73c4edc5fc3efbc0dd05a07bd916f7e' bugCount='1'></FileStats><FileStats path='org/apache/hadoop/mapred/QueueConfigurationParser.java' size='222' bugHash='3af13e78107465381b78eee6b3762b66' bugCount='1'></FileStats><FileStats path='org/apache/hadoop/mapred/QueueManager.java' size='224' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapred/QueueRefresher.java' size='4' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapred/RamManager.java' size='3' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapred/RawKeyValueIterator.java' size='6' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapred/RecordReader.java' size='7' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapred/RecordWriter.java' size='3' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapred/ReduceTask.java' size='388' bugHash='78e55945a315b67e9d74fb9264415a6d' bugCount='4'></FileStats><FileStats path='org/apache/hadoop/mapred/ReduceTaskStatus.java' size='80' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapred/Reducer.java' size='2' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapred/Reporter.java' size='30' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapred/RunningJob.java' size='26' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapred/SequenceFileAsBinaryInputFormat.java' size='60' bugHash='24cf38cca06cc79740d3a02bc6de155b' bugCount='1'></FileStats><FileStats path='org/apache/hadoop/mapred/SequenceFileAsBinaryOutputFormat.java' size='58' bugHash='82bf896916a636bc7a2ca2ec96d1d88c' bugCount='2'></FileStats><FileStats path='org/apache/hadoop/mapred/SequenceFileAsTextInputFormat.java' size='7' bugHash='e8ef492462cf8a0ea518c2cea334f21a' bugCount='1'></FileStats><FileStats path='org/apache/hadoop/mapred/SequenceFileAsTextRecordReader.java' size='33' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapred/SequenceFileInputFilter.java' size='74' bugHash='35364ddf9f795a7d0df606234b7b0597' bugCount='3'></FileStats><FileStats path='org/apache/hadoop/mapred/SequenceFileInputFormat.java' size='17' bugHash='5b93ae72c7f0b63b07f5abf4dd8fc7eb' bugCount='1'></FileStats><FileStats path='org/apache/hadoop/mapred/SequenceFileOutputFormat.java' size='44' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapred/SequenceFileRecordReader.java' size='59' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapred/ShuffleConsumerPlugin.java' size='92' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapred/SkipBadRecords.java' size='52' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapred/SortedRanges.java' size='186' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapred/SpillRecord.java' size='66' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapred/SplitLocationInfo.java' size='14' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapred/StatePeriodicStats.java' size='10' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapred/StatisticsCollector.java' size='201' bugHash='3383976fead9f02c8a0fdf38038009f0' bugCount='2'></FileStats><FileStats path='org/apache/hadoop/mapred/TIPStatus.java' size='14' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapred/Task.java' size='1111' bugHash='89cf06826c652c96e0dd12494103292d' bugCount='11'></FileStats><FileStats path='org/apache/hadoop/mapred/TaskAttemptContext.java' size='6' bugHash='08310d780bd609583b08b7b6b83e4d4d' bugCount='1'></FileStats><FileStats path='org/apache/hadoop/mapred/TaskAttemptContextImpl.java' size='30' bugHash='e21d6493fcba830d3e4c453df94ac5bd' bugCount='5'></FileStats><FileStats path='org/apache/hadoop/mapred/TaskAttemptID.java' size='44' bugHash='b1a1eaa1d709274eae72abfed577b09e' bugCount='4'></FileStats><FileStats path='org/apache/hadoop/mapred/TaskCompletionEvent.java' size='64' bugHash='f01751cdacea8a2cc2842490b2be1e4e' bugCount='3'></FileStats><FileStats path='org/apache/hadoop/mapred/TaskID.java' size='48' bugHash='cb19e7c3ada6742ad51e672e9548224d' bugCount='2'></FileStats><FileStats path='org/apache/hadoop/mapred/TaskLog.java' size='349' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapred/TaskLogAppender.java' size='68' bugHash='a1252dfe765c670d99ec0b155502b3cf' bugCount='4'></FileStats><FileStats path='org/apache/hadoop/mapred/TaskReport.java' size='50' bugHash='7838d6dbc13f1cdc61bc482974cc5762' bugCount='1'></FileStats><FileStats path='org/apache/hadoop/mapred/TaskStatus.java' size='255' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapred/TaskUmbilicalProtocol.java' size='16' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapred/TextInputFormat.java' size='20' bugHash='33ac8efa1c0a3cf2f6541c559d8f067a' bugCount='1'></FileStats><FileStats path='org/apache/hadoop/mapred/TextOutputFormat.java' size='60' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapred/Utils.java' size='17' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapred/jobcontrol/Job.java' size='63' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapred/jobcontrol/JobControl.java' size='38' bugHash='d291d5e282083164adc2fb1ca120c982' bugCount='1'></FileStats><FileStats path='org/apache/hadoop/mapred/join/ArrayListBackedIterator.java' size='7' bugHash='f8c5d67a9272f22cac127a8ce4ee00df' bugCount='1'></FileStats><FileStats path='org/apache/hadoop/mapred/join/ComposableInputFormat.java' size='4' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapred/join/ComposableRecordReader.java' size='7' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapred/join/CompositeInputFormat.java' size='60' bugHash='0fc3c617d8f0d2a82a1b4ca52a37b0f4' bugCount='2'></FileStats><FileStats path='org/apache/hadoop/mapred/join/CompositeInputSplit.java' size='58' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapred/join/CompositeRecordReader.java' size='215' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapred/join/InnerJoinRecordReader.java' size='13' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapred/join/JoinRecordReader.java' size='53' bugHash='4792b6bcd3cca0d61b7576a2becd1984' bugCount='1'></FileStats><FileStats path='org/apache/hadoop/mapred/join/MultiFilterRecordReader.java' size='69' bugHash='175500cf1484578f729a85ce0f00ded0' bugCount='1'></FileStats><FileStats path='org/apache/hadoop/mapred/join/OuterJoinRecordReader.java' size='10' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapred/join/OverrideRecordReader.java' size='32' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapred/join/Parser.java' size='284' bugHash='3705efdc73e3c689a471f3ce6eab0b2f' bugCount='1'></FileStats><FileStats path='org/apache/hadoop/mapred/join/ResetableIterator.java' size='4' bugHash='08fcf13507a9af957a7851d03d43e909' bugCount='2'></FileStats><FileStats path='org/apache/hadoop/mapred/join/StreamBackedIterator.java' size='3' bugHash='976b1dbbda0df139c49da285ae0421df' bugCount='1'></FileStats><FileStats path='org/apache/hadoop/mapred/join/TupleWritable.java' size='16' bugHash='96dea77b799ebe08b70bd4881182fc5e' bugCount='1'></FileStats><FileStats path='org/apache/hadoop/mapred/join/WrappedRecordReader.java' size='92' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapred/lib/BinaryPartitioner.java' size='6' bugHash='66797556c14254b46406c4f1aea21f4b' bugCount='1'></FileStats><FileStats path='org/apache/hadoop/mapred/lib/Chain.java' size='158' bugHash='456b9b8bdbc55a7f8fd87e2840a1352f' bugCount='2'></FileStats><FileStats path='org/apache/hadoop/mapred/lib/ChainMapper.java' size='23' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapred/lib/ChainReducer.java' size='28' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapred/lib/CombineFileInputFormat.java' size='37' bugHash='fe64bf1570c30794e69fd4db14d6a0de' bugCount='1'></FileStats><FileStats path='org/apache/hadoop/mapred/lib/CombineFileRecordReader.java' size='63' bugHash='200ce4f08c4878326d7bf3dd8d2d94a2' bugCount='1'></FileStats><FileStats path='org/apache/hadoop/mapred/lib/CombineFileRecordReaderWrapper.java' size='23' bugHash='95ec8021ad9b15817afb23703ec044b6' bugCount='1'></FileStats><FileStats path='org/apache/hadoop/mapred/lib/CombineFileSplit.java' size='18' bugHash='f8fa4b1b17721a5f7f9b7247d36a1498' bugCount='1'></FileStats><FileStats path='org/apache/hadoop/mapred/lib/CombineSequenceFileInputFormat.java' size='9' bugHash='6713aefa52abc367f653d664cb89880d' bugCount='1'></FileStats><FileStats path='org/apache/hadoop/mapred/lib/CombineTextInputFormat.java' size='9' bugHash='bcbe2e12272caef37d76222c8df1f657' bugCount='1'></FileStats><FileStats path='org/apache/hadoop/mapred/lib/DelegatingInputFormat.java' size='45' bugHash='d47973ba137ae29ed6c5cbf9fb2d7c3f' bugCount='1'></FileStats><FileStats path='org/apache/hadoop/mapred/lib/DelegatingMapper.java' size='19' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapred/lib/FieldSelectionMapReduce.java' size='81' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapred/lib/FilterOutputFormat.java' size='40' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapred/lib/HashPartitioner.java' size='7' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapred/lib/IdentityMapper.java' size='6' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapred/lib/IdentityReducer.java' size='7' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapred/lib/InputSampler.java' size='102' bugHash='88b6eec46fe211d90beb48d62d0cda20' bugCount='5'></FileStats><FileStats path='org/apache/hadoop/mapred/lib/InverseMapper.java' size='6' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapred/lib/KeyFieldBasedComparator.java' size='6' bugHash='ec352aaa2981d614bcfec5e05daa7f56' bugCount='2'></FileStats><FileStats path='org/apache/hadoop/mapred/lib/KeyFieldBasedPartitioner.java' size='6' bugHash='7c5718ed7245946d8604132a1d3fa170' bugCount='1'></FileStats><FileStats path='org/apache/hadoop/mapred/lib/LazyOutputFormat.java' size='47' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapred/lib/LongSumReducer.java' size='9' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapred/lib/MultipleInputs.java' size='42' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapred/lib/MultipleOutputFormat.java' size='65' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapred/lib/MultipleOutputs.java' size='166' bugHash='76c30344407807c2af5250b0f2a52ea4' bugCount='1'></FileStats><FileStats path='org/apache/hadoop/mapred/lib/MultipleSequenceFileOutputFormat.java' size='9' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapred/lib/MultipleTextOutputFormat.java' size='9' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapred/lib/MultithreadedMapRunner.java' size='108' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapred/lib/NLineInputFormat.java' size='21' bugHash='d2e25b580bcd6f24fb467acac1d64ed6' bugCount='1'></FileStats><FileStats path='org/apache/hadoop/mapred/lib/NullOutputFormat.java' size='15' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapred/lib/RegexMapper.java' size='17' bugHash='cdffc6d08710b4c6a0d77263eb76edc9' bugCount='1'></FileStats><FileStats path='org/apache/hadoop/mapred/lib/TaggedInputSplit.java' size='53' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapred/lib/TokenCountMapper.java' size='11' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapred/lib/TotalOrderPartitioner.java' size='13' bugHash='a302639493e6d2adc58b5b2b6c1c1319' bugCount='1'></FileStats><FileStats path='org/apache/hadoop/mapred/lib/aggregate/DoubleValueSum.java' size='3' bugHash='3d8ff1a17885dae3cef538a8657e944b' bugCount='1'></FileStats><FileStats path='org/apache/hadoop/mapred/lib/aggregate/LongValueMax.java' size='3' bugHash='8d625787f44bf85f9e934626c732a347' bugCount='1'></FileStats><FileStats path='org/apache/hadoop/mapred/lib/aggregate/LongValueMin.java' size='3' bugHash='17eb088597ad2c33dd5780c74a0d3c43' bugCount='1'></FileStats><FileStats path='org/apache/hadoop/mapred/lib/aggregate/LongValueSum.java' size='3' bugHash='49e8aa6f99e49ae5254fe7cf0d6a59bc' bugCount='1'></FileStats><FileStats path='org/apache/hadoop/mapred/lib/aggregate/StringValueMax.java' size='3' bugHash='fb229b212049f53493ba8e6bcf4c8134' bugCount='1'></FileStats><FileStats path='org/apache/hadoop/mapred/lib/aggregate/StringValueMin.java' size='3' bugHash='4bd73681fc692635058c5b107fd6af46' bugCount='1'></FileStats><FileStats path='org/apache/hadoop/mapred/lib/aggregate/UniqValueCount.java' size='7' bugHash='9e5dfae870459d83fcd2115319558348' bugCount='1'></FileStats><FileStats path='org/apache/hadoop/mapred/lib/aggregate/UserDefinedValueAggregatorDescriptor.java' size='10' bugHash='c530eaab97c0e7bc5fb168e93a32fbae' bugCount='1'></FileStats><FileStats path='org/apache/hadoop/mapred/lib/aggregate/ValueAggregator.java' size='1' bugHash='e5800d73310d48fc98d4471d5e5261dd' bugCount='1'></FileStats><FileStats path='org/apache/hadoop/mapred/lib/aggregate/ValueAggregatorBaseDescriptor.java' size='40' bugHash='1e61140b55e13582e7fa811addebfec3' bugCount='2'></FileStats><FileStats path='org/apache/hadoop/mapred/lib/aggregate/ValueAggregatorCombiner.java' size='28' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapred/lib/aggregate/ValueAggregatorDescriptor.java' size='6' bugHash='659ad8997bcdb1fe8f1412b273c4235f' bugCount='1'></FileStats><FileStats path='org/apache/hadoop/mapred/lib/aggregate/ValueAggregatorJob.java' size='79' bugHash='cd63b0ac97ba7693c9c90f481498c5ce' bugCount='2'></FileStats><FileStats path='org/apache/hadoop/mapred/lib/aggregate/ValueAggregatorJobBase.java' size='39' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapred/lib/aggregate/ValueAggregatorMapper.java' size='20' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapred/lib/aggregate/ValueAggregatorReducer.java' size='22' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapred/lib/aggregate/ValueHistogram.java' size='3' bugHash='9ccabd30f808cfdf154614eb091c3ec1' bugCount='1'></FileStats><FileStats path='org/apache/hadoop/mapred/lib/db/DBConfiguration.java' size='29' bugHash='68b341fec9de936ee1aab7c0b0e9cc8c' bugCount='1'></FileStats><FileStats path='org/apache/hadoop/mapred/lib/db/DBInputFormat.java' size='97' bugHash='3d7fb016215949e0da1105dd20b42588' bugCount='6'></FileStats><FileStats path='org/apache/hadoop/mapred/lib/db/DBOutputFormat.java' size='40' bugHash='fb214854643cbbae1096c0dcc82bbdcb' bugCount='2'></FileStats><FileStats path='org/apache/hadoop/mapred/lib/db/DBWritable.java' size='1' bugHash='6d8862bba5e4047a0c85909c93dcc331' bugCount='1'></FileStats><FileStats path='org/apache/hadoop/mapred/pipes/Application.java' size='111' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapred/pipes/BinaryProtocol.java' size='257' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapred/pipes/DownwardProtocol.java' size='14' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapred/pipes/OutputHandler.java' size='90' bugHash='0a05775a74984fc2ab8e803a9d6cafbe' bugCount='3'></FileStats><FileStats path='org/apache/hadoop/mapred/pipes/PipesMapRunner.java' size='40' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapred/pipes/PipesNonJavaInputFormat.java' size='32' bugHash='1b27b5dcd890e996d7faf8b71d31245a' bugCount='1'></FileStats><FileStats path='org/apache/hadoop/mapred/pipes/PipesPartitioner.java' size='21' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapred/pipes/PipesReducer.java' size='67' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapred/pipes/Submitter.java' size='229' bugHash='d9686df6f6d3daa664e7bccf74ca1a43' bugCount='1'></FileStats><FileStats path='org/apache/hadoop/mapred/pipes/UpwardProtocol.java' size='10' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/Cluster.java' size='171' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/ClusterMetrics.java' size='92' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/ContextFactory.java' size='128' bugHash='b1f7cca423a5e972b5a006c5da4f0aaa' bugCount='2'></FileStats><FileStats path='org/apache/hadoop/mapreduce/Counter.java' size='8' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/CounterGroup.java' size='1' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/Counters.java' size='59' bugHash='249a8f4b12e7b8fd8a497f732ffd1d40' bugCount='1'></FileStats><FileStats path='org/apache/hadoop/mapreduce/CryptoUtils.java' size='75' bugHash='59722b64d022a62d5f75c2724913ecbc' bugCount='1'></FileStats><FileStats path='org/apache/hadoop/mapreduce/FileSystemCounter.java' size='18' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/ID.java' size='35' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/InputFormat.java' size='5' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/InputSplit.java' size='7' bugHash='cc650c9ec7ddc0b6ade0c26f4b236f53' bugCount='1'></FileStats><FileStats path='org/apache/hadoop/mapreduce/Job.java' size='756' bugHash='15b3429e3131b825222fcf926dafcb00' bugCount='2'></FileStats><FileStats path='org/apache/hadoop/mapreduce/JobACL.java' size='17' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/JobContext.java' size='38' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/JobCounter.java' size='62' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/JobID.java' size='62' bugHash='ef457f8a6d934594e72c4ae632380729' bugCount='2'></FileStats><FileStats path='org/apache/hadoop/mapreduce/JobPriority.java' size='22' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/JobResourceUploader.java' size='440' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/JobStatus.java' size='287' bugHash='9dd5858ec0c1ad4bb87a51009a6b2786' bugCount='5'></FileStats><FileStats path='org/apache/hadoop/mapreduce/JobSubmissionFiles.java' size='58' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/JobSubmitter.java' size='225' bugHash='80f05870817b0c3aee349af8366662c2' bugCount='4'></FileStats><FileStats path='org/apache/hadoop/mapreduce/MRConfig.java' size='40' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/MRJobConfig.java' size='405' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/MapContext.java' size='2' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/Mapper.java' size='21' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/MarkableIterator.java' size='23' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/MarkableIteratorInterface.java' size='4' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/OutputCommitter.java' size='24' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/OutputFormat.java' size='6' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/Partitioner.java' size='4' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/QueueAclsInfo.java' size='26' bugHash='90c5aa6f3d12c0370485ee4d6586de7c' bugCount='2'></FileStats><FileStats path='org/apache/hadoop/mapreduce/QueueInfo.java' size='86' bugHash='e807fdd8b8139218ce64410c0f55b798' bugCount='2'></FileStats><FileStats path='org/apache/hadoop/mapreduce/QueueState.java' size='29' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/RecordReader.java' size='9' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/RecordWriter.java' size='5' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/ReduceContext.java' size='5' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/Reducer.java' size='27' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/SharedCacheConfig.java' size='51' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/StatusReporter.java' size='8' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/TaskAttemptContext.java' size='7' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/TaskAttemptID.java' size='74' bugHash='7078df025f7744643a3b71026b2f5eba' bugCount='2'></FileStats><FileStats path='org/apache/hadoop/mapreduce/TaskCompletionEvent.java' size='112' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/TaskCounter.java' size='62' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/TaskID.java' size='123' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/TaskInputOutputContext.java' size='6' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/TaskReport.java' size='116' bugHash='424689f368803df1584863239a8ef6f3' bugCount='3'></FileStats><FileStats path='org/apache/hadoop/mapreduce/TaskTrackerInfo.java' size='42' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/TaskType.java' size='14' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/checkpoint/CheckpointID.java' size='1' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/checkpoint/CheckpointNamingService.java' size='2' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/checkpoint/CheckpointService.java' size='8' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/checkpoint/EnumCounter.java' size='17' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/checkpoint/FSCheckpointID.java' size='24' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/checkpoint/FSCheckpointService.java' size='92' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/checkpoint/RandomNameCNS.java' size='5' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/checkpoint/SimpleNamingService.java' size='8' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/checkpoint/TaskCheckpointID.java' size='49' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/counters/AbstractCounter.java' size='16' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/counters/AbstractCounterGroup.java' size='91' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/counters/AbstractCounters.java' size='192' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/counters/CounterGroupBase.java' size='12' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/counters/CounterGroupFactory.java' size='62' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/counters/FileSystemCounterGroup.java' size='188' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/counters/FrameworkCounterGroup.java' size='154' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/counters/GenericCounter.java' size='50' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/counters/LimitExceededException.java' size='8' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/counters/Limits.java' size='63' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/counters/package-info.java' size='1' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/filecache/ClientDistributedCacheManager.java' size='123' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/filecache/DistributedCache.java' size='122' bugHash='9b252a63394c9bd964440187714c791d' bugCount='6'></FileStats><FileStats path='org/apache/hadoop/mapreduce/filecache/package-info.java' size='1' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/jobhistory/AMStarted.java' size='224' bugHash='e743b14df32f0a3607e19f4b31b65753' bugCount='2'></FileStats><FileStats path='org/apache/hadoop/mapreduce/jobhistory/AMStartedEvent.java' size='60' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/jobhistory/AvroArrayUtils.java' size='20' bugHash='466a0427a23a54be211c93942e861066' bugCount='2'></FileStats><FileStats path='org/apache/hadoop/mapreduce/jobhistory/Event.java' size='107' bugHash='1848df9aefbbb5a3cdf196610e3e269d' bugCount='2'></FileStats><FileStats path='org/apache/hadoop/mapreduce/jobhistory/EventReader.java' size='92' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/jobhistory/EventType.java' size='45' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/jobhistory/EventWriter.java' size='88' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/jobhistory/Events.java' size='8' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/jobhistory/HistoryEvent.java' size='6' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/jobhistory/HistoryEventHandler.java' size='2' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/jobhistory/HistoryViewer.java' size='285' bugHash='0983dc65dc653cda0add4bdc67ffe651' bugCount='2'></FileStats><FileStats path='org/apache/hadoop/mapreduce/jobhistory/HistoryViewerPrinter.java' size='2' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/jobhistory/HumanReadableHistoryViewerPrinter.java' size='347' bugHash='a505135572727ba11e45c5baf898e5f5' bugCount='1'></FileStats><FileStats path='org/apache/hadoop/mapreduce/jobhistory/JSONHistoryViewerPrinter.java' size='167' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/jobhistory/JhCounter.java' size='136' bugHash='c5f0f6ee3928fe40a534288b89b3b355' bugCount='2'></FileStats><FileStats path='org/apache/hadoop/mapreduce/jobhistory/JhCounterGroup.java' size='137' bugHash='4ed467a91dcbcb455907a1adfaa270be' bugCount='2'></FileStats><FileStats path='org/apache/hadoop/mapreduce/jobhistory/JhCounters.java' size='107' bugHash='990011a908604d2249f8b9a37fdd2da2' bugCount='2'></FileStats><FileStats path='org/apache/hadoop/mapreduce/jobhistory/JobFinished.java' size='370' bugHash='b48a10d881d9ef34ad5325054c72a468' bugCount='3'></FileStats><FileStats path='org/apache/hadoop/mapreduce/jobhistory/JobFinishedEvent.java' size='107' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/jobhistory/JobHistoryParser.java' size='552' bugHash='7c7b201ba59c055aa3b662e8c13ee1c9' bugCount='19'></FileStats><FileStats path='org/apache/hadoop/mapreduce/jobhistory/JobInfoChange.java' size='135' bugHash='24e14b16dbb30806a5f96014645d1bb3' bugCount='2'></FileStats><FileStats path='org/apache/hadoop/mapreduce/jobhistory/JobInfoChangeEvent.java' size='32' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/jobhistory/JobInited.java' size='223' bugHash='86a52d6ead62e37282cc4688e999b44a' bugCount='2'></FileStats><FileStats path='org/apache/hadoop/mapreduce/jobhistory/JobInitedEvent.java' size='43' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/jobhistory/JobPriorityChange.java' size='107' bugHash='600295192666793d418ac8e5be341f21' bugCount='2'></FileStats><FileStats path='org/apache/hadoop/mapreduce/jobhistory/JobPriorityChangeEvent.java' size='28' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/jobhistory/JobQueueChange.java' size='107' bugHash='1c146a525c934b1f687dcfc7996040dc' bugCount='2'></FileStats><FileStats path='org/apache/hadoop/mapreduce/jobhistory/JobQueueChangeEvent.java' size='30' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/jobhistory/JobStatusChanged.java' size='107' bugHash='e9fb6007b6b500ebdefd3d2af47cd9d8' bugCount='2'></FileStats><FileStats path='org/apache/hadoop/mapreduce/jobhistory/JobStatusChangedEvent.java' size='28' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/jobhistory/JobSubmitted.java' size='406' bugHash='88bfcbfaf84f544f59f79e56495372eb' bugCount='3'></FileStats><FileStats path='org/apache/hadoop/mapreduce/jobhistory/JobSubmittedEvent.java' size='113' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/jobhistory/JobUnsuccessfulCompletion.java' size='340' bugHash='aadcb9be46502876ec8a3cdf200a6ee1' bugCount='3'></FileStats><FileStats path='org/apache/hadoop/mapreduce/jobhistory/JobUnsuccessfulCompletionEvent.java' size='80' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/jobhistory/MapAttemptFinished.java' size='494' bugHash='5e7cc5cf2713289d484a6701923cd48d' bugCount='3'></FileStats><FileStats path='org/apache/hadoop/mapreduce/jobhistory/MapAttemptFinishedEvent.java' size='140' bugHash='4160746a1e039d162967ed1c8d792d2a' bugCount='9'></FileStats><FileStats path='org/apache/hadoop/mapreduce/jobhistory/NormalizedResourceEvent.java' size='26' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/jobhistory/ReduceAttemptFinished.java' size='523' bugHash='38ad0fefc1fe728769208be81688b24c' bugCount='3'></FileStats><FileStats path='org/apache/hadoop/mapreduce/jobhistory/ReduceAttemptFinishedEvent.java' size='147' bugHash='f6e1c26288104e4dd3f1354e901b3455' bugCount='9'></FileStats><FileStats path='org/apache/hadoop/mapreduce/jobhistory/TaskAttemptFinished.java' size='316' bugHash='421dd49edff712f3ba1b64bdda68f59d' bugCount='3'></FileStats><FileStats path='org/apache/hadoop/mapreduce/jobhistory/TaskAttemptFinishedEvent.java' size='92' bugHash='20cdeb6b50bb76843f1dea0794e8646c' bugCount='4'></FileStats><FileStats path='org/apache/hadoop/mapreduce/jobhistory/TaskAttemptStarted.java' size='344' bugHash='dad1b9e48515a6883e0b99a681ff1e8e' bugCount='3'></FileStats><FileStats path='org/apache/hadoop/mapreduce/jobhistory/TaskAttemptStartedEvent.java' size='70' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/jobhistory/TaskAttemptUnsuccessfulCompletion.java' size='465' bugHash='38a5859888c25779617ee59e5cf1cba5' bugCount='3'></FileStats><FileStats path='org/apache/hadoop/mapreduce/jobhistory/TaskAttemptUnsuccessfulCompletionEvent.java' size='154' bugHash='e32f2f994da8a960794d1b9c8b0cc8a2' bugCount='8'></FileStats><FileStats path='org/apache/hadoop/mapreduce/jobhistory/TaskFailed.java' size='256' bugHash='07a95912178c427aa3ea64dfcdc019f6' bugCount='2'></FileStats><FileStats path='org/apache/hadoop/mapreduce/jobhistory/TaskFailedEvent.java' size='94' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/jobhistory/TaskFinished.java' size='226' bugHash='a38a7599bbcd70a9d90d4176f2e3f2ed' bugCount='2'></FileStats><FileStats path='org/apache/hadoop/mapreduce/jobhistory/TaskFinishedEvent.java' size='78' bugHash='a521a3f8a1aadbdab684048a9eb134b3' bugCount='1'></FileStats><FileStats path='org/apache/hadoop/mapreduce/jobhistory/TaskStarted.java' size='166' bugHash='4106e085e302522dcf17a7f2645cd9e0' bugCount='2'></FileStats><FileStats path='org/apache/hadoop/mapreduce/jobhistory/TaskStartedEvent.java' size='35' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/jobhistory/TaskUpdated.java' size='106' bugHash='87fb6050ee365fe6ed7a10f05a796c67' bugCount='2'></FileStats><FileStats path='org/apache/hadoop/mapreduce/jobhistory/TaskUpdatedEvent.java' size='27' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/jobhistory/package-info.java' size='1' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/lib/aggregate/DoubleValueSum.java' size='24' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/lib/aggregate/LongValueMax.java' size='27' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/lib/aggregate/LongValueMin.java' size='27' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/lib/aggregate/LongValueSum.java' size='24' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/lib/aggregate/StringValueMax.java' size='23' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/lib/aggregate/StringValueMin.java' size='23' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/lib/aggregate/UniqValueCount.java' size='45' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/lib/aggregate/UserDefinedValueAggregatorDescriptor.java' size='38' bugHash='1e5a6f833961de8441f9f4daf9ea4761' bugCount='1'></FileStats><FileStats path='org/apache/hadoop/mapreduce/lib/aggregate/ValueAggregator.java' size='5' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/lib/aggregate/ValueAggregatorBaseDescriptor.java' size='68' bugHash='fd7c995bfa18bd0754d2992344b92a4f' bugCount='1'></FileStats><FileStats path='org/apache/hadoop/mapreduce/lib/aggregate/ValueAggregatorCombiner.java' size='24' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/lib/aggregate/ValueAggregatorDescriptor.java' size='7' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/lib/aggregate/ValueAggregatorJob.java' size='75' bugHash='e431ced33c4e76f46de8e6281a6d9833' bugCount='1'></FileStats><FileStats path='org/apache/hadoop/mapreduce/lib/aggregate/ValueAggregatorJobBase.java' size='40' bugHash='093fb0d786e5d4e8e672537a610ad82b' bugCount='1'></FileStats><FileStats path='org/apache/hadoop/mapreduce/lib/aggregate/ValueAggregatorMapper.java' size='21' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/lib/aggregate/ValueAggregatorReducer.java' size='25' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/lib/aggregate/ValueHistogram.java' size='87' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/lib/chain/Chain.java' size='423' bugHash='b4ac645dfd5f2f9edb63bc739bd862e0' bugCount='5'></FileStats><FileStats path='org/apache/hadoop/mapreduce/lib/chain/ChainMapContextImpl.java' size='118' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/lib/chain/ChainMapper.java' size='31' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/lib/chain/ChainReduceContextImpl.java' size='115' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/lib/chain/ChainReducer.java' size='37' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/lib/db/BigDecimalSplitter.java' size='53' bugHash='c1b799d52c16c3e25f338363f3b41e46' bugCount='1'></FileStats><FileStats path='org/apache/hadoop/mapreduce/lib/db/BooleanSplitter.java' size='17' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/lib/db/DBConfiguration.java' size='103' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/lib/db/DBInputFormat.java' size='158' bugHash='8e840165d79292129fe3b5c4d5502de3' bugCount='2'></FileStats><FileStats path='org/apache/hadoop/mapreduce/lib/db/DBOutputFormat.java' size='112' bugHash='0ce1f769d47c1582f4c416d7194bf0ed' bugCount='3'></FileStats><FileStats path='org/apache/hadoop/mapreduce/lib/db/DBRecordReader.java' size='122' bugHash='368dc9069c4af443150cd613e5737cf3' bugCount='2'></FileStats><FileStats path='org/apache/hadoop/mapreduce/lib/db/DBSplitter.java' size='2' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/lib/db/DBWritable.java' size='3' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/lib/db/DataDrivenDBInputFormat.java' size='119' bugHash='c55f6f0e50fd5a9dd0af0741331473c8' bugCount='2'></FileStats><FileStats path='org/apache/hadoop/mapreduce/lib/db/DataDrivenDBRecordReader.java' size='42' bugHash='a57c0066cd02be6a82fb207e11aadcca' bugCount='1'></FileStats><FileStats path='org/apache/hadoop/mapreduce/lib/db/DateSplitter.java' size='63' bugHash='7578735fee637bf9b90dda33e57d3817' bugCount='3'></FileStats><FileStats path='org/apache/hadoop/mapreduce/lib/db/FloatSplitter.java' size='40' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/lib/db/IntegerSplitter.java' size='43' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/lib/db/MySQLDBRecordReader.java' size='8' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/lib/db/MySQLDataDrivenDBRecordReader.java' size='8' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/lib/db/OracleDBRecordReader.java' size='61' bugHash='c4ed2effef5e94a2c11d18b016b2cd04' bugCount='2'></FileStats><FileStats path='org/apache/hadoop/mapreduce/lib/db/OracleDataDrivenDBInputFormat.java' size='15' bugHash='4e9e5c9ef35425626c5fcdc269246bde' bugCount='1'></FileStats><FileStats path='org/apache/hadoop/mapreduce/lib/db/OracleDataDrivenDBRecordReader.java' size='5' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/lib/db/OracleDateSplitter.java' size='5' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/lib/db/TextSplitter.java' size='80' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/lib/fieldsel/FieldSelectionHelper.java' size='112' bugHash='779e28bbe2f192eff0480d473d3a2510' bugCount='3'></FileStats><FileStats path='org/apache/hadoop/mapreduce/lib/fieldsel/FieldSelectionMapper.java' size='36' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/lib/fieldsel/FieldSelectionReducer.java' size='35' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/lib/input/CombineFileInputFormat.java' size='359' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/lib/input/CombineFileRecordReader.java' size='71' bugHash='6ecfd5d770489f401d349d585d585e15' bugCount='2'></FileStats><FileStats path='org/apache/hadoop/mapreduce/lib/input/CombineFileRecordReaderWrapper.java' size='41' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/lib/input/CombineFileSplit.java' size='96' bugHash='dd00d5d45c68d0d1743bb0f997d9cf47' bugCount='4'></FileStats><FileStats path='org/apache/hadoop/mapreduce/lib/input/CombineSequenceFileInputFormat.java' size='9' bugHash='50373be83eb4677dc8773f87da3cb7fd' bugCount='1'></FileStats><FileStats path='org/apache/hadoop/mapreduce/lib/input/CombineTextInputFormat.java' size='9' bugHash='784545bee8ad1912ba6f6dc17e9f6bd4' bugCount='1'></FileStats><FileStats path='org/apache/hadoop/mapreduce/lib/input/CompressedSplitLineReader.java' size='31' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/lib/input/DelegatingInputFormat.java' size='47' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/lib/input/DelegatingMapper.java' size='14' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/lib/input/DelegatingRecordReader.java' size='25' bugHash='fd2b93ee3caddd2b70ae729054f854a2' bugCount='2'></FileStats><FileStats path='org/apache/hadoop/mapreduce/lib/input/FileInputFormat.java' size='260' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/lib/input/FileInputFormatCounter.java' size='10' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/lib/input/FileSplit.java' size='51' bugHash='fd2cfe794433dab961cea978ea5194fc' bugCount='3'></FileStats><FileStats path='org/apache/hadoop/mapreduce/lib/input/FixedLengthInputFormat.java' size='18' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/lib/input/FixedLengthRecordReader.java' size='115' bugHash='bed97786b851ad9bf94dcfcaf6b3425e' bugCount='4'></FileStats><FileStats path='org/apache/hadoop/mapreduce/lib/input/InvalidInputException.java' size='17' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/lib/input/KeyValueLineRecordReader.java' size='61' bugHash='49d04d03e192a63c8c3fcc97013a22eb' bugCount='2'></FileStats><FileStats path='org/apache/hadoop/mapreduce/lib/input/KeyValueTextInputFormat.java' size='12' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/lib/input/LineRecordReader.java' size='121' bugHash='8b5eeee8c47277b075a3117ab97aca89' bugCount='2'></FileStats><FileStats path='org/apache/hadoop/mapreduce/lib/input/MultipleInputs.java' size='49' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/lib/input/NLineInputFormat.java' size='50' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/lib/input/SequenceFileAsBinaryInputFormat.java' size='67' bugHash='9b6aacdc50d160fc12e1bda79bd17efe' bugCount='3'></FileStats><FileStats path='org/apache/hadoop/mapreduce/lib/input/SequenceFileAsTextInputFormat.java' size='7' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/lib/input/SequenceFileAsTextRecordReader.java' size='33' bugHash='04ece5a5d3e792a0ed2a18735171c6ba' bugCount='2'></FileStats><FileStats path='org/apache/hadoop/mapreduce/lib/input/SequenceFileInputFilter.java' size='138' bugHash='ea9bdcce9999e62e56c6a77145a3fa89' bugCount='4'></FileStats><FileStats path='org/apache/hadoop/mapreduce/lib/input/SequenceFileInputFormat.java' size='17' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/lib/input/SequenceFileRecordReader.java' size='46' bugHash='934fa6f2d8ff28caff0c782a57b1e9e9' bugCount='1'></FileStats><FileStats path='org/apache/hadoop/mapreduce/lib/input/SplitLineReader.java' size='9' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/lib/input/TaggedInputSplit.java' size='60' bugHash='205dc0dad6f9ee0b765d7f8f5e7a650b' bugCount='2'></FileStats><FileStats path='org/apache/hadoop/mapreduce/lib/input/TextInputFormat.java' size='15' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/lib/input/UncompressedSplitLineReader.java' size='40' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/lib/jobcontrol/ControlledJob.java' size='155' bugHash='1e4fc84fb74471dfcd2fc3dd65561892' bugCount='3'></FileStats><FileStats path='org/apache/hadoop/mapreduce/lib/jobcontrol/JobControl.java' size='184' bugHash='1c82bc168c703b669d8c9e56f87b45ac' bugCount='1'></FileStats><FileStats path='org/apache/hadoop/mapreduce/lib/join/ArrayListBackedIterator.java' size='42' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/lib/join/ComposableInputFormat.java' size='6' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/lib/join/ComposableRecordReader.java' size='11' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/lib/join/CompositeInputFormat.java' size='60' bugHash='a3def3f863a5143c728af684ed612a13' bugCount='2'></FileStats><FileStats path='org/apache/hadoop/mapreduce/lib/join/CompositeInputSplit.java' size='67' bugHash='957160cfa25881d0ca4543457b891f49' bugCount='2'></FileStats><FileStats path='org/apache/hadoop/mapreduce/lib/join/CompositeRecordReader.java' size='231' bugHash='160f0dc2a0197ecaa687fd6ec3cdcd2f' bugCount='2'></FileStats><FileStats path='org/apache/hadoop/mapreduce/lib/join/InnerJoinRecordReader.java' size='13' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/lib/join/JoinRecordReader.java' size='55' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/lib/join/MultiFilterRecordReader.java' size='65' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/lib/join/OuterJoinRecordReader.java' size='10' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/lib/join/OverrideRecordReader.java' size='44' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/lib/join/Parser.java' size='308' bugHash='d8fc6bb1ce872a4fce61ba8134db247f' bugCount='1'></FileStats><FileStats path='org/apache/hadoop/mapreduce/lib/join/ResetableIterator.java' size='25' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/lib/join/StreamBackedIterator.java' size='53' bugHash='9746c52582fadf7b2ae992c29af9a456' bugCount='3'></FileStats><FileStats path='org/apache/hadoop/mapreduce/lib/join/TupleWritable.java' size='143' bugHash='eeae4ef46f05549815628c6ce66eb649' bugCount='1'></FileStats><FileStats path='org/apache/hadoop/mapreduce/lib/join/WrappedRecordReader.java' size='105' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/lib/map/InverseMapper.java' size='6' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/lib/map/MultithreadedMapper.java' size='137' bugHash='43d78f020e34a6250393182005ca21a2' bugCount='2'></FileStats><FileStats path='org/apache/hadoop/mapreduce/lib/map/RegexMapper.java' size='23' bugHash='07df48fbdc4005e111b9a1c28807d194' bugCount='3'></FileStats><FileStats path='org/apache/hadoop/mapreduce/lib/map/TokenCounterMapper.java' size='16' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/lib/map/WrappedMapper.java' size='115' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/lib/output/BindingPathOutputCommitter.java' size='54' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/lib/output/FileOutputCommitter.java' size='297' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/lib/output/FileOutputCommitterFactory.java' size='5' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/lib/output/FileOutputFormat.java' size='111' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/lib/output/FileOutputFormatCounter.java' size='10' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/lib/output/FilterOutputFormat.java' size='42' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/lib/output/LazyOutputFormat.java' size='46' bugHash='14ef5141fb35ced7490e2b222d09f7af' bugCount='1'></FileStats><FileStats path='org/apache/hadoop/mapreduce/lib/output/MapFileOutputFormat.java' size='53' bugHash='472f57f0e56d5d8d711df147764ea758' bugCount='1'></FileStats><FileStats path='org/apache/hadoop/mapreduce/lib/output/MultipleOutputs.java' size='165' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/lib/output/NamedCommitterFactory.java' size='22' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/lib/output/NullOutputFormat.java' size='37' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/lib/output/PartialFileOutputCommitter.java' size='33' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/lib/output/PartialOutputCommitter.java' size='2' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/lib/output/PathOutputCommitter.java' size='22' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/lib/output/PathOutputCommitterFactory.java' size='40' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/lib/output/SequenceFileAsBinaryOutputFormat.java' size='67' bugHash='81a575b37dbcdf1e8ec4b738ba976499' bugCount='3'></FileStats><FileStats path='org/apache/hadoop/mapreduce/lib/output/SequenceFileOutputFormat.java' size='39' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/lib/output/TextOutputFormat.java' size='65' bugHash='b219f3a158643bd44864152bdb75244c' bugCount='2'></FileStats><FileStats path='org/apache/hadoop/mapreduce/lib/partition/BinaryPartitioner.java' size='33' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/lib/partition/HashPartitioner.java' size='5' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/lib/partition/InputSampler.java' size='208' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/lib/partition/KeyFieldBasedComparator.java' size='172' bugHash='3a110f61b7dcb417778bcfed885291b4' bugCount='3'></FileStats><FileStats path='org/apache/hadoop/mapreduce/lib/partition/KeyFieldBasedPartitioner.java' size='59' bugHash='5c7e7979989e37208a9dbc6ac82c317e' bugCount='1'></FileStats><FileStats path='org/apache/hadoop/mapreduce/lib/partition/KeyFieldHelper.java' size='164' bugHash='41640aa6289b8b992a5cc0f05c0d9665' bugCount='3'></FileStats><FileStats path='org/apache/hadoop/mapreduce/lib/partition/RehashPartitioner.java' size='9' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/lib/partition/TotalOrderPartitioner.java' size='183' bugHash='ed7c9832502cb90e4ccadfc0ff3756d1' bugCount='1'></FileStats><FileStats path='org/apache/hadoop/mapreduce/lib/reduce/IntSumReducer.java' size='13' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/lib/reduce/LongSumReducer.java' size='13' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/lib/reduce/WrappedReducer.java' size='117' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/protocol/ClientProtocol.java' size='32' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/protocol/ClientProtocolProvider.java' size='6' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/protocol/package-info.java' size='1' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/security/SecureShuffleUtils.java' size='41' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/security/TokenCache.java' size='95' bugHash='c7b26c32ad70536bd0ef504153754b58' bugCount='1'></FileStats><FileStats path='org/apache/hadoop/mapreduce/security/token/JobTokenIdentifier.java' size='32' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/security/token/JobTokenSecretManager.java' size='42' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/security/token/JobTokenSelector.java' size='12' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/security/token/delegation/DelegationTokenIdentifier.java' size='12' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/security/token/delegation/DelegationTokenSecretManager.java' size='8' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/security/token/delegation/DelegationTokenSelector.java' size='4' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/security/token/delegation/package-info.java' size='1' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/security/token/package-info.java' size='1' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/server/jobtracker/JTConfig.java' size='10' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/server/tasktracker/TTConfig.java' size='34' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/split/JobSplit.java' size='123' bugHash='6fb7a56f6362f61a4dd9f1460b73e15f' bugCount='5'></FileStats><FileStats path='org/apache/hadoop/mapreduce/split/JobSplitWriter.java' size='94' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/split/SplitMetaInfoReader.java' size='31' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/split/package-info.java' size='1' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/task/JobContextImpl.java' size='112' bugHash='ff566cbd300b4122c66d7cb5aa84818f' bugCount='1'></FileStats><FileStats path='org/apache/hadoop/mapreduce/task/MapContextImpl.java' size='16' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/task/ReduceContextImpl.java' size='230' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/task/TaskAttemptContextImpl.java' size='54' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/task/TaskInputOutputContextImpl.java' size='16' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/task/annotation/Checkpointable.java' size='1' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/task/package-info.java' size='1' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/task/reduce/EventFetcher.java' size='80' bugHash='4353ff35fd3d4e86c41514d3c4af51f4' bugCount='2'></FileStats><FileStats path='org/apache/hadoop/mapreduce/task/reduce/ExceptionReporter.java' size='2' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/task/reduce/Fetcher.java' size='419' bugHash='b4e70ce075d18352e90a2d9273939356' bugCount='2'></FileStats><FileStats path='org/apache/hadoop/mapreduce/task/reduce/IFileWrappedMapOutput.java' size='14' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/task/reduce/InMemoryMapOutput.java' size='46' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/task/reduce/InMemoryReader.java' size='70' bugHash='26066994e41e30b7dc426dc573e334ad' bugCount='1'></FileStats><FileStats path='org/apache/hadoop/mapreduce/task/reduce/InMemoryWriter.java' size='26' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/task/reduce/LocalFetcher.java' size='64' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/task/reduce/MapHost.java' size='57' bugHash='3bd95c88b0e71a6cc371926d4cf6b970' bugCount='1'></FileStats><FileStats path='org/apache/hadoop/mapreduce/task/reduce/MapOutput.java' size='50' bugHash='17bcff4f90184b8b8b4899248e0a0a80' bugCount='1'></FileStats><FileStats path='org/apache/hadoop/mapreduce/task/reduce/MergeManager.java' size='4' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/task/reduce/MergeManagerImpl.java' size='485' bugHash='d4d98ce33378fa01ed828180b4b4c559' bugCount='5'></FileStats><FileStats path='org/apache/hadoop/mapreduce/task/reduce/MergeThread.java' size='65' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/task/reduce/OnDiskMapOutput.java' size='69' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/task/reduce/Shuffle.java' size='103' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/task/reduce/ShuffleClientMetrics.java' size='27' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/task/reduce/ShuffleHeader.java' size='31' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/task/reduce/ShuffleScheduler.java' size='4' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/task/reduce/ShuffleSchedulerImpl.java' size='406' bugHash='3c4f574a7274eb07c45ca557db43918b' bugCount='4'></FileStats><FileStats path='org/apache/hadoop/mapreduce/task/reduce/package-info.java' size='1' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/tools/CLI.java' size='513' bugHash='366cae789fc8b547770bd8cd17060c3f' bugCount='2'></FileStats><FileStats path='org/apache/hadoop/mapreduce/util/ConfigUtil.java' size='17' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/util/CountersStrings.java' size='121' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/util/HostUtil.java' size='12' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/util/JobHistoryEventUtils.java' size='37' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/util/MRJobConfUtil.java' size='14' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/util/ProcessTree.java' size='145' bugHash='b1e5320a9cad0572157cca25f19ec935' bugCount='2'></FileStats><FileStats path='org/apache/hadoop/mapreduce/util/ResourceBundles.java' size='20' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/util/package-info.java' size='1' bugCount='0'></FileStats><FileStats path='org/apache/hadoop/mapreduce/v2/LogParams.java' size='31' bugCount='0'></FileStats><PackageStats package='org.apache.hadoop.filecache' priority_1='1' total_bugs='1' total_size='39' total_types='1'><ClassStats bugs='1' size='39' priority_1='1' interface='false' sourceFile='DistributedCache.java' class='org.apache.hadoop.filecache.DistributedCache'></ClassStats></PackageStats><PackageStats package='org.apache.hadoop.mapred' priority_1='15' total_bugs='112' priority_2='25' priority_3='72' total_size='11299' total_types='258'><ClassStats bugs='0' size='23' interface='false' sourceFile='AMFeedback.java' class='org.apache.hadoop.mapred.AMFeedback'></ClassStats><ClassStats bugs='0' size='197' interface='false' sourceFile='BackupStore.java' class='org.apache.hadoop.mapred.BackupStore'></ClassStats><ClassStats bugs='0' size='30' interface='false' sourceFile='BackupStore.java' class='org.apache.hadoop.mapred.BackupStore$BackupRamManager'></ClassStats><ClassStats bugs='0' size='58' interface='false' sourceFile='BackupStore.java' class='org.apache.hadoop.mapred.BackupStore$FileCache'></ClassStats><ClassStats bugs='1' size='84' priority_3='1' interface='false' sourceFile='BackupStore.java' class='org.apache.hadoop.mapred.BackupStore$MemoryCache'></ClassStats><ClassStats bugs='0' size='69' interface='false' sourceFile='BasicTypeSorterBase.java' class='org.apache.hadoop.mapred.BasicTypeSorterBase'></ClassStats><ClassStats bugs='0' size='7' interface='true' sourceFile='BufferSorter.java' class='org.apache.hadoop.mapred.BufferSorter'></ClassStats><ClassStats bugs='0' size='25' interface='false' sourceFile='CleanupQueue.java' class='org.apache.hadoop.mapred.CleanupQueue'></ClassStats><ClassStats bugs='0' size='33' interface='false' sourceFile='CleanupQueue.java' class='org.apache.hadoop.mapred.CleanupQueue$PathCleanupThread'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='CleanupQueue.java' class='org.apache.hadoop.mapred.CleanupQueue$PathDeletionContext'></ClassStats><ClassStats bugs='0' size='5' interface='false' sourceFile='Clock.java' class='org.apache.hadoop.mapred.Clock'></ClassStats><ClassStats bugs='0' size='132' interface='false' sourceFile='ClusterStatus.java' class='org.apache.hadoop.mapred.ClusterStatus'></ClassStats><ClassStats bugs='2' size='63' priority_3='2' interface='false' sourceFile='ClusterStatus.java' class='org.apache.hadoop.mapred.ClusterStatus$BlackListInfo'></ClassStats><ClassStats bugs='0' size='111' interface='false' sourceFile='Counters.java' class='org.apache.hadoop.mapred.Counters'></ClassStats><ClassStats bugs='0' size='1' interface='false' sourceFile='Counters.java' class='org.apache.hadoop.mapred.Counters$1'></ClassStats><ClassStats bugs='0' size='49' interface='false' sourceFile='Counters.java' class='org.apache.hadoop.mapred.Counters$Counter'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='Counters.java' class='org.apache.hadoop.mapred.Counters$CountersExceededException'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='Counters.java' class='org.apache.hadoop.mapred.Counters$FSGroupImpl'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='Counters.java' class='org.apache.hadoop.mapred.Counters$FrameworkGroupImpl'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='Counters.java' class='org.apache.hadoop.mapred.Counters$GenericGroup'></ClassStats><ClassStats bugs='0' size='73' interface='false' sourceFile='Counters.java' class='org.apache.hadoop.mapred.Counters$Group'></ClassStats><ClassStats bugs='1' size='11' priority_3='1' interface='false' sourceFile='Counters.java' class='org.apache.hadoop.mapred.Counters$GroupFactory'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='Counters.java' class='org.apache.hadoop.mapred.Counters$GroupFactory$1'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='CumulativePeriodicStats.java' class='org.apache.hadoop.mapred.CumulativePeriodicStats'></ClassStats><ClassStats bugs='0' size='61' interface='false' sourceFile='DeprecatedQueueConfigurationParser.java' class='org.apache.hadoop.mapred.DeprecatedQueueConfigurationParser'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='FileAlreadyExistsException.java' class='org.apache.hadoop.mapred.FileAlreadyExistsException'></ClassStats><ClassStats bugs='0' size='297' interface='false' sourceFile='FileInputFormat.java' class='org.apache.hadoop.mapred.FileInputFormat'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='FileInputFormat.java' class='org.apache.hadoop.mapred.FileInputFormat$1'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='FileInputFormat.java' class='org.apache.hadoop.mapred.FileInputFormat$2'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='FileInputFormat.java' class='org.apache.hadoop.mapred.FileInputFormat$Counter'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='FileInputFormat.java' class='org.apache.hadoop.mapred.FileInputFormat$MultiPathFilter'></ClassStats><ClassStats bugs='0' size='22' interface='false' sourceFile='FileInputFormat.java' class='org.apache.hadoop.mapred.FileInputFormat$NodeInfo'></ClassStats><ClassStats bugs='5' size='89' priority_2='4' priority_3='1' interface='false' sourceFile='FileOutputCommitter.java' class='org.apache.hadoop.mapred.FileOutputCommitter'></ClassStats><ClassStats bugs='0' size='72' interface='false' sourceFile='FileOutputFormat.java' class='org.apache.hadoop.mapred.FileOutputFormat'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='FileOutputFormat.java' class='org.apache.hadoop.mapred.FileOutputFormat$Counter'></ClassStats><ClassStats bugs='0' size='39' interface='false' sourceFile='FileSplit.java' class='org.apache.hadoop.mapred.FileSplit'></ClassStats><ClassStats bugs='1' size='23' priority_3='1' interface='false' sourceFile='FixedLengthInputFormat.java' class='org.apache.hadoop.mapred.FixedLengthInputFormat'></ClassStats><ClassStats bugs='0' size='33' interface='false' sourceFile='FixedLengthRecordReader.java' class='org.apache.hadoop.mapred.FixedLengthRecordReader'></ClassStats><ClassStats bugs='1' size='7' priority_1='1' interface='false' sourceFile='ID.java' class='org.apache.hadoop.mapred.ID'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='IFile.java' class='org.apache.hadoop.mapred.IFile'></ClassStats><ClassStats bugs='0' size='111' interface='false' sourceFile='IFile.java' class='org.apache.hadoop.mapred.IFile$Reader'></ClassStats><ClassStats bugs='0' size='128' interface='false' sourceFile='IFile.java' class='org.apache.hadoop.mapred.IFile$Writer'></ClassStats><ClassStats bugs='1' size='119' priority_2='1' interface='false' sourceFile='IFileInputStream.java' class='org.apache.hadoop.mapred.IFileInputStream'></ClassStats><ClassStats bugs='0' size='36' interface='false' sourceFile='IFileOutputStream.java' class='org.apache.hadoop.mapred.IFileOutputStream'></ClassStats><ClassStats bugs='0' size='93' interface='false' sourceFile='IndexCache.java' class='org.apache.hadoop.mapred.IndexCache'></ClassStats><ClassStats bugs='0' size='1' interface='false' sourceFile='IndexCache.java' class='org.apache.hadoop.mapred.IndexCache$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='IndexCache.java' class='org.apache.hadoop.mapred.IndexCache$IndexInformation'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='IndexRecord.java' class='org.apache.hadoop.mapred.IndexRecord'></ClassStats><ClassStats bugs='0' size='3' interface='true' sourceFile='InputFormat.java' class='org.apache.hadoop.mapred.InputFormat'></ClassStats><ClassStats bugs='0' size='3' interface='true' sourceFile='InputSplit.java' class='org.apache.hadoop.mapred.InputSplit'></ClassStats><ClassStats bugs='0' size='2' interface='true' sourceFile='InputSplitWithLocationInfo.java' class='org.apache.hadoop.mapred.InputSplitWithLocationInfo'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='InvalidFileTypeException.java' class='org.apache.hadoop.mapred.InvalidFileTypeException'></ClassStats><ClassStats bugs='0' size='17' interface='false' sourceFile='InvalidInputException.java' class='org.apache.hadoop.mapred.InvalidInputException'></ClassStats><ClassStats bugs='0' size='14' interface='false' sourceFile='InvalidJobConfException.java' class='org.apache.hadoop.mapred.InvalidJobConfException'></ClassStats><ClassStats bugs='1' size='89' priority_3='1' interface='false' sourceFile='JVMId.java' class='org.apache.hadoop.mapred.JVMId'></ClassStats><ClassStats bugs='1' size='40' priority_3='1' interface='false' sourceFile='JobACLsManager.java' class='org.apache.hadoop.mapred.JobACLsManager'></ClassStats><ClassStats bugs='4' size='310' priority_3='4' interface='false' sourceFile='JobClient.java' class='org.apache.hadoop.mapred.JobClient'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='JobClient.java' class='org.apache.hadoop.mapred.JobClient$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='JobClient.java' class='org.apache.hadoop.mapred.JobClient$10'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='JobClient.java' class='org.apache.hadoop.mapred.JobClient$11'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='JobClient.java' class='org.apache.hadoop.mapred.JobClient$12'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='JobClient.java' class='org.apache.hadoop.mapred.JobClient$13'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='JobClient.java' class='org.apache.hadoop.mapred.JobClient$14'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='JobClient.java' class='org.apache.hadoop.mapred.JobClient$15'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='JobClient.java' class='org.apache.hadoop.mapred.JobClient$16'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='JobClient.java' class='org.apache.hadoop.mapred.JobClient$2'></ClassStats><ClassStats bugs='0' size='14' interface='false' sourceFile='JobClient.java' class='org.apache.hadoop.mapred.JobClient$3'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='JobClient.java' class='org.apache.hadoop.mapred.JobClient$4'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='JobClient.java' class='org.apache.hadoop.mapred.JobClient$5'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='JobClient.java' class='org.apache.hadoop.mapred.JobClient$6'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='JobClient.java' class='org.apache.hadoop.mapred.JobClient$7'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='JobClient.java' class='org.apache.hadoop.mapred.JobClient$8'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='JobClient.java' class='org.apache.hadoop.mapred.JobClient$9'></ClassStats><ClassStats bugs='3' size='109' priority_3='3' interface='false' sourceFile='JobClient.java' class='org.apache.hadoop.mapred.JobClient$NetworkedJob'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='JobClient.java' class='org.apache.hadoop.mapred.JobClient$TaskStatusFilter'></ClassStats><ClassStats bugs='1' size='544' priority_3='1' interface='false' sourceFile='JobConf.java' class='org.apache.hadoop.mapred.JobConf'></ClassStats><ClassStats bugs='0' size='4' interface='false' sourceFile='JobConf.java' class='org.apache.hadoop.mapred.JobConf$1'></ClassStats><ClassStats bugs='0' size='2' interface='true' sourceFile='JobConfigurable.java' class='org.apache.hadoop.mapred.JobConfigurable'></ClassStats><ClassStats bugs='1' size='3' priority_2='1' interface='true' sourceFile='JobContext.java' class='org.apache.hadoop.mapred.JobContext'></ClassStats><ClassStats bugs='1' size='15' priority_1='1' interface='false' sourceFile='JobContextImpl.java' class='org.apache.hadoop.mapred.JobContextImpl'></ClassStats><ClassStats bugs='0' size='50' interface='false' sourceFile='JobEndNotifier.java' class='org.apache.hadoop.mapred.JobEndNotifier'></ClassStats><ClassStats bugs='0' size='46' interface='false' sourceFile='JobEndNotifier.java' class='org.apache.hadoop.mapred.JobEndNotifier$JobEndStatusInfo'></ClassStats><ClassStats bugs='1' size='28' priority_1='1' interface='false' sourceFile='JobID.java' class='org.apache.hadoop.mapred.JobID'></ClassStats><ClassStats bugs='0' size='3' interface='false' sourceFile='JobInProgress.java' class='org.apache.hadoop.mapred.JobInProgress'></ClassStats><ClassStats bugs='0' size='30' interface='false' sourceFile='JobInProgress.java' class='org.apache.hadoop.mapred.JobInProgress$Counter'></ClassStats><ClassStats bugs='1' size='30' priority_3='1' interface='false' sourceFile='JobInfo.java' class='org.apache.hadoop.mapred.JobInfo'></ClassStats><ClassStats bugs='0' size='22' interface='false' sourceFile='JobPriority.java' class='org.apache.hadoop.mapred.JobPriority'></ClassStats><ClassStats bugs='0' size='62' interface='false' sourceFile='JobProfile.java' class='org.apache.hadoop.mapred.JobProfile'></ClassStats><ClassStats bugs='0' size='5' interface='false' sourceFile='JobProfile.java' class='org.apache.hadoop.mapred.JobProfile$1'></ClassStats><ClassStats bugs='3' size='135' priority_3='3' interface='false' sourceFile='JobQueueClient.java' class='org.apache.hadoop.mapred.JobQueueClient'></ClassStats><ClassStats bugs='0' size='54' interface='false' sourceFile='JobQueueInfo.java' class='org.apache.hadoop.mapred.JobQueueInfo'></ClassStats><ClassStats bugs='1' size='154' priority_1='1' interface='false' sourceFile='JobStatus.java' class='org.apache.hadoop.mapred.JobStatus'></ClassStats><ClassStats bugs='0' size='3' interface='false' sourceFile='JobTracker.java' class='org.apache.hadoop.mapred.JobTracker'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='JobTracker.java' class='org.apache.hadoop.mapred.JobTracker$State'></ClassStats><ClassStats bugs='0' size='25' interface='false' sourceFile='JvmContext.java' class='org.apache.hadoop.mapred.JvmContext'></ClassStats><ClassStats bugs='0' size='32' interface='false' sourceFile='JvmTask.java' class='org.apache.hadoop.mapred.JvmTask'></ClassStats><ClassStats bugs='0' size='47' interface='false' sourceFile='KeyValueLineRecordReader.java' class='org.apache.hadoop.mapred.KeyValueLineRecordReader'></ClassStats><ClassStats bugs='1' size='16' priority_3='1' interface='false' sourceFile='KeyValueTextInputFormat.java' class='org.apache.hadoop.mapred.KeyValueTextInputFormat'></ClassStats><ClassStats bugs='0' size='138' interface='false' sourceFile='LineRecordReader.java' class='org.apache.hadoop.mapred.LineRecordReader'></ClassStats><ClassStats bugs='0' size='19' interface='false' sourceFile='LineRecordReader.java' class='org.apache.hadoop.mapred.LineRecordReader$LineReader'></ClassStats><ClassStats bugs='1' size='95' priority_2='1' interface='false' sourceFile='LocatedFileStatusFetcher.java' class='org.apache.hadoop.mapred.LocatedFileStatusFetcher'></ClassStats><ClassStats bugs='0' size='1' interface='false' sourceFile='LocatedFileStatusFetcher.java' class='org.apache.hadoop.mapred.LocatedFileStatusFetcher$1'></ClassStats><ClassStats bugs='0' size='23' interface='false' sourceFile='LocatedFileStatusFetcher.java' class='org.apache.hadoop.mapred.LocatedFileStatusFetcher$ProcessInitialInputPathCallable'></ClassStats><ClassStats bugs='0' size='17' interface='false' sourceFile='LocatedFileStatusFetcher.java' class='org.apache.hadoop.mapred.LocatedFileStatusFetcher$ProcessInitialInputPathCallable$Result'></ClassStats><ClassStats bugs='0' size='24' interface='false' sourceFile='LocatedFileStatusFetcher.java' class='org.apache.hadoop.mapred.LocatedFileStatusFetcher$ProcessInitialInputPathCallback'></ClassStats><ClassStats bugs='0' size='30' interface='false' sourceFile='LocatedFileStatusFetcher.java' class='org.apache.hadoop.mapred.LocatedFileStatusFetcher$ProcessInputDirCallable'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='LocatedFileStatusFetcher.java' class='org.apache.hadoop.mapred.LocatedFileStatusFetcher$ProcessInputDirCallable$Result'></ClassStats><ClassStats bugs='0' size='25' interface='false' sourceFile='LocatedFileStatusFetcher.java' class='org.apache.hadoop.mapred.LocatedFileStatusFetcher$ProcessInputDirCallback'></ClassStats><ClassStats bugs='0' size='10' interface='true' sourceFile='MRConstants.java' class='org.apache.hadoop.mapred.MRConstants'></ClassStats><ClassStats bugs='1' size='49' priority_3='1' interface='false' sourceFile='MROutputFiles.java' class='org.apache.hadoop.mapred.MROutputFiles'></ClassStats><ClassStats bugs='0' size='41' interface='false' sourceFile='BasicTypeSorterBase.java' class='org.apache.hadoop.mapred.MRSortResultIterator'></ClassStats><ClassStats bugs='0' size='1' interface='false' sourceFile='BasicTypeSorterBase.java' class='org.apache.hadoop.mapred.MRSortResultIterator$1'></ClassStats><ClassStats bugs='0' size='20' interface='false' sourceFile='BasicTypeSorterBase.java' class='org.apache.hadoop.mapred.MRSortResultIterator$InMemUncompressedBytes'></ClassStats><ClassStats bugs='1' size='26' priority_3='1' interface='false' sourceFile='MapFileOutputFormat.java' class='org.apache.hadoop.mapred.MapFileOutputFormat'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='MapFileOutputFormat.java' class='org.apache.hadoop.mapred.MapFileOutputFormat$1'></ClassStats><ClassStats bugs='0' size='5' interface='true' sourceFile='MapOutputCollector.java' class='org.apache.hadoop.mapred.MapOutputCollector'></ClassStats><ClassStats bugs='0' size='16' interface='false' sourceFile='MapOutputCollector.java' class='org.apache.hadoop.mapred.MapOutputCollector$Context'></ClassStats><ClassStats bugs='0' size='26' interface='false' sourceFile='MapOutputFile.java' class='org.apache.hadoop.mapred.MapOutputFile'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='MapReduceBase.java' class='org.apache.hadoop.mapred.MapReduceBase'></ClassStats><ClassStats bugs='0' size='2' interface='true' sourceFile='MapRunnable.java' class='org.apache.hadoop.mapred.MapRunnable'></ClassStats><ClassStats bugs='0' size='22' interface='false' sourceFile='MapRunner.java' class='org.apache.hadoop.mapred.MapRunner'></ClassStats><ClassStats bugs='0' size='216' interface='false' sourceFile='MapTask.java' class='org.apache.hadoop.mapred.MapTask'></ClassStats><ClassStats bugs='0' size='54' interface='false' sourceFile='MapTask.java' class='org.apache.hadoop.mapred.MapTask$DirectMapOutputCollector'></ClassStats><ClassStats bugs='0' size='4' interface='false' sourceFile='MapTask.java' class='org.apache.hadoop.mapred.MapTask$MapBufferTooSmallException'></ClassStats><ClassStats bugs='4' size='555' priority_2='1' priority_3='3' interface='false' sourceFile='MapTask.java' class='org.apache.hadoop.mapred.MapTask$MapOutputBuffer'></ClassStats><ClassStats bugs='0' size='27' interface='false' sourceFile='MapTask.java' class='org.apache.hadoop.mapred.MapTask$MapOutputBuffer$BlockingBuffer'></ClassStats><ClassStats bugs='0' size='57' interface='false' sourceFile='MapTask.java' class='org.apache.hadoop.mapred.MapTask$MapOutputBuffer$Buffer'></ClassStats><ClassStats bugs='1' size='19' priority_2='1' interface='false' sourceFile='MapTask.java' class='org.apache.hadoop.mapred.MapTask$MapOutputBuffer$InMemValBytes'></ClassStats><ClassStats bugs='0' size='27' interface='false' sourceFile='MapTask.java' class='org.apache.hadoop.mapred.MapTask$MapOutputBuffer$MRResultIterator'></ClassStats><ClassStats bugs='0' size='27' interface='false' sourceFile='MapTask.java' class='org.apache.hadoop.mapred.MapTask$MapOutputBuffer$SpillThread'></ClassStats><ClassStats bugs='1' size='47' priority_3='1' interface='false' sourceFile='MapTask.java' class='org.apache.hadoop.mapred.MapTask$NewDirectOutputCollector'></ClassStats><ClassStats bugs='1' size='27' priority_3='1' interface='false' sourceFile='MapTask.java' class='org.apache.hadoop.mapred.MapTask$NewOutputCollector'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='MapTask.java' class='org.apache.hadoop.mapred.MapTask$NewOutputCollector$1'></ClassStats><ClassStats bugs='0' size='57' interface='false' sourceFile='MapTask.java' class='org.apache.hadoop.mapred.MapTask$NewTrackingRecordReader'></ClassStats><ClassStats bugs='0' size='21' interface='false' sourceFile='MapTask.java' class='org.apache.hadoop.mapred.MapTask$OldOutputCollector'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='MapTask.java' class='org.apache.hadoop.mapred.MapTask$OldOutputCollector$1'></ClassStats><ClassStats bugs='0' size='52' interface='false' sourceFile='MapTask.java' class='org.apache.hadoop.mapred.MapTask$SkippingRecordReader'></ClassStats><ClassStats bugs='0' size='64' interface='false' sourceFile='MapTask.java' class='org.apache.hadoop.mapred.MapTask$TrackedRecordReader'></ClassStats><ClassStats bugs='2' size='27' priority_2='2' interface='false' sourceFile='MapTaskCompletionEventsUpdate.java' class='org.apache.hadoop.mapred.MapTaskCompletionEventsUpdate'></ClassStats><ClassStats bugs='0' size='39' interface='false' sourceFile='MapTaskStatus.java' class='org.apache.hadoop.mapred.MapTaskStatus'></ClassStats><ClassStats bugs='0' size='2' interface='true' sourceFile='Mapper.java' class='org.apache.hadoop.mapred.Mapper'></ClassStats><ClassStats bugs='0' size='16' interface='false' sourceFile='Master.java' class='org.apache.hadoop.mapred.Master'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='Master.java' class='org.apache.hadoop.mapred.Master$State'></ClassStats><ClassStats bugs='4' size='29' priority_2='1' priority_3='3' interface='false' sourceFile='MergeSorter.java' class='org.apache.hadoop.mapred.MergeSorter'></ClassStats><ClassStats bugs='0' size='38' interface='false' sourceFile='Merger.java' class='org.apache.hadoop.mapred.Merger'></ClassStats><ClassStats bugs='0' size='250' interface='false' sourceFile='Merger.java' class='org.apache.hadoop.mapred.Merger$MergeQueue'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='Merger.java' class='org.apache.hadoop.mapred.Merger$MergeQueue$1'></ClassStats><ClassStats bugs='0' size='111' interface='false' sourceFile='Merger.java' class='org.apache.hadoop.mapred.Merger$Segment'></ClassStats><ClassStats bugs='0' size='39' interface='false' sourceFile='MultiFileInputFormat.java' class='org.apache.hadoop.mapred.MultiFileInputFormat'></ClassStats><ClassStats bugs='0' size='27' interface='false' sourceFile='MultiFileSplit.java' class='org.apache.hadoop.mapred.MultiFileSplit'></ClassStats><ClassStats bugs='0' size='33' interface='false' sourceFile='Operation.java' class='org.apache.hadoop.mapred.Operation'></ClassStats><ClassStats bugs='0' size='2' interface='true' sourceFile='OutputCollector.java' class='org.apache.hadoop.mapred.OutputCollector'></ClassStats><ClassStats bugs='17' size='57' priority_1='1' priority_2='4' priority_3='12' interface='false' sourceFile='OutputCommitter.java' class='org.apache.hadoop.mapred.OutputCommitter'></ClassStats><ClassStats bugs='0' size='3' interface='true' sourceFile='OutputFormat.java' class='org.apache.hadoop.mapred.OutputFormat'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='OutputLogFilter.java' class='org.apache.hadoop.mapred.OutputLogFilter'></ClassStats><ClassStats bugs='0' size='2' interface='true' sourceFile='Partitioner.java' class='org.apache.hadoop.mapred.Partitioner'></ClassStats><ClassStats bugs='0' size='51' interface='false' sourceFile='PeriodicStatsAccumulator.java' class='org.apache.hadoop.mapred.PeriodicStatsAccumulator'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='PeriodicStatsAccumulator.java' class='org.apache.hadoop.mapred.PeriodicStatsAccumulator$StatsetState'></ClassStats><ClassStats bugs='0' size='37' interface='false' sourceFile='ProgressSplitsBlock.java' class='org.apache.hadoop.mapred.ProgressSplitsBlock'></ClassStats><ClassStats bugs='0' size='145' interface='false' sourceFile='Queue.java' class='org.apache.hadoop.mapred.Queue'></ClassStats><ClassStats bugs='0' size='17' interface='false' sourceFile='QueueACL.java' class='org.apache.hadoop.mapred.QueueACL'></ClassStats><ClassStats bugs='1' size='9' priority_1='1' interface='false' sourceFile='QueueAclsInfo.java' class='org.apache.hadoop.mapred.QueueAclsInfo'></ClassStats><ClassStats bugs='1' size='222' priority_3='1' interface='false' sourceFile='QueueConfigurationParser.java' class='org.apache.hadoop.mapred.QueueConfigurationParser'></ClassStats><ClassStats bugs='0' size='224' interface='false' sourceFile='QueueManager.java' class='org.apache.hadoop.mapred.QueueManager'></ClassStats><ClassStats bugs='0' size='4' interface='false' sourceFile='QueueRefresher.java' class='org.apache.hadoop.mapred.QueueRefresher'></ClassStats><ClassStats bugs='0' size='3' interface='true' sourceFile='RamManager.java' class='org.apache.hadoop.mapred.RamManager'></ClassStats><ClassStats bugs='0' size='6' interface='true' sourceFile='RawKeyValueIterator.java' class='org.apache.hadoop.mapred.RawKeyValueIterator'></ClassStats><ClassStats bugs='0' size='7' interface='true' sourceFile='RecordReader.java' class='org.apache.hadoop.mapred.RecordReader'></ClassStats><ClassStats bugs='0' size='3' interface='true' sourceFile='RecordWriter.java' class='org.apache.hadoop.mapred.RecordWriter'></ClassStats><ClassStats bugs='4' size='178' priority_3='4' interface='false' sourceFile='ReduceTask.java' class='org.apache.hadoop.mapred.ReduceTask'></ClassStats><ClassStats bugs='0' size='5' interface='false' sourceFile='ReduceTask.java' class='org.apache.hadoop.mapred.ReduceTask$1'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='ReduceTask.java' class='org.apache.hadoop.mapred.ReduceTask$2'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='ReduceTask.java' class='org.apache.hadoop.mapred.ReduceTask$3'></ClassStats><ClassStats bugs='0' size='19' interface='false' sourceFile='ReduceTask.java' class='org.apache.hadoop.mapred.ReduceTask$4'></ClassStats><ClassStats bugs='0' size='40' interface='false' sourceFile='ReduceTask.java' class='org.apache.hadoop.mapred.ReduceTask$NewTrackingRecordWriter'></ClassStats><ClassStats bugs='0' size='39' interface='false' sourceFile='ReduceTask.java' class='org.apache.hadoop.mapred.ReduceTask$OldTrackingRecordWriter'></ClassStats><ClassStats bugs='0' size='15' interface='false' sourceFile='ReduceTask.java' class='org.apache.hadoop.mapred.ReduceTask$ReduceValuesIterator'></ClassStats><ClassStats bugs='0' size='69' interface='false' sourceFile='ReduceTask.java' class='org.apache.hadoop.mapred.ReduceTask$SkippingReduceValuesIterator'></ClassStats><ClassStats bugs='0' size='80' interface='false' sourceFile='ReduceTaskStatus.java' class='org.apache.hadoop.mapred.ReduceTaskStatus'></ClassStats><ClassStats bugs='0' size='2' interface='true' sourceFile='Reducer.java' class='org.apache.hadoop.mapred.Reducer'></ClassStats><ClassStats bugs='0' size='11' interface='true' sourceFile='Reporter.java' class='org.apache.hadoop.mapred.Reporter'></ClassStats><ClassStats bugs='0' size='19' interface='false' sourceFile='Reporter.java' class='org.apache.hadoop.mapred.Reporter$1'></ClassStats><ClassStats bugs='0' size='26' interface='true' sourceFile='RunningJob.java' class='org.apache.hadoop.mapred.RunningJob'></ClassStats><ClassStats bugs='1' size='6' priority_3='1' interface='false' sourceFile='SequenceFileAsBinaryInputFormat.java' class='org.apache.hadoop.mapred.SequenceFileAsBinaryInputFormat'></ClassStats><ClassStats bugs='0' size='54' interface='false' sourceFile='SequenceFileAsBinaryInputFormat.java' class='org.apache.hadoop.mapred.SequenceFileAsBinaryInputFormat$SequenceFileAsBinaryRecordReader'></ClassStats><ClassStats bugs='1' size='35' priority_3='1' interface='false' sourceFile='SequenceFileAsBinaryOutputFormat.java' class='org.apache.hadoop.mapred.SequenceFileAsBinaryOutputFormat'></ClassStats><ClassStats bugs='0' size='16' interface='false' sourceFile='SequenceFileAsBinaryOutputFormat.java' class='org.apache.hadoop.mapred.SequenceFileAsBinaryOutputFormat$1'></ClassStats><ClassStats bugs='1' size='7' priority_1='1' interface='false' sourceFile='SequenceFileAsBinaryOutputFormat.java' class='org.apache.hadoop.mapred.SequenceFileAsBinaryOutputFormat$WritableValueBytes'></ClassStats><ClassStats bugs='1' size='7' priority_3='1' interface='false' sourceFile='SequenceFileAsTextInputFormat.java' class='org.apache.hadoop.mapred.SequenceFileAsTextInputFormat'></ClassStats><ClassStats bugs='0' size='33' interface='false' sourceFile='SequenceFileAsTextRecordReader.java' class='org.apache.hadoop.mapred.SequenceFileAsTextRecordReader'></ClassStats><ClassStats bugs='1' size='11' priority_3='1' interface='false' sourceFile='SequenceFileInputFilter.java' class='org.apache.hadoop.mapred.SequenceFileInputFilter'></ClassStats><ClassStats bugs='1' size='1' priority_2='1' interface='true' sourceFile='SequenceFileInputFilter.java' class='org.apache.hadoop.mapred.SequenceFileInputFilter$Filter'></ClassStats><ClassStats bugs='1' size='3' priority_1='1' interface='false' sourceFile='SequenceFileInputFilter.java' class='org.apache.hadoop.mapred.SequenceFileInputFilter$FilterBase'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='SequenceFileInputFilter.java' class='org.apache.hadoop.mapred.SequenceFileInputFilter$FilterRecordReader'></ClassStats><ClassStats bugs='0' size='16' interface='false' sourceFile='SequenceFileInputFilter.java' class='org.apache.hadoop.mapred.SequenceFileInputFilter$MD5Filter'></ClassStats><ClassStats bugs='0' size='15' interface='false' sourceFile='SequenceFileInputFilter.java' class='org.apache.hadoop.mapred.SequenceFileInputFilter$PercentFilter'></ClassStats><ClassStats bugs='0' size='15' interface='false' sourceFile='SequenceFileInputFilter.java' class='org.apache.hadoop.mapred.SequenceFileInputFilter$RegexFilter'></ClassStats><ClassStats bugs='1' size='17' priority_3='1' interface='false' sourceFile='SequenceFileInputFormat.java' class='org.apache.hadoop.mapred.SequenceFileInputFormat'></ClassStats><ClassStats bugs='0' size='34' interface='false' sourceFile='SequenceFileOutputFormat.java' class='org.apache.hadoop.mapred.SequenceFileOutputFormat'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='SequenceFileOutputFormat.java' class='org.apache.hadoop.mapred.SequenceFileOutputFormat$1'></ClassStats><ClassStats bugs='0' size='59' interface='false' sourceFile='SequenceFileRecordReader.java' class='org.apache.hadoop.mapred.SequenceFileRecordReader'></ClassStats><ClassStats bugs='0' size='4' interface='true' sourceFile='ShuffleConsumerPlugin.java' class='org.apache.hadoop.mapred.ShuffleConsumerPlugin'></ClassStats><ClassStats bugs='0' size='88' interface='false' sourceFile='ShuffleConsumerPlugin.java' class='org.apache.hadoop.mapred.ShuffleConsumerPlugin$Context'></ClassStats><ClassStats bugs='0' size='52' interface='false' sourceFile='SkipBadRecords.java' class='org.apache.hadoop.mapred.SkipBadRecords'></ClassStats><ClassStats bugs='0' size='106' interface='false' sourceFile='SortedRanges.java' class='org.apache.hadoop.mapred.SortedRanges'></ClassStats><ClassStats bugs='0' size='43' interface='false' sourceFile='SortedRanges.java' class='org.apache.hadoop.mapred.SortedRanges$Range'></ClassStats><ClassStats bugs='0' size='37' interface='false' sourceFile='SortedRanges.java' class='org.apache.hadoop.mapred.SortedRanges$SkipRangeIterator'></ClassStats><ClassStats bugs='0' size='66' interface='false' sourceFile='SpillRecord.java' class='org.apache.hadoop.mapred.SpillRecord'></ClassStats><ClassStats bugs='0' size='14' interface='false' sourceFile='SplitLocationInfo.java' class='org.apache.hadoop.mapred.SplitLocationInfo'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='StatePeriodicStats.java' class='org.apache.hadoop.mapred.StatePeriodicStats'></ClassStats><ClassStats bugs='1' size='72' priority_3='1' interface='false' sourceFile='StatisticsCollector.java' class='org.apache.hadoop.mapred.StatisticsCollector'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='StatisticsCollector.java' class='org.apache.hadoop.mapred.StatisticsCollector$1'></ClassStats><ClassStats bugs='1' size='20' priority_3='1' interface='false' sourceFile='StatisticsCollector.java' class='org.apache.hadoop.mapred.StatisticsCollector$Stat'></ClassStats><ClassStats bugs='0' size='28' interface='false' sourceFile='StatisticsCollector.java' class='org.apache.hadoop.mapred.StatisticsCollector$Stat$TimeStat'></ClassStats><ClassStats bugs='0' size='16' interface='false' sourceFile='StatisticsCollector.java' class='org.apache.hadoop.mapred.StatisticsCollector$StatUpdater'></ClassStats><ClassStats bugs='0' size='32' interface='false' sourceFile='StatisticsCollector.java' class='org.apache.hadoop.mapred.StatisticsCollector$TimeWindow'></ClassStats><ClassStats bugs='0' size='26' interface='false' sourceFile='StatisticsCollector.java' class='org.apache.hadoop.mapred.StatisticsCollector$TimeWindowStatUpdater'></ClassStats><ClassStats bugs='0' size='14' interface='false' sourceFile='TIPStatus.java' class='org.apache.hadoop.mapred.TIPStatus'></ClassStats><ClassStats bugs='6' size='561' priority_1='1' priority_2='5' interface='false' sourceFile='Task.java' class='org.apache.hadoop.mapred.Task'></ClassStats><ClassStats bugs='1' size='20' priority_3='1' interface='false' sourceFile='Task.java' class='org.apache.hadoop.mapred.Task$CombineOutputCollector'></ClassStats><ClassStats bugs='0' size='15' interface='false' sourceFile='Task.java' class='org.apache.hadoop.mapred.Task$CombineValuesIterator'></ClassStats><ClassStats bugs='0' size='22' interface='false' sourceFile='Task.java' class='org.apache.hadoop.mapred.Task$CombinerRunner'></ClassStats><ClassStats bugs='0' size='56' interface='false' sourceFile='Task.java' class='org.apache.hadoop.mapred.Task$Counter'></ClassStats><ClassStats bugs='0' size='43' interface='false' sourceFile='Task.java' class='org.apache.hadoop.mapred.Task$FileSystemStatisticUpdater'></ClassStats><ClassStats bugs='0' size='27' interface='false' sourceFile='Task.java' class='org.apache.hadoop.mapred.Task$GcTimeUpdater'></ClassStats><ClassStats bugs='0' size='22' interface='false' sourceFile='Task.java' class='org.apache.hadoop.mapred.Task$NewCombinerRunner'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='Task.java' class='org.apache.hadoop.mapred.Task$NewCombinerRunner$OutputConverter'></ClassStats><ClassStats bugs='0' size='23' interface='false' sourceFile='Task.java' class='org.apache.hadoop.mapred.Task$OldCombinerRunner'></ClassStats><ClassStats bugs='3' size='193' priority_2='1' priority_3='2' interface='false' sourceFile='Task.java' class='org.apache.hadoop.mapred.Task$TaskReporter'></ClassStats><ClassStats bugs='0' size='36' interface='false' sourceFile='Task.java' class='org.apache.hadoop.mapred.Task$TaskReporter$DiskLimitCheck'></ClassStats><ClassStats bugs='1' size='6' priority_3='1' interface='false' sourceFile='Task.java' class='org.apache.hadoop.mapred.Task$TaskReporter$TaskLimitException'></ClassStats><ClassStats bugs='0' size='76' interface='false' sourceFile='Task.java' class='org.apache.hadoop.mapred.Task$ValuesIterator'></ClassStats><ClassStats bugs='1' size='6' priority_2='1' interface='true' sourceFile='TaskAttemptContext.java' class='org.apache.hadoop.mapred.TaskAttemptContext'></ClassStats><ClassStats bugs='5' size='30' priority_1='1' priority_3='4' interface='false' sourceFile='TaskAttemptContextImpl.java' class='org.apache.hadoop.mapred.TaskAttemptContextImpl'></ClassStats><ClassStats bugs='4' size='44' priority_1='1' priority_3='3' interface='false' sourceFile='TaskAttemptID.java' class='org.apache.hadoop.mapred.TaskAttemptID'></ClassStats><ClassStats bugs='3' size='46' priority_1='2' priority_2='1' interface='false' sourceFile='TaskCompletionEvent.java' class='org.apache.hadoop.mapred.TaskCompletionEvent'></ClassStats><ClassStats bugs='0' size='18' interface='false' sourceFile='TaskCompletionEvent.java' class='org.apache.hadoop.mapred.TaskCompletionEvent$Status'></ClassStats><ClassStats bugs='2' size='48' priority_1='1' priority_3='1' interface='false' sourceFile='TaskID.java' class='org.apache.hadoop.mapred.TaskID'></ClassStats><ClassStats bugs='0' size='253' interface='false' sourceFile='TaskLog.java' class='org.apache.hadoop.mapred.TaskLog'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='TaskLog.java' class='org.apache.hadoop.mapred.TaskLog$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='TaskLog.java' class='org.apache.hadoop.mapred.TaskLog$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='TaskLog.java' class='org.apache.hadoop.mapred.TaskLog$3'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='TaskLog.java' class='org.apache.hadoop.mapred.TaskLog$LogFileDetail'></ClassStats><ClassStats bugs='0' size='23' interface='false' sourceFile='TaskLog.java' class='org.apache.hadoop.mapred.TaskLog$LogName'></ClassStats><ClassStats bugs='0' size='44' interface='false' sourceFile='TaskLog.java' class='org.apache.hadoop.mapred.TaskLog$Reader'></ClassStats><ClassStats bugs='4' size='68' priority_3='4' interface='false' sourceFile='TaskLogAppender.java' class='org.apache.hadoop.mapred.TaskLogAppender'></ClassStats><ClassStats bugs='1' size='50' priority_1='1' interface='false' sourceFile='TaskReport.java' class='org.apache.hadoop.mapred.TaskReport'></ClassStats><ClassStats bugs='0' size='223' interface='false' sourceFile='TaskStatus.java' class='org.apache.hadoop.mapred.TaskStatus'></ClassStats><ClassStats bugs='0' size='14' interface='false' sourceFile='TaskStatus.java' class='org.apache.hadoop.mapred.TaskStatus$Phase'></ClassStats><ClassStats bugs='0' size='18' interface='false' sourceFile='TaskStatus.java' class='org.apache.hadoop.mapred.TaskStatus$State'></ClassStats><ClassStats bugs='0' size='16' interface='true' sourceFile='TaskUmbilicalProtocol.java' class='org.apache.hadoop.mapred.TaskUmbilicalProtocol'></ClassStats><ClassStats bugs='1' size='20' priority_3='1' interface='false' sourceFile='TextInputFormat.java' class='org.apache.hadoop.mapred.TextInputFormat'></ClassStats><ClassStats bugs='0' size='21' interface='false' sourceFile='TextOutputFormat.java' class='org.apache.hadoop.mapred.TextOutputFormat'></ClassStats><ClassStats bugs='0' size='39' interface='false' sourceFile='TextOutputFormat.java' class='org.apache.hadoop.mapred.TextOutputFormat$LineRecordWriter'></ClassStats><ClassStats bugs='0' size='3' interface='false' sourceFile='Utils.java' class='org.apache.hadoop.mapred.Utils'></ClassStats><ClassStats bugs='0' size='3' interface='false' sourceFile='Utils.java' class='org.apache.hadoop.mapred.Utils$OutputFileUtils'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='Utils.java' class='org.apache.hadoop.mapred.Utils$OutputFileUtils$OutputFilesFilter'></ClassStats><ClassStats bugs='0' size='5' interface='false' sourceFile='Utils.java' class='org.apache.hadoop.mapred.Utils$OutputFileUtils$OutputLogFilter'></ClassStats></PackageStats><PackageStats package='org.apache.hadoop.mapred.jobcontrol' priority_1='1' total_bugs='1' total_size='101' total_types='2'><ClassStats bugs='0' size='63' interface='false' sourceFile='Job.java' class='org.apache.hadoop.mapred.jobcontrol.Job'></ClassStats><ClassStats bugs='1' size='38' priority_1='1' interface='false' sourceFile='JobControl.java' class='org.apache.hadoop.mapred.jobcontrol.JobControl'></ClassStats></PackageStats><PackageStats package='org.apache.hadoop.mapred.join' priority_1='4' total_bugs='10' priority_2='2' priority_3='4' total_size='927' total_types='31'><ClassStats bugs='1' size='7' priority_1='1' interface='false' sourceFile='ArrayListBackedIterator.java' class='org.apache.hadoop.mapred.join.ArrayListBackedIterator'></ClassStats><ClassStats bugs='0' size='4' interface='true' sourceFile='ComposableInputFormat.java' class='org.apache.hadoop.mapred.join.ComposableInputFormat'></ClassStats><ClassStats bugs='0' size='7' interface='true' sourceFile='ComposableRecordReader.java' class='org.apache.hadoop.mapred.join.ComposableRecordReader'></ClassStats><ClassStats bugs='2' size='60' priority_3='2' interface='false' sourceFile='CompositeInputFormat.java' class='org.apache.hadoop.mapred.join.CompositeInputFormat'></ClassStats><ClassStats bugs='0' size='58' interface='false' sourceFile='CompositeInputSplit.java' class='org.apache.hadoop.mapred.join.CompositeInputSplit'></ClassStats><ClassStats bugs='0' size='116' interface='false' sourceFile='CompositeRecordReader.java' class='org.apache.hadoop.mapred.join.CompositeRecordReader'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='CompositeRecordReader.java' class='org.apache.hadoop.mapred.join.CompositeRecordReader$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='CompositeRecordReader.java' class='org.apache.hadoop.mapred.join.CompositeRecordReader$2'></ClassStats><ClassStats bugs='0' size='85' interface='false' sourceFile='CompositeRecordReader.java' class='org.apache.hadoop.mapred.join.CompositeRecordReader$JoinCollector'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='InnerJoinRecordReader.java' class='org.apache.hadoop.mapred.join.InnerJoinRecordReader'></ClassStats><ClassStats bugs='1' size='29' priority_3='1' interface='false' sourceFile='JoinRecordReader.java' class='org.apache.hadoop.mapred.join.JoinRecordReader'></ClassStats><ClassStats bugs='0' size='24' interface='false' sourceFile='JoinRecordReader.java' class='org.apache.hadoop.mapred.join.JoinRecordReader$JoinDelegationIterator'></ClassStats><ClassStats bugs='1' size='45' priority_3='1' interface='false' sourceFile='MultiFilterRecordReader.java' class='org.apache.hadoop.mapred.join.MultiFilterRecordReader'></ClassStats><ClassStats bugs='0' size='24' interface='false' sourceFile='MultiFilterRecordReader.java' class='org.apache.hadoop.mapred.join.MultiFilterRecordReader$MultiFilterDelegationIterator'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='OuterJoinRecordReader.java' class='org.apache.hadoop.mapred.join.OuterJoinRecordReader'></ClassStats><ClassStats bugs='0' size='32' interface='false' sourceFile='OverrideRecordReader.java' class='org.apache.hadoop.mapred.join.OverrideRecordReader'></ClassStats><ClassStats bugs='0' size='32' interface='false' sourceFile='Parser.java' class='org.apache.hadoop.mapred.join.Parser'></ClassStats><ClassStats bugs='0' size='75' interface='false' sourceFile='Parser.java' class='org.apache.hadoop.mapred.join.Parser$CNode'></ClassStats><ClassStats bugs='0' size='25' interface='false' sourceFile='Parser.java' class='org.apache.hadoop.mapred.join.Parser$Lexer'></ClassStats><ClassStats bugs='1' size='43' priority_2='1' interface='false' sourceFile='Parser.java' class='org.apache.hadoop.mapred.join.Parser$Node'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='Parser.java' class='org.apache.hadoop.mapred.join.Parser$NodeToken'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='Parser.java' class='org.apache.hadoop.mapred.join.Parser$NumToken'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='Parser.java' class='org.apache.hadoop.mapred.join.Parser$StrToken'></ClassStats><ClassStats bugs='0' size='15' interface='false' sourceFile='Parser.java' class='org.apache.hadoop.mapred.join.Parser$TType'></ClassStats><ClassStats bugs='0' size='14' interface='false' sourceFile='Parser.java' class='org.apache.hadoop.mapred.join.Parser$Token'></ClassStats><ClassStats bugs='0' size='56' interface='false' sourceFile='Parser.java' class='org.apache.hadoop.mapred.join.Parser$WNode'></ClassStats><ClassStats bugs='1' size='1' priority_2='1' interface='true' sourceFile='ResetableIterator.java' class='org.apache.hadoop.mapred.join.ResetableIterator'></ClassStats><ClassStats bugs='1' size='3' priority_1='1' interface='false' sourceFile='ResetableIterator.java' class='org.apache.hadoop.mapred.join.ResetableIterator$EMPTY'></ClassStats><ClassStats bugs='1' size='3' priority_1='1' interface='false' sourceFile='StreamBackedIterator.java' class='org.apache.hadoop.mapred.join.StreamBackedIterator'></ClassStats><ClassStats bugs='1' size='16' priority_1='1' interface='false' sourceFile='TupleWritable.java' class='org.apache.hadoop.mapred.join.TupleWritable'></ClassStats><ClassStats bugs='0' size='92' interface='false' sourceFile='WrappedRecordReader.java' class='org.apache.hadoop.mapred.join.WrappedRecordReader'></ClassStats></PackageStats><PackageStats package='org.apache.hadoop.mapred.lib' priority_1='11' total_bugs='22' priority_2='2' priority_3='9' total_size='1284' total_types='52'><ClassStats bugs='1' size='6' priority_1='1' interface='false' sourceFile='BinaryPartitioner.java' class='org.apache.hadoop.mapred.lib.BinaryPartitioner'></ClassStats><ClassStats bugs='2' size='96' priority_1='1' priority_3='1' interface='false' sourceFile='Chain.java' class='org.apache.hadoop.mapred.lib.Chain'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='Chain.java' class='org.apache.hadoop.mapred.lib.Chain$1'></ClassStats><ClassStats bugs='0' size='55' interface='false' sourceFile='Chain.java' class='org.apache.hadoop.mapred.lib.Chain$ChainOutputCollector'></ClassStats><ClassStats bugs='0' size='23' interface='false' sourceFile='ChainMapper.java' class='org.apache.hadoop.mapred.lib.ChainMapper'></ClassStats><ClassStats bugs='0' size='28' interface='false' sourceFile='ChainReducer.java' class='org.apache.hadoop.mapred.lib.ChainReducer'></ClassStats><ClassStats bugs='1' size='37' priority_1='1' interface='false' sourceFile='CombineFileInputFormat.java' class='org.apache.hadoop.mapred.lib.CombineFileInputFormat'></ClassStats><ClassStats bugs='1' size='63' priority_3='1' interface='false' sourceFile='CombineFileRecordReader.java' class='org.apache.hadoop.mapred.lib.CombineFileRecordReader'></ClassStats><ClassStats bugs='1' size='23' priority_3='1' interface='false' sourceFile='CombineFileRecordReaderWrapper.java' class='org.apache.hadoop.mapred.lib.CombineFileRecordReaderWrapper'></ClassStats><ClassStats bugs='1' size='18' priority_1='1' interface='false' sourceFile='CombineFileSplit.java' class='org.apache.hadoop.mapred.lib.CombineFileSplit'></ClassStats><ClassStats bugs='1' size='5' priority_3='1' interface='false' sourceFile='CombineSequenceFileInputFormat.java' class='org.apache.hadoop.mapred.lib.CombineSequenceFileInputFormat'></ClassStats><ClassStats bugs='0' size='4' interface='false' sourceFile='CombineSequenceFileInputFormat.java' class='org.apache.hadoop.mapred.lib.CombineSequenceFileInputFormat$SequenceFileRecordReaderWrapper'></ClassStats><ClassStats bugs='1' size='5' priority_3='1' interface='false' sourceFile='CombineTextInputFormat.java' class='org.apache.hadoop.mapred.lib.CombineTextInputFormat'></ClassStats><ClassStats bugs='0' size='4' interface='false' sourceFile='CombineTextInputFormat.java' class='org.apache.hadoop.mapred.lib.CombineTextInputFormat$TextRecordReaderWrapper'></ClassStats><ClassStats bugs='1' size='45' priority_3='1' interface='false' sourceFile='DelegatingInputFormat.java' class='org.apache.hadoop.mapred.lib.DelegatingInputFormat'></ClassStats><ClassStats bugs='0' size='19' interface='false' sourceFile='DelegatingMapper.java' class='org.apache.hadoop.mapred.lib.DelegatingMapper'></ClassStats><ClassStats bugs='0' size='81' interface='false' sourceFile='FieldSelectionMapReduce.java' class='org.apache.hadoop.mapred.lib.FieldSelectionMapReduce'></ClassStats><ClassStats bugs='0' size='19' interface='false' sourceFile='FilterOutputFormat.java' class='org.apache.hadoop.mapred.lib.FilterOutputFormat'></ClassStats><ClassStats bugs='0' size='21' interface='false' sourceFile='FilterOutputFormat.java' class='org.apache.hadoop.mapred.lib.FilterOutputFormat$FilterRecordWriter'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='HashPartitioner.java' class='org.apache.hadoop.mapred.lib.HashPartitioner'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='IdentityMapper.java' class='org.apache.hadoop.mapred.lib.IdentityMapper'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='IdentityReducer.java' class='org.apache.hadoop.mapred.lib.IdentityReducer'></ClassStats><ClassStats bugs='1' size='12' priority_1='1' interface='false' sourceFile='InputSampler.java' class='org.apache.hadoop.mapred.lib.InputSampler'></ClassStats><ClassStats bugs='1' size='26' priority_1='1' interface='false' sourceFile='InputSampler.java' class='org.apache.hadoop.mapred.lib.InputSampler$IntervalSampler'></ClassStats><ClassStats bugs='1' size='36' priority_1='1' interface='false' sourceFile='InputSampler.java' class='org.apache.hadoop.mapred.lib.InputSampler$RandomSampler'></ClassStats><ClassStats bugs='1' size='2' priority_2='1' interface='true' sourceFile='InputSampler.java' class='org.apache.hadoop.mapred.lib.InputSampler$Sampler'></ClassStats><ClassStats bugs='1' size='26' priority_1='1' interface='false' sourceFile='InputSampler.java' class='org.apache.hadoop.mapred.lib.InputSampler$SplitSampler'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='InverseMapper.java' class='org.apache.hadoop.mapred.lib.InverseMapper'></ClassStats><ClassStats bugs='2' size='6' priority_1='1' priority_2='1' interface='false' sourceFile='KeyFieldBasedComparator.java' class='org.apache.hadoop.mapred.lib.KeyFieldBasedComparator'></ClassStats><ClassStats bugs='1' size='6' priority_1='1' interface='false' sourceFile='KeyFieldBasedPartitioner.java' class='org.apache.hadoop.mapred.lib.KeyFieldBasedPartitioner'></ClassStats><ClassStats bugs='0' size='22' interface='false' sourceFile='LazyOutputFormat.java' class='org.apache.hadoop.mapred.lib.LazyOutputFormat'></ClassStats><ClassStats bugs='0' size='25' interface='false' sourceFile='LazyOutputFormat.java' class='org.apache.hadoop.mapred.lib.LazyOutputFormat$LazyRecordWriter'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='LongSumReducer.java' class='org.apache.hadoop.mapred.lib.LongSumReducer'></ClassStats><ClassStats bugs='0' size='42' interface='false' sourceFile='MultipleInputs.java' class='org.apache.hadoop.mapred.lib.MultipleInputs'></ClassStats><ClassStats bugs='0' size='36' interface='false' sourceFile='MultipleOutputFormat.java' class='org.apache.hadoop.mapred.lib.MultipleOutputFormat'></ClassStats><ClassStats bugs='0' size='29' interface='false' sourceFile='MultipleOutputFormat.java' class='org.apache.hadoop.mapred.lib.MultipleOutputFormat$1'></ClassStats><ClassStats bugs='1' size='127' priority_3='1' interface='false' sourceFile='MultipleOutputs.java' class='org.apache.hadoop.mapred.lib.MultipleOutputs'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='MultipleOutputs.java' class='org.apache.hadoop.mapred.lib.MultipleOutputs$1'></ClassStats><ClassStats bugs='0' size='14' interface='false' sourceFile='MultipleOutputs.java' class='org.apache.hadoop.mapred.lib.MultipleOutputs$InternalFileOutputFormat'></ClassStats><ClassStats bugs='0' size='17' interface='false' sourceFile='MultipleOutputs.java' class='org.apache.hadoop.mapred.lib.MultipleOutputs$RecordWriterWithCounter'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='MultipleSequenceFileOutputFormat.java' class='org.apache.hadoop.mapred.lib.MultipleSequenceFileOutputFormat'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='MultipleTextOutputFormat.java' class='org.apache.hadoop.mapred.lib.MultipleTextOutputFormat'></ClassStats><ClassStats bugs='0' size='63' interface='false' sourceFile='MultithreadedMapRunner.java' class='org.apache.hadoop.mapred.lib.MultithreadedMapRunner'></ClassStats><ClassStats bugs='0' size='16' interface='false' sourceFile='MultithreadedMapRunner.java' class='org.apache.hadoop.mapred.lib.MultithreadedMapRunner$BlockingArrayQueue'></ClassStats><ClassStats bugs='0' size='29' interface='false' sourceFile='MultithreadedMapRunner.java' class='org.apache.hadoop.mapred.lib.MultithreadedMapRunner$MapperInvokeRunable'></ClassStats><ClassStats bugs='1' size='21' priority_3='1' interface='false' sourceFile='NLineInputFormat.java' class='org.apache.hadoop.mapred.lib.NLineInputFormat'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='NullOutputFormat.java' class='org.apache.hadoop.mapred.lib.NullOutputFormat'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='NullOutputFormat.java' class='org.apache.hadoop.mapred.lib.NullOutputFormat$1'></ClassStats><ClassStats bugs='1' size='17' priority_3='1' interface='false' sourceFile='RegexMapper.java' class='org.apache.hadoop.mapred.lib.RegexMapper'></ClassStats><ClassStats bugs='0' size='53' interface='false' sourceFile='TaggedInputSplit.java' class='org.apache.hadoop.mapred.lib.TaggedInputSplit'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='TokenCountMapper.java' class='org.apache.hadoop.mapred.lib.TokenCountMapper'></ClassStats><ClassStats bugs='1' size='13' priority_1='1' interface='false' sourceFile='TotalOrderPartitioner.java' class='org.apache.hadoop.mapred.lib.TotalOrderPartitioner'></ClassStats></PackageStats><PackageStats package='org.apache.hadoop.mapred.lib.aggregate' priority_1='11' total_bugs='15' priority_2='3' priority_3='1' total_size='273' total_types='17'><ClassStats bugs='1' size='3' priority_1='1' interface='false' sourceFile='DoubleValueSum.java' class='org.apache.hadoop.mapred.lib.aggregate.DoubleValueSum'></ClassStats><ClassStats bugs='1' size='3' priority_1='1' interface='false' sourceFile='LongValueMax.java' class='org.apache.hadoop.mapred.lib.aggregate.LongValueMax'></ClassStats><ClassStats bugs='1' size='3' priority_1='1' interface='false' sourceFile='LongValueMin.java' class='org.apache.hadoop.mapred.lib.aggregate.LongValueMin'></ClassStats><ClassStats bugs='1' size='3' priority_1='1' interface='false' sourceFile='LongValueSum.java' class='org.apache.hadoop.mapred.lib.aggregate.LongValueSum'></ClassStats><ClassStats bugs='1' size='3' priority_1='1' interface='false' sourceFile='StringValueMax.java' class='org.apache.hadoop.mapred.lib.aggregate.StringValueMax'></ClassStats><ClassStats bugs='1' size='3' priority_1='1' interface='false' sourceFile='StringValueMin.java' class='org.apache.hadoop.mapred.lib.aggregate.StringValueMin'></ClassStats><ClassStats bugs='1' size='7' priority_1='1' interface='false' sourceFile='UniqValueCount.java' class='org.apache.hadoop.mapred.lib.aggregate.UniqValueCount'></ClassStats><ClassStats bugs='1' size='10' priority_1='1' interface='false' sourceFile='UserDefinedValueAggregatorDescriptor.java' class='org.apache.hadoop.mapred.lib.aggregate.UserDefinedValueAggregatorDescriptor'></ClassStats><ClassStats bugs='1' size='1' priority_2='1' interface='true' sourceFile='ValueAggregator.java' class='org.apache.hadoop.mapred.lib.aggregate.ValueAggregator'></ClassStats><ClassStats bugs='2' size='40' priority_1='2' interface='false' sourceFile='ValueAggregatorBaseDescriptor.java' class='org.apache.hadoop.mapred.lib.aggregate.ValueAggregatorBaseDescriptor'></ClassStats><ClassStats bugs='0' size='28' interface='false' sourceFile='ValueAggregatorCombiner.java' class='org.apache.hadoop.mapred.lib.aggregate.ValueAggregatorCombiner'></ClassStats><ClassStats bugs='1' size='6' priority_2='1' interface='true' sourceFile='ValueAggregatorDescriptor.java' class='org.apache.hadoop.mapred.lib.aggregate.ValueAggregatorDescriptor'></ClassStats><ClassStats bugs='2' size='79' priority_2='1' priority_3='1' interface='false' sourceFile='ValueAggregatorJob.java' class='org.apache.hadoop.mapred.lib.aggregate.ValueAggregatorJob'></ClassStats><ClassStats bugs='0' size='39' interface='false' sourceFile='ValueAggregatorJobBase.java' class='org.apache.hadoop.mapred.lib.aggregate.ValueAggregatorJobBase'></ClassStats><ClassStats bugs='0' size='20' interface='false' sourceFile='ValueAggregatorMapper.java' class='org.apache.hadoop.mapred.lib.aggregate.ValueAggregatorMapper'></ClassStats><ClassStats bugs='0' size='22' interface='false' sourceFile='ValueAggregatorReducer.java' class='org.apache.hadoop.mapred.lib.aggregate.ValueAggregatorReducer'></ClassStats><ClassStats bugs='1' size='3' priority_1='1' interface='false' sourceFile='ValueHistogram.java' class='org.apache.hadoop.mapred.lib.aggregate.ValueHistogram'></ClassStats></PackageStats><PackageStats package='org.apache.hadoop.mapred.lib.db' priority_1='6' total_bugs='10' priority_2='1' priority_3='3' total_size='167' total_types='9'><ClassStats bugs='1' size='29' priority_1='1' interface='false' sourceFile='DBConfiguration.java' class='org.apache.hadoop.mapred.lib.db.DBConfiguration'></ClassStats><ClassStats bugs='2' size='40' priority_1='1' priority_3='1' interface='false' sourceFile='DBInputFormat.java' class='org.apache.hadoop.mapred.lib.db.DBInputFormat'></ClassStats><ClassStats bugs='1' size='7' priority_1='1' interface='false' sourceFile='DBInputFormat.java' class='org.apache.hadoop.mapred.lib.db.DBInputFormat$DBInputSplit'></ClassStats><ClassStats bugs='1' size='24' priority_3='1' interface='false' sourceFile='DBInputFormat.java' class='org.apache.hadoop.mapred.lib.db.DBInputFormat$DBRecordReader'></ClassStats><ClassStats bugs='0' size='23' interface='false' sourceFile='DBInputFormat.java' class='org.apache.hadoop.mapred.lib.db.DBInputFormat$DBRecordReaderWrapper'></ClassStats><ClassStats bugs='2' size='3' priority_1='1' priority_3='1' interface='false' sourceFile='DBInputFormat.java' class='org.apache.hadoop.mapred.lib.db.DBInputFormat$NullDBWritable'></ClassStats><ClassStats bugs='1' size='31' priority_1='1' interface='false' sourceFile='DBOutputFormat.java' class='org.apache.hadoop.mapred.lib.db.DBOutputFormat'></ClassStats><ClassStats bugs='1' size='9' priority_1='1' interface='false' sourceFile='DBOutputFormat.java' class='org.apache.hadoop.mapred.lib.db.DBOutputFormat$DBRecordWriter'></ClassStats><ClassStats bugs='1' size='1' priority_2='1' interface='true' sourceFile='DBWritable.java' class='org.apache.hadoop.mapred.lib.db.DBWritable'></ClassStats></PackageStats><PackageStats package='org.apache.hadoop.mapred.pipes' total_bugs='5' priority_3='5' total_size='871' total_types='17'><ClassStats bugs='0' size='111' interface='false' sourceFile='Application.java' class='org.apache.hadoop.mapred.pipes.Application'></ClassStats><ClassStats bugs='0' size='111' interface='false' sourceFile='BinaryProtocol.java' class='org.apache.hadoop.mapred.pipes.BinaryProtocol'></ClassStats><ClassStats bugs='0' size='48' interface='false' sourceFile='BinaryProtocol.java' class='org.apache.hadoop.mapred.pipes.BinaryProtocol$MessageType'></ClassStats><ClassStats bugs='0' size='24' interface='false' sourceFile='BinaryProtocol.java' class='org.apache.hadoop.mapred.pipes.BinaryProtocol$TeeOutputStream'></ClassStats><ClassStats bugs='0' size='74' interface='false' sourceFile='BinaryProtocol.java' class='org.apache.hadoop.mapred.pipes.BinaryProtocol$UplinkReaderThread'></ClassStats><ClassStats bugs='0' size='14' interface='true' sourceFile='DownwardProtocol.java' class='org.apache.hadoop.mapred.pipes.DownwardProtocol'></ClassStats><ClassStats bugs='3' size='90' priority_3='3' interface='false' sourceFile='OutputHandler.java' class='org.apache.hadoop.mapred.pipes.OutputHandler'></ClassStats><ClassStats bugs='0' size='40' interface='false' sourceFile='PipesMapRunner.java' class='org.apache.hadoop.mapred.pipes.PipesMapRunner'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='PipesNonJavaInputFormat.java' class='org.apache.hadoop.mapred.pipes.PipesNonJavaInputFormat'></ClassStats><ClassStats bugs='1' size='23' priority_3='1' interface='false' sourceFile='PipesNonJavaInputFormat.java' class='org.apache.hadoop.mapred.pipes.PipesNonJavaInputFormat$PipesDummyRecordReader'></ClassStats><ClassStats bugs='0' size='21' interface='false' sourceFile='PipesPartitioner.java' class='org.apache.hadoop.mapred.pipes.PipesPartitioner'></ClassStats><ClassStats bugs='0' size='60' interface='false' sourceFile='PipesReducer.java' class='org.apache.hadoop.mapred.pipes.PipesReducer'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='PipesReducer.java' class='org.apache.hadoop.mapred.pipes.PipesReducer$1'></ClassStats><ClassStats bugs='1' size='188' priority_3='1' interface='false' sourceFile='Submitter.java' class='org.apache.hadoop.mapred.pipes.Submitter'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='Submitter.java' class='org.apache.hadoop.mapred.pipes.Submitter$1'></ClassStats><ClassStats bugs='0' size='33' interface='false' sourceFile='Submitter.java' class='org.apache.hadoop.mapred.pipes.Submitter$CommandLineParser'></ClassStats><ClassStats bugs='0' size='10' interface='true' sourceFile='UpwardProtocol.java' class='org.apache.hadoop.mapred.pipes.UpwardProtocol'></ClassStats></PackageStats><PackageStats package='org.apache.hadoop.mapreduce' total_bugs='27' priority_2='7' priority_3='20' total_size='3897' total_types='80'><ClassStats bugs='0' size='153' interface='false' sourceFile='Cluster.java' class='org.apache.hadoop.mapreduce.Cluster'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='Cluster.java' class='org.apache.hadoop.mapreduce.Cluster$1'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='Cluster.java' class='org.apache.hadoop.mapreduce.Cluster$JobTrackerStatus'></ClassStats><ClassStats bugs='0' size='92' interface='false' sourceFile='ClusterMetrics.java' class='org.apache.hadoop.mapreduce.ClusterMetrics'></ClassStats><ClassStats bugs='2' size='128' priority_3='2' interface='false' sourceFile='ContextFactory.java' class='org.apache.hadoop.mapreduce.ContextFactory'></ClassStats><ClassStats bugs='0' size='8' interface='true' sourceFile='Counter.java' class='org.apache.hadoop.mapreduce.Counter'></ClassStats><ClassStats bugs='0' size='1' interface='true' sourceFile='CounterGroup.java' class='org.apache.hadoop.mapreduce.CounterGroup'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='Counters.java' class='org.apache.hadoop.mapreduce.Counters'></ClassStats><ClassStats bugs='0' size='1' interface='false' sourceFile='Counters.java' class='org.apache.hadoop.mapreduce.Counters$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='Counters.java' class='org.apache.hadoop.mapreduce.Counters$FileSystemGroup'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='Counters.java' class='org.apache.hadoop.mapreduce.Counters$FrameworkGroupImpl'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='Counters.java' class='org.apache.hadoop.mapreduce.Counters$GenericGroup'></ClassStats><ClassStats bugs='1' size='12' priority_3='1' interface='false' sourceFile='Counters.java' class='org.apache.hadoop.mapreduce.Counters$GroupFactory'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='Counters.java' class='org.apache.hadoop.mapreduce.Counters$GroupFactory$1'></ClassStats><ClassStats bugs='1' size='75' priority_3='1' interface='false' sourceFile='CryptoUtils.java' class='org.apache.hadoop.mapreduce.CryptoUtils'></ClassStats><ClassStats bugs='0' size='18' interface='false' sourceFile='FileSystemCounter.java' class='org.apache.hadoop.mapreduce.FileSystemCounter'></ClassStats><ClassStats bugs='0' size='35' interface='false' sourceFile='ID.java' class='org.apache.hadoop.mapreduce.ID'></ClassStats><ClassStats bugs='0' size='5' interface='false' sourceFile='InputFormat.java' class='org.apache.hadoop.mapreduce.InputFormat'></ClassStats><ClassStats bugs='1' size='7' priority_3='1' interface='false' sourceFile='InputSplit.java' class='org.apache.hadoop.mapreduce.InputSplit'></ClassStats><ClassStats bugs='2' size='638' priority_3='2' interface='false' sourceFile='Job.java' class='org.apache.hadoop.mapreduce.Job'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='Job.java' class='org.apache.hadoop.mapreduce.Job$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='Job.java' class='org.apache.hadoop.mapreduce.Job$10'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='Job.java' class='org.apache.hadoop.mapreduce.Job$11'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='Job.java' class='org.apache.hadoop.mapreduce.Job$12'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='Job.java' class='org.apache.hadoop.mapreduce.Job$2'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='Job.java' class='org.apache.hadoop.mapreduce.Job$3'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='Job.java' class='org.apache.hadoop.mapreduce.Job$4'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='Job.java' class='org.apache.hadoop.mapreduce.Job$5'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='Job.java' class='org.apache.hadoop.mapreduce.Job$6'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='Job.java' class='org.apache.hadoop.mapreduce.Job$7'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='Job.java' class='org.apache.hadoop.mapreduce.Job$8'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='Job.java' class='org.apache.hadoop.mapreduce.Job$9'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='Job.java' class='org.apache.hadoop.mapreduce.Job$JobState'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='Job.java' class='org.apache.hadoop.mapreduce.Job$TaskStatusFilter'></ClassStats><ClassStats bugs='0' size='17' interface='false' sourceFile='JobACL.java' class='org.apache.hadoop.mapreduce.JobACL'></ClassStats><ClassStats bugs='0' size='38' interface='true' sourceFile='JobContext.java' class='org.apache.hadoop.mapreduce.JobContext'></ClassStats><ClassStats bugs='0' size='62' interface='false' sourceFile='JobCounter.java' class='org.apache.hadoop.mapreduce.JobCounter'></ClassStats><ClassStats bugs='2' size='62' priority_3='2' interface='false' sourceFile='JobID.java' class='org.apache.hadoop.mapreduce.JobID'></ClassStats><ClassStats bugs='0' size='22' interface='false' sourceFile='JobPriority.java' class='org.apache.hadoop.mapreduce.JobPriority'></ClassStats><ClassStats bugs='0' size='400' interface='false' sourceFile='JobResourceUploader.java' class='org.apache.hadoop.mapreduce.JobResourceUploader'></ClassStats><ClassStats bugs='0' size='40' interface='false' sourceFile='JobResourceUploader.java' class='org.apache.hadoop.mapreduce.JobResourceUploader$LimitChecker'></ClassStats><ClassStats bugs='5' size='259' priority_3='5' interface='false' sourceFile='JobStatus.java' class='org.apache.hadoop.mapreduce.JobStatus'></ClassStats><ClassStats bugs='0' size='5' interface='false' sourceFile='JobStatus.java' class='org.apache.hadoop.mapreduce.JobStatus$1'></ClassStats><ClassStats bugs='0' size='23' interface='false' sourceFile='JobStatus.java' class='org.apache.hadoop.mapreduce.JobStatus$State'></ClassStats><ClassStats bugs='0' size='58' interface='false' sourceFile='JobSubmissionFiles.java' class='org.apache.hadoop.mapreduce.JobSubmissionFiles'></ClassStats><ClassStats bugs='3' size='193' priority_3='3' interface='false' sourceFile='JobSubmitter.java' class='org.apache.hadoop.mapreduce.JobSubmitter'></ClassStats><ClassStats bugs='0' size='15' interface='false' sourceFile='JobSubmitter.java' class='org.apache.hadoop.mapreduce.JobSubmitter$1'></ClassStats><ClassStats bugs='1' size='17' priority_2='1' interface='false' sourceFile='JobSubmitter.java' class='org.apache.hadoop.mapreduce.JobSubmitter$SplitComparator'></ClassStats><ClassStats bugs='0' size='40' interface='true' sourceFile='MRConfig.java' class='org.apache.hadoop.mapreduce.MRConfig'></ClassStats><ClassStats bugs='0' size='405' interface='true' sourceFile='MRJobConfig.java' class='org.apache.hadoop.mapreduce.MRJobConfig'></ClassStats><ClassStats bugs='0' size='2' interface='true' sourceFile='MapContext.java' class='org.apache.hadoop.mapreduce.MapContext'></ClassStats><ClassStats bugs='0' size='17' interface='false' sourceFile='Mapper.java' class='org.apache.hadoop.mapreduce.Mapper'></ClassStats><ClassStats bugs='0' size='4' interface='false' sourceFile='Mapper.java' class='org.apache.hadoop.mapreduce.Mapper$Context'></ClassStats><ClassStats bugs='0' size='23' interface='false' sourceFile='MarkableIterator.java' class='org.apache.hadoop.mapreduce.MarkableIterator'></ClassStats><ClassStats bugs='0' size='4' interface='true' sourceFile='MarkableIteratorInterface.java' class='org.apache.hadoop.mapreduce.MarkableIteratorInterface'></ClassStats><ClassStats bugs='0' size='24' interface='false' sourceFile='OutputCommitter.java' class='org.apache.hadoop.mapreduce.OutputCommitter'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='OutputFormat.java' class='org.apache.hadoop.mapreduce.OutputFormat'></ClassStats><ClassStats bugs='0' size='4' interface='false' sourceFile='Partitioner.java' class='org.apache.hadoop.mapreduce.Partitioner'></ClassStats><ClassStats bugs='2' size='26' priority_2='2' interface='false' sourceFile='QueueAclsInfo.java' class='org.apache.hadoop.mapreduce.QueueAclsInfo'></ClassStats><ClassStats bugs='2' size='86' priority_2='2' interface='false' sourceFile='QueueInfo.java' class='org.apache.hadoop.mapreduce.QueueInfo'></ClassStats><ClassStats bugs='0' size='29' interface='false' sourceFile='QueueState.java' class='org.apache.hadoop.mapreduce.QueueState'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='RecordReader.java' class='org.apache.hadoop.mapreduce.RecordReader'></ClassStats><ClassStats bugs='0' size='5' interface='false' sourceFile='RecordWriter.java' class='org.apache.hadoop.mapreduce.RecordWriter'></ClassStats><ClassStats bugs='0' size='3' interface='true' sourceFile='ReduceContext.java' class='org.apache.hadoop.mapreduce.ReduceContext'></ClassStats><ClassStats bugs='0' size='2' interface='true' sourceFile='ReduceContext.java' class='org.apache.hadoop.mapreduce.ReduceContext$ValueIterator'></ClassStats><ClassStats bugs='0' size='23' interface='false' sourceFile='Reducer.java' class='org.apache.hadoop.mapreduce.Reducer'></ClassStats><ClassStats bugs='0' size='4' interface='false' sourceFile='Reducer.java' class='org.apache.hadoop.mapreduce.Reducer$Context'></ClassStats><ClassStats bugs='0' size='51' interface='false' sourceFile='SharedCacheConfig.java' class='org.apache.hadoop.mapreduce.SharedCacheConfig'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='StatusReporter.java' class='org.apache.hadoop.mapreduce.StatusReporter'></ClassStats><ClassStats bugs='0' size='7' interface='true' sourceFile='TaskAttemptContext.java' class='org.apache.hadoop.mapreduce.TaskAttemptContext'></ClassStats><ClassStats bugs='2' size='74' priority_3='2' interface='false' sourceFile='TaskAttemptID.java' class='org.apache.hadoop.mapreduce.TaskAttemptID'></ClassStats><ClassStats bugs='0' size='94' interface='false' sourceFile='TaskCompletionEvent.java' class='org.apache.hadoop.mapreduce.TaskCompletionEvent'></ClassStats><ClassStats bugs='0' size='18' interface='false' sourceFile='TaskCompletionEvent.java' class='org.apache.hadoop.mapreduce.TaskCompletionEvent$Status'></ClassStats><ClassStats bugs='0' size='62' interface='false' sourceFile='TaskCounter.java' class='org.apache.hadoop.mapreduce.TaskCounter'></ClassStats><ClassStats bugs='0' size='92' interface='false' sourceFile='TaskID.java' class='org.apache.hadoop.mapreduce.TaskID'></ClassStats><ClassStats bugs='0' size='31' interface='false' sourceFile='TaskID.java' class='org.apache.hadoop.mapreduce.TaskID$CharTaskTypeMaps'></ClassStats><ClassStats bugs='0' size='6' interface='true' sourceFile='TaskInputOutputContext.java' class='org.apache.hadoop.mapreduce.TaskInputOutputContext'></ClassStats><ClassStats bugs='3' size='116' priority_2='2' priority_3='1' interface='false' sourceFile='TaskReport.java' class='org.apache.hadoop.mapreduce.TaskReport'></ClassStats><ClassStats bugs='0' size='42' interface='false' sourceFile='TaskTrackerInfo.java' class='org.apache.hadoop.mapreduce.TaskTrackerInfo'></ClassStats><ClassStats bugs='0' size='14' interface='false' sourceFile='TaskType.java' class='org.apache.hadoop.mapreduce.TaskType'></ClassStats></PackageStats><PackageStats package='org.apache.hadoop.mapreduce.checkpoint' total_bugs='0' total_size='206' total_types='13'><ClassStats bugs='0' size='1' interface='true' sourceFile='CheckpointID.java' class='org.apache.hadoop.mapreduce.checkpoint.CheckpointID'></ClassStats><ClassStats bugs='0' size='2' interface='true' sourceFile='CheckpointNamingService.java' class='org.apache.hadoop.mapreduce.checkpoint.CheckpointNamingService'></ClassStats><ClassStats bugs='0' size='6' interface='true' sourceFile='CheckpointService.java' class='org.apache.hadoop.mapreduce.checkpoint.CheckpointService'></ClassStats><ClassStats bugs='0' size='1' interface='true' sourceFile='CheckpointService.java' class='org.apache.hadoop.mapreduce.checkpoint.CheckpointService$CheckpointReadChannel'></ClassStats><ClassStats bugs='0' size='1' interface='true' sourceFile='CheckpointService.java' class='org.apache.hadoop.mapreduce.checkpoint.CheckpointService$CheckpointWriteChannel'></ClassStats><ClassStats bugs='0' size='17' interface='false' sourceFile='EnumCounter.java' class='org.apache.hadoop.mapreduce.checkpoint.EnumCounter'></ClassStats><ClassStats bugs='0' size='24' interface='false' sourceFile='FSCheckpointID.java' class='org.apache.hadoop.mapreduce.checkpoint.FSCheckpointID'></ClassStats><ClassStats bugs='0' size='56' interface='false' sourceFile='FSCheckpointService.java' class='org.apache.hadoop.mapreduce.checkpoint.FSCheckpointService'></ClassStats><ClassStats bugs='0' size='16' interface='false' sourceFile='FSCheckpointService.java' class='org.apache.hadoop.mapreduce.checkpoint.FSCheckpointService$FSCheckpointReadChannel'></ClassStats><ClassStats bugs='0' size='20' interface='false' sourceFile='FSCheckpointService.java' class='org.apache.hadoop.mapreduce.checkpoint.FSCheckpointService$FSCheckpointWriteChannel'></ClassStats><ClassStats bugs='0' size='5' interface='false' sourceFile='RandomNameCNS.java' class='org.apache.hadoop.mapreduce.checkpoint.RandomNameCNS'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='SimpleNamingService.java' class='org.apache.hadoop.mapreduce.checkpoint.SimpleNamingService'></ClassStats><ClassStats bugs='0' size='49' interface='false' sourceFile='TaskCheckpointID.java' class='org.apache.hadoop.mapreduce.checkpoint.TaskCheckpointID'></ClassStats></PackageStats><PackageStats package='org.apache.hadoop.mapreduce.counters' total_bugs='0' total_size='837' total_types='18'><ClassStats bugs='0' size='16' interface='false' sourceFile='AbstractCounter.java' class='org.apache.hadoop.mapreduce.counters.AbstractCounter'></ClassStats><ClassStats bugs='0' size='91' interface='false' sourceFile='AbstractCounterGroup.java' class='org.apache.hadoop.mapreduce.counters.AbstractCounterGroup'></ClassStats><ClassStats bugs='0' size='179' interface='false' sourceFile='AbstractCounters.java' class='org.apache.hadoop.mapreduce.counters.AbstractCounters'></ClassStats><ClassStats bugs='0' size='4' interface='false' sourceFile='AbstractCounters.java' class='org.apache.hadoop.mapreduce.counters.AbstractCounters$1'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='AbstractCounters.java' class='org.apache.hadoop.mapreduce.counters.AbstractCounters$GroupType'></ClassStats><ClassStats bugs='0' size='12' interface='true' sourceFile='CounterGroupBase.java' class='org.apache.hadoop.mapreduce.counters.CounterGroupBase'></ClassStats><ClassStats bugs='0' size='60' interface='false' sourceFile='CounterGroupFactory.java' class='org.apache.hadoop.mapreduce.counters.CounterGroupFactory'></ClassStats><ClassStats bugs='0' size='2' interface='true' sourceFile='CounterGroupFactory.java' class='org.apache.hadoop.mapreduce.counters.CounterGroupFactory$FrameworkGroupFactory'></ClassStats><ClassStats bugs='0' size='130' interface='false' sourceFile='FileSystemCounterGroup.java' class='org.apache.hadoop.mapreduce.counters.FileSystemCounterGroup'></ClassStats><ClassStats bugs='0' size='20' interface='false' sourceFile='FileSystemCounterGroup.java' class='org.apache.hadoop.mapreduce.counters.FileSystemCounterGroup$1'></ClassStats><ClassStats bugs='0' size='38' interface='false' sourceFile='FileSystemCounterGroup.java' class='org.apache.hadoop.mapreduce.counters.FileSystemCounterGroup$FSCounter'></ClassStats><ClassStats bugs='0' size='103' interface='false' sourceFile='FrameworkCounterGroup.java' class='org.apache.hadoop.mapreduce.counters.FrameworkCounterGroup'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='FrameworkCounterGroup.java' class='org.apache.hadoop.mapreduce.counters.FrameworkCounterGroup$1'></ClassStats><ClassStats bugs='0' size='38' interface='false' sourceFile='FrameworkCounterGroup.java' class='org.apache.hadoop.mapreduce.counters.FrameworkCounterGroup$FrameworkCounter'></ClassStats><ClassStats bugs='0' size='50' interface='false' sourceFile='GenericCounter.java' class='org.apache.hadoop.mapreduce.counters.GenericCounter'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='LimitExceededException.java' class='org.apache.hadoop.mapreduce.counters.LimitExceededException'></ClassStats><ClassStats bugs='0' size='63' interface='false' sourceFile='Limits.java' class='org.apache.hadoop.mapreduce.counters.Limits'></ClassStats><ClassStats bugs='0' size='1' interface='true' sourceFile='package-info.java' class='org.apache.hadoop.mapreduce.counters.package-info'></ClassStats></PackageStats><PackageStats package='org.apache.hadoop.mapreduce.filecache' total_bugs='6' priority_3='6' total_size='246' total_types='3'><ClassStats bugs='0' size='123' interface='false' sourceFile='ClientDistributedCacheManager.java' class='org.apache.hadoop.mapreduce.filecache.ClientDistributedCacheManager'></ClassStats><ClassStats bugs='6' size='122' priority_3='6' interface='false' sourceFile='DistributedCache.java' class='org.apache.hadoop.mapreduce.filecache.DistributedCache'></ClassStats><ClassStats bugs='0' size='1' interface='true' sourceFile='package-info.java' class='org.apache.hadoop.mapreduce.filecache.package-info'></ClassStats></PackageStats><PackageStats package='org.apache.hadoop.mapreduce.jobhistory' total_bugs='107' priority_2='17' priority_3='90' total_size='8401' total_types='114'><ClassStats bugs='1' size='80' priority_3='1' interface='false' sourceFile='AMStarted.java' class='org.apache.hadoop.mapreduce.jobhistory.AMStarted'></ClassStats><ClassStats bugs='0' size='1' interface='false' sourceFile='AMStarted.java' class='org.apache.hadoop.mapreduce.jobhistory.AMStarted$1'></ClassStats><ClassStats bugs='1' size='143' priority_3='1' interface='false' sourceFile='AMStarted.java' class='org.apache.hadoop.mapreduce.jobhistory.AMStarted$Builder'></ClassStats><ClassStats bugs='0' size='60' interface='false' sourceFile='AMStartedEvent.java' class='org.apache.hadoop.mapreduce.jobhistory.AMStartedEvent'></ClassStats><ClassStats bugs='2' size='20' priority_3='2' interface='false' sourceFile='AvroArrayUtils.java' class='org.apache.hadoop.mapreduce.jobhistory.AvroArrayUtils'></ClassStats><ClassStats bugs='1' size='44' priority_3='1' interface='false' sourceFile='Event.java' class='org.apache.hadoop.mapreduce.jobhistory.Event'></ClassStats><ClassStats bugs='0' size='1' interface='false' sourceFile='Event.java' class='org.apache.hadoop.mapreduce.jobhistory.Event$1'></ClassStats><ClassStats bugs='1' size='62' priority_3='1' interface='false' sourceFile='Event.java' class='org.apache.hadoop.mapreduce.jobhistory.Event$Builder'></ClassStats><ClassStats bugs='0' size='88' interface='false' sourceFile='EventReader.java' class='org.apache.hadoop.mapreduce.jobhistory.EventReader'></ClassStats><ClassStats bugs='0' size='4' interface='false' sourceFile='EventReader.java' class='org.apache.hadoop.mapreduce.jobhistory.EventReader$1'></ClassStats><ClassStats bugs='0' size='45' interface='false' sourceFile='EventType.java' class='org.apache.hadoop.mapreduce.jobhistory.EventType'></ClassStats><ClassStats bugs='0' size='79' interface='false' sourceFile='EventWriter.java' class='org.apache.hadoop.mapreduce.jobhistory.EventWriter'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='EventWriter.java' class='org.apache.hadoop.mapreduce.jobhistory.EventWriter$WriteMode'></ClassStats><ClassStats bugs='0' size='4' interface='true' sourceFile='Events.java' class='org.apache.hadoop.mapreduce.jobhistory.Events'></ClassStats><ClassStats bugs='0' size='4' interface='true' sourceFile='Events.java' class='org.apache.hadoop.mapreduce.jobhistory.Events$Callback'></ClassStats><ClassStats bugs='0' size='6' interface='true' sourceFile='HistoryEvent.java' class='org.apache.hadoop.mapreduce.jobhistory.HistoryEvent'></ClassStats><ClassStats bugs='0' size='2' interface='true' sourceFile='HistoryEventHandler.java' class='org.apache.hadoop.mapreduce.jobhistory.HistoryEventHandler'></ClassStats><ClassStats bugs='0' size='49' interface='false' sourceFile='HistoryViewer.java' class='org.apache.hadoop.mapreduce.jobhistory.HistoryViewer'></ClassStats><ClassStats bugs='2' size='52' priority_2='2' interface='false' sourceFile='HistoryViewer.java' class='org.apache.hadoop.mapreduce.jobhistory.HistoryViewer$AnalyzedJob'></ClassStats><ClassStats bugs='0' size='28' interface='false' sourceFile='HistoryViewer.java' class='org.apache.hadoop.mapreduce.jobhistory.HistoryViewer$FilteredJob'></ClassStats><ClassStats bugs='0' size='156' interface='false' sourceFile='HistoryViewer.java' class='org.apache.hadoop.mapreduce.jobhistory.HistoryViewer$SummarizedJob'></ClassStats><ClassStats bugs='0' size='2' interface='true' sourceFile='HistoryViewerPrinter.java' class='org.apache.hadoop.mapreduce.jobhistory.HistoryViewerPrinter'></ClassStats><ClassStats bugs='1' size='307' priority_3='1' interface='false' sourceFile='HumanReadableHistoryViewerPrinter.java' class='org.apache.hadoop.mapreduce.jobhistory.HumanReadableHistoryViewerPrinter'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='HumanReadableHistoryViewerPrinter.java' class='org.apache.hadoop.mapreduce.jobhistory.HumanReadableHistoryViewerPrinter$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='HumanReadableHistoryViewerPrinter.java' class='org.apache.hadoop.mapreduce.jobhistory.HumanReadableHistoryViewerPrinter$2'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='HumanReadableHistoryViewerPrinter.java' class='org.apache.hadoop.mapreduce.jobhistory.HumanReadableHistoryViewerPrinter$3'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='HumanReadableHistoryViewerPrinter.java' class='org.apache.hadoop.mapreduce.jobhistory.HumanReadableHistoryViewerPrinter$4'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='HumanReadableHistoryViewerPrinter.java' class='org.apache.hadoop.mapreduce.jobhistory.HumanReadableHistoryViewerPrinter$5'></ClassStats><ClassStats bugs='0' size='167' interface='false' sourceFile='JSONHistoryViewerPrinter.java' class='org.apache.hadoop.mapreduce.jobhistory.JSONHistoryViewerPrinter'></ClassStats><ClassStats bugs='1' size='53' priority_3='1' interface='false' sourceFile='JhCounter.java' class='org.apache.hadoop.mapreduce.jobhistory.JhCounter'></ClassStats><ClassStats bugs='0' size='1' interface='false' sourceFile='JhCounter.java' class='org.apache.hadoop.mapreduce.jobhistory.JhCounter$1'></ClassStats><ClassStats bugs='1' size='82' priority_3='1' interface='false' sourceFile='JhCounter.java' class='org.apache.hadoop.mapreduce.jobhistory.JhCounter$Builder'></ClassStats><ClassStats bugs='1' size='53' priority_3='1' interface='false' sourceFile='JhCounterGroup.java' class='org.apache.hadoop.mapreduce.jobhistory.JhCounterGroup'></ClassStats><ClassStats bugs='0' size='1' interface='false' sourceFile='JhCounterGroup.java' class='org.apache.hadoop.mapreduce.jobhistory.JhCounterGroup$1'></ClassStats><ClassStats bugs='1' size='83' priority_3='1' interface='false' sourceFile='JhCounterGroup.java' class='org.apache.hadoop.mapreduce.jobhistory.JhCounterGroup$Builder'></ClassStats><ClassStats bugs='1' size='44' priority_3='1' interface='false' sourceFile='JhCounters.java' class='org.apache.hadoop.mapreduce.jobhistory.JhCounters'></ClassStats><ClassStats bugs='0' size='1' interface='false' sourceFile='JhCounters.java' class='org.apache.hadoop.mapreduce.jobhistory.JhCounters$1'></ClassStats><ClassStats bugs='1' size='62' priority_3='1' interface='false' sourceFile='JhCounters.java' class='org.apache.hadoop.mapreduce.jobhistory.JhCounters$Builder'></ClassStats><ClassStats bugs='1' size='125' priority_3='1' interface='false' sourceFile='JobFinished.java' class='org.apache.hadoop.mapreduce.jobhistory.JobFinished'></ClassStats><ClassStats bugs='0' size='1' interface='false' sourceFile='JobFinished.java' class='org.apache.hadoop.mapreduce.jobhistory.JobFinished$1'></ClassStats><ClassStats bugs='2' size='244' priority_3='2' interface='false' sourceFile='JobFinished.java' class='org.apache.hadoop.mapreduce.jobhistory.JobFinished$Builder'></ClassStats><ClassStats bugs='0' size='107' interface='false' sourceFile='JobFinishedEvent.java' class='org.apache.hadoop.mapreduce.jobhistory.JobFinishedEvent'></ClassStats><ClassStats bugs='17' size='255' priority_3='17' interface='false' sourceFile='JobHistoryParser.java' class='org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser'></ClassStats><ClassStats bugs='0' size='4' interface='false' sourceFile='JobHistoryParser.java' class='org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser$1'></ClassStats><ClassStats bugs='0' size='42' interface='false' sourceFile='JobHistoryParser.java' class='org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser$AMInfo'></ClassStats><ClassStats bugs='0' size='122' interface='false' sourceFile='JobHistoryParser.java' class='org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser$JobInfo'></ClassStats><ClassStats bugs='2' size='78' priority_3='2' interface='false' sourceFile='JobHistoryParser.java' class='org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser$TaskAttemptInfo'></ClassStats><ClassStats bugs='0' size='51' interface='false' sourceFile='JobHistoryParser.java' class='org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser$TaskInfo'></ClassStats><ClassStats bugs='1' size='53' priority_3='1' interface='false' sourceFile='JobInfoChange.java' class='org.apache.hadoop.mapreduce.jobhistory.JobInfoChange'></ClassStats><ClassStats bugs='0' size='1' interface='false' sourceFile='JobInfoChange.java' class='org.apache.hadoop.mapreduce.jobhistory.JobInfoChange$1'></ClassStats><ClassStats bugs='1' size='81' priority_3='1' interface='false' sourceFile='JobInfoChange.java' class='org.apache.hadoop.mapreduce.jobhistory.JobInfoChange$Builder'></ClassStats><ClassStats bugs='0' size='32' interface='false' sourceFile='JobInfoChangeEvent.java' class='org.apache.hadoop.mapreduce.jobhistory.JobInfoChangeEvent'></ClassStats><ClassStats bugs='1' size='80' priority_3='1' interface='false' sourceFile='JobInited.java' class='org.apache.hadoop.mapreduce.jobhistory.JobInited'></ClassStats><ClassStats bugs='0' size='1' interface='false' sourceFile='JobInited.java' class='org.apache.hadoop.mapreduce.jobhistory.JobInited$1'></ClassStats><ClassStats bugs='1' size='142' priority_3='1' interface='false' sourceFile='JobInited.java' class='org.apache.hadoop.mapreduce.jobhistory.JobInited$Builder'></ClassStats><ClassStats bugs='0' size='43' interface='false' sourceFile='JobInitedEvent.java' class='org.apache.hadoop.mapreduce.jobhistory.JobInitedEvent'></ClassStats><ClassStats bugs='1' size='44' priority_3='1' interface='false' sourceFile='JobPriorityChange.java' class='org.apache.hadoop.mapreduce.jobhistory.JobPriorityChange'></ClassStats><ClassStats bugs='0' size='1' interface='false' sourceFile='JobPriorityChange.java' class='org.apache.hadoop.mapreduce.jobhistory.JobPriorityChange$1'></ClassStats><ClassStats bugs='1' size='62' priority_3='1' interface='false' sourceFile='JobPriorityChange.java' class='org.apache.hadoop.mapreduce.jobhistory.JobPriorityChange$Builder'></ClassStats><ClassStats bugs='0' size='28' interface='false' sourceFile='JobPriorityChangeEvent.java' class='org.apache.hadoop.mapreduce.jobhistory.JobPriorityChangeEvent'></ClassStats><ClassStats bugs='1' size='44' priority_3='1' interface='false' sourceFile='JobQueueChange.java' class='org.apache.hadoop.mapreduce.jobhistory.JobQueueChange'></ClassStats><ClassStats bugs='0' size='1' interface='false' sourceFile='JobQueueChange.java' class='org.apache.hadoop.mapreduce.jobhistory.JobQueueChange$1'></ClassStats><ClassStats bugs='1' size='62' priority_3='1' interface='false' sourceFile='JobQueueChange.java' class='org.apache.hadoop.mapreduce.jobhistory.JobQueueChange$Builder'></ClassStats><ClassStats bugs='0' size='30' interface='false' sourceFile='JobQueueChangeEvent.java' class='org.apache.hadoop.mapreduce.jobhistory.JobQueueChangeEvent'></ClassStats><ClassStats bugs='1' size='44' priority_3='1' interface='false' sourceFile='JobStatusChanged.java' class='org.apache.hadoop.mapreduce.jobhistory.JobStatusChanged'></ClassStats><ClassStats bugs='0' size='1' interface='false' sourceFile='JobStatusChanged.java' class='org.apache.hadoop.mapreduce.jobhistory.JobStatusChanged$1'></ClassStats><ClassStats bugs='1' size='62' priority_3='1' interface='false' sourceFile='JobStatusChanged.java' class='org.apache.hadoop.mapreduce.jobhistory.JobStatusChanged$Builder'></ClassStats><ClassStats bugs='0' size='28' interface='false' sourceFile='JobStatusChangedEvent.java' class='org.apache.hadoop.mapreduce.jobhistory.JobStatusChangedEvent'></ClassStats><ClassStats bugs='1' size='134' priority_3='1' interface='false' sourceFile='JobSubmitted.java' class='org.apache.hadoop.mapreduce.jobhistory.JobSubmitted'></ClassStats><ClassStats bugs='0' size='1' interface='false' sourceFile='JobSubmitted.java' class='org.apache.hadoop.mapreduce.jobhistory.JobSubmitted$1'></ClassStats><ClassStats bugs='2' size='271' priority_3='2' interface='false' sourceFile='JobSubmitted.java' class='org.apache.hadoop.mapreduce.jobhistory.JobSubmitted$Builder'></ClassStats><ClassStats bugs='0' size='113' interface='false' sourceFile='JobSubmittedEvent.java' class='org.apache.hadoop.mapreduce.jobhistory.JobSubmittedEvent'></ClassStats><ClassStats bugs='1' size='116' priority_3='1' interface='false' sourceFile='JobUnsuccessfulCompletion.java' class='org.apache.hadoop.mapreduce.jobhistory.JobUnsuccessfulCompletion'></ClassStats><ClassStats bugs='0' size='1' interface='false' sourceFile='JobUnsuccessfulCompletion.java' class='org.apache.hadoop.mapreduce.jobhistory.JobUnsuccessfulCompletion$1'></ClassStats><ClassStats bugs='2' size='223' priority_3='2' interface='false' sourceFile='JobUnsuccessfulCompletion.java' class='org.apache.hadoop.mapreduce.jobhistory.JobUnsuccessfulCompletion$Builder'></ClassStats><ClassStats bugs='0' size='80' interface='false' sourceFile='JobUnsuccessfulCompletionEvent.java' class='org.apache.hadoop.mapreduce.jobhistory.JobUnsuccessfulCompletionEvent'></ClassStats><ClassStats bugs='1' size='161' priority_3='1' interface='false' sourceFile='MapAttemptFinished.java' class='org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished'></ClassStats><ClassStats bugs='0' size='1' interface='false' sourceFile='MapAttemptFinished.java' class='org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished$1'></ClassStats><ClassStats bugs='2' size='332' priority_3='2' interface='false' sourceFile='MapAttemptFinished.java' class='org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinished$Builder'></ClassStats><ClassStats bugs='9' size='140' priority_2='5' priority_3='4' interface='false' sourceFile='MapAttemptFinishedEvent.java' class='org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinishedEvent'></ClassStats><ClassStats bugs='0' size='26' interface='false' sourceFile='NormalizedResourceEvent.java' class='org.apache.hadoop.mapreduce.jobhistory.NormalizedResourceEvent'></ClassStats><ClassStats bugs='1' size='170' priority_3='1' interface='false' sourceFile='ReduceAttemptFinished.java' class='org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished'></ClassStats><ClassStats bugs='0' size='1' interface='false' sourceFile='ReduceAttemptFinished.java' class='org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished$1'></ClassStats><ClassStats bugs='2' size='352' priority_3='2' interface='false' sourceFile='ReduceAttemptFinished.java' class='org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinished$Builder'></ClassStats><ClassStats bugs='9' size='147' priority_2='5' priority_3='4' interface='false' sourceFile='ReduceAttemptFinishedEvent.java' class='org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinishedEvent'></ClassStats><ClassStats bugs='1' size='107' priority_3='1' interface='false' sourceFile='TaskAttemptFinished.java' class='org.apache.hadoop.mapreduce.jobhistory.TaskAttemptFinished'></ClassStats><ClassStats bugs='0' size='1' interface='false' sourceFile='TaskAttemptFinished.java' class='org.apache.hadoop.mapreduce.jobhistory.TaskAttemptFinished$1'></ClassStats><ClassStats bugs='2' size='208' priority_3='2' interface='false' sourceFile='TaskAttemptFinished.java' class='org.apache.hadoop.mapreduce.jobhistory.TaskAttemptFinished$Builder'></ClassStats><ClassStats bugs='4' size='92' priority_3='4' interface='false' sourceFile='TaskAttemptFinishedEvent.java' class='org.apache.hadoop.mapreduce.jobhistory.TaskAttemptFinishedEvent'></ClassStats><ClassStats bugs='1' size='116' priority_3='1' interface='false' sourceFile='TaskAttemptStarted.java' class='org.apache.hadoop.mapreduce.jobhistory.TaskAttemptStarted'></ClassStats><ClassStats bugs='0' size='1' interface='false' sourceFile='TaskAttemptStarted.java' class='org.apache.hadoop.mapreduce.jobhistory.TaskAttemptStarted$1'></ClassStats><ClassStats bugs='2' size='227' priority_3='2' interface='false' sourceFile='TaskAttemptStarted.java' class='org.apache.hadoop.mapreduce.jobhistory.TaskAttemptStarted$Builder'></ClassStats><ClassStats bugs='0' size='70' interface='false' sourceFile='TaskAttemptStartedEvent.java' class='org.apache.hadoop.mapreduce.jobhistory.TaskAttemptStartedEvent'></ClassStats><ClassStats bugs='1' size='152' priority_3='1' interface='false' sourceFile='TaskAttemptUnsuccessfulCompletion.java' class='org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion'></ClassStats><ClassStats bugs='0' size='1' interface='false' sourceFile='TaskAttemptUnsuccessfulCompletion.java' class='org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion$1'></ClassStats><ClassStats bugs='2' size='312' priority_3='2' interface='false' sourceFile='TaskAttemptUnsuccessfulCompletion.java' class='org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion$Builder'></ClassStats><ClassStats bugs='8' size='154' priority_2='5' priority_3='3' interface='false' sourceFile='TaskAttemptUnsuccessfulCompletionEvent.java' class='org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletionEvent'></ClassStats><ClassStats bugs='1' size='89' priority_3='1' interface='false' sourceFile='TaskFailed.java' class='org.apache.hadoop.mapreduce.jobhistory.TaskFailed'></ClassStats><ClassStats bugs='0' size='1' interface='false' sourceFile='TaskFailed.java' class='org.apache.hadoop.mapreduce.jobhistory.TaskFailed$1'></ClassStats><ClassStats bugs='1' size='166' priority_3='1' interface='false' sourceFile='TaskFailed.java' class='org.apache.hadoop.mapreduce.jobhistory.TaskFailed$Builder'></ClassStats><ClassStats bugs='0' size='94' interface='false' sourceFile='TaskFailedEvent.java' class='org.apache.hadoop.mapreduce.jobhistory.TaskFailedEvent'></ClassStats><ClassStats bugs='1' size='80' priority_3='1' interface='false' sourceFile='TaskFinished.java' class='org.apache.hadoop.mapreduce.jobhistory.TaskFinished'></ClassStats><ClassStats bugs='0' size='1' interface='false' sourceFile='TaskFinished.java' class='org.apache.hadoop.mapreduce.jobhistory.TaskFinished$1'></ClassStats><ClassStats bugs='1' size='145' priority_3='1' interface='false' sourceFile='TaskFinished.java' class='org.apache.hadoop.mapreduce.jobhistory.TaskFinished$Builder'></ClassStats><ClassStats bugs='1' size='78' priority_3='1' interface='false' sourceFile='TaskFinishedEvent.java' class='org.apache.hadoop.mapreduce.jobhistory.TaskFinishedEvent'></ClassStats><ClassStats bugs='1' size='62' priority_3='1' interface='false' sourceFile='TaskStarted.java' class='org.apache.hadoop.mapreduce.jobhistory.TaskStarted'></ClassStats><ClassStats bugs='0' size='1' interface='false' sourceFile='TaskStarted.java' class='org.apache.hadoop.mapreduce.jobhistory.TaskStarted$1'></ClassStats><ClassStats bugs='1' size='103' priority_3='1' interface='false' sourceFile='TaskStarted.java' class='org.apache.hadoop.mapreduce.jobhistory.TaskStarted$Builder'></ClassStats><ClassStats bugs='0' size='35' interface='false' sourceFile='TaskStartedEvent.java' class='org.apache.hadoop.mapreduce.jobhistory.TaskStartedEvent'></ClassStats><ClassStats bugs='1' size='44' priority_3='1' interface='false' sourceFile='TaskUpdated.java' class='org.apache.hadoop.mapreduce.jobhistory.TaskUpdated'></ClassStats><ClassStats bugs='0' size='1' interface='false' sourceFile='TaskUpdated.java' class='org.apache.hadoop.mapreduce.jobhistory.TaskUpdated$1'></ClassStats><ClassStats bugs='1' size='61' priority_3='1' interface='false' sourceFile='TaskUpdated.java' class='org.apache.hadoop.mapreduce.jobhistory.TaskUpdated$Builder'></ClassStats><ClassStats bugs='0' size='27' interface='false' sourceFile='TaskUpdatedEvent.java' class='org.apache.hadoop.mapreduce.jobhistory.TaskUpdatedEvent'></ClassStats><ClassStats bugs='0' size='1' interface='true' sourceFile='package-info.java' class='org.apache.hadoop.mapreduce.jobhistory.package-info'></ClassStats></PackageStats><PackageStats package='org.apache.hadoop.mapreduce.lib.aggregate' total_bugs='4' priority_2='1' priority_3='3' total_size='583' total_types='18'><ClassStats bugs='0' size='24' interface='false' sourceFile='DoubleValueSum.java' class='org.apache.hadoop.mapreduce.lib.aggregate.DoubleValueSum'></ClassStats><ClassStats bugs='0' size='27' interface='false' sourceFile='LongValueMax.java' class='org.apache.hadoop.mapreduce.lib.aggregate.LongValueMax'></ClassStats><ClassStats bugs='0' size='27' interface='false' sourceFile='LongValueMin.java' class='org.apache.hadoop.mapreduce.lib.aggregate.LongValueMin'></ClassStats><ClassStats bugs='0' size='24' interface='false' sourceFile='LongValueSum.java' class='org.apache.hadoop.mapreduce.lib.aggregate.LongValueSum'></ClassStats><ClassStats bugs='0' size='23' interface='false' sourceFile='StringValueMax.java' class='org.apache.hadoop.mapreduce.lib.aggregate.StringValueMax'></ClassStats><ClassStats bugs='0' size='23' interface='false' sourceFile='StringValueMin.java' class='org.apache.hadoop.mapreduce.lib.aggregate.StringValueMin'></ClassStats><ClassStats bugs='0' size='45' interface='false' sourceFile='UniqValueCount.java' class='org.apache.hadoop.mapreduce.lib.aggregate.UniqValueCount'></ClassStats><ClassStats bugs='1' size='38' priority_3='1' interface='false' sourceFile='UserDefinedValueAggregatorDescriptor.java' class='org.apache.hadoop.mapreduce.lib.aggregate.UserDefinedValueAggregatorDescriptor'></ClassStats><ClassStats bugs='0' size='5' interface='true' sourceFile='ValueAggregator.java' class='org.apache.hadoop.mapreduce.lib.aggregate.ValueAggregator'></ClassStats><ClassStats bugs='1' size='49' priority_3='1' interface='false' sourceFile='ValueAggregatorBaseDescriptor.java' class='org.apache.hadoop.mapreduce.lib.aggregate.ValueAggregatorBaseDescriptor'></ClassStats><ClassStats bugs='0' size='19' interface='false' sourceFile='ValueAggregatorBaseDescriptor.java' class='org.apache.hadoop.mapreduce.lib.aggregate.ValueAggregatorBaseDescriptor$MyEntry'></ClassStats><ClassStats bugs='0' size='24' interface='false' sourceFile='ValueAggregatorCombiner.java' class='org.apache.hadoop.mapreduce.lib.aggregate.ValueAggregatorCombiner'></ClassStats><ClassStats bugs='0' size='7' interface='true' sourceFile='ValueAggregatorDescriptor.java' class='org.apache.hadoop.mapreduce.lib.aggregate.ValueAggregatorDescriptor'></ClassStats><ClassStats bugs='1' size='75' priority_3='1' interface='false' sourceFile='ValueAggregatorJob.java' class='org.apache.hadoop.mapreduce.lib.aggregate.ValueAggregatorJob'></ClassStats><ClassStats bugs='1' size='40' priority_2='1' interface='false' sourceFile='ValueAggregatorJobBase.java' class='org.apache.hadoop.mapreduce.lib.aggregate.ValueAggregatorJobBase'></ClassStats><ClassStats bugs='0' size='21' interface='false' sourceFile='ValueAggregatorMapper.java' class='org.apache.hadoop.mapreduce.lib.aggregate.ValueAggregatorMapper'></ClassStats><ClassStats bugs='0' size='25' interface='false' sourceFile='ValueAggregatorReducer.java' class='org.apache.hadoop.mapreduce.lib.aggregate.ValueAggregatorReducer'></ClassStats><ClassStats bugs='0' size='87' interface='false' sourceFile='ValueHistogram.java' class='org.apache.hadoop.mapreduce.lib.aggregate.ValueHistogram'></ClassStats></PackageStats><PackageStats package='org.apache.hadoop.mapreduce.lib.chain' total_bugs='5' priority_3='5' total_size='724' total_types='11'><ClassStats bugs='2' size='247' priority_3='2' interface='false' sourceFile='Chain.java' class='org.apache.hadoop.mapreduce.lib.chain.Chain'></ClassStats><ClassStats bugs='3' size='31' priority_3='3' interface='false' sourceFile='Chain.java' class='org.apache.hadoop.mapreduce.lib.chain.Chain$ChainBlockingQueue'></ClassStats><ClassStats bugs='0' size='49' interface='false' sourceFile='Chain.java' class='org.apache.hadoop.mapreduce.lib.chain.Chain$ChainRecordReader'></ClassStats><ClassStats bugs='0' size='37' interface='false' sourceFile='Chain.java' class='org.apache.hadoop.mapreduce.lib.chain.Chain$ChainRecordWriter'></ClassStats><ClassStats bugs='0' size='16' interface='false' sourceFile='Chain.java' class='org.apache.hadoop.mapreduce.lib.chain.Chain$KeyValuePair'></ClassStats><ClassStats bugs='0' size='24' interface='false' sourceFile='Chain.java' class='org.apache.hadoop.mapreduce.lib.chain.Chain$MapRunner'></ClassStats><ClassStats bugs='0' size='19' interface='false' sourceFile='Chain.java' class='org.apache.hadoop.mapreduce.lib.chain.Chain$ReduceRunner'></ClassStats><ClassStats bugs='0' size='118' interface='false' sourceFile='ChainMapContextImpl.java' class='org.apache.hadoop.mapreduce.lib.chain.ChainMapContextImpl'></ClassStats><ClassStats bugs='0' size='31' interface='false' sourceFile='ChainMapper.java' class='org.apache.hadoop.mapreduce.lib.chain.ChainMapper'></ClassStats><ClassStats bugs='0' size='115' interface='false' sourceFile='ChainReduceContextImpl.java' class='org.apache.hadoop.mapreduce.lib.chain.ChainReduceContextImpl'></ClassStats><ClassStats bugs='0' size='37' interface='false' sourceFile='ChainReducer.java' class='org.apache.hadoop.mapreduce.lib.chain.ChainReducer'></ClassStats></PackageStats><PackageStats package='org.apache.hadoop.mapreduce.lib.db' total_bugs='17' priority_2='1' priority_3='16' total_size='1059' total_types='24'><ClassStats bugs='1' size='53' priority_3='1' interface='false' sourceFile='BigDecimalSplitter.java' class='org.apache.hadoop.mapreduce.lib.db.BigDecimalSplitter'></ClassStats><ClassStats bugs='0' size='17' interface='false' sourceFile='BooleanSplitter.java' class='org.apache.hadoop.mapreduce.lib.db.BooleanSplitter'></ClassStats><ClassStats bugs='0' size='103' interface='false' sourceFile='DBConfiguration.java' class='org.apache.hadoop.mapreduce.lib.db.DBConfiguration'></ClassStats><ClassStats bugs='2' size='118' priority_3='2' interface='false' sourceFile='DBInputFormat.java' class='org.apache.hadoop.mapreduce.lib.db.DBInputFormat'></ClassStats><ClassStats bugs='0' size='29' interface='false' sourceFile='DBInputFormat.java' class='org.apache.hadoop.mapreduce.lib.db.DBInputFormat$DBInputSplit'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='DBInputFormat.java' class='org.apache.hadoop.mapreduce.lib.db.DBInputFormat$NullDBWritable'></ClassStats><ClassStats bugs='3' size='69' priority_3='3' interface='false' sourceFile='DBOutputFormat.java' class='org.apache.hadoop.mapreduce.lib.db.DBOutputFormat'></ClassStats><ClassStats bugs='0' size='43' interface='false' sourceFile='DBOutputFormat.java' class='org.apache.hadoop.mapreduce.lib.db.DBOutputFormat$DBRecordWriter'></ClassStats><ClassStats bugs='2' size='122' priority_2='1' priority_3='1' interface='false' sourceFile='DBRecordReader.java' class='org.apache.hadoop.mapreduce.lib.db.DBRecordReader'></ClassStats><ClassStats bugs='0' size='2' interface='true' sourceFile='DBSplitter.java' class='org.apache.hadoop.mapreduce.lib.db.DBSplitter'></ClassStats><ClassStats bugs='0' size='3' interface='true' sourceFile='DBWritable.java' class='org.apache.hadoop.mapreduce.lib.db.DBWritable'></ClassStats><ClassStats bugs='2' size='94' priority_3='2' interface='false' sourceFile='DataDrivenDBInputFormat.java' class='org.apache.hadoop.mapreduce.lib.db.DataDrivenDBInputFormat'></ClassStats><ClassStats bugs='0' size='25' interface='false' sourceFile='DataDrivenDBInputFormat.java' class='org.apache.hadoop.mapreduce.lib.db.DataDrivenDBInputFormat$DataDrivenDBInputSplit'></ClassStats><ClassStats bugs='1' size='42' priority_3='1' interface='false' sourceFile='DataDrivenDBRecordReader.java' class='org.apache.hadoop.mapreduce.lib.db.DataDrivenDBRecordReader'></ClassStats><ClassStats bugs='3' size='63' priority_3='3' interface='false' sourceFile='DateSplitter.java' class='org.apache.hadoop.mapreduce.lib.db.DateSplitter'></ClassStats><ClassStats bugs='0' size='40' interface='false' sourceFile='FloatSplitter.java' class='org.apache.hadoop.mapreduce.lib.db.FloatSplitter'></ClassStats><ClassStats bugs='0' size='43' interface='false' sourceFile='IntegerSplitter.java' class='org.apache.hadoop.mapreduce.lib.db.IntegerSplitter'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='MySQLDBRecordReader.java' class='org.apache.hadoop.mapreduce.lib.db.MySQLDBRecordReader'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='MySQLDataDrivenDBRecordReader.java' class='org.apache.hadoop.mapreduce.lib.db.MySQLDataDrivenDBRecordReader'></ClassStats><ClassStats bugs='2' size='61' priority_3='2' interface='false' sourceFile='OracleDBRecordReader.java' class='org.apache.hadoop.mapreduce.lib.db.OracleDBRecordReader'></ClassStats><ClassStats bugs='1' size='15' priority_3='1' interface='false' sourceFile='OracleDataDrivenDBInputFormat.java' class='org.apache.hadoop.mapreduce.lib.db.OracleDataDrivenDBInputFormat'></ClassStats><ClassStats bugs='0' size='5' interface='false' sourceFile='OracleDataDrivenDBRecordReader.java' class='org.apache.hadoop.mapreduce.lib.db.OracleDataDrivenDBRecordReader'></ClassStats><ClassStats bugs='0' size='5' interface='false' sourceFile='OracleDateSplitter.java' class='org.apache.hadoop.mapreduce.lib.db.OracleDateSplitter'></ClassStats><ClassStats bugs='0' size='80' interface='false' sourceFile='TextSplitter.java' class='org.apache.hadoop.mapreduce.lib.db.TextSplitter'></ClassStats></PackageStats><PackageStats package='org.apache.hadoop.mapreduce.lib.fieldsel' priority_1='1' total_bugs='3' priority_3='2' total_size='183' total_types='3'><ClassStats bugs='3' size='112' priority_1='1' priority_3='2' interface='false' sourceFile='FieldSelectionHelper.java' class='org.apache.hadoop.mapreduce.lib.fieldsel.FieldSelectionHelper'></ClassStats><ClassStats bugs='0' size='36' interface='false' sourceFile='FieldSelectionMapper.java' class='org.apache.hadoop.mapreduce.lib.fieldsel.FieldSelectionMapper'></ClassStats><ClassStats bugs='0' size='35' interface='false' sourceFile='FieldSelectionReducer.java' class='org.apache.hadoop.mapreduce.lib.fieldsel.FieldSelectionReducer'></ClassStats></PackageStats><PackageStats package='org.apache.hadoop.mapreduce.lib.input' total_bugs='33' priority_2='8' priority_3='25' total_size='1898' total_types='46'><ClassStats bugs='0' size='235' interface='false' sourceFile='CombineFileInputFormat.java' class='org.apache.hadoop.mapreduce.lib.input.CombineFileInputFormat'></ClassStats><ClassStats bugs='0' size='28' interface='false' sourceFile='CombineFileInputFormat.java' class='org.apache.hadoop.mapreduce.lib.input.CombineFileInputFormat$MultiPathFilter'></ClassStats><ClassStats bugs='0' size='25' interface='false' sourceFile='CombineFileInputFormat.java' class='org.apache.hadoop.mapreduce.lib.input.CombineFileInputFormat$OneBlockInfo'></ClassStats><ClassStats bugs='0' size='71' interface='false' sourceFile='CombineFileInputFormat.java' class='org.apache.hadoop.mapreduce.lib.input.CombineFileInputFormat$OneFileInfo'></ClassStats><ClassStats bugs='2' size='71' priority_3='2' interface='false' sourceFile='CombineFileRecordReader.java' class='org.apache.hadoop.mapreduce.lib.input.CombineFileRecordReader'></ClassStats><ClassStats bugs='0' size='41' interface='false' sourceFile='CombineFileRecordReaderWrapper.java' class='org.apache.hadoop.mapreduce.lib.input.CombineFileRecordReaderWrapper'></ClassStats><ClassStats bugs='4' size='96' priority_2='4' interface='false' sourceFile='CombineFileSplit.java' class='org.apache.hadoop.mapreduce.lib.input.CombineFileSplit'></ClassStats><ClassStats bugs='1' size='5' priority_3='1' interface='false' sourceFile='CombineSequenceFileInputFormat.java' class='org.apache.hadoop.mapreduce.lib.input.CombineSequenceFileInputFormat'></ClassStats><ClassStats bugs='0' size='4' interface='false' sourceFile='CombineSequenceFileInputFormat.java' class='org.apache.hadoop.mapreduce.lib.input.CombineSequenceFileInputFormat$SequenceFileRecordReaderWrapper'></ClassStats><ClassStats bugs='1' size='5' priority_3='1' interface='false' sourceFile='CombineTextInputFormat.java' class='org.apache.hadoop.mapreduce.lib.input.CombineTextInputFormat'></ClassStats><ClassStats bugs='0' size='4' interface='false' sourceFile='CombineTextInputFormat.java' class='org.apache.hadoop.mapreduce.lib.input.CombineTextInputFormat$TextRecordReaderWrapper'></ClassStats><ClassStats bugs='0' size='31' interface='false' sourceFile='CompressedSplitLineReader.java' class='org.apache.hadoop.mapreduce.lib.input.CompressedSplitLineReader'></ClassStats><ClassStats bugs='0' size='47' interface='false' sourceFile='DelegatingInputFormat.java' class='org.apache.hadoop.mapreduce.lib.input.DelegatingInputFormat'></ClassStats><ClassStats bugs='0' size='14' interface='false' sourceFile='DelegatingMapper.java' class='org.apache.hadoop.mapreduce.lib.input.DelegatingMapper'></ClassStats><ClassStats bugs='2' size='25' priority_3='2' interface='false' sourceFile='DelegatingRecordReader.java' class='org.apache.hadoop.mapreduce.lib.input.DelegatingRecordReader'></ClassStats><ClassStats bugs='0' size='232' interface='false' sourceFile='FileInputFormat.java' class='org.apache.hadoop.mapreduce.lib.input.FileInputFormat'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='FileInputFormat.java' class='org.apache.hadoop.mapreduce.lib.input.FileInputFormat$1'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='FileInputFormat.java' class='org.apache.hadoop.mapreduce.lib.input.FileInputFormat$Counter'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='FileInputFormat.java' class='org.apache.hadoop.mapreduce.lib.input.FileInputFormat$MultiPathFilter'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='FileInputFormatCounter.java' class='org.apache.hadoop.mapreduce.lib.input.FileInputFormatCounter'></ClassStats><ClassStats bugs='3' size='51' priority_2='3' interface='false' sourceFile='FileSplit.java' class='org.apache.hadoop.mapreduce.lib.input.FileSplit'></ClassStats><ClassStats bugs='0' size='18' interface='false' sourceFile='FixedLengthInputFormat.java' class='org.apache.hadoop.mapreduce.lib.input.FixedLengthInputFormat'></ClassStats><ClassStats bugs='4' size='115' priority_3='4' interface='false' sourceFile='FixedLengthRecordReader.java' class='org.apache.hadoop.mapreduce.lib.input.FixedLengthRecordReader'></ClassStats><ClassStats bugs='0' size='17' interface='false' sourceFile='InvalidInputException.java' class='org.apache.hadoop.mapreduce.lib.input.InvalidInputException'></ClassStats><ClassStats bugs='2' size='61' priority_3='2' interface='false' sourceFile='KeyValueLineRecordReader.java' class='org.apache.hadoop.mapreduce.lib.input.KeyValueLineRecordReader'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='KeyValueTextInputFormat.java' class='org.apache.hadoop.mapreduce.lib.input.KeyValueTextInputFormat'></ClassStats><ClassStats bugs='2' size='121' priority_2='1' priority_3='1' interface='false' sourceFile='LineRecordReader.java' class='org.apache.hadoop.mapreduce.lib.input.LineRecordReader'></ClassStats><ClassStats bugs='0' size='49' interface='false' sourceFile='MultipleInputs.java' class='org.apache.hadoop.mapreduce.lib.input.MultipleInputs'></ClassStats><ClassStats bugs='0' size='50' interface='false' sourceFile='NLineInputFormat.java' class='org.apache.hadoop.mapreduce.lib.input.NLineInputFormat'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SequenceFileAsBinaryInputFormat.java' class='org.apache.hadoop.mapreduce.lib.input.SequenceFileAsBinaryInputFormat'></ClassStats><ClassStats bugs='3' size='61' priority_3='3' interface='false' sourceFile='SequenceFileAsBinaryInputFormat.java' class='org.apache.hadoop.mapreduce.lib.input.SequenceFileAsBinaryInputFormat$SequenceFileAsBinaryRecordReader'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SequenceFileAsTextInputFormat.java' class='org.apache.hadoop.mapreduce.lib.input.SequenceFileAsTextInputFormat'></ClassStats><ClassStats bugs='2' size='33' priority_3='2' interface='false' sourceFile='SequenceFileAsTextRecordReader.java' class='org.apache.hadoop.mapreduce.lib.input.SequenceFileAsTextRecordReader'></ClassStats><ClassStats bugs='0' size='17' interface='false' sourceFile='SequenceFileInputFilter.java' class='org.apache.hadoop.mapreduce.lib.input.SequenceFileInputFilter'></ClassStats><ClassStats bugs='0' size='2' interface='true' sourceFile='SequenceFileInputFilter.java' class='org.apache.hadoop.mapreduce.lib.input.SequenceFileInputFilter$Filter'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SequenceFileInputFilter.java' class='org.apache.hadoop.mapreduce.lib.input.SequenceFileInputFilter$FilterBase'></ClassStats><ClassStats bugs='2' size='20' priority_3='2' interface='false' sourceFile='SequenceFileInputFilter.java' class='org.apache.hadoop.mapreduce.lib.input.SequenceFileInputFilter$FilterRecordReader'></ClassStats><ClassStats bugs='1' size='50' priority_3='1' interface='false' sourceFile='SequenceFileInputFilter.java' class='org.apache.hadoop.mapreduce.lib.input.SequenceFileInputFilter$MD5Filter'></ClassStats><ClassStats bugs='0' size='23' interface='false' sourceFile='SequenceFileInputFilter.java' class='org.apache.hadoop.mapreduce.lib.input.SequenceFileInputFilter$PercentFilter'></ClassStats><ClassStats bugs='1' size='20' priority_3='1' interface='false' sourceFile='SequenceFileInputFilter.java' class='org.apache.hadoop.mapreduce.lib.input.SequenceFileInputFilter$RegexFilter'></ClassStats><ClassStats bugs='0' size='17' interface='false' sourceFile='SequenceFileInputFormat.java' class='org.apache.hadoop.mapreduce.lib.input.SequenceFileInputFormat'></ClassStats><ClassStats bugs='1' size='46' priority_3='1' interface='false' sourceFile='SequenceFileRecordReader.java' class='org.apache.hadoop.mapreduce.lib.input.SequenceFileRecordReader'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='SplitLineReader.java' class='org.apache.hadoop.mapreduce.lib.input.SplitLineReader'></ClassStats><ClassStats bugs='2' size='60' priority_3='2' interface='false' sourceFile='TaggedInputSplit.java' class='org.apache.hadoop.mapreduce.lib.input.TaggedInputSplit'></ClassStats><ClassStats bugs='0' size='15' interface='false' sourceFile='TextInputFormat.java' class='org.apache.hadoop.mapreduce.lib.input.TextInputFormat'></ClassStats><ClassStats bugs='0' size='40' interface='false' sourceFile='UncompressedSplitLineReader.java' class='org.apache.hadoop.mapreduce.lib.input.UncompressedSplitLineReader'></ClassStats></PackageStats><PackageStats package='org.apache.hadoop.mapreduce.lib.jobcontrol' total_bugs='4' priority_3='4' total_size='339' total_types='5'><ClassStats bugs='3' size='141' priority_3='3' interface='false' sourceFile='ControlledJob.java' class='org.apache.hadoop.mapreduce.lib.jobcontrol.ControlledJob'></ClassStats><ClassStats bugs='0' size='14' interface='false' sourceFile='ControlledJob.java' class='org.apache.hadoop.mapreduce.lib.jobcontrol.ControlledJob$State'></ClassStats><ClassStats bugs='1' size='168' priority_3='1' interface='false' sourceFile='JobControl.java' class='org.apache.hadoop.mapreduce.lib.jobcontrol.JobControl'></ClassStats><ClassStats bugs='0' size='4' interface='false' sourceFile='JobControl.java' class='org.apache.hadoop.mapreduce.lib.jobcontrol.JobControl$1'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='JobControl.java' class='org.apache.hadoop.mapreduce.lib.jobcontrol.JobControl$ThreadState'></ClassStats></PackageStats><PackageStats package='org.apache.hadoop.mapreduce.lib.join' total_bugs='11' priority_2='2' priority_3='9' total_size='1238' total_types='34'><ClassStats bugs='0' size='42' interface='false' sourceFile='ArrayListBackedIterator.java' class='org.apache.hadoop.mapreduce.lib.join.ArrayListBackedIterator'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ComposableInputFormat.java' class='org.apache.hadoop.mapreduce.lib.join.ComposableInputFormat'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='ComposableRecordReader.java' class='org.apache.hadoop.mapreduce.lib.join.ComposableRecordReader'></ClassStats><ClassStats bugs='2' size='60' priority_3='2' interface='false' sourceFile='CompositeInputFormat.java' class='org.apache.hadoop.mapreduce.lib.join.CompositeInputFormat'></ClassStats><ClassStats bugs='2' size='67' priority_3='2' interface='false' sourceFile='CompositeInputSplit.java' class='org.apache.hadoop.mapreduce.lib.join.CompositeInputSplit'></ClassStats><ClassStats bugs='2' size='132' priority_3='2' interface='false' sourceFile='CompositeRecordReader.java' class='org.apache.hadoop.mapreduce.lib.join.CompositeRecordReader'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='CompositeRecordReader.java' class='org.apache.hadoop.mapreduce.lib.join.CompositeRecordReader$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='CompositeRecordReader.java' class='org.apache.hadoop.mapreduce.lib.join.CompositeRecordReader$2'></ClassStats><ClassStats bugs='0' size='85' interface='false' sourceFile='CompositeRecordReader.java' class='org.apache.hadoop.mapreduce.lib.join.CompositeRecordReader$JoinCollector'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='InnerJoinRecordReader.java' class='org.apache.hadoop.mapreduce.lib.join.InnerJoinRecordReader'></ClassStats><ClassStats bugs='0' size='31' interface='false' sourceFile='JoinRecordReader.java' class='org.apache.hadoop.mapreduce.lib.join.JoinRecordReader'></ClassStats><ClassStats bugs='0' size='24' interface='false' sourceFile='JoinRecordReader.java' class='org.apache.hadoop.mapreduce.lib.join.JoinRecordReader$JoinDelegationIterator'></ClassStats><ClassStats bugs='0' size='41' interface='false' sourceFile='MultiFilterRecordReader.java' class='org.apache.hadoop.mapreduce.lib.join.MultiFilterRecordReader'></ClassStats><ClassStats bugs='0' size='24' interface='false' sourceFile='MultiFilterRecordReader.java' class='org.apache.hadoop.mapreduce.lib.join.MultiFilterRecordReader$MultiFilterDelegationIterator'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='OuterJoinRecordReader.java' class='org.apache.hadoop.mapreduce.lib.join.OuterJoinRecordReader'></ClassStats><ClassStats bugs='0' size='44' interface='false' sourceFile='OverrideRecordReader.java' class='org.apache.hadoop.mapreduce.lib.join.OverrideRecordReader'></ClassStats><ClassStats bugs='0' size='31' interface='false' sourceFile='Parser.java' class='org.apache.hadoop.mapreduce.lib.join.Parser'></ClassStats><ClassStats bugs='0' size='78' interface='false' sourceFile='Parser.java' class='org.apache.hadoop.mapreduce.lib.join.Parser$CNode'></ClassStats><ClassStats bugs='0' size='25' interface='false' sourceFile='Parser.java' class='org.apache.hadoop.mapreduce.lib.join.Parser$Lexer'></ClassStats><ClassStats bugs='1' size='43' priority_2='1' interface='false' sourceFile='Parser.java' class='org.apache.hadoop.mapreduce.lib.join.Parser$Node'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='Parser.java' class='org.apache.hadoop.mapreduce.lib.join.Parser$NodeToken'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='Parser.java' class='org.apache.hadoop.mapreduce.lib.join.Parser$NumToken'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='Parser.java' class='org.apache.hadoop.mapreduce.lib.join.Parser$StrToken'></ClassStats><ClassStats bugs='0' size='15' interface='false' sourceFile='Parser.java' class='org.apache.hadoop.mapreduce.lib.join.Parser$TType'></ClassStats><ClassStats bugs='0' size='14' interface='false' sourceFile='Parser.java' class='org.apache.hadoop.mapreduce.lib.join.Parser$Token'></ClassStats><ClassStats bugs='0' size='60' interface='false' sourceFile='Parser.java' class='org.apache.hadoop.mapreduce.lib.join.Parser$WNode'></ClassStats><ClassStats bugs='0' size='18' interface='false' sourceFile='Parser.java' class='org.apache.hadoop.mapreduce.lib.join.Parser$WrappedStatusReporter'></ClassStats><ClassStats bugs='0' size='8' interface='true' sourceFile='ResetableIterator.java' class='org.apache.hadoop.mapreduce.lib.join.ResetableIterator'></ClassStats><ClassStats bugs='0' size='17' interface='false' sourceFile='ResetableIterator.java' class='org.apache.hadoop.mapreduce.lib.join.ResetableIterator$EMPTY'></ClassStats><ClassStats bugs='3' size='45' priority_3='3' interface='false' sourceFile='StreamBackedIterator.java' class='org.apache.hadoop.mapreduce.lib.join.StreamBackedIterator'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='StreamBackedIterator.java' class='org.apache.hadoop.mapreduce.lib.join.StreamBackedIterator$ReplayableByteInputStream'></ClassStats><ClassStats bugs='1' size='122' priority_2='1' interface='false' sourceFile='TupleWritable.java' class='org.apache.hadoop.mapreduce.lib.join.TupleWritable'></ClassStats><ClassStats bugs='0' size='21' interface='false' sourceFile='TupleWritable.java' class='org.apache.hadoop.mapreduce.lib.join.TupleWritable$1'></ClassStats><ClassStats bugs='0' size='105' interface='false' sourceFile='WrappedRecordReader.java' class='org.apache.hadoop.mapreduce.lib.join.WrappedRecordReader'></ClassStats></PackageStats><PackageStats package='org.apache.hadoop.mapreduce.lib.map' priority_1='4' total_bugs='5' priority_3='1' total_size='297' total_types='11'><ClassStats bugs='0' size='6' interface='false' sourceFile='InverseMapper.java' class='org.apache.hadoop.mapreduce.lib.map.InverseMapper'></ClassStats><ClassStats bugs='2' size='51' priority_1='2' interface='false' sourceFile='MultithreadedMapper.java' class='org.apache.hadoop.mapreduce.lib.map.MultithreadedMapper'></ClassStats><ClassStats bugs='0' size='1' interface='false' sourceFile='MultithreadedMapper.java' class='org.apache.hadoop.mapreduce.lib.map.MultithreadedMapper$1'></ClassStats><ClassStats bugs='0' size='28' interface='false' sourceFile='MultithreadedMapper.java' class='org.apache.hadoop.mapreduce.lib.map.MultithreadedMapper$MapRunner'></ClassStats><ClassStats bugs='0' size='28' interface='false' sourceFile='MultithreadedMapper.java' class='org.apache.hadoop.mapreduce.lib.map.MultithreadedMapper$SubMapRecordReader'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='MultithreadedMapper.java' class='org.apache.hadoop.mapreduce.lib.map.MultithreadedMapper$SubMapRecordWriter'></ClassStats><ClassStats bugs='0' size='17' interface='false' sourceFile='MultithreadedMapper.java' class='org.apache.hadoop.mapreduce.lib.map.MultithreadedMapper$SubMapStatusReporter'></ClassStats><ClassStats bugs='3' size='23' priority_1='2' priority_3='1' interface='false' sourceFile='RegexMapper.java' class='org.apache.hadoop.mapreduce.lib.map.RegexMapper'></ClassStats><ClassStats bugs='0' size='16' interface='false' sourceFile='TokenCounterMapper.java' class='org.apache.hadoop.mapreduce.lib.map.TokenCounterMapper'></ClassStats><ClassStats bugs='0' size='5' interface='false' sourceFile='WrappedMapper.java' class='org.apache.hadoop.mapreduce.lib.map.WrappedMapper'></ClassStats><ClassStats bugs='0' size='110' interface='false' sourceFile='WrappedMapper.java' class='org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context'></ClassStats></PackageStats><PackageStats package='org.apache.hadoop.mapreduce.lib.output' priority_1='4' total_bugs='7' priority_3='3' total_size='1110' total_types='33'><ClassStats bugs='0' size='54' interface='false' sourceFile='BindingPathOutputCommitter.java' class='org.apache.hadoop.mapreduce.lib.output.BindingPathOutputCommitter'></ClassStats><ClassStats bugs='0' size='290' interface='false' sourceFile='FileOutputCommitter.java' class='org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter'></ClassStats><ClassStats bugs='0' size='1' interface='false' sourceFile='FileOutputCommitter.java' class='org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='FileOutputCommitter.java' class='org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter$CommittedTaskFilter'></ClassStats><ClassStats bugs='0' size='5' interface='false' sourceFile='FileOutputCommitterFactory.java' class='org.apache.hadoop.mapreduce.lib.output.FileOutputCommitterFactory'></ClassStats><ClassStats bugs='0' size='101' interface='false' sourceFile='FileOutputFormat.java' class='org.apache.hadoop.mapreduce.lib.output.FileOutputFormat'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='FileOutputFormat.java' class='org.apache.hadoop.mapreduce.lib.output.FileOutputFormat$Counter'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='FileOutputFormatCounter.java' class='org.apache.hadoop.mapreduce.lib.output.FileOutputFormatCounter'></ClassStats><ClassStats bugs='0' size='21' interface='false' sourceFile='FilterOutputFormat.java' class='org.apache.hadoop.mapreduce.lib.output.FilterOutputFormat'></ClassStats><ClassStats bugs='0' size='21' interface='false' sourceFile='FilterOutputFormat.java' class='org.apache.hadoop.mapreduce.lib.output.FilterOutputFormat$FilterRecordWriter'></ClassStats><ClassStats bugs='1' size='29' priority_1='1' interface='false' sourceFile='LazyOutputFormat.java' class='org.apache.hadoop.mapreduce.lib.output.LazyOutputFormat'></ClassStats><ClassStats bugs='0' size='17' interface='false' sourceFile='LazyOutputFormat.java' class='org.apache.hadoop.mapreduce.lib.output.LazyOutputFormat$LazyRecordWriter'></ClassStats><ClassStats bugs='1' size='33' priority_3='1' interface='false' sourceFile='MapFileOutputFormat.java' class='org.apache.hadoop.mapreduce.lib.output.MapFileOutputFormat'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='MapFileOutputFormat.java' class='org.apache.hadoop.mapreduce.lib.output.MapFileOutputFormat$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='MapFileOutputFormat.java' class='org.apache.hadoop.mapreduce.lib.output.MapFileOutputFormat$2'></ClassStats><ClassStats bugs='0' size='130' interface='false' sourceFile='MultipleOutputs.java' class='org.apache.hadoop.mapreduce.lib.output.MultipleOutputs'></ClassStats><ClassStats bugs='0' size='17' interface='false' sourceFile='MultipleOutputs.java' class='org.apache.hadoop.mapreduce.lib.output.MultipleOutputs$RecordWriterWithCounter'></ClassStats><ClassStats bugs='0' size='18' interface='false' sourceFile='MultipleOutputs.java' class='org.apache.hadoop.mapreduce.lib.output.MultipleOutputs$WrappedStatusReporter'></ClassStats><ClassStats bugs='0' size='22' interface='false' sourceFile='NamedCommitterFactory.java' class='org.apache.hadoop.mapreduce.lib.output.NamedCommitterFactory'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='NullOutputFormat.java' class='org.apache.hadoop.mapreduce.lib.output.NullOutputFormat'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='NullOutputFormat.java' class='org.apache.hadoop.mapreduce.lib.output.NullOutputFormat$1'></ClassStats><ClassStats bugs='0' size='20' interface='false' sourceFile='NullOutputFormat.java' class='org.apache.hadoop.mapreduce.lib.output.NullOutputFormat$2'></ClassStats><ClassStats bugs='0' size='33' interface='false' sourceFile='PartialFileOutputCommitter.java' class='org.apache.hadoop.mapreduce.lib.output.PartialFileOutputCommitter'></ClassStats><ClassStats bugs='0' size='2' interface='true' sourceFile='PartialOutputCommitter.java' class='org.apache.hadoop.mapreduce.lib.output.PartialOutputCommitter'></ClassStats><ClassStats bugs='0' size='22' interface='false' sourceFile='PathOutputCommitter.java' class='org.apache.hadoop.mapreduce.lib.output.PathOutputCommitter'></ClassStats><ClassStats bugs='0' size='40' interface='false' sourceFile='PathOutputCommitterFactory.java' class='org.apache.hadoop.mapreduce.lib.output.PathOutputCommitterFactory'></ClassStats><ClassStats bugs='3' size='31' priority_1='2' priority_3='1' interface='false' sourceFile='SequenceFileAsBinaryOutputFormat.java' class='org.apache.hadoop.mapreduce.lib.output.SequenceFileAsBinaryOutputFormat'></ClassStats><ClassStats bugs='0' size='16' interface='false' sourceFile='SequenceFileAsBinaryOutputFormat.java' class='org.apache.hadoop.mapreduce.lib.output.SequenceFileAsBinaryOutputFormat$1'></ClassStats><ClassStats bugs='0' size='20' interface='false' sourceFile='SequenceFileAsBinaryOutputFormat.java' class='org.apache.hadoop.mapreduce.lib.output.SequenceFileAsBinaryOutputFormat$WritableValueBytes'></ClassStats><ClassStats bugs='0' size='28' interface='false' sourceFile='SequenceFileOutputFormat.java' class='org.apache.hadoop.mapreduce.lib.output.SequenceFileOutputFormat'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='SequenceFileOutputFormat.java' class='org.apache.hadoop.mapreduce.lib.output.SequenceFileOutputFormat$1'></ClassStats><ClassStats bugs='2' size='26' priority_1='1' priority_3='1' interface='false' sourceFile='TextOutputFormat.java' class='org.apache.hadoop.mapreduce.lib.output.TextOutputFormat'></ClassStats><ClassStats bugs='0' size='39' interface='false' sourceFile='TextOutputFormat.java' class='org.apache.hadoop.mapreduce.lib.output.TextOutputFormat$LineRecordWriter'></ClassStats></PackageStats><PackageStats package='org.apache.hadoop.mapreduce.lib.partition' priority_1='2' total_bugs='8' priority_3='6' total_size='833' total_types='21'><ClassStats bugs='0' size='33' interface='false' sourceFile='BinaryPartitioner.java' class='org.apache.hadoop.mapreduce.lib.partition.BinaryPartitioner'></ClassStats><ClassStats bugs='0' size='5' interface='false' sourceFile='HashPartitioner.java' class='org.apache.hadoop.mapreduce.lib.partition.HashPartitioner'></ClassStats><ClassStats bugs='0' size='99' interface='false' sourceFile='InputSampler.java' class='org.apache.hadoop.mapreduce.lib.partition.InputSampler'></ClassStats><ClassStats bugs='0' size='31' interface='false' sourceFile='InputSampler.java' class='org.apache.hadoop.mapreduce.lib.partition.InputSampler$IntervalSampler'></ClassStats><ClassStats bugs='0' size='45' interface='false' sourceFile='InputSampler.java' class='org.apache.hadoop.mapreduce.lib.partition.InputSampler$RandomSampler'></ClassStats><ClassStats bugs='0' size='2' interface='true' sourceFile='InputSampler.java' class='org.apache.hadoop.mapreduce.lib.partition.InputSampler$Sampler'></ClassStats><ClassStats bugs='0' size='31' interface='false' sourceFile='InputSampler.java' class='org.apache.hadoop.mapreduce.lib.partition.InputSampler$SplitSampler'></ClassStats><ClassStats bugs='3' size='172' priority_1='1' priority_3='2' interface='false' sourceFile='KeyFieldBasedComparator.java' class='org.apache.hadoop.mapreduce.lib.partition.KeyFieldBasedComparator'></ClassStats><ClassStats bugs='1' size='59' priority_1='1' interface='false' sourceFile='KeyFieldBasedPartitioner.java' class='org.apache.hadoop.mapreduce.lib.partition.KeyFieldBasedPartitioner'></ClassStats><ClassStats bugs='3' size='149' priority_3='3' interface='false' sourceFile='KeyFieldHelper.java' class='org.apache.hadoop.mapreduce.lib.partition.KeyFieldHelper'></ClassStats><ClassStats bugs='0' size='15' interface='false' sourceFile='KeyFieldHelper.java' class='org.apache.hadoop.mapreduce.lib.partition.KeyFieldHelper$KeyDescription'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='RehashPartitioner.java' class='org.apache.hadoop.mapreduce.lib.partition.RehashPartitioner'></ClassStats><ClassStats bugs='1' size='95' priority_3='1' interface='false' sourceFile='TotalOrderPartitioner.java' class='org.apache.hadoop.mapreduce.lib.partition.TotalOrderPartitioner'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='TotalOrderPartitioner.java' class='org.apache.hadoop.mapreduce.lib.partition.TotalOrderPartitioner$BinarySearchNode'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='TotalOrderPartitioner.java' class='org.apache.hadoop.mapreduce.lib.partition.TotalOrderPartitioner$CarriedTrieNodeRef'></ClassStats><ClassStats bugs='0' size='16' interface='false' sourceFile='TotalOrderPartitioner.java' class='org.apache.hadoop.mapreduce.lib.partition.TotalOrderPartitioner$InnerTrieNode'></ClassStats><ClassStats bugs='0' size='17' interface='false' sourceFile='TotalOrderPartitioner.java' class='org.apache.hadoop.mapreduce.lib.partition.TotalOrderPartitioner$LeafTrieNode'></ClassStats><ClassStats bugs='0' size='2' interface='true' sourceFile='TotalOrderPartitioner.java' class='org.apache.hadoop.mapreduce.lib.partition.TotalOrderPartitioner$Node'></ClassStats><ClassStats bugs='0' size='14' interface='false' sourceFile='TotalOrderPartitioner.java' class='org.apache.hadoop.mapreduce.lib.partition.TotalOrderPartitioner$SinglySplitTrieNode'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='TotalOrderPartitioner.java' class='org.apache.hadoop.mapreduce.lib.partition.TotalOrderPartitioner$TrieNode'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='TotalOrderPartitioner.java' class='org.apache.hadoop.mapreduce.lib.partition.TotalOrderPartitioner$UnsplitTrieNode'></ClassStats></PackageStats><PackageStats package='org.apache.hadoop.mapreduce.lib.reduce' total_bugs='0' total_size='143' total_types='4'><ClassStats bugs='0' size='13' interface='false' sourceFile='IntSumReducer.java' class='org.apache.hadoop.mapreduce.lib.reduce.IntSumReducer'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='LongSumReducer.java' class='org.apache.hadoop.mapreduce.lib.reduce.LongSumReducer'></ClassStats><ClassStats bugs='0' size='5' interface='false' sourceFile='WrappedReducer.java' class='org.apache.hadoop.mapreduce.lib.reduce.WrappedReducer'></ClassStats><ClassStats bugs='0' size='112' interface='false' sourceFile='WrappedReducer.java' class='org.apache.hadoop.mapreduce.lib.reduce.WrappedReducer$Context'></ClassStats></PackageStats><PackageStats package='org.apache.hadoop.mapreduce.protocol' total_bugs='0' total_size='39' total_types='3'><ClassStats bugs='0' size='32' interface='true' sourceFile='ClientProtocol.java' class='org.apache.hadoop.mapreduce.protocol.ClientProtocol'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClientProtocolProvider.java' class='org.apache.hadoop.mapreduce.protocol.ClientProtocolProvider'></ClassStats><ClassStats bugs='0' size='1' interface='true' sourceFile='package-info.java' class='org.apache.hadoop.mapreduce.protocol.package-info'></ClassStats></PackageStats><PackageStats package='org.apache.hadoop.mapreduce.security' total_bugs='1' priority_3='1' total_size='136' total_types='2'><ClassStats bugs='0' size='41' interface='false' sourceFile='SecureShuffleUtils.java' class='org.apache.hadoop.mapreduce.security.SecureShuffleUtils'></ClassStats><ClassStats bugs='1' size='95' priority_3='1' interface='false' sourceFile='TokenCache.java' class='org.apache.hadoop.mapreduce.security.TokenCache'></ClassStats></PackageStats><PackageStats package='org.apache.hadoop.mapreduce.security.token' total_bugs='0' total_size='87' total_types='5'><ClassStats bugs='0' size='27' interface='false' sourceFile='JobTokenIdentifier.java' class='org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier'></ClassStats><ClassStats bugs='0' size='5' interface='false' sourceFile='JobTokenIdentifier.java' class='org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier$Renewer'></ClassStats><ClassStats bugs='0' size='42' interface='false' sourceFile='JobTokenSecretManager.java' class='org.apache.hadoop.mapreduce.security.token.JobTokenSecretManager'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='JobTokenSelector.java' class='org.apache.hadoop.mapreduce.security.token.JobTokenSelector'></ClassStats><ClassStats bugs='0' size='1' interface='true' sourceFile='package-info.java' class='org.apache.hadoop.mapreduce.security.token.package-info'></ClassStats></PackageStats><PackageStats package='org.apache.hadoop.mapreduce.security.token.delegation' total_bugs='0' total_size='25' total_types='4'><ClassStats bugs='0' size='12' interface='false' sourceFile='DelegationTokenIdentifier.java' class='org.apache.hadoop.mapreduce.security.token.delegation.DelegationTokenIdentifier'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='DelegationTokenSecretManager.java' class='org.apache.hadoop.mapreduce.security.token.delegation.DelegationTokenSecretManager'></ClassStats><ClassStats bugs='0' size='4' interface='false' sourceFile='DelegationTokenSelector.java' class='org.apache.hadoop.mapreduce.security.token.delegation.DelegationTokenSelector'></ClassStats><ClassStats bugs='0' size='1' interface='true' sourceFile='package-info.java' class='org.apache.hadoop.mapreduce.security.token.delegation.package-info'></ClassStats></PackageStats><PackageStats package='org.apache.hadoop.mapreduce.server.jobtracker' total_bugs='0' total_size='10' total_types='1'><ClassStats bugs='0' size='10' interface='true' sourceFile='JTConfig.java' class='org.apache.hadoop.mapreduce.server.jobtracker.JTConfig'></ClassStats></PackageStats><PackageStats package='org.apache.hadoop.mapreduce.server.tasktracker' total_bugs='0' total_size='34' total_types='1'><ClassStats bugs='0' size='34' interface='true' sourceFile='TTConfig.java' class='org.apache.hadoop.mapreduce.server.tasktracker.TTConfig'></ClassStats></PackageStats><PackageStats package='org.apache.hadoop.mapreduce.split' total_bugs='5' priority_2='5' total_size='249' total_types='7'><ClassStats bugs='0' size='12' interface='false' sourceFile='JobSplit.java' class='org.apache.hadoop.mapreduce.split.JobSplit'></ClassStats><ClassStats bugs='3' size='56' priority_2='3' interface='false' sourceFile='JobSplit.java' class='org.apache.hadoop.mapreduce.split.JobSplit$SplitMetaInfo'></ClassStats><ClassStats bugs='0' size='23' interface='false' sourceFile='JobSplit.java' class='org.apache.hadoop.mapreduce.split.JobSplit$TaskSplitIndex'></ClassStats><ClassStats bugs='2' size='32' priority_2='2' interface='false' sourceFile='JobSplit.java' class='org.apache.hadoop.mapreduce.split.JobSplit$TaskSplitMetaInfo'></ClassStats><ClassStats bugs='0' size='94' interface='false' sourceFile='JobSplitWriter.java' class='org.apache.hadoop.mapreduce.split.JobSplitWriter'></ClassStats><ClassStats bugs='0' size='31' interface='false' sourceFile='SplitMetaInfoReader.java' class='org.apache.hadoop.mapreduce.split.SplitMetaInfoReader'></ClassStats><ClassStats bugs='0' size='1' interface='true' sourceFile='package-info.java' class='org.apache.hadoop.mapreduce.split.package-info'></ClassStats></PackageStats><PackageStats package='org.apache.hadoop.mapreduce.task' total_bugs='1' priority_3='1' total_size='429' total_types='9'><ClassStats bugs='1' size='112' priority_3='1' interface='false' sourceFile='JobContextImpl.java' class='org.apache.hadoop.mapreduce.task.JobContextImpl'></ClassStats><ClassStats bugs='0' size='16' interface='false' sourceFile='MapContextImpl.java' class='org.apache.hadoop.mapreduce.task.MapContextImpl'></ClassStats><ClassStats bugs='0' size='116' interface='false' sourceFile='ReduceContextImpl.java' class='org.apache.hadoop.mapreduce.task.ReduceContextImpl'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='ReduceContextImpl.java' class='org.apache.hadoop.mapreduce.task.ReduceContextImpl$ValueIterable'></ClassStats><ClassStats bugs='0' size='106' interface='false' sourceFile='ReduceContextImpl.java' class='org.apache.hadoop.mapreduce.task.ReduceContextImpl$ValueIterator'></ClassStats><ClassStats bugs='0' size='41' interface='false' sourceFile='TaskAttemptContextImpl.java' class='org.apache.hadoop.mapreduce.task.TaskAttemptContextImpl'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='TaskAttemptContextImpl.java' class='org.apache.hadoop.mapreduce.task.TaskAttemptContextImpl$DummyReporter'></ClassStats><ClassStats bugs='0' size='16' interface='false' sourceFile='TaskInputOutputContextImpl.java' class='org.apache.hadoop.mapreduce.task.TaskInputOutputContextImpl'></ClassStats><ClassStats bugs='0' size='1' interface='true' sourceFile='package-info.java' class='org.apache.hadoop.mapreduce.task.package-info'></ClassStats></PackageStats><PackageStats package='org.apache.hadoop.mapreduce.task.annotation' total_bugs='0' total_size='1' total_types='1'><ClassStats bugs='0' size='1' interface='true' sourceFile='Checkpointable.java' class='org.apache.hadoop.mapreduce.task.annotation.Checkpointable'></ClassStats></PackageStats><PackageStats package='org.apache.hadoop.mapreduce.task.reduce' total_bugs='16' priority_2='7' priority_3='9' total_size='2023' total_types='37'><ClassStats bugs='2' size='80' priority_3='2' interface='false' sourceFile='EventFetcher.java' class='org.apache.hadoop.mapreduce.task.reduce.EventFetcher'></ClassStats><ClassStats bugs='0' size='2' interface='true' sourceFile='ExceptionReporter.java' class='org.apache.hadoop.mapreduce.task.reduce.ExceptionReporter'></ClassStats><ClassStats bugs='2' size='397' priority_3='2' interface='false' sourceFile='Fetcher.java' class='org.apache.hadoop.mapreduce.task.reduce.Fetcher'></ClassStats><ClassStats bugs='0' size='14' interface='false' sourceFile='Fetcher.java' class='org.apache.hadoop.mapreduce.task.reduce.Fetcher$ShuffleErrors'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='Fetcher.java' class='org.apache.hadoop.mapreduce.task.reduce.Fetcher$TryAgainLaterException'></ClassStats><ClassStats bugs='0' size='14' interface='false' sourceFile='IFileWrappedMapOutput.java' class='org.apache.hadoop.mapreduce.task.reduce.IFileWrappedMapOutput'></ClassStats><ClassStats bugs='0' size='46' interface='false' sourceFile='InMemoryMapOutput.java' class='org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput'></ClassStats><ClassStats bugs='1' size='70' priority_2='1' interface='false' sourceFile='InMemoryReader.java' class='org.apache.hadoop.mapreduce.task.reduce.InMemoryReader'></ClassStats><ClassStats bugs='0' size='26' interface='false' sourceFile='InMemoryWriter.java' class='org.apache.hadoop.mapreduce.task.reduce.InMemoryWriter'></ClassStats><ClassStats bugs='0' size='64' interface='false' sourceFile='LocalFetcher.java' class='org.apache.hadoop.mapreduce.task.reduce.LocalFetcher'></ClassStats><ClassStats bugs='1' size='42' priority_3='1' interface='false' sourceFile='MapHost.java' class='org.apache.hadoop.mapreduce.task.reduce.MapHost'></ClassStats><ClassStats bugs='0' size='15' interface='false' sourceFile='MapHost.java' class='org.apache.hadoop.mapreduce.task.reduce.MapHost$State'></ClassStats><ClassStats bugs='0' size='36' interface='false' sourceFile='MapOutput.java' class='org.apache.hadoop.mapreduce.task.reduce.MapOutput'></ClassStats><ClassStats bugs='1' size='14' priority_2='1' interface='false' sourceFile='MapOutput.java' class='org.apache.hadoop.mapreduce.task.reduce.MapOutput$MapOutputComparator'></ClassStats><ClassStats bugs='0' size='4' interface='true' sourceFile='MergeManager.java' class='org.apache.hadoop.mapreduce.task.reduce.MergeManager'></ClassStats><ClassStats bugs='4' size='289' priority_2='3' priority_3='1' interface='false' sourceFile='MergeManagerImpl.java' class='org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='MergeManagerImpl.java' class='org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl$1'></ClassStats><ClassStats bugs='1' size='24' priority_3='1' interface='false' sourceFile='MergeManagerImpl.java' class='org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl$CompressAwarePath'></ClassStats><ClassStats bugs='0' size='49' interface='false' sourceFile='MergeManagerImpl.java' class='org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl$InMemoryMerger'></ClassStats><ClassStats bugs='0' size='34' interface='false' sourceFile='MergeManagerImpl.java' class='org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl$IntermediateMemoryToMemoryMerger'></ClassStats><ClassStats bugs='0' size='51' interface='false' sourceFile='MergeManagerImpl.java' class='org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl$OnDiskMerger'></ClassStats><ClassStats bugs='0' size='29' interface='false' sourceFile='MergeManagerImpl.java' class='org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl$RawKVIteratorReader'></ClassStats><ClassStats bugs='0' size='65' interface='false' sourceFile='MergeThread.java' class='org.apache.hadoop.mapreduce.task.reduce.MergeThread'></ClassStats><ClassStats bugs='0' size='69' interface='false' sourceFile='OnDiskMapOutput.java' class='org.apache.hadoop.mapreduce.task.reduce.OnDiskMapOutput'></ClassStats><ClassStats bugs='0' size='98' interface='false' sourceFile='Shuffle.java' class='org.apache.hadoop.mapreduce.task.reduce.Shuffle'></ClassStats><ClassStats bugs='0' size='5' interface='false' sourceFile='Shuffle.java' class='org.apache.hadoop.mapreduce.task.reduce.Shuffle$ShuffleError'></ClassStats><ClassStats bugs='0' size='27' interface='false' sourceFile='ShuffleClientMetrics.java' class='org.apache.hadoop.mapreduce.task.reduce.ShuffleClientMetrics'></ClassStats><ClassStats bugs='0' size='31' interface='false' sourceFile='ShuffleHeader.java' class='org.apache.hadoop.mapreduce.task.reduce.ShuffleHeader'></ClassStats><ClassStats bugs='0' size='4' interface='true' sourceFile='ShuffleScheduler.java' class='org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler'></ClassStats><ClassStats bugs='3' size='315' priority_2='1' priority_3='2' interface='false' sourceFile='ShuffleSchedulerImpl.java' class='org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ShuffleSchedulerImpl.java' class='org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl$1'></ClassStats><ClassStats bugs='0' size='4' interface='false' sourceFile='ShuffleSchedulerImpl.java' class='org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl$2'></ClassStats><ClassStats bugs='0' size='35' interface='false' sourceFile='ShuffleSchedulerImpl.java' class='org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl$CopyTimeTracker'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='ShuffleSchedulerImpl.java' class='org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl$CopyTimeTracker$Interval'></ClassStats><ClassStats bugs='1' size='16' priority_2='1' interface='false' sourceFile='ShuffleSchedulerImpl.java' class='org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl$Penalty'></ClassStats><ClassStats bugs='0' size='20' interface='false' sourceFile='ShuffleSchedulerImpl.java' class='org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl$Referee'></ClassStats><ClassStats bugs='0' size='1' interface='true' sourceFile='package-info.java' class='org.apache.hadoop.mapreduce.task.reduce.package-info'></ClassStats></PackageStats><PackageStats package='org.apache.hadoop.mapreduce.tools' priority_1='2' total_bugs='2' total_size='513' total_types='1'><ClassStats bugs='2' size='513' priority_1='2' interface='false' sourceFile='CLI.java' class='org.apache.hadoop.mapreduce.tools.CLI'></ClassStats></PackageStats><PackageStats package='org.apache.hadoop.mapreduce.util' total_bugs='2' priority_2='2' total_size='367' total_types='10'><ClassStats bugs='0' size='17' interface='false' sourceFile='ConfigUtil.java' class='org.apache.hadoop.mapreduce.util.ConfigUtil'></ClassStats><ClassStats bugs='0' size='121' interface='false' sourceFile='CountersStrings.java' class='org.apache.hadoop.mapreduce.util.CountersStrings'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='HostUtil.java' class='org.apache.hadoop.mapreduce.util.HostUtil'></ClassStats><ClassStats bugs='0' size='37' interface='false' sourceFile='JobHistoryEventUtils.java' class='org.apache.hadoop.mapreduce.util.JobHistoryEventUtils'></ClassStats><ClassStats bugs='0' size='14' interface='false' sourceFile='MRJobConfUtil.java' class='org.apache.hadoop.mapreduce.util.MRJobConfUtil'></ClassStats><ClassStats bugs='2' size='125' priority_2='2' interface='false' sourceFile='ProcessTree.java' class='org.apache.hadoop.mapreduce.util.ProcessTree'></ClassStats><ClassStats bugs='0' size='1' interface='false' sourceFile='ProcessTree.java' class='org.apache.hadoop.mapreduce.util.ProcessTree$1'></ClassStats><ClassStats bugs='0' size='19' interface='false' sourceFile='ProcessTree.java' class='org.apache.hadoop.mapreduce.util.ProcessTree$SigKillThread'></ClassStats><ClassStats bugs='0' size='20' interface='false' sourceFile='ResourceBundles.java' class='org.apache.hadoop.mapreduce.util.ResourceBundles'></ClassStats><ClassStats bugs='0' size='1' interface='true' sourceFile='package-info.java' class='org.apache.hadoop.mapreduce.util.package-info'></ClassStats></PackageStats><PackageStats package='org.apache.hadoop.mapreduce.v2' total_bugs='0' total_size='31' total_types='1'><ClassStats bugs='0' size='31' interface='false' sourceFile='LogParams.java' class='org.apache.hadoop.mapreduce.v2.LogParams'></ClassStats></PackageStats><FindBugsProfile><ClassProfile avgMicrosecondsPerInvocation='331' totalMilliseconds='1325' name='edu.umd.cs.findbugs.classfile.engine.ClassDataAnalysisEngine' maxMicrosecondsPerInvocation='28169' standardDeviationMicrosecondsPerInvocation='477' invocations='3997'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='151' totalMilliseconds='1064' name='edu.umd.cs.findbugs.ba.npe.NullDerefAndRedundantComparisonFinder' maxMicrosecondsPerInvocation='21657' standardDeviationMicrosecondsPerInvocation='559' invocations='7002'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='138' totalMilliseconds='1002' name='edu.umd.cs.findbugs.classfile.engine.bcel.IsNullValueDataflowFactory' maxMicrosecondsPerInvocation='10353' standardDeviationMicrosecondsPerInvocation='400' invocations='7226'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='110' totalMilliseconds='823' name='edu.umd.cs.findbugs.classfile.engine.bcel.TypeDataflowFactory' maxMicrosecondsPerInvocation='13628' standardDeviationMicrosecondsPerInvocation='426' invocations='7420'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='196' totalMilliseconds='783' name='edu.umd.cs.findbugs.classfile.engine.ClassInfoAnalysisEngine' maxMicrosecondsPerInvocation='50208' standardDeviationMicrosecondsPerInvocation='1112' invocations='3985'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='134' totalMilliseconds='768' name='edu.umd.cs.findbugs.detect.FindRefComparison$SpecialTypeAnalysis' maxMicrosecondsPerInvocation='238876' standardDeviationMicrosecondsPerInvocation='3175' invocations='5695'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='105' totalMilliseconds='752' name='edu.umd.cs.findbugs.classfile.engine.bcel.UnconditionalValueDerefDataflowFactory' maxMicrosecondsPerInvocation='13205' standardDeviationMicrosecondsPerInvocation='357' invocations='7109'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='98' totalMilliseconds='735' name='edu.umd.cs.findbugs.classfile.engine.bcel.ValueNumberDataflowFactory' maxMicrosecondsPerInvocation='9267' standardDeviationMicrosecondsPerInvocation='313' invocations='7466'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='72' totalMilliseconds='527' name='edu.umd.cs.findbugs.classfile.engine.bcel.CFGFactory' maxMicrosecondsPerInvocation='10040' standardDeviationMicrosecondsPerInvocation='194' invocations='7226'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='321' totalMilliseconds='502' name='edu.umd.cs.findbugs.detect.FieldItemSummary' maxMicrosecondsPerInvocation='28027' standardDeviationMicrosecondsPerInvocation='1309' invocations='1565'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='291' totalMilliseconds='456' name='edu.umd.cs.findbugs.detect.FindNoSideEffectMethods' maxMicrosecondsPerInvocation='14430' standardDeviationMicrosecondsPerInvocation='684' invocations='1565'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='43' totalMilliseconds='395' name='edu.umd.cs.findbugs.OpcodeStack$JumpInfoFactory' maxMicrosecondsPerInvocation='3347' standardDeviationMicrosecondsPerInvocation='107' invocations='9069'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='1' totalMilliseconds='352' name='edu.umd.cs.findbugs.ba.npe.TypeQualifierNullnessAnnotationDatabase' maxMicrosecondsPerInvocation='1180' standardDeviationMicrosecondsPerInvocation='4' invocations='189755'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='40' totalMilliseconds='304' name='edu.umd.cs.findbugs.classfile.engine.bcel.MethodGenFactory' maxMicrosecondsPerInvocation='163025' standardDeviationMicrosecondsPerInvocation='1871' invocations='7590'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='2' totalMilliseconds='298' name='edu.umd.cs.findbugs.DetectorToDetector2Adapter' maxMicrosecondsPerInvocation='52' standardDeviationMicrosecondsPerInvocation='1' invocations='109907'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='30' totalMilliseconds='222' name='edu.umd.cs.findbugs.classfile.engine.bcel.ConstantDataflowFactory' maxMicrosecondsPerInvocation='8510' standardDeviationMicrosecondsPerInvocation='130' invocations='7226'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='232' totalMilliseconds='211' name='edu.umd.cs.findbugs.detect.DumbMethods' maxMicrosecondsPerInvocation='5897' standardDeviationMicrosecondsPerInvocation='458' invocations='907'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='232' totalMilliseconds='210' name='edu.umd.cs.findbugs.detect.LoadOfKnownNullValue' maxMicrosecondsPerInvocation='9714' standardDeviationMicrosecondsPerInvocation='520' invocations='907'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='205' totalMilliseconds='186' name='edu.umd.cs.findbugs.detect.FindOpenStream' maxMicrosecondsPerInvocation='16612' standardDeviationMicrosecondsPerInvocation='826' invocations='907'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='116' totalMilliseconds='181' name='edu.umd.cs.findbugs.detect.NoteDirectlyRelevantTypeQualifiers' maxMicrosecondsPerInvocation='27471' standardDeviationMicrosecondsPerInvocation='821' invocations='1565'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='196' totalMilliseconds='178' name='edu.umd.cs.findbugs.detect.FindInconsistentSync2' maxMicrosecondsPerInvocation='5792' standardDeviationMicrosecondsPerInvocation='386' invocations='907'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='194' totalMilliseconds='176' name='edu.umd.cs.findbugs.detect.UnreadFields' maxMicrosecondsPerInvocation='2557' standardDeviationMicrosecondsPerInvocation='242' invocations='907'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='20' totalMilliseconds='140' name='edu.umd.cs.findbugs.detect.FindNullDeref$CheckCallSitesAndReturnInstructions' maxMicrosecondsPerInvocation='1550' standardDeviationMicrosecondsPerInvocation='44' invocations='7002'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='78' totalMilliseconds='137' name='edu.umd.cs.findbugs.classfile.engine.bcel.JavaClassAnalysisEngine' maxMicrosecondsPerInvocation='19262' standardDeviationMicrosecondsPerInvocation='588' invocations='1750'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='20' totalMilliseconds='135' name='edu.umd.cs.findbugs.classfile.engine.bcel.LiveLocalStoreDataflowFactory' maxMicrosecondsPerInvocation='14630' standardDeviationMicrosecondsPerInvocation='184' invocations='6735'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='137' totalMilliseconds='124' name='edu.umd.cs.findbugs.detect.FindNullDeref' maxMicrosecondsPerInvocation='2809' standardDeviationMicrosecondsPerInvocation='211' invocations='907'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='77' totalMilliseconds='121' name='edu.umd.cs.findbugs.detect.BuildObligationPolicyDatabase' maxMicrosecondsPerInvocation='15637' standardDeviationMicrosecondsPerInvocation='412' invocations='1565'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='129' totalMilliseconds='117' name='edu.umd.cs.findbugs.detect.FindRefComparison' maxMicrosecondsPerInvocation='2689' standardDeviationMicrosecondsPerInvocation='212' invocations='907'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='126' totalMilliseconds='115' name='edu.umd.cs.findbugs.detect.FindBadCast2' maxMicrosecondsPerInvocation='5002' standardDeviationMicrosecondsPerInvocation='334' invocations='907'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='123' totalMilliseconds='111' name='edu.umd.cs.findbugs.detect.MethodReturnCheck' maxMicrosecondsPerInvocation='2189' standardDeviationMicrosecondsPerInvocation='211' invocations='907'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='122' totalMilliseconds='111' name='edu.umd.cs.findbugs.detect.RuntimeExceptionCapture' maxMicrosecondsPerInvocation='2006' standardDeviationMicrosecondsPerInvocation='220' invocations='907'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='118' totalMilliseconds='107' name='edu.umd.cs.findbugs.detect.FindPuzzlers' maxMicrosecondsPerInvocation='2819' standardDeviationMicrosecondsPerInvocation='230' invocations='907'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='114' totalMilliseconds='103' name='edu.umd.cs.findbugs.detect.FindDeadLocalStores' maxMicrosecondsPerInvocation='2619' standardDeviationMicrosecondsPerInvocation='228' invocations='907'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='200' totalMilliseconds='103' name='edu.umd.cs.findbugs.detect.StreamResourceTracker' maxMicrosecondsPerInvocation='1917' standardDeviationMicrosecondsPerInvocation='313' invocations='514'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='123' totalMilliseconds='102' name='edu.umd.cs.findbugs.ba.obl.ObligationAnalysis' maxMicrosecondsPerInvocation='3082' standardDeviationMicrosecondsPerInvocation='209' invocations='831'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='25' totalMilliseconds='100' name='edu.umd.cs.findbugs.util.TopologicalSort' maxMicrosecondsPerInvocation='3833' standardDeviationMicrosecondsPerInvocation='75' invocations='3876'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='109' totalMilliseconds='99' name='edu.umd.cs.findbugs.detect.CheckRelaxingNullnessAnnotation' maxMicrosecondsPerInvocation='22642' standardDeviationMicrosecondsPerInvocation='812' invocations='907'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='62' totalMilliseconds='97' name='edu.umd.cs.findbugs.detect.CalledMethods' maxMicrosecondsPerInvocation='1900' standardDeviationMicrosecondsPerInvocation='128' invocations='1565'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='106' totalMilliseconds='96' name='edu.umd.cs.findbugs.detect.FindHEmismatch' maxMicrosecondsPerInvocation='1758' standardDeviationMicrosecondsPerInvocation='163' invocations='907'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='105' totalMilliseconds='95' name='edu.umd.cs.findbugs.detect.FindUselessObjects' maxMicrosecondsPerInvocation='2739' standardDeviationMicrosecondsPerInvocation='196' invocations='907'></ClassProfile></FindBugsProfile></FindBugsSummary><ClassFeatures></ClassFeatures><History></History></BugCollection>